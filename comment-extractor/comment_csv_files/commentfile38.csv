 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2018 Oracle and/or its affiliates. All rights reserved. */

/**

 * ixgbevf_ipsec_set_pf_sa - ask the PF to set up an SA

 * @adapter: board private structure

 * @xs: xfrm info to be sent to the PF

 *

 * Returns: positive offload handle from the PF, or negative error code

 send the important bits to the PF */

/**

 * ixgbevf_ipsec_del_pf_sa - ask the PF to delete an SA

 * @adapter: board private structure

 * @pfsa: sa index returned from PF when created, -1 for all

 *

 * Returns: 0 on success, or negative error code

/**

 * ixgbevf_ipsec_restore - restore the IPsec HW settings after a reset

 * @adapter: board private structure

 *

 * Reload the HW tables from the SW tables after they've been bashed

 * by a chip reset.  While we're here, make sure any stale VF data is

 * removed, since we go through reset when num_vfs changes.

 reload the Rx and Tx keys */

/**

 * ixgbevf_ipsec_find_empty_idx - find the first unused security parameter index

 * @ipsec: pointer to IPsec struct

 * @rxtable: true if we need to look in the Rx table

 *

 * Returns the first unused index in either the Rx or Tx SA table

 search rx sa table */

 search tx sa table */

/**

 * ixgbevf_ipsec_find_rx_state - find the state that matches

 * @ipsec: pointer to IPsec struct

 * @daddr: inbound address to match

 * @proto: protocol to match

 * @spi: SPI to match

 * @ip4: true if using an IPv4 address

 *

 * Returns a pointer to the matching SA state information

/**

 * ixgbevf_ipsec_parse_proto_keys - find the key and salt based on the protocol

 * @xs: pointer to xfrm_state struct

 * @mykey: pointer to key array to populate

 * @mysalt: pointer to salt value to populate

 *

 * This copies the protocol keys and salt to our own data tables.  The

 * 82599 family only supports the one algorithm.

	/* The key bytes come down in a big endian array of bytes, so

	 * we don't need to do any byte swapping.

	 * 160 accounts for 16 byte key and 4 byte salt

/**

 * ixgbevf_ipsec_add_sa - program device with a security association

 * @xs: pointer to transformer state struct

 find the first unused index */

 get the key and salt */

 get ip for rx sa table */

 the preparations worked, so save the info */

 hash the new entry for faster search in Rx path */

 find the first unused index */

 the preparations worked, so save the info */

/**

 * ixgbevf_ipsec_del_sa - clear out this specific SA

 * @xs: pointer to transformer state struct

/**

 * ixgbevf_ipsec_offload_ok - can this packet use the xfrm hw offload

 * @skb: current data packet

 * @xs: pointer to transformer state struct

 Offload with IPv4 options is not supported yet */

 Offload with IPv6 extension headers is not support yet */

/**

 * ixgbevf_ipsec_tx - setup Tx flags for IPsec offload

 * @tx_ring: outgoing context

 * @first: current data packet

 * @itd: ipsec Tx data for later use in building context descriptor

		/* The actual trailer length is authlen (16 bytes) plus

		 * 2 bytes for the proto and the padlen values, plus

		 * padlen bytes of padding.  This ends up not the same

		 * as the static value found in xs->props.trailer_len (21).

		 *

		 * ... but if we're doing GSO, don't bother as the stack

		 * doesn't add a trailer for those.

			/* The "correct" way to get the auth length would be

			 * to use

			 *    authlen = crypto_aead_authsize(xs->data);

			 * but since we know we only have one size to worry

			 * about * we can let the compiler use the constant

			 * and save us a few CPU cycles.

/**

 * ixgbevf_ipsec_rx - decode IPsec bits from Rx descriptor

 * @rx_ring: receiving ring

 * @rx_desc: receive data descriptor

 * @skb: current data packet

 *

 * Determine if there was an IPsec encapsulation noticed, and if so set up

 * the resulting status for later in the receive stack.

	/* Find the IP and crypto headers in the data.

	 * We can assume no VLAN header in the way, b/c the

	 * hw won't recognize the IPsec packet and anyway the

	 * currently VLAN device doesn't support xfrm offload.

/**

 * ixgbevf_init_ipsec_offload - initialize registers for IPsec operation

 * @adapter: board private structure

/**

 * ixgbevf_stop_ipsec_offload - tear down the IPsec offload

 * @adapter: board private structure

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 ethtool support for ixgbevf */

 generate a number suitable for ethtool's register version */

 General Registers */

 Interrupt */

	/* don't read EICR because it can clear interrupt causes, instead

	 * read EICS which is a shadow but doesn't clear EICR

 Receive DMA */

 Receive */

 Transmit */

 if nothing to do return success */

 clone ring and setup updated count */

 clone ring and setup updated count */

 clone ring and setup updated count */

 Clear copied XDP RX-queue info */

 bring interface down to prepare for update */

 Tx */

 Rx */

 restore interface using new values */

 free Tx resources if Rx error is encountered */

 populate Tx queue data */

 populate XDP queue data */

 populate Rx queue data */

 ethtool register test data */

/* In the hardware, registers are laid out either singly, in arrays

 * spaced 0x40 bytes apart, or in contiguous tables.  We assume

 * most tests take place on arrays or single registers (handled

 * as a single-element array) and special-case the tables.

 * Table tests are always pattern tests.

 *

 * We also make provision for some required setup steps by specifying

 * registers to be written without any read-back testing.

 default VF register test */

	/* Perform the register test, looping through the test table

	 * until we either fail or reach the null entry.

 Offline tests */

		/* Link test performed before hardware reset so autoneg doesn't

		 * interfere with test result

 indicate we're in test mode */

 Online tests */

 Online tests aren't run; pass by default */

 only valid if in constant ITR mode */

 if in mixed Tx/Rx queues per vector mode, report only Rx settings */

 only valid if in constant ITR mode */

 don't accept Tx specific changes if we've got mixed RxTx vectors */

 Tx only */

 Rx only or mixed */

		/* If neither indirection table nor hash key was requested

		 *  - just return a success avoiding taking any locks.

 reset interface to repopulate queues */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/* On Hyper-V, to reset, we need to read from this offset

 * from the PCI config space. This is the mechanism used on

 * Hyper-V to support PF/VF communication.

/**

 *  ixgbevf_start_hw_vf - Prepare hardware for Tx/Rx

 *  @hw: pointer to hardware structure

 *

 *  Starts the hardware by filling the bus info structure and media type, clears

 *  all on chip counters, initializes receive address registers, multicast

 *  table, VLAN filter table, calls routine to set up link and flow control

 *  settings, and leaves transmit and receive units disabled and uninitialized

 Clear adapter stopped flag */

/**

 *  ixgbevf_init_hw_vf - virtual function hardware initialization

 *  @hw: pointer to hardware structure

 *

 *  Initialize the hardware by resetting the hardware and then starting

 *  the hardware

/**

 *  ixgbevf_reset_hw_vf - Performs hardware reset

 *  @hw: pointer to hardware structure

 *

 *  Resets the hardware by resetting the transmit and receive units, masks and

 *  clears all interrupts.

 Call adapter stop to disable tx/rx and clear interrupts */

 reset the api version */

 we cannot reset while the RSTI / RSTD bits are asserted */

 mailbox timeout can now become active */

	/* set our "perm_addr" based on info provided by PF

	 * also set up the mc_filter_type which is piggy backed

	 * on the mac address in word 3

	/* New versions of the PF may NACK the reset return message

	 * to indicate that no MAC address has yet been assigned for

	 * the VF.

/**

 * ixgbevf_hv_reset_hw_vf - reset via Hyper-V

 * @hw: pointer to private hardware struct

 *

 * Hyper-V variant; the VF/PF communication is through the PCI

 * config space.

/**

 *  ixgbevf_stop_hw_vf - Generic stop Tx/Rx units

 *  @hw: pointer to hardware structure

 *

 *  Sets the adapter_stopped flag within ixgbe_hw struct. Clears interrupts,

 *  disables transmit and receive units. The adapter_stopped flag is used by

 *  the shared code and drivers to determine if the adapter is in a stopped

 *  state and should not touch the hardware.

	/* Set the adapter_stopped flag so other driver functions stop touching

	 * the hardware

 Disable the receive unit by stopped each queue */

 Clear interrupt mask to stop from interrupts being generated */

 Clear any pending interrupts */

 Disable the transmit unit.  Each queue must be disabled. */

/**

 *  ixgbevf_mta_vector - Determines bit-vector in multicast table to set

 *  @hw: pointer to hardware structure

 *  @mc_addr: the multicast address

 *

 *  Extracts the 12 bits, from a multicast address, to determine which

 *  bit-vector to set in the multicast table. The hardware uses 12 bits, from

 *  incoming Rx multicast addresses, to determine the bit-vector to check in

 *  the MTA. Which of the 4 combination, of 12-bits, the hardware uses is set

 *  by the MO field of the MCSTCTRL. The MO field is set during initialization

 *  to mc_filter_type.

 use bits [47:36] of the address */

 use bits [46:35] of the address */

 use bits [45:34] of the address */

 use bits [43:32] of the address */

 Invalid mc_filter_type */

 vector can only be 12-bits or boundary will be exceeded */

/**

 *  ixgbevf_get_mac_addr_vf - Read device MAC address

 *  @hw: pointer to the HW structure

 *  @mac_addr: pointer to storage for retrieved MAC address

	/* If index is one then this is the start of a new list and needs

	 * indication to the PF so it can do it's own list management.

	 * If it is zero then that tells the PF to just clear all of

	 * this VF's macvlans and there is no new list.

/**

 * ixgbevf_get_reta_locked - get the RSS redirection table (RETA) contents.

 * @hw: pointer to hardware structure

 * @reta: buffer to fill with RETA contents.

 * @num_rx_queues: Number of Rx queues configured for this port

 *

 * The "reta" buffer should be big enough to contain 32 registers.

 *

 * Returns: 0 on success.

 *          if API doesn't support this operation - (-EOPNOTSUPP).

	/* We have to use a mailbox for 82599 and x540 devices only.

	 * For these devices RETA has 128 entries.

	 * Also these VFs support up to 4 RSS queues. Therefore PF will compress

	 * 16 RETA entries in each DWORD giving 2 bits to each entry.

	/* We support the RSS querying for 82599 and x540 devices only.

	 * Thus return an error if API doesn't support RETA querying or querying

	 * is not supported for this device type.

 If the operation has been refused by a PF return -EPERM */

	/* If we didn't get an ACK there must have been

	 * some sort of mailbox error so we should treat it

	 * as such.

 ixgbevf doesn't support more than 2 queues at the moment */

/**

 * ixgbevf_get_rss_key_locked - get the RSS Random Key

 * @hw: pointer to the HW structure

 * @rss_key: buffer to fill with RSS Hash Key contents.

 *

 * The "rss_key" buffer should be big enough to contain 10 registers.

 *

 * Returns: 0 on success.

 *          if API doesn't support this operation - (-EOPNOTSUPP).

	/* We currently support the RSS Random Key retrieval for 82599 and x540

	 * devices only.

	 *

	 * Thus return an error if API doesn't support RSS Random Key retrieval

	 * or if the operation is not supported for this device type.

 If the operation has been refused by a PF return -EPERM */

	/* If we didn't get an ACK there must have been

	 * some sort of mailbox error so we should treat it

	 * as such.

/**

 *  ixgbevf_set_rar_vf - set device MAC address

 *  @hw: pointer to hardware structure

 *  @index: Receive address register to write

 *  @addr: Address to put into receive address register

 *  @vmdq: Unused in this implementation

 if nacked the address was rejected, use "perm_addr" */

/**

 *  ixgbevf_hv_set_rar_vf - set device MAC address Hyper-V variant

 *  @hw: pointer to hardware structure

 *  @index: Receive address register to write

 *  @addr: Address to put into receive address register

 *  @vmdq: Unused in this implementation

 *

 * We don't really allow setting the device MAC address. However,

 * if the address being set is the permanent MAC address we will

 * permit that.

/**

 *  ixgbevf_update_mc_addr_list_vf - Update Multicast addresses

 *  @hw: pointer to the HW structure

 *  @netdev: pointer to net device structure

 *

 *  Updates the Multicast Table Array.

	/* Each entry in the list uses 1 16 bit word.  We have 30

	 * 16 bit words available in our HW msg buffer (minus 1 for the

	 * msg type).  That's 30 hash values if we pack 'em right.  If

	 * there are more than 30 MC addresses to add then punt the

	 * extras for now and then add code to handle more than 30 later.

	 * It would be unusual for a server to request that many multi-cast

	 * addresses except for in large enterprise network environments.

/**

 * ixgbevf_hv_update_mc_addr_list_vf - stub

 * @hw: unused

 * @netdev: unused

 *

 * Hyper-V variant - just a stub.

/**

 *  ixgbevf_update_xcast_mode - Update Multicast mode

 *  @hw: pointer to the HW structure

 *  @xcast_mode: new multicast mode

 *

 *  Updates the Multicast Mode of VF.

 promisc introduced in 1.3 version */

/**

 * ixgbevf_hv_update_xcast_mode - stub

 * @hw: unused

 * @xcast_mode: unused

 *

 * Hyper-V variant - just a stub.

/**

 *  ixgbevf_set_vfta_vf - Set/Unset VLAN filter table address

 *  @hw: pointer to the HW structure

 *  @vlan: 12 bit VLAN ID

 *  @vind: unused by VF drivers

 *  @vlan_on: if true then set bit, else clear bit

 Setting the 8 bit field MSG INFO to TRUE indicates "add" */

 remove extra bits from the message */

/**

 * ixgbevf_hv_set_vfta_vf - * Hyper-V variant - just a stub.

 * @hw: unused

 * @vlan: unused

 * @vind: unused

 * @vlan_on: unused

/**

 *  ixgbevf_setup_mac_link_vf - Setup MAC link settings

 *  @hw: pointer to hardware structure

 *  @speed: Unused in this implementation

 *  @autoneg: Unused in this implementation

 *  @autoneg_wait_to_complete: Unused in this implementation

 *

 *  Do nothing and return success.  VF drivers are not allowed to change

 *  global settings.  Maintained for driver compatibility.

/**

 *  ixgbevf_check_mac_link_vf - Get link/speed status

 *  @hw: pointer to hardware structure

 *  @speed: pointer to link speed

 *  @link_up: true is link is up, false otherwise

 *  @autoneg_wait_to_complete: unused

 *

 *  Reads the links register to determine if link is up and the current speed

 If we were hit with a reset drop the link */

 if link status is down no point in checking to see if pf is up */

	/* for SFP+ modules and DA cables on 82599 it can take up to 500usecs

	 * before the link status is correct

	/* if the read failed it could just be a mailbox collision, best wait

	 * until we are called again and don't report an error

 msg is not CTS and is NACK we must have lost CTS status */

 the pf is talking, if we timed out in the past we reinit */

	/* if we passed all the tests above then the link is up and we no

	 * longer need to check for link

/**

 * ixgbevf_hv_check_mac_link_vf - check link

 * @hw: pointer to private hardware struct

 * @speed: pointer to link speed

 * @link_up: true is link is up, false otherwise

 * @autoneg_wait_to_complete: unused

 *

 * Hyper-V variant; there is no mailbox communication.

 If we were hit with a reset drop the link */

 if link status is down no point in checking to see if pf is up */

	/* for SFP+ modules and DA cables on 82599 it can take up to 500usecs

	 * before the link status is correct

	/* if we passed all the tests above then the link is up and we no

	 * longer need to check for link

/**

 *  ixgbevf_set_rlpml_vf - Set the maximum receive packet length

 *  @hw: pointer to the HW structure

 *  @max_size: value to assign to max frame size

/**

 * ixgbevf_hv_set_rlpml_vf - Set the maximum receive packet length

 * @hw: pointer to the HW structure

 * @max_size: value to assign to max frame size

 * Hyper-V variant.

	/* If we are on Hyper-V, we implement this functionality

	 * differently.

 CRC == 4 */

/**

 *  ixgbevf_negotiate_api_version_vf - Negotiate supported API version

 *  @hw: pointer to the HW structure

 *  @api: integer containing requested API version

 Negotiate the mailbox API version */

 Store value and return 0 on success */

/**

 *  ixgbevf_hv_negotiate_api_version_vf - Negotiate supported API version

 *  @hw: pointer to the HW structure

 *  @api: integer containing requested API version

 *  Hyper-V version - only ixgbe_mbox_api_10 supported.

 Hyper-V only supports api version ixgbe_mbox_api_10 */

 do nothing if API doesn't support ixgbevf_get_queues */

 Fetch queue configuration from the PF */

		/* if we we didn't get an ACK there must have been

		 * some sort of mailbox error so we should treat it

		 * as such

 record and validate values from message */

 in case of unknown state assume we cannot tag frames */

 default to queue 0 on out-of-bounds queue number */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 *  ixgbevf_poll_for_msg - Wait for message notification

 *  @hw: pointer to the HW structure

 *

 *  returns 0 if it successfully received a message notification

 if we failed, all future posted messages fail until reset */

/**

 *  ixgbevf_poll_for_ack - Wait for message acknowledgment

 *  @hw: pointer to the HW structure

 *

 *  returns 0 if it successfully received a message acknowledgment

 if we failed, all future posted messages fail until reset */

/**

 *  ixgbevf_read_posted_mbx - Wait for message notification and receive message

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *

 *  returns 0 if it successfully received a message notification and

 *  copied it into the receive buffer.

 if ack received read message, otherwise we timed out */

/**

 *  ixgbevf_write_posted_mbx - Write a message to the mailbox, wait for ack

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *

 *  returns 0 if it successfully copied message into the buffer and

 *  received an ack to that message within delay * timeout period

 exit if either we can't write or there isn't a defined timeout */

 send msg */

 if msg sent wait until we receive an ack */

/**

 *  ixgbevf_read_v2p_mailbox - read v2p mailbox

 *  @hw: pointer to the HW structure

 *

 *  This function is used to read the v2p mailbox without losing the read to

 *  clear status bits.

/**

 *  ixgbevf_check_for_bit_vf - Determine if a status bit was set

 *  @hw: pointer to the HW structure

 *  @mask: bitmask for bits to be tested and cleared

 *

 *  This function is used to check for the read to clear bits within

 *  the V2P mailbox.

/**

 *  ixgbevf_check_for_msg_vf - checks to see if the PF has sent mail

 *  @hw: pointer to the HW structure

 *

 *  returns 0 if the PF has set the Status bit or else ERR_MBX

/**

 *  ixgbevf_check_for_ack_vf - checks to see if the PF has ACK'd

 *  @hw: pointer to the HW structure

 *

 *  returns 0 if the PF has set the ACK bit or else ERR_MBX

/**

 *  ixgbevf_check_for_rst_vf - checks to see if the PF has reset

 *  @hw: pointer to the HW structure

 *

 *  returns true if the PF has set the reset done bit or else false

/**

 *  ixgbevf_obtain_mbx_lock_vf - obtain mailbox lock

 *  @hw: pointer to the HW structure

 *

 *  return 0 if we obtained the mailbox lock

 Take ownership of the buffer */

 reserve mailbox for VF use */

/**

 *  ixgbevf_write_mbx_vf - Write a message to the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *

 *  returns 0 if it successfully copied message into the buffer

 lock the mailbox to prevent PF/VF race condition */

 flush msg and acks as we are overwriting the message buffer */

 copy the caller specified message to the mailbox memory buffer */

 update stats */

 Drop VFU and interrupt the PF to tell it a message has been sent */

/**

 *  ixgbevf_read_mbx_vf - Reads a message from the inbox intended for VF

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *

 *  returns 0 if it successfully read message from buffer

 lock the mailbox to prevent PF/VF race condition */

 copy the message from the mailbox memory buffer */

 Acknowledge receipt and release mailbox, then we're done */

 update stats */

/**

 *  ixgbevf_init_mbx_params_vf - set initial values for VF mailbox

 *  @hw: pointer to the HW structure

 *

 *  Initializes the hw->mbx struct to correct values for VF mailbox

	/* start mailbox as timed out and let the reset_hw call set the timeout

	 * value to begin communications

/* Mailbox operations when running on Hyper-V.

 * On Hyper-V, PF/VF communication is not through the

 * hardware mailbox; this communication is through

 * a software mediated path.

 * Most mail box operations are noop while running on

 * Hyper-V.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/******************************************************************************

 Copyright (c)2006 - 2007 Myricom, Inc. for some LRO specific code

/* ixgbevf_pci_tbl - PCI Device ID Table

 *

 * Wildcard entries (PCI_ANY_ID) should come last

 * Last entry must be all 0s

 *

 * { Vendor ID, Device ID, SubVendor ID, SubDevice ID,

 *   Class, Class Mask, private data (not used) }

 required last entry */

 flush memory to make sure state is correct before next watchdog */

 forward decls */

	/* The following check not only optimizes a bit by not

	 * performing a read on the status register when the

	 * register just read was a status register read that

	 * returned IXGBE_FAILED_READ_REG. It also blocks any

	 * potential recursion.

/**

 * ixgbevf_set_ivar - set IVAR registers - maps interrupt causes to vectors

 * @adapter: pointer to adapter struct

 * @direction: 0 for Rx, 1 for Tx, -1 for other causes

 * @queue: queue to map the corresponding interrupt to

 * @msix_vector: the vector to map to the corresponding queue

 other causes */

 Tx or Rx causes */

	/* Check for a hung queue, but be thorough. This verifies

	 * that a transmit has been completed since the previous

	 * check AND there is at least one packet pending. The

	 * ARMED bit is set to indicate a potential hang.

 make sure it is true for two checks in a row */

 reset the countdown */

 update completed stats and continue */

 Do the reset outside of interrupt context */

/**

 * ixgbevf_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: transmit queue hanging (unused)

/**

 * ixgbevf_clean_tx_irq - Reclaim resources after transmit completes

 * @q_vector: board private structure

 * @tx_ring: tx ring to clean

 * @napi_budget: Used to determine if we are in netpoll

 if next_to_watch is not set then there is no work pending */

 prevent any other reads prior to eop_desc */

 if DD is not set pending work has not been completed */

 clear next_to_watch to prevent false hangs */

 update the statistics for this packet */

 free the skb */

 unmap skb header data */

 clear tx_buffer data */

 unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 issue prefetch for next Tx descriptor */

 update budget accounting */

 schedule immediate reset if we believe we hung */

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

/**

 * ixgbevf_rx_skb - Helper function to determine proper Rx method

 * @q_vector: structure containing interrupt and ring information

 * @skb: packet to send up

/**

 * ixgbevf_rx_checksum - indicate in skb if hw indicated a good cksum

 * @ring: structure containig ring specific data

 * @rx_desc: current Rx descriptor being processed

 * @skb: skb currently being received and modified

 Rx csum disabled */

 if IP and error */

 It must be a TCP or UDP packet with a valid checksum */

/**

 * ixgbevf_process_skb_fields - Populate skb header fields from Rx descriptor

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @rx_desc: pointer to the EOP Rx descriptor

 * @skb: pointer to current skb being populated

 *

 * This function checks the ring, descriptor, and packet information in

 * order to populate the checksum, VLAN, protocol, and other fields within

 * the skb.

 we are reusing so sync this buffer for CPU use */

 hand second half of page back to the ring */

			/* We are not reusing the buffer so unmap it and free

			 * any references we are holding to it

 clear contents of rx_buffer */

/**

 * ixgbevf_is_non_eop - process handling of non-EOP buffers

 * @rx_ring: Rx ring being processed

 * @rx_desc: Rx descriptor for current buffer

 *

 * This function updates next to clean.  If the buffer is an EOP buffer

 * this function exits returning false, otherwise it will place the

 * sk_buff in the next buffer to be chained and return true indicating

 * that this is in fact a non-EOP buffer.

 fetch, update, and store next to clean */

 since we are recycling buffers we should seldom need to alloc */

 alloc new page for storage */

 map page for use */

	/* if mapping failed free memory back to system since

	 * there isn't much point in holding memory we can't use

/**

 * ixgbevf_alloc_rx_buffers - Replace used receive buffers; packet split

 * @rx_ring: rx descriptor ring (for a specific queue) to setup buffers on

 * @cleaned_count: number of buffers to replace

 nothing to do or no valid netdev defined */

 sync the buffer for use by the device */

		/* Refresh the desc even if pkt_addr didn't change

		 * because each write-back erases this info.

 clear the length for the next_to_use descriptor */

 record the next descriptor to use */

 update next to alloc since we have filled the ring */

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

/**

 * ixgbevf_cleanup_headers - Correct corrupted or empty headers

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @rx_desc: pointer to the EOP Rx descriptor

 * @skb: pointer to current skb being fixed

 *

 * Check for corrupted packet headers caused by senders on the local L2

 * embedded NIC switch not setting up their Tx Descriptors right.  These

 * should be very rare.

 *

 * Also address the case where we are pulling data in on pages only

 * and as such no data is present in the skb header.

 *

 * In addition if skb is not at least 60 bytes we need to pad it so that

 * it is large enough to qualify as a valid Ethernet frame.

 *

 * Returns true if an error was encountered and skb was freed.

 XDP packets use error pointer so abort at this point */

 verify that the packet does not have any known errors */

 if eth_skb_pad returns an error the skb was freed */

/**

 * ixgbevf_reuse_rx_page - page flip buffer and store it back on the ring

 * @rx_ring: rx descriptor ring to store buffers on

 * @old_buff: donor buffer to have page reused

 *

 * Synchronizes page for reuse by the adapter

 update, and store next to alloc */

 transfer page from old buffer to new buffer */

 avoid re-using remote and pfmemalloc pages */

 if we are only owner of page we can reuse it */

	/* If we have drained the page fragment pool we need to update

	 * the pagecnt_bias and page count so that we fully restock the

	 * number of references the driver holds.

/**

 * ixgbevf_add_rx_frag - Add contents of Rx buffer to sk_buff

 * @rx_ring: rx descriptor ring to transact packets on

 * @rx_buffer: buffer containing page to add

 * @skb: sk_buff to place the data into

 * @size: size of buffer to be added

 *

 * This function will add the data contained in rx_buffer->page to the skb.

 prefetch first cache line of first page */

	/* Note, we get here by enabling legacy-rx via:

	 *

	 *    ethtool --set-priv-flags <dev> legacy-rx on

	 *

	 * In this mode, we currently get 0 extra XDP headroom as

	 * opposed to having legacy-rx off, where we process XDP

	 * packets going to stack via ixgbevf_build_skb().

	 *

	 * For ixgbevf_construct_skb() mode it means that the

	 * xdp->data_meta will always point to xdp->data, since

	 * the helper cannot expand the head. Should this ever

	 * changed in future for legacy-rx mode on, then lets also

	 * add xdp->data_meta handling here.

 allocate a skb to store the frags */

 Determine available headroom for copy */

 align pull length to size of long to optimize memcpy performance */

 update all of the pointers */

	/* Prefetch first cache line of first page. If xdp->data_meta

	 * is unused, this points to xdp->data, otherwise, we likely

	 * have a consumer accessing first few bytes of meta data,

	 * and then actual data.

 build an skb around the page buffer */

 update pointers within the skb to store the data */

 update buffer offset */

 record the location of the first descriptor for this packet */

	/* Populate minimal context descriptor that will provide for the

	 * fact that we are expected to process Ethernet frames.

 put descriptor type bits */

 Avoid any potential race with cleanup */

 set next_to_watch value indicating a packet is present */

 handle aborts by dropping packet */

 Must be power-of-2 */

 Frame size depend on rx_ring setup when PAGE_SIZE=4K */

 return some buffers to hardware, one at a time is too slow */

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we know the

		 * RXD_STAT_DD bit is set

 retrieve a buffer from the ring */

 At larger PAGE_SIZE, frame_sz depend on len size */

 exit if we failed to retrieve a buffer */

 fetch next buffer in frame if non-eop */

 verify the packet layout is correct */

 probably a little skewed due to removing CRC */

		/* Workaround hardware that can't do proper VEPA multicast

		 * source pruning.

 populate checksum, VLAN, and protocol */

 reset skb pointer */

 update budget accounting */

 place incomplete frames back on ring for completion */

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.

/**

 * ixgbevf_poll - NAPI polling calback

 * @napi: napi struct with our devices info in it

 * @budget: amount of work driver is allowed to do this pass, in packets

 *

 * This function will clean more than one or more rings associated with a

 * q_vector.

	/* attempt to distribute budget to each queue fairly, but don't allow

	 * the budget to go below 1 because we'll exit polling

 If all work not completed, return budget and keep polling */

	/* Exit the polling mode, but don't re-enable interrupts if stack might

	 * poll us due to busy-polling

/**

 * ixgbevf_write_eitr - write VTEITR register in hardware specific way

 * @q_vector: structure containing interrupt and ring information

	/* set the WDIS bit to not clear the timer bits and cause an

	 * immediate assertion of the interrupt

/**

 * ixgbevf_configure_msix - Configure MSI-X hardware

 * @adapter: board private structure

 *

 * ixgbevf_configure_msix sets up the hardware to properly generate MSI-X

 * interrupts.

	/* Populate the IVAR table and set the ITR values to the

	 * corresponding register.

 Tx only vector */

 Rx or Rx/Tx vector */

 add q_vector eims value to global eims_enable_mask */

 setup eims_other and add value to global eims_enable_mask */

/**

 * ixgbevf_update_itr - update the dynamic ITR value based on statistics

 * @q_vector: structure containing interrupt and ring information

 * @ring_container: structure containing ring performance data

 *

 * Stores a new ITR value based on packets and byte

 * counts during the last interrupt.  The advantage of per interrupt

 * computation is faster updates and more accurate ITR for the current

 * traffic pattern.  Constants in this function were computed

 * based on theoretical maximum wire speed and thresholds were set based

 * on testing data as well as attempting to minimize response time

 * while increasing bulk throughput.

	/* simple throttle rate management

	 *    0-20MB/s lowest (100000 ints/s)

	 *   20-100MB/s low   (20000 ints/s)

	 *  100-1249MB/s bulk (12000 ints/s)

 what was last interrupt timeslice? */

 bytes/usec */

 clear work counters since we have the values we need */

 write updated itr to ring container */

 counts and packets in update_itr are dependent on these numbers */

 do an exponential smoothing */

 save the algorithm value here */

/**

 * ixgbevf_msix_clean_rings - single unshared vector rx clean (all queues)

 * @irq: unused

 * @data: pointer to our q_vector struct for this interrupt vector

 EIAM disabled interrupts (on this vector) for us */

/**

 * ixgbevf_request_msix_irqs - Initialize MSI-X interrupts

 * @adapter: board private structure

 *

 * ixgbevf_request_msix_irqs allocates MSI-X vectors and requests

 * interrupts from the kernel.

 skip this unused q_vector */

	/* This failure is non-recoverable - it indicates the system is

	 * out of MSIX vector resources and the VF driver cannot run

	 * without them.  Set the number of msix vectors to zero

	 * indicating that not enough can be allocated.  The error

	 * will be returned to the user indicating device open failed.

	 * Any further attempts to force the driver to open will also

	 * fail.  The only way to recover is to unload the driver and

	 * reload it again.  If the system has recovered some MSIX

	 * vectors then it may succeed.

/**

 * ixgbevf_request_irq - initialize interrupts

 * @adapter: board private structure

 *

 * Attempts to configure interrupts using the best available

 * capabilities of the hardware and kernel.

 free only the irqs that were actually requested */

/**

 * ixgbevf_irq_disable - Mask off interrupt generation on the NIC

 * @adapter: board private structure

/**

 * ixgbevf_irq_enable - Enable default interrupt generation settings

 * @adapter: board private structure

/**

 * ixgbevf_configure_tx_ring - Configure 82599 VF Tx ring after Reset

 * @adapter: board private structure

 * @ring: structure containing ring specific data

 *

 * Configure the Tx descriptor ring after a reset.

 disable queue to avoid issues while updating state */

 disable head writeback */

 enable relaxed ordering */

 reset head and tail pointers */

 reset ntu and ntc to place SW in sync with hardwdare */

	/* In order to avoid issues WTHRESH + PTHRESH should always be equal

	 * to or less than the number of on chip descriptors, which is

	 * currently 40.

 WTHRESH = 8 */

 Setting PTHRESH to 32 both improves performance */

 HTHRESH = 1 */

 PTHRESH = 32 */

 reinitialize tx_buffer_info */

 poll to verify queue is enabled */

/**

 * ixgbevf_configure_tx - Configure 82599 VF Transmit Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Tx unit of the MAC after a reset.

 Setup the HW Tx Head and Tail descriptor pointers */

 PSRTYPE must be initialized in 82599 */

 write value back with RXDCTL.ENABLE bit cleared */

 the hardware may take up to 100us to really disable the Rx queue */

/**

 * ixgbevf_init_rss_key - Initialize adapter RSS key

 * @adapter: device handle

 *

 * Allocates and initializes the RSS key if it is not allocated.

 Fill out hash function seeds */

 Perform hash on these packet types */

 disable queue to avoid issues while updating state */

 enable relaxed ordering */

 reset head and tail pointers */

 initialize rx_buffer_info */

 initialize Rx descriptor 0 */

 reset ntu and ntc to place SW in sync with hardwdare */

 RXDCTL.RLPML does not work on 82599 */

 Limit the maximum frame size so we don't overrun the skb */

 set build_skb and buffer size flags */

/**

 * ixgbevf_configure_rx - Configure 82599 VF Receive Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Rx unit of the MAC after a reset.

 notify the PF of our intent to use this size of frame */

	/* Setup the HW Rx Head and Tail Descriptor Pointers and

	 * the Base and Length of the Rx Descriptor Ring

 add VID to filter table */

 translate error return types so error makes sense */

 remove VID from filter table */

		/* If the list is empty then send message to PF driver to

		 * clear all MAC VLANs on this VF.

/**

 * ixgbevf_set_rx_mode - Multicast and unicast set

 * @netdev: network interface device structure

 *

 * The set_rx_method entry point is called whenever the multicast address

 * list, unicast address list or the network interface flags are updated.

 * This routine is responsible for configuring the hardware for proper

 * multicast mode and configuring requested unicast filters.

 request the most inclusive mode we need */

 reprogram multicast list */

 fetch queue configuration from the PF */

 we need only one Tx queue */

 update default Tx ring register index */

 we need as many queues as traffic classes */

 if we have a bad config abort request queue reset */

 force mailbox timeout to prevent further messages */

 wait for watchdog to come around and bail us out */

 Only save pre-reset stats if there are some */

 clear any pending interrupts, may auto mask */

 enable transmits */

/**

 * ixgbevf_clean_rx_ring - Free Rx Buffers per Queue

 * @rx_ring: ring to free buffers from

 Free Rx ring sk_buff */

 Free all the Rx ring pages */

		/* Invalidate cache lines that may have been written to by

		 * device so that we avoid corrupting memory.

 free resources associated with mapping */

/**

 * ixgbevf_clean_tx_ring - Free Tx Buffers

 * @tx_ring: ring to be cleaned

 Free all the Tx ring sk_buffs */

 unmap skb header data */

 check for eop_desc to determine the end of the packet */

 unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 reset next_to_use and next_to_clean */

/**

 * ixgbevf_clean_all_rx_rings - Free Rx Buffers for all queues

 * @adapter: board private structure

/**

 * ixgbevf_clean_all_tx_rings - Free Tx Buffers for all queues

 * @adapter: board private structure

 signal that we are down to the interrupt handler */

 do nothing if already down */

 disable all enabled Rx queues */

 call carrier off first to avoid false dev_watchdog timeouts */

 disable transmits in the hardware now that interrupts are off */

	/* We'll want at least 2 (vector_threshold):

	 * 1) TxQ[0] + RxQ[0] handler

	 * 2) Other (Link Status Change, etc.)

	/* The more we get, the more we will assign to Tx/Rx Cleanup

	 * for the separate queues...where Rx Cleanup >= Tx Cleanup.

	 * Right now, we simply care about how many we'll get; we'll

	 * set them up later while requesting irq's.

	/* Adjust for only the vectors we'll use, which is minimum

	 * of max_msix_q_vectors + NON_Q_VECTORS, or the number of

	 * vectors we were allocated.

/**

 * ixgbevf_set_num_queues - Allocate queues for device, feature dependent

 * @adapter: board private structure to initialize

 *

 * This is the top level queue allocation routine.  The order here is very

 * important, starting with the "most" number of features turned on at once,

 * and ending with the smallest set of features.  This way large combinations

 * can be allocated if they're turned on, and smaller combinations are the

 * fall through conditions.

 *

 Start with base case */

 fetch queue configuration from the PF */

 we need as many queues as traffic classes */

/**

 * ixgbevf_set_interrupt_capability - set MSI-X or FAIL if not supported

 * @adapter: board private structure to initialize

 *

 * Attempt to configure the interrupts using the best available

 * capabilities of the hardware and the kernel.

	/* It's easy to be greedy for MSI-X vectors, but it really

	 * doesn't do us much good if we have a lot more vectors

	 * than CPU's.  So let's be conservative and only ask for

	 * (roughly) the same number of vectors as there are CPU's.

	 * The default is to use pairs of vectors.

	/* A failure in MSI-X entry allocation isn't fatal, but the VF driver

	 * does not support any other modes, so we will simply fail here. Note

	 * that we clean up the msix_entries pointer else-where.

/**

 * ixgbevf_alloc_q_vector - Allocate memory for a single interrupt vector

 * @adapter: board private structure to initialize

 * @v_idx: index of vector in adapter struct

 * @txr_count: number of Tx rings for q vector

 * @txr_idx: index of first Tx ring to assign

 * @xdp_count: total number of XDP rings to allocate

 * @xdp_idx: index of first XDP ring to allocate

 * @rxr_count: number of Rx rings for q vector

 * @rxr_idx: index of first Rx ring to assign

 *

 * We allocate one q_vector.  If allocation fails we return -ENOMEM.

 allocate q_vector and rings */

 initialize NAPI */

 tie q_vector and adapter together */

 initialize pointer to rings */

 assign generic ring traits */

 configure backlink on ring */

 update q_vector Tx values */

 apply Tx specific ring traits */

 assign ring to adapter */

 update count and index */

 push pointer to next ring */

 assign generic ring traits */

 configure backlink on ring */

 update q_vector Tx values */

 apply Tx specific ring traits */

 assign ring to adapter */

 update count and index */

 push pointer to next ring */

 assign generic ring traits */

 configure backlink on ring */

 update q_vector Rx values */

 apply Rx specific ring traits */

 assign ring to adapter */

 update count and index */

 push pointer to next ring */

/**

 * ixgbevf_free_q_vector - Free memory allocated for specific interrupt vector

 * @adapter: board private structure to initialize

 * @v_idx: index of vector in adapter struct

 *

 * This function frees the memory allocated to the q_vector.  In addition if

 * NAPI is enabled it will delete any references to the NAPI struct prior

 * to freeing the q_vector.

	/* ixgbevf_get_stats() might access the rings on this vector,

	 * we must wait a grace period before freeing it.

/**

 * ixgbevf_alloc_q_vectors - Allocate memory for interrupt vectors

 * @adapter: board private structure to initialize

 *

 * We allocate one q_vector per queue interrupt.  If allocation fails we

 * return -ENOMEM.

 update counts and index */

 update counts and index */

/**

 * ixgbevf_free_q_vectors - Free memory allocated for interrupt vectors

 * @adapter: board private structure to initialize

 *

 * This function frees the memory allocated to the q_vectors.  In addition if

 * NAPI is enabled it will delete any references to the NAPI struct prior

 * to freeing the q_vector.

/**

 * ixgbevf_reset_interrupt_capability - Reset MSIX setup

 * @adapter: board private structure

 *

/**

 * ixgbevf_init_interrupt_scheme - Determine if MSIX is supported and init

 * @adapter: board private structure to initialize

 *

 Number of supported queues */

/**

 * ixgbevf_clear_interrupt_scheme - Clear the current interrupt scheme settings

 * @adapter: board private structure to clear interrupt scheme on

 *

 * We go through and clear interrupt specific resources and reset the structure

 * to pre-load conditions

/**

 * ixgbevf_sw_init - Initialize general software structures

 * @adapter: board private structure to initialize

 *

 * ixgbevf_sw_init initializes the Adapter private data structure.

 * Fields are initialized based on PCI device information and

 * OS network device settings (MTU size).

 PCI config space info */

 assume legacy case in which PF would only give VF 2 queues */

 lock to protect mailbox accesses */

 Enable dynamic interrupt throttling rates */

 set default ring sizes */

/**

 * ixgbevf_update_stats - Update the board statistics counters.

 * @adapter: board private structure

/**

 * ixgbevf_service_timer - Timer Call-back

 * @t: pointer to timer_list struct

 Reset the timer */

 If we're already down or resetting, just bail */

/**

 * ixgbevf_check_hang_subtask - check for hung queues and dropped interrupts

 * @adapter: pointer to the device adapter structure

 *

 * This function serves two purposes.  First it strobes the interrupt lines

 * in order to make certain interrupts are occurring.  Secondly it sets the

 * bits needed to check for TX hangs.  As a result we should immediately

 * determine if a hang has occurred.

 If we're down or resetting, just bail */

 Force detection of hung controller */

 get one bit for every active Tx/Rx interrupt vector */

 Cause software interrupt to ensure rings are cleaned */

/**

 * ixgbevf_watchdog_update_link - update the link status

 * @adapter: pointer to the device adapter structure

 if check for link returns error we will need to reset */

/**

 * ixgbevf_watchdog_link_is_up - update netif_carrier status and

 *				 print link up message

 * @adapter: pointer to the device adapter structure

 only continue if link was previously down */

/**

 * ixgbevf_watchdog_link_is_down - update netif_carrier status and

 *				   print link down message

 * @adapter: pointer to the adapter structure

 only continue if link was up previously */

/**

 * ixgbevf_watchdog_subtask - worker thread to bring link up

 * @adapter: board private structure

 if interface is down do nothing */

/**

 * ixgbevf_service_task - manages and runs subtasks

 * @work: pointer to work_struct containing our data

/**

 * ixgbevf_free_tx_resources - Free Tx Resources per Queue

 * @tx_ring: Tx descriptor ring for a specific queue

 *

 * Free all transmit software resources

 if not set, then don't free */

/**

 * ixgbevf_free_all_tx_resources - Free Tx Resources for All Queues

 * @adapter: board private structure

 *

 * Free all transmit software resources

/**

 * ixgbevf_setup_tx_resources - allocate Tx resources (Descriptors)

 * @tx_ring: Tx descriptor ring (for a specific queue) to setup

 *

 * Return 0 on success, negative on failure

 round up to nearest 4K */

/**

 * ixgbevf_setup_all_tx_resources - allocate all queues Tx resources

 * @adapter: board private structure

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

 rewind the index freeing the rings as we go */

/**

 * ixgbevf_setup_rx_resources - allocate Rx resources (Descriptors)

 * @adapter: board private structure

 * @rx_ring: Rx descriptor ring (for a specific queue) to setup

 *

 * Returns 0 on success, negative on failure

 Round up to nearest 4K */

 XDP RX-queue info */

/**

 * ixgbevf_setup_all_rx_resources - allocate all queues Rx resources

 * @adapter: board private structure

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

 rewind the index freeing the rings as we go */

/**

 * ixgbevf_free_rx_resources - Free Rx Resources

 * @rx_ring: ring to clean the resources from

 *

 * Free all receive software resources

/**

 * ixgbevf_free_all_rx_resources - Free Rx Resources for All Queues

 * @adapter: board private structure

 *

 * Free all receive software resources

/**

 * ixgbevf_open - Called when a network interface is made active

 * @netdev: network interface device structure

 *

 * Returns 0 on success, negative value on failure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP).  At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the watchdog timer is started,

 * and the stack is notified that the interface is ready.

	/* A previous failure to open the device because of a lack of

	 * available MSIX vector resources may have reset the number

	 * of msix vectors variable to zero.  The only way to recover

	 * is to unload/reload the driver and hope that the system has

	 * been able to recover some MSIX vector resources.

		/* if adapter is still stopped then PF isn't up and

		 * the VF can't start.

 disallow open during test */

 allocate transmit descriptors */

 allocate receive descriptors */

 Notify the stack of the actual queue counts. */

/**

 * ixgbevf_close_suspend - actions necessary to both suspend and close flows

 * @adapter: the private adapter struct

 *

 * This function should contain the necessary work common to both suspending

 * and closing of the device.

/**

 * ixgbevf_close - Disables a network interface

 * @netdev: network interface device structure

 *

 * Returns 0, this is not allowed to fail

 *

 * The close entry point is called when an interface is de-activated

 * by the OS.  The hardware is still under the drivers control, but

 * needs to be disabled.  A global MAC reset is issued to stop the

 * hardware, and all transmit and receive resources are freed.

 if interface is down do nothing */

	/* Hardware has to reinitialize queues and interrupts to

	 * match packet buffer alignment. Unfortunately, the

	 * hardware is not flexible enough to do this dynamically.

 set bits to identify this as an advanced context descriptor */

 ADV DTYP TUCMD MKRLOC/ISCSIHEDLEN */

 initialize outer IP header fields */

		/* IP header will have to cancel out any data that

		 * is not a part of the outer IP header, so set to

		 * a reverse csum if needed, else init check to 0.

 determine offset of inner transport header */

 compute length of segmentation header */

 remove payload length from inner checksum */

 update gso size and bytecount with header size */

 mss_l4len_id: use 1 as index for TSO */

 vlan_macip_lens: HEADLEN, MACLEN, VLAN tag */

 validate that this is actually an SCTP request */

 update TX checksum flag */

 vlan_macip_lens: MACLEN, VLAN tag */

 set type for advanced descriptor with frame checksum insertion */

 set HW VLAN bit if VLAN is present */

 set segmentation enable bits for TSO/FSO */

 enable L4 checksum for TSO and TX checksum offload */

 enble IPv4 checksum for TSO */

 enable IPsec */

 use index 1 context for TSO/FSO/FCOE/IPSEC */

	/* Check Context must be set if Tx switch is enabled, which it

	 * always is for case where virtual functions are running

 record length, and DMA address */

 write last descriptor with RS and EOP bits */

 set the timestamp */

	/* Force memory writes to complete before letting h/w know there

	 * are new descriptors to fetch.  (Only applicable for weak-ordered

	 * memory model archs, such as IA-64).

	 *

	 * We also need this memory barrier (wmb) to make certain all of the

	 * status bits have been updated before next_to_watch is written.

 set next_to_watch value indicating a packet is present */

 notify HW of packet */

 clear dma mappings for failed tx_buffer_info map */

	/* Herbert's original patch had:

	 *  smp_mb__after_netif_stop_queue();

	 * but since that doesn't exist yet, just open code it.

	/* We need to check again in a case another CPU has just

	 * made room available.

 A reprieve! - use start_queue because it doesn't call schedule */

	/* need: 1 descriptor per page * PAGE_SIZE/IXGBE_MAX_DATA_PER_TXD,

	 *       + 1 desc for skb_headlen/IXGBE_MAX_DATA_PER_TXD,

	 *       + 2 desc gap to keep tail from touching head,

	 *       + 1 desc for context descriptor,

	 * otherwise try next time

 record the location of the first descriptor for this packet */

 record initial flags and protocol */

	/* The minimum packet size for olinfo paylen is 17 so pad the skb

	 * in order to meet this minimum size requirement.

/**

 * ixgbevf_set_mac - Change the Ethernet Address of the NIC

 * @netdev: network interface device structure

 * @p: pointer to an address structure

 *

 * Returns 0 on success, negative on failure

/**

 * ixgbevf_change_mtu - Change the Maximum Transfer Unit

 * @netdev: network interface device structure

 * @new_mtu: new value for maximum frame size

 *

 * Returns 0 on success, negative on failure

 prevent MTU being changed to a size unsupported by XDP */

 notify the PF of our intent to use this size of frame */

 must set new MTU before calling down or up */

 Make certain the headers can be described by a context descriptor */

	/* We can only support IPV4 TSO in tunnels if we can mangle the

	 * inner IP ID field, so strip TSO if MANGLEID is not supported.

 verify ixgbevf ring attributes are sufficient for XDP */

 If transitioning XDP modes reconfigure rings */

		/* Hardware has to reinitialize queues and interrupts to

		 * match packet buffer alignment. Unfortunately, the

		 * hardware is not flexible enough to do this dynamically.

/**

 * ixgbevf_probe - Device Initialization Routine

 * @pdev: PCI device information struct

 * @ent: entry in ixgbevf_pci_tbl

 *

 * Returns 0 on success, negative on failure

 *

 * ixgbevf_probe initializes an adapter identified by a pci_dev structure.

 * The OS initialization, configuring of the adapter private structure,

 * and a hardware reset occur.

	/* call save state here in standalone driver because it relies on

	 * adapter struct to exist, and needs to call netdev_priv

 Setup HW API */

 setup the private structure */

 The HW MAC address was set and/or determined in sw_init */

 set this bit last since it cannot be part of vlan_features */

 MTU range: 68 - 1504 or 9710 */

 print the VF info */

/**

 * ixgbevf_remove - Device Removal Routine

 * @pdev: PCI device information struct

 *

 * ixgbevf_remove is called by the PCI subsystem to alert the driver

 * that it should release a PCI device.  The could be caused by a

 * Hot-Plug event, or because the driver is going to be removed from

 * memory.

/**

 * ixgbevf_io_error_detected - called when PCI error is detected

 * @pdev: Pointer to PCI device

 * @state: The current pci connection state

 *

 * This function is called after a PCI bus error affecting

 * this device has been detected.

 Request a slot slot reset. */

/**

 * ixgbevf_io_slot_reset - called after the pci bus has been reset.

 * @pdev: Pointer to PCI device

 *

 * Restart the card from scratch, as if from a cold-boot. Implementation

 * resembles the first-half of the ixgbevf_resume routine.

/**

 * ixgbevf_io_resume - called when traffic can start flowing again.

 * @pdev: Pointer to PCI device

 *

 * This callback is called when the error recovery driver tells us that

 * its OK to resume normal operation. Implementation resembles the

 * second-half of the ixgbevf_resume routine.

 PCI Error Recovery (ERS) */

 Power Management Hooks */

/**

 * ixgbevf_init_module - Driver Registration Routine

 *

 * ixgbevf_init_module is the first routine called when the driver is

 * loaded. All it does is register with the PCI subsystem.

/**

 * ixgbevf_exit_module - Driver Exit Cleanup Routine

 *

 * ixgbevf_exit_module is called just before the driver is removed

 * from memory.

/**

 * ixgbevf_get_hw_dev_name - return device name string

 * used by hardware layer to print debugging information

 * @hw: pointer to private hardware struct

 ixgbevf_main.c */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019, Intel Corporation. */

/**

 * ice_dcbnl_devreset - perform enough of a ifdown/ifup to sync DCBNL info

 * @netdev: device associated with interface that needs reset

/**

 * ice_dcbnl_getets - retrieve local ETS configuration

 * @netdev: the relevant netdev

 * @ets: struct to hold ETS configuration

/**

 * ice_dcbnl_setets - set IEEE ETS configuration

 * @netdev: pointer to relevant netdev

 * @ets: struct to hold ETS configuration

 in DSCP mode up->tc mapping cannot change */

 return of zero indicates new cfg applied */

/**

 * ice_dcbnl_getnumtcs - Get max number of traffic classes supported

 * @dev: pointer to netdev struct

 * @tcid: TC ID

 * @num: total number of TCs supported by the adapter

 *

 * Return the total number of TCs supported

/**

 * ice_dcbnl_getdcbx - retrieve current DCBX capability

 * @netdev: pointer to the netdev struct

/**

 * ice_dcbnl_setdcbx - set required DCBX capability

 * @netdev: the corresponding netdev

 * @mode: required mode

 if FW LLDP agent is running, DCBNL not allowed to change mode */

 No support for LLD_MANAGED modes or CEE+IEEE */

 Already set to the given mode no change */

/**

 * ice_dcbnl_get_perm_hw_addr - MAC address used by DCBX

 * @netdev: pointer to netdev struct

 * @perm_addr: buffer to return permanent MAC address

/**

 * ice_get_pfc_delay - Retrieve PFC Link Delay

 * @hw: pointer to HW struct

 * @delay: holds the PFC Link Delay value

/**

 * ice_dcbnl_getpfc - retrieve local IEEE PFC config

 * @netdev: pointer to netdev struct

 * @pfc: struct to hold PFC info

/**

 * ice_dcbnl_setpfc - set local IEEE PFC config

 * @netdev: pointer to relevant netdev

 * @pfc: pointer to struct holding PFC config

/**

 * ice_dcbnl_get_pfc_cfg - Get CEE PFC config

 * @netdev: pointer to netdev struct

 * @prio: corresponding user priority

 * @setting: the PFC setting for given priority

/**

 * ice_dcbnl_set_pfc_cfg - Set CEE PFC config

 * @netdev: the corresponding netdev

 * @prio: User Priority

 * @set: PFC setting to apply

/**

 * ice_dcbnl_getpfcstate - get CEE PFC mode

 * @netdev: pointer to netdev struct

 Return enabled if any UP enabled for PFC */

/**

 * ice_dcbnl_getstate - get DCB enabled state

 * @netdev: pointer to netdev struct

/**

 * ice_dcbnl_setstate - Set CEE DCB state

 * @netdev: pointer to relevant netdev

 * @state: state value to set

 Nothing to do */

/**

 * ice_dcbnl_get_pg_tc_cfg_tx - get CEE PG Tx config

 * @netdev: pointer to netdev struct

 * @prio: the corresponding user priority

 * @prio_type: traffic priority type

 * @pgid: the BW group ID the traffic class belongs to

 * @bw_pct: BW percentage for the corresponding BWG

 * @up_map: prio mapped to corresponding TC

/**

 * ice_dcbnl_set_pg_tc_cfg_tx - set CEE PG Tx config

 * @netdev: pointer to relevant netdev

 * @tc: the corresponding traffic class

 * @prio_type: the traffic priority type

 * @bwg_id: the BW group ID the TC belongs to

 * @bw_pct: the BW perventage for the BWG

 * @up_map: prio mapped to corresponding TC

 prio_type, bwg_id and bw_pct per UP are not supported */

/**

 * ice_dcbnl_get_pg_bwg_cfg_tx - Get CEE PGBW config

 * @netdev: pointer to the netdev struct

 * @pgid: corresponding traffic class

 * @bw_pct: the BW percentage for the corresponding TC

/**

 * ice_dcbnl_set_pg_bwg_cfg_tx - set CEE PG Tx BW config

 * @netdev: the corresponding netdev

 * @pgid: Correspongind traffic class

 * @bw_pct: the BW percentage for the specified TC

/**

 * ice_dcbnl_get_pg_tc_cfg_rx - Get CEE PG Rx config

 * @netdev: pointer to netdev struct

 * @prio: the corresponding user priority

 * @prio_type: the traffic priority type

 * @pgid: the PG ID

 * @bw_pct: the BW percentage for the corresponding BWG

 * @up_map: prio mapped to corresponding TC

/**

 * ice_dcbnl_set_pg_tc_cfg_rx

 * @netdev: relevant netdev struct

 * @prio: corresponding user priority

 * @prio_type: the traffic priority type

 * @pgid: the PG ID

 * @bw_pct: BW percentage for corresponding BWG

 * @up_map: prio mapped to corresponding TC

 *

 * lldpad requires this function pointer to be non-NULL to complete CEE config.

/**

 * ice_dcbnl_get_pg_bwg_cfg_rx - Get CEE PG BW Rx config

 * @netdev: pointer to netdev struct

 * @pgid: the corresponding traffic class

 * @bw_pct: the BW percentage for the corresponding TC

/**

 * ice_dcbnl_set_pg_bwg_cfg_rx

 * @netdev: the corresponding netdev

 * @pgid: corresponding TC

 * @bw_pct: BW percentage for given TC

 *

 * lldpad requires this function pointer to be non-NULL to complete CEE config.

/**

 * ice_dcbnl_get_cap - Get DCBX capabilities of adapter

 * @netdev: pointer to netdev struct

 * @capid: the capability type

 * @cap: the capability value

/**

 * ice_dcbnl_getapp - get CEE APP

 * @netdev: pointer to netdev struct

 * @idtype: the App selector

 * @id: the App ethtype or port number

/**

 * ice_dcbnl_find_app - Search for APP in given DCB config

 * @cfg: struct to hold DCBX config

 * @app: struct to hold app data to look for

/**

 * ice_dcbnl_setapp - set local IEEE App config

 * @netdev: relevant netdev struct

 * @app: struct to hold app config info

 ONLY DSCP APP TLVs have operational significance */

 only allow APP TLVs in SW Mode */

 grab TC mutex */

 If port is not in DSCP mode, need to set */

 set DSCP mode */

 set default DSCP QoS values */

 if less that 8 TCs supported */

 end of switching to DSCP mode */

 apply new mapping for this DSCP value */

 return of zero indicates new cfg applied */

/**

 * ice_dcbnl_delapp - Delete local IEEE App config

 * @netdev: relevant netdev

 * @app: struct to hold app too delete

 *

 * Will not delete first application required by the FW

 Did not find DCB App */

 if not a DSCP APP TLV or DSCP is not supported, we are done */

 if DSCP TLV, then need to address change in mapping */

 remap this DSCP value to default value */

	/* if the last DSCP mapping just got deleted, need to switch

	 * to L2 VLAN QoS mode

	/* return of ICE_DCB_HW_CHG_RST indicates new cfg applied

	 * and reset needs to be performed

	/* if the change was not siginificant enough to actually call

	 * the reconfiguration flow, we still need to tell caller that

	 * their request was successfully handled

/**

 * ice_dcbnl_cee_set_all - Commit CEE DCB settings to HW

 * @netdev: the corresponding netdev

 IEEE 802.1Qaz std */

 CEE std */

 DCBX configuration */

/**

 * ice_dcbnl_set_all - set all the apps and ieee data from DCBX config

 * @vsi: pointer to VSI struct

 SW DCB taken care of by SW Default Config */

 DCB not enabled */

 Add APP only if the TC is enabled for this VSI */

 Notify user-space of the changes */

/**

 * ice_dcbnl_vsi_del_app - Delete APP on all VSIs

 * @vsi: pointer to the main VSI

 * @app: APP to delete

 *

 * Delete given APP from all the VSIs for given PF

/**

 * ice_dcbnl_flush_apps - Delete all removed APPs

 * @pf: the corresponding PF

 * @old_cfg: old DCBX configuration data

 * @new_cfg: new DCBX configuration data

 *

 * Find and delete all APPS that are not present in the passed

 * DCB configuration

 The APP is not available anymore delete it */

/**

 * ice_dcbnl_setup - setup DCBNL

 * @vsi: VSI to get associated netdev from

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018-2021, Intel Corporation. */

 Link Aggregation code */

/**

 * ice_lag_nop_handler - no-op Rx handler to disable LAG

 * @pskb: pointer to skb pointer

/**

 * ice_lag_set_primary - set PF LAG state as Primary

 * @lag: LAG info struct

/**

 * ice_lag_set_backup - set PF LAG state to Backup

 * @lag: LAG info struct

/**

 * ice_display_lag_info - print LAG info

 * @lag: LAG info struct

/**

 * ice_lag_info_event - handle NETDEV_BONDING_INFO event

 * @lag: LAG info struct

 * @ptr: opaque data pointer

 *

 * ptr is to be cast to (netdev_notifier_bonding_info *)

/**

 * ice_lag_link - handle LAG link event

 * @lag: LAG info struct

 * @info: info from the netdev notifier

 if this is the first element in an LAG mark as master */

/**

 * ice_lag_unlink - handle unlink event

 * @lag: LAG info struct

 * @info: info from netdev notification

 determine if we are in the new LAG config or not */

/**

 * ice_lag_changeupper_event - handle LAG changeupper event

 * @lag: LAG info struct

 * @ptr: opaque pointer data

 *

 * ptr is to be cast into netdev_notifier_changeupper_info

 not for this netdev */

/**

 * ice_lag_changelower_event - handle LAG changelower event

 * @lag: LAG info struct

 * @ptr: opaque data pointer

 *

 * ptr to be cast to netdev_notifier_changelowerstate_info

/**

 * ice_lag_event_handler - handle LAG events from netdev

 * @notif_blk: notifier block registered by this netdev

 * @event: event type

 * @ptr: opaque data containing notifier event

 Check that the netdev is in the working namespace */

/**

 * ice_register_lag_handler - register LAG handler on netdev

 * @lag: LAG struct

/**

 * ice_unregister_lag_handler - unregister LAG handler on netdev

 * @lag: LAG struct

/**

 * ice_init_lag - initialize support for LAG

 * @pf: PF struct

 *

 * Alloc memory for LAG structs and initialize the elements.

 * Memory will be freed in ice_deinit_lag

/**

 * ice_deinit_lag - Clean up LAG

 * @pf: PF struct

 *

 * Clean up kernel LAG info and free memory

 * This function is meant to only be called on driver remove/shutdown

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019, Intel Corporation. */

/**

 * ice_release_rx_desc - Store the new tail and head values

 * @rx_ring: ring to bump

 * @val: new head index

 update next to alloc since we have filled the ring */

	/* QRX_TAIL will be updated with any tail value, but hardware ignores

	 * the lower 3 bits. This makes it so we only bump tail on meaningful

	 * boundaries. Also, this allows us to bump tail on intervals of 8 up to

	 * the budget depending on the current traffic load.

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch. (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

/**

 * ice_ptype_to_htype - get a hash type

 * @ptype: the ptype value from the descriptor

 *

 * Returns appropriate hash type (such as PKT_HASH_TYPE_L2/L3/L4) to be used by

 * skb_set_hash based on PTYPE as parsed by HW Rx pipeline and is part of

 * Rx desc.

/**

 * ice_rx_hash - set the hash value in the skb

 * @rx_ring: descriptor ring

 * @rx_desc: specific descriptor

 * @skb: pointer to current skb

 * @rx_ptype: the ptype value from the descriptor

/**

 * ice_rx_csum - Indicate in skb if checksum is good

 * @ring: the ring we care about

 * @skb: skb currently being received and modified

 * @rx_desc: the receive descriptor

 * @ptype: the packet type decoded by hardware

 *

 * skb->protocol must be set before this function is called

 Start with CHECKSUM_NONE and by default csum_level = 0 */

 check if Rx checksum is enabled */

 check if HW has decoded the packet and checksum */

	/* check for L4 errors and handle packets that were not able to be

	 * checksummed due to arrival speed

 check for outer UDP checksum error in tunneled packets */

	/* If there is an outer header present that might contain a checksum

	 * we need to bump the checksum level by 1 to reflect the fact that

	 * we are indicating we validated the inner checksum.

 Only report checksum unnecessary for TCP, UDP, or SCTP */

/**

 * ice_process_skb_fields - Populate skb header fields from Rx descriptor

 * @rx_ring: Rx descriptor ring packet is being transacted on

 * @rx_desc: pointer to the EOP Rx descriptor

 * @skb: pointer to current skb being populated

 * @ptype: the packet type decoded by hardware

 *

 * This function checks the ring, descriptor, and packet information in

 * order to populate the hash, checksum, VLAN, protocol, and

 * other fields within the skb.

 modifies the skb - consumes the enet header */

/**

 * ice_receive_skb - Send a completed packet up the stack

 * @rx_ring: Rx ring in play

 * @skb: packet to send up

 * @vlan_tag: VLAN tag for packet

 *

 * This function sends the completed packet (via. skb) up the stack using

 * gro receive functions (with/without VLAN tag)

/**

 * ice_clean_xdp_irq - Reclaim resources after transmit completes on XDP ring

 * @xdp_ring: XDP ring to clean

		/* normally tx_buf->gso_segs was taken but at this point

		 * it's always 1 for us

/**

 * ice_xmit_xdp_ring - submit single packet to XDP ring for transmission

 * @data: packet data pointer

 * @size: packet data size

 * @xdp_ring: XDP ring for transmission

 record length, and DMA address */

/**

 * ice_xmit_xdp_buff - convert an XDP buffer to an XDP frame and send it

 * @xdp: XDP buffer

 * @xdp_ring: XDP Tx ring

 *

 * Returns negative on failure, 0 on success.

/**

 * ice_finalize_xdp_rx - Bump XDP Tx tail and/or flush redirect map

 * @xdp_ring: XDP ring

 * @xdp_res: Result of the receive batch

 *

 * This function bumps XDP Tx tail and/or flush redirect map, and

 * should be called when a batch of packets has been processed in the

 * napi loop.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

/**

 * ice_vsi_type_str - maps VSI type enum to string equivalents

 * @vsi_type: VSI type enum

/**

 * ice_vsi_ctrl_all_rx_rings - Start or stop a VSI's Rx rings

 * @vsi: the VSI being configured

 * @ena: start or stop the Rx rings

 *

 * First enable/disable all of the Rx rings, flush any remaining writes, and

 * then verify that they have all been enabled/disabled successfully. This will

 * let all of the register writes complete when enabling/disabling the Rx rings

 * before waiting for the change in hardware to complete.

/**

 * ice_vsi_alloc_arrays - Allocate queue and vector pointer arrays for the VSI

 * @vsi: VSI pointer

 *

 * On error: returns error code (negative)

 * On success: returns 0

 allocate memory for both Tx and Rx ring pointers */

 XDP will have vsi->alloc_txq Tx queues as well, so double the size */

 There is no need to allocate q_vectors for a loopback VSI. */

 allocate memory for q_vector pointers */

/**

 * ice_vsi_set_num_desc - Set number of descriptors for queues on this VSI

 * @vsi: the VSI being configured

		/* a user could change the values of num_[tr]x_desc using

		 * ethtool -G so we should keep those values instead of

		 * overwriting them with the defaults.

/**

 * ice_vsi_set_num_qs - Set number of queues, descriptors and vectors for a VSI

 * @vsi: the VSI being configured

 * @vf_id: ID of the VF being configured

 *

 * Return 0 on success and a negative value on error

 only 1 Rx queue unless RSS is enabled */

		/* The number of queues for ctrl VSI is equal to number of VFs.

		 * Each ring is associated to the corresponding VF_PR netdev.

		/* pf->num_msix_per_vf includes (VF miscellaneous vector +

		 * data queue interrupts). Since vsi->num_q_vectors is number

		 * of queues vectors, subtract 1 (ICE_NONQ_VECS_VF) from the

		 * original vector count

/**

 * ice_get_free_slot - get the next non-NULL location index in array

 * @array: array to search

 * @size: size of the array

 * @curr: last known occupied index to be used as a search hint

 *

 * void * is being used to keep the functionality generic. This lets us use this

 * function on any array of pointers.

/**

 * ice_vsi_delete - delete a VSI from the switch

 * @vsi: pointer to VSI being removed

/**

 * ice_vsi_free_arrays - De-allocate queue and vector pointer arrays for the VSI

 * @vsi: pointer to VSI being cleared

 free the ring and vector containers */

/**

 * ice_vsi_clear - clean up and deallocate the provided VSI

 * @vsi: pointer to VSI being cleared

 *

 * This deallocates the VSI's queue resources, removes it from the PF's

 * VSI array if necessary, and deallocates the VSI

 *

 * Returns 0 on success, negative on failure

 updates the PF for this cleared VSI */

/**

 * ice_msix_clean_ctrl_vsi - MSIX mode interrupt handler for ctrl VSI

 * @irq: interrupt number

 * @data: pointer to a q_vector

/**

 * ice_msix_clean_rings - MSIX mode Interrupt Handler

 * @irq: interrupt number

 * @data: pointer to a q_vector

/**

 * ice_vsi_alloc - Allocates the next available struct VSI in the PF

 * @pf: board private structure

 * @vsi_type: type of VSI

 * @ch: ptr to channel

 * @vf_id: ID of the VF being configured

 *

 * returns a pointer to a VSI on success, NULL on failure.

 Need to protect the allocation of the VSIs at the PF level */

	/* If we have already allocated our maximum number of VSIs,

	 * pf->next_vsi will be ICE_NO_VSI. If not, pf->next_vsi index

	 * is available to be populated

 Setup eswitch MSIX irq handler for VSI */

 Setup default MSIX irq handler for VSI */

 Setup ctrl VSI MSIX irq handler */

 Use the last VSI slot as the index for PF control VSI */

 fill slot and make note of the index */

 prepare pf->next_vsi for next use */

/**

 * ice_alloc_fd_res - Allocate FD resource for a VSI

 * @vsi: pointer to the ice_vsi

 *

 * This allocates the FD resources

 *

 * Returns 0 on success, -EPERM on no-op or -EIO on failure

	/* Flow Director filters are only allocated/assigned to the PF VSI which

	 * passes the traffic. The CTRL VSI is only used to add/delete filters

	 * so we don't allocate resources to it

 FD filters from guaranteed pool per VSI */

 FD filters from best effort pool */

 each VSI gets same "best_effort" quota */

 each VSI gets same "best_effort" quota */

/**

 * ice_vsi_get_qs - Assign queues from PF to VSI

 * @vsi: the VSI to assign queues to

 *

 * Returns 0 on success and a negative value on error

/**

 * ice_vsi_put_qs - Release queues from VSI to PF

 * @vsi: the VSI that is going to release queues

/**

 * ice_is_safe_mode

 * @pf: pointer to the PF struct

 *

 * returns true if driver is in safe mode, false otherwise

/**

 * ice_is_aux_ena

 * @pf: pointer to the PF struct

 *

 * returns true if AUX devices/drivers are supported, false otherwise

/**

 * ice_vsi_clean_rss_flow_fld - Delete RSS configuration

 * @vsi: the VSI being cleaned up

 *

 * This function deletes RSS input set for all flows that were configured

 * for this VSI

/**

 * ice_rss_clean - Delete RSS related VSI structures and configuration

 * @vsi: the VSI being removed

 remove RSS replay list */

/**

 * ice_vsi_set_rss_params - Setup RSS capabilities per VSI type

 * @vsi: the VSI being configured

 PF VSI will inherit RSS instance of PF */

		/* VF VSI will get a small RSS table.

		 * For VSI_LUT, LUT size should be set to 64 bytes.

/**

 * ice_set_dflt_vsi_ctx - Set default VSI context before adding a VSI

 * @ctxt: the VSI context being set

 *

 * This initializes a default VSI context for all sections except the Queues.

 VSI's should be allocated from shared pool */

 Src pruning enabled by default */

 Traffic from VSI can be sent to LAN */

	/* By default bits 3 and 4 in vlan_flags are 0's which results in legacy

	 * behavior (show VLAN, DEI, and UP) in descriptor. Also, allow all

	 * packets untagged/tagged.

 Have 1:1 UP mapping for both ingress/egress tables */

 Have 1:1 UP mapping for outer to inner UP table */

 No Outer tag support outer_tag_flags remains to zero */

/**

 * ice_vsi_setup_q_map - Setup a VSI queue map

 * @vsi: the VSI being configured

 * @ctxt: VSI context structure

 at least TC0 should be enabled by default */

 find the (rounded up) power-of-2 of qcount */

	/* TC mapping is a function of the number of Rx queues assigned to the

	 * VSI for each traffic class and the offset of these queues.

	 * The first 10 bits are for queue offset for TC0, next 4 bits for no:of

	 * queues allocated to TC0. No:of queues is a power-of-2.

	 *

	 * If TC is not enabled, the queue offset is set to 0, and allocate one

	 * queue, this way, traffic for the given TC will be sent to the default

	 * queue.

	 *

	 * Setup number and offset of Rx queues for all TCs for the VSI

 TC is not enabled */

 TC is enabled */

	/* if offset is non-zero, means it is calculated correctly based on

	 * enabled TCs for a given VSI otherwise qcount_rx will always

	 * be correct and non-zero because it is based off - VSI's

	 * allocated Rx queues which is at least 1 (hence qcount_tx will be

	 * at least 1)

		/* since there is a chance that num_rxq could have been changed

		 * in the above for loop, make num_txq equal to num_rxq.

 Rx queue mapping */

	/* q_mapping buffer holds the info for the first queue allocated for

	 * this VSI in the PF space and also the number of queues associated

	 * with this VSI.

/**

 * ice_set_fd_vsi_ctx - Set FD VSI context before adding a VSI

 * @ctxt: the VSI context being set

 * @vsi: the VSI being configured

 enable flow director filtering/programming */

 max of allocated flow director filters */

 max of shared flow director filters any VSI may program */

 default queue index within the VSI of the default FD */

 target queue or queue group to the FD filter */

 queue index on which FD filter completion is reported */

 priority of the default qindex action */

/**

 * ice_set_rss_vsi_ctx - Set RSS VSI context before adding a VSI

 * @ctxt: the VSI context being set

 * @vsi: the VSI being configured

 PF VSI will inherit RSS instance of PF */

 VF VSI will gets a small RSS table which is a VSI LUT type */

/**

 * ice_vsi_init - Create and initialize a VSI

 * @vsi: the VSI being configured

 * @init_vsi: is this call creating a VSI

 *

 * This initializes a VSI context depending on the VSI type to be added and

 * passes it down to the add_vsi aq command to create a new VSI.

 VF number here is the absolute VF number (0-255) */

	/* Handle VLAN pruning for channel VSI if main VSI has VLAN

	 * prune enabled

 if the switch is in VEB mode, allow VSI loopback */

 Set LUT type and HASH type if RSS is enabled */

		/* if updating VSI context, make sure to set valid_section:

		 * to indicate which section of VSI context being updated

 means VSI being updated */

			/* must to indicate which section of VSI context are

			 * being modified

	/* enable/disable MAC and VLAN anti-spoof when spoofchk is on/off

	 * respectively

 Allow control frames out of main VSI */

 keep context for update VSI operations */

 record VSI number returned */

/**

 * ice_free_res - free a block of resources

 * @res: pointer to the resource

 * @index: starting index previously returned by ice_get_res

 * @id: identifier to track owner

 *

 * Returns number of resources freed

/**

 * ice_search_res - Search the tracker for a block of resources

 * @res: pointer to the resource

 * @needed: size of the block needed

 * @id: identifier to track owner

 *

 * Returns the base item index of the block, or -ENOMEM for error

 skip already allocated entries */

 there was enough, so assign it to the requestor */

/**

 * ice_get_free_res_count - Get free count from a resource tracker

 * @res: Resource tracker instance

/**

 * ice_get_res - get a block of resources

 * @pf: board private structure

 * @res: pointer to the resource

 * @needed: size of the block needed

 * @id: identifier to track owner

 *

 * Returns the base item index of the block, or negative for error

/**

 * ice_vsi_setup_vector_base - Set up the base vector for the given VSI

 * @vsi: ptr to the VSI

 *

 * This should only be called after ice_vsi_alloc() which allocates the

 * corresponding SW VSI structure and initializes num_queue_pairs for the

 * newly allocated VSI.

 *

 * Returns 0 on success or negative on failure

 SRIOV doesn't grab irq_tracker entries for each VSI */

 reserve slots from OS requested IRQs */

/**

 * ice_vsi_clear_rings - Deallocates the Tx and Rx rings for VSI

 * @vsi: the VSI having rings deallocated

 Avoid stale references by clearing map from vector to ring */

/**

 * ice_vsi_alloc_rings - Allocates Tx and Rx rings for the VSI

 * @vsi: VSI which is having rings allocated

 Allocate Tx rings */

 allocate with kzalloc(), free with kfree_rcu() */

 Allocate Rx rings */

 allocate with kzalloc(), free with kfree_rcu() */

/**

 * ice_vsi_manage_rss_lut - disable/enable RSS

 * @vsi: the VSI being changed

 * @ena: boolean value indicating if this is an enable or disable request

 *

 * In the event of disable request for RSS, this function will zero out RSS

 * LUT, while in the event of enable request for RSS, it will reconfigure RSS

 * LUT.

/**

 * ice_vsi_cfg_rss_lut_key - Configure RSS params for a VSI

 * @vsi: VSI to be configured

		/* If orig_rss_size is valid and it is less than determined

		 * main VSI's rss_size, update main VSI's rss_size to be

		 * orig_rss_size so that when tc-qdisc is deleted, main VSI

		 * RSS table gets programmed to be correct (whatever it was

		 * to begin with (prior to setup-tc for ADQ config)

 now orig_rss_size is used, reset it to zero */

/**

 * ice_vsi_set_vf_rss_flow_fld - Sets VF VSI RSS input set for different flows

 * @vsi: VSI to be configured

 *

 * This function will only be called during the VF VSI setup. Upon successful

 * completion of package download, this function will configure default RSS

 * input sets for VF VSI.

/**

 * ice_vsi_set_rss_flow_fld - Sets RSS input set for different flows

 * @vsi: VSI to be configured

 *

 * This function will only be called after successful download package call

 * during initialization of PF. Since the downloaded package will erase the

 * RSS section, this function will configure RSS input sets for different

 * flow types. The last profile added has the highest priority, therefore 2

 * tuple profiles (i.e. IPv4 src/dst) are added before 4 tuple profiles

 * (i.e. IPv4 src/dst TCP src/dst port).

 configure RSS for IPv4 with input set IP src/dst */

 configure RSS for IPv6 with input set IPv6 src/dst */

 configure RSS for tcp4 with input set IP src/dst, TCP src/dst */

 configure RSS for udp4 with input set IP src/dst, UDP src/dst */

 configure RSS for sctp4 with input set IP src/dst */

 configure RSS for tcp6 with input set IPv6 src/dst, TCP src/dst */

 configure RSS for udp6 with input set IPv6 src/dst, UDP src/dst */

 configure RSS for sctp6 with input set IPv6 src/dst */

/**

 * ice_pf_state_is_nominal - checks the PF for nominal state

 * @pf: pointer to PF to check

 *

 * Check the PF's state for a collection of bits that would indicate

 * the PF is in a state that would inhibit normal operation for

 * driver functionality.

 *

 * Returns true if PF is in a nominal state, false otherwise

/**

 * ice_update_eth_stats - Update VSI-specific ethernet statistics counters

 * @vsi: the VSI to be updated

 HW absolute index of a VSI */

/**

 * ice_vsi_add_vlan - Add VSI membership for given VLAN

 * @vsi: the VSI being configured

 * @vid: VLAN ID to be added

 * @action: filter action to be performed on match

/**

 * ice_vsi_kill_vlan - Remove VSI membership for a given VLAN

 * @vsi: the VSI being configured

 * @vid: VLAN ID to be removed

 *

 * Returns 0 on success and negative on failure

/**

 * ice_vsi_cfg_frame_size - setup max frame size and Rx buffer length

 * @vsi: VSI

/**

 * ice_write_qrxflxp_cntxt - write/configure QRXFLXP_CNTXT register

 * @hw: HW pointer

 * @pf_q: index of the Rx queue in the PF's queue space

 * @rxdid: flexible descriptor RXDID

 * @prio: priority for the RXDID for this queue

 * @ena_ts: true to enable timestamp and false to disable timestamp

 clear any previous values */

 Enable TimeSync on this queue */

/**

 * ice_vsi_cfg_rxqs - Configure the VSI for Rx

 * @vsi: the VSI being configured

 *

 * Return 0 on success and a negative value on error

 * Configure the Rx VSI for operation.

 set up individual rings */

/**

 * ice_vsi_cfg_txqs - Configure the VSI for Tx

 * @vsi: the VSI being configured

 * @rings: Tx ring array to be configured

 * @count: number of Tx ring array elements

 *

 * Return 0 on success and a negative value on error

 * Configure the Tx VSI for operation.

/**

 * ice_vsi_cfg_lan_txqs - Configure the VSI for Tx

 * @vsi: the VSI being configured

 *

 * Return 0 on success and a negative value on error

 * Configure the Tx VSI for operation.

/**

 * ice_vsi_cfg_xdp_txqs - Configure Tx queues dedicated for XDP in given VSI

 * @vsi: the VSI being configured

 *

 * Return 0 on success and a negative value on error

 * Configure the Tx queues dedicated for XDP in given VSI for operation.

/**

 * ice_intrl_usec_to_reg - convert interrupt rate limit to register value

 * @intrl: interrupt rate limit in usecs

 * @gran: interrupt rate limit granularity in usecs

 *

 * This function converts a decimal interrupt rate limit in usecs to the format

 * expected by firmware.

/**

 * ice_write_intrl - write throttle rate limit to interrupt specific register

 * @q_vector: pointer to interrupt specific structure

 * @intrl: throttle rate limit in microseconds to write

/**

 * __ice_write_itr - write throttle rate to register

 * @q_vector: pointer to interrupt data structure

 * @rc: pointer to ring container

 * @itr: throttle rate in microseconds to write

/**

 * ice_write_itr - write throttle rate to queue specific register

 * @rc: pointer to ring container

 * @itr: throttle rate in microseconds to write

/**

 * ice_set_q_vector_intrl - set up interrupt rate limiting

 * @q_vector: the vector to be configured

 *

 * Interrupt rate limiting is local to the vector, not per-queue so we must

 * detect if either ring container has dynamic moderation enabled to decide

 * what to set the interrupt rate limit to via INTRL settings. In the case that

 * dynamic moderation is disabled on both, write the value with the cached

 * setting to make sure INTRL register matches the user visible value.

		/* in the case of dynamic enabled, cap each vector to no more

		 * than (4 us) 250,000 ints/sec, which allows low latency

		 * but still less than 500,000 interrupts per second, which

		 * reduces CPU a bit in the case of the lowest latency

		 * setting. The 4 here is a value in microseconds.

/**

 * ice_vsi_cfg_msix - MSIX mode Interrupt Config in the HW

 * @vsi: the VSI being configured

 *

 * This configures MSIX mode interrupts for the PF VSI, and should not be used

 * for the VF VSI.

		/* Both Transmit Queue Interrupt Cause Control register

		 * and Receive Queue Interrupt Cause control register

		 * expects MSIX_INDX field to be the vector index

		 * within the function space and not the absolute

		 * vector index across PF or across device.

		 * For SR-IOV VF VSIs queue vector index always starts

		 * with 1 since first vector index(0) is used for OICR

		 * in VF space. Since VMDq and other PF VSIs are within

		 * the PF function space, use the vector index that is

		 * tracked for this PF.

/**

 * ice_vsi_manage_vlan_insertion - Manage VLAN insertion for the VSI for Tx

 * @vsi: the VSI being changed

	/* Here we are configuring the VSI to let the driver add VLAN tags by

	 * setting vlan_flags to ICE_AQ_VSI_VLAN_MODE_ALL. The actual VLAN tag

	 * insertion happens in the Tx hot path, in ice_tx_map.

 Preserve existing VLAN strip setting */

/**

 * ice_vsi_manage_vlan_stripping - Manage VLAN stripping for the VSI for Rx

 * @vsi: the VSI being changed

 * @ena: boolean value indicating if this is a enable or disable request

	/* do not allow modifying VLAN stripping when a port VLAN is configured

	 * on this VSI

	/* Here we are configuring what the VSI should do with the VLAN tag in

	 * the Rx packet. We can either leave the tag in the packet or put it in

	 * the Rx descriptor.

 Strip VLAN tag from Rx packet and put it in the desc */

 Disable stripping. Leave tag in packet */

 Allow all packets untagged/tagged */

/**

 * ice_vsi_start_all_rx_rings - start/enable all of a VSI's Rx rings

 * @vsi: the VSI whose rings are to be enabled

 *

 * Returns 0 on success and a negative value on error

/**

 * ice_vsi_stop_all_rx_rings - stop/disable all of a VSI's Rx rings

 * @vsi: the VSI whose rings are to be disabled

 *

 * Returns 0 on success and a negative value on error

/**

 * ice_vsi_stop_tx_rings - Disable Tx rings

 * @vsi: the VSI being configured

 * @rst_src: reset source

 * @rel_vmvf_num: Relative ID of VF/VM

 * @rings: Tx ring array to be stopped

 * @count: number of Tx ring array elements

/**

 * ice_vsi_stop_lan_tx_rings - Disable LAN Tx rings

 * @vsi: the VSI being configured

 * @rst_src: reset source

 * @rel_vmvf_num: Relative ID of VF/VM

/**

 * ice_vsi_stop_xdp_tx_rings - Disable XDP Tx rings

 * @vsi: the VSI being configured

/**

 * ice_vsi_is_vlan_pruning_ena - check if VLAN pruning is enabled or not

 * @vsi: VSI to check whether or not VLAN pruning is enabled.

 *

 * returns true if Rx VLAN pruning is enabled and false otherwise.

/**

 * ice_cfg_vlan_pruning - enable or disable VLAN pruning on the VSI

 * @vsi: VSI to enable or disable VLAN pruning on

 * @ena: set to true to enable VLAN pruning and false to disable it

 *

 * returns 0 if VSI is updated, negative otherwise

	/* Don't enable VLAN pruning if the netdev is currently in promiscuous

	 * mode. VLAN pruning will be enabled when the interface exits

	 * promiscuous mode if any VLAN filters are active.

 set VSI TC information based on DCB config */

/**

 * ice_vsi_set_q_vectors_reg_idx - set the HW register index for all q_vectors

 * @vsi: VSI to set the q_vectors register index on

/**

 * ice_cfg_sw_lldp - Config switch rules for LLDP packet handling

 * @vsi: the VSI being configured

 * @tx: bool to determine Tx or Rx rule

 * @create: bool to determine create or remove Rule

/**

 * ice_set_agg_vsi - sets up scheduler aggregator node and move VSI into it

 * @vsi: pointer to the VSI

 *

 * This function will allocate new scheduler aggregator now if needed and will

 * move specified VSI into it.

	/* create (as needed) scheduler aggregator node and move VSI into

	 * corresponding aggregator node

	 * - PF aggregator node to contains VSIs of type _PF and _CTRL

	 * - VF aggregator nodes will contain VF VSI

		/* user can create 'n' VFs on a given PF, but since max children

		 * per aggregator node can be only 64. Following code handles

		 * aggregator(s) for VF VSIs, either selects a agg_node which

		 * was already created provided num_vsis < 64, otherwise

		 * select next available node, which will be created

 other VSI type, handle later if needed */

 find the appropriate aggregator node */

		/* see if we can find space in previously created

		 * node if num_vsis < 64, otherwise skip

 find unclaimed agg_id */

 move to next agg_node */

 if selected aggregator node was not created, create it */

 aggregator node is created, store the neeeded info */

 move VSI to corresponding aggregator node */

 keep active children count for aggregator node */

	/* cache the 'agg_id' in VSI, so that after reset - VSI will be moved

	 * to aggregator node

/**

 * ice_vsi_setup - Set up a VSI by a given type

 * @pf: board private structure

 * @pi: pointer to the port_info instance

 * @vsi_type: VSI type

 * @vf_id: defines VF ID to which this VSI connects. This field is meant to be

 *         used only for ICE_VSI_VF VSI type. For other VSI types, should

 *         fill-in ICE_INVAL_VFID as input.

 * @ch: ptr to channel

 *

 * This allocates the sw VSI structure and its queue resources.

 *

 * Returns pointer to the successfully allocated and configured VSI sw struct on

 * success, NULL on failure.

 set RSS capabilities */

 set TC configuration */

 create the VSI */

		/* Always add VLAN ID 0 switch rule by default. This is needed

		 * in order to allow all untagged and 0 tagged priority traffic

		 * if Rx VLAN pruning is enabled. Also there are cases where we

		 * don't get the call to add VLAN 0 via ice_vlan_rx_add_vid()

		 * so this handles those cases (i.e. adding the PF to a bridge

		 * without the 8021q module loaded).

 ICE_VSI_CTRL does not need RSS so skip RSS processing */

			/* Do not exit if configuring RSS had an issue, at

			 * least receive traffic on first queue. Hence no

			 * need to capture return value

		/* VF driver will take care of creating netdev for this type and

		 * map queues to vectors through Virtchnl, PF driver only

		 * creates a VSI and corresponding structures for bookkeeping

		 * purpose

		/* Do not exit if configuring RSS had an issue, at least

		 * receive traffic on first queue. Hence no need to capture

		 * return value

 clean up the resources and exit */

 configure VSI nodes based on number of queues and TC's */

	/* Add switch rule to drop all Tx Flow Control Frames, of look up

	 * type ETHERTYPE from VSIs, and restrict malicious VF from sending

	 * out PAUSE or PFC frames. If enabled, FW can still send FC frames.

	 * The rule is added once for PF VSI in order to create appropriate

	 * recipe, since VSI/VSI list is ignored with drop action...

	 * Also add rules to handle LLDP Tx packets.  Tx LLDP packets need to

	 * be dropped so that VFs cannot send LLDP packets to reconfig DCB

	 * settings in the HW.

 reclaim SW interrupts back to the common pool */

/**

 * ice_vsi_release_msix - Clear the queue to Interrupt mapping in HW

 * @vsi: the VSI being cleaned up

/**

 * ice_vsi_free_irq - Free the IRQ association with the OS

 * @vsi: the VSI being configured

 free only the irqs that were actually requested */

 clear the affinity notifier in the IRQ descriptor */

 clear the affinity_mask in the IRQ descriptor */

/**

 * ice_vsi_free_tx_rings - Free Tx resources for VSI queues

 * @vsi: the VSI having resources freed

/**

 * ice_vsi_free_rx_rings - Free Rx resources for VSI queues

 * @vsi: the VSI having resources freed

/**

 * ice_vsi_close - Shut down a VSI

 * @vsi: the VSI being shut down

/**

 * ice_ena_vsi - resume a VSI

 * @vsi: the VSI being resume

 * @locked: is the rtnl_lock already held

/**

 * ice_dis_vsi - pause a VSI

 * @vsi: the VSI being paused

 * @locked: is the rtnl_lock already held

/**

 * ice_vsi_dis_irq - Mask off queue interrupt generation on the VSI

 * @vsi: the VSI being un-configured

 disable interrupt causation from each queue */

 disable each interrupt */

 don't call synchronize_irq() for VF's from the host */

/**

 * ice_napi_del - Remove NAPI handler for the VSI

 * @vsi: VSI for which NAPI handler is to be removed

/**

 * ice_vsi_release - Delete a VSI and free its resources

 * @vsi: the VSI being removed

 *

 * Returns 0 on success or < 0 on error

	/* do not unregister while driver is in the reset recovery pending

	 * state. Since reset/rebuild happens through PF service task workqueue,

	 * it's not a good idea to unregister netdev that is associated to the

	 * PF that is running the work queue items currently. This is done to

	 * avoid check_flush_dependency() warning on this wq

 Disable VSI and free resources */

	/* SR-IOV determines needed MSIX resources all at once instead of per

	 * VSI since when VFs are spawned we know how many VFs there are and how

	 * many interrupts each VF needs. SR-IOV MSIX resources are also

	 * cleared in the same manner.

			/* No other VFs left that have control VSI, reclaim SW

			 * interrupts back to the common pool

 reclaim SW interrupts back to the common pool */

			/* The Rx rule will only exist to remove if the LLDP FW

			 * engine is currently stopped

	/* retain SW VSI data structure since it is needed to unregister and

	 * free VSI netdev when PF is not in reset recovery pending state,\

	 * for ex: during rmmod.

/**

 * ice_vsi_rebuild_get_coalesce - get coalesce from all q_vectors

 * @vsi: VSI connected with q_vectors

 * @coalesce: array of struct with stored coalesce

 *

 * Returns array size.

/**

 * ice_vsi_rebuild_set_coalesce - set coalesce from earlier saved arrays

 * @vsi: VSI connected with q_vectors

 * @coalesce: pointer to array of struct with stored coalesce

 * @size: size of coalesce array

 *

 * Before this function, ice_vsi_rebuild_get_coalesce should be called to save

 * ITR params in arrays. If size is 0 or coalesce wasn't stored set coalesce

 * to default value.

	/* There are a couple of cases that have to be handled here:

	 *   1. The case where the number of queue vectors stays the same, but

	 *      the number of Tx or Rx rings changes (the first for loop)

	 *   2. The case where the number of queue vectors increased (the

	 *      second for loop)

		/* There are 2 cases to handle here and they are the same for

		 * both Tx and Rx:

		 *   if the entry was valid previously (coalesce[i].[tr]x_valid

		 *   and the loop variable is less than the number of rings

		 *   allocated, then write the previous values

		 *

		 *   if the entry was not valid previously, but the number of

		 *   rings is less than are allocated (this means the number of

		 *   rings increased from previously), then write out the

		 *   values in the first element

		 *

		 *   Also, always write the ITR, even if in ITR_IS_DYNAMIC

		 *   as there is no harm because the dynamic algorithm

		 *   will just overwrite.

	/* the number of queue vectors increased so write whatever is in

	 * the first element

 transmit */

 receive */

/**

 * ice_vsi_rebuild - Rebuild VSI after reset

 * @vsi: VSI to be rebuild

 * @init_vsi: is this an initialization or a reconfigure of the VSI

 *

 * Returns 0 on success and negative value on failure

	/* SR-IOV determines needed MSIX resources all at once instead of per

	 * VSI since when VFs are spawned we know how many VFs there are and how

	 * many interrupts each VF needs. SR-IOV MSIX resources are also

	 * cleared in the same manner.

 reclaim SW interrupts back to the common pool */

		/* return value check can be skipped here, it always returns

		 * 0 if reset is in progress

 Initialize VSI struct elements and create VSI in FW */

 ICE_VSI_CTRL does not need RSS so skip RSS processing */

			/* Do not exit if configuring RSS had an issue, at

			 * least receive traffic on first queue. Hence no

			 * need to capture return value

 configure VSI nodes based on number of queues and TC's */

		/* configure VSI nodes based on number of queues and TC's.

		 * ADQ creates VSIs for each TC/Channel but doesn't

		 * allocate queues instead it reconfigures the PF queues

		 * as per the TC command. So max_txqs should point to the

		 * PF Tx queues.

		/* If MQPRIO is set, means channel code path, hence for main

		 * VSI's, use TC as 1

/**

 * ice_is_reset_in_progress - check for a reset in progress

 * @state: PF state field

/**

 * ice_wait_for_reset - Wait for driver to finish reset and rebuild

 * @pf: pointer to the PF structure

 * @timeout: length of time to wait, in jiffies

 *

 * Wait (sleep) for a short time until the driver finishes cleaning up from

 * a device reset. The caller must be able to sleep. Use this to delay

 * operations that could fail while the driver is cleaning up after a device

 * reset.

 *

 * Returns 0 on success, -EBUSY if the reset is not finished within the

 * timeout, and -ERESTARTSYS if the thread was interrupted.

/**

 * ice_vsi_update_q_map - update our copy of the VSI info with new queue map

 * @vsi: VSI being configured

 * @ctx: the context buffer returned from AQ VSI update command

/**

 * ice_vsi_cfg_netdev_tc - Setup the netdev TC configuration

 * @vsi: the VSI being configured

 * @ena_tc: TC map to be enabled

 CHNL VSI doesn't have it's own netdev, hence, no netdev_tc */

 setup TC queue map for CHNL TCs */

 Get the mapped netdev TC# for the UP */

/**

 * ice_vsi_setup_q_map_mqprio - Prepares mqprio based tc_config

 * @vsi: the VSI being configured,

 * @ctxt: VSI context structure

 * @ena_tc: number of traffic classes to enable

 *

 * Prepares VSI tc_config to have queue configurations based on MQPRIO options.

 TC is not enabled */

 Set actual Tx/Rx queue pairs */

 Setup queue TC[0].qmap for given VSI context */

	/* Find queue count available for channel VSIs and starting offset

	 * for channel VSIs

/**

 * ice_vsi_cfg_tc - Configure VSI Tx Sched for given TC map

 * @vsi: VSI to be configured

 * @ena_tc: TC bitmap

 *

 * VSI queues expected to be quiesced before calling this function

 build bitmap of enabled TCs */

 populate max_txqs per TC */

		/* Update max_txqs if it is CHNL VSI, because alloc_t[r]xq are

		 * zero for CHNL VSI, hence use num_txq instead as max_txqs

 must to indicate which section of VSI context are being modified */

/**

 * ice_update_ring_stats - Update ring statistics

 * @stats: stats to be updated

 * @pkts: number of processed packets

 * @bytes: number of processed bytes

 *

 * This function assumes that caller has acquired a u64_stats_sync lock.

/**

 * ice_update_tx_ring_stats - Update Tx ring specific counters

 * @tx_ring: ring to update

 * @pkts: number of processed packets

 * @bytes: number of processed bytes

/**

 * ice_update_rx_ring_stats - Update Rx ring specific counters

 * @rx_ring: ring to update

 * @pkts: number of processed packets

 * @bytes: number of processed bytes

/**

 * ice_status_to_errno - convert from enum ice_status to Linux errno

 * @err: ice_status value to convert

/**

 * ice_is_dflt_vsi_in_use - check if the default forwarding VSI is being used

 * @sw: switch to check if its default forwarding VSI is free

 *

 * Return true if the default forwarding VSI is already being used, else returns

 * false signalling that it's available to use.

/**

 * ice_is_vsi_dflt_vsi - check if the VSI passed in is the default VSI

 * @sw: switch for the default forwarding VSI to compare against

 * @vsi: VSI to compare against default forwarding VSI

 *

 * If this VSI passed in is the default forwarding VSI then return true, else

 * return false

/**

 * ice_set_dflt_vsi - set the default forwarding VSI

 * @sw: switch used to assign the default forwarding VSI

 * @vsi: VSI getting set as the default forwarding VSI on the switch

 *

 * If the VSI passed in is already the default VSI and it's enabled just return

 * success.

 *

 * If there is already a default VSI on the switch and it's enabled then return

 * -EEXIST since there can only be one default VSI per switch.

 *

 *  Otherwise try to set the VSI passed in as the switch's default VSI and

 *  return the result.

 the VSI passed in is already the default VSI */

 another VSI is already the default VSI for this switch */

/**

 * ice_clear_dflt_vsi - clear the default forwarding VSI

 * @sw: switch used to clear the default VSI

 *

 * If the switch has no default VSI or it's not enabled then return error.

 *

 * Otherwise try to clear the default VSI and return the result.

 there is no default VSI configured */

/**

 * ice_get_link_speed_mbps - get link speed in Mbps

 * @vsi: the VSI whose link speed is being queried

 *

 * Return current VSI link speed and 0 if the speed is unknown.

/**

 * ice_get_link_speed_kbps - get link speed in Kbps

 * @vsi: the VSI whose link speed is being queried

 *

 * Return current VSI link speed and 0 if the speed is unknown.

/**

 * ice_set_min_bw_limit - setup minimum BW limit for Tx based on min_tx_rate

 * @vsi: VSI to be configured

 * @min_tx_rate: min Tx rate in Kbps to be configured as BW limit

 *

 * If the min_tx_rate is specified as 0 that means to clear the minimum BW limit

 * profile, otherwise a non-zero value will force a minimum BW limit for the VSI

 * on TC 0.

 Configure min BW for VSI limit */

/**

 * ice_set_max_bw_limit - setup maximum BW limit for Tx based on max_tx_rate

 * @vsi: VSI to be configured

 * @max_tx_rate: max Tx rate in Kbps to be configured as BW limit

 *

 * If the max_tx_rate is specified as 0 that means to clear the maximum BW limit

 * profile, otherwise a non-zero value will force a maximum BW limit for the VSI

 * on TC 0.

 Configure max BW for VSI limit */

/**

 * ice_set_link - turn on/off physical link

 * @vsi: VSI to modify physical link on

 * @ena: turn on/off physical link

	/* if link is owned by manageability, FW will return ICE_AQ_RC_EMODE.

	 * this is not a fatal error, so print a warning message and return

	 * a success code. Return an error if FW returns an error code other

	 * than ICE_AQ_RC_EMODE

/**

 * ice_is_feature_supported

 * @pf: pointer to the struct ice_pf instance

 * @f: feature enum to be checked

 *

 * returns true if feature is supported, false otherwise

/**

 * ice_set_feature_support

 * @pf: pointer to the struct ice_pf instance

 * @f: feature enum to set

/**

 * ice_clear_feature_support

 * @pf: pointer to the struct ice_pf instance

 * @f: feature enum to clear

/**

 * ice_init_feature_support

 * @pf: pointer to the struct ice_pf instance

 *

 * called during init to setup supported feature

/**

 * ice_vsi_update_security - update security block in VSI

 * @vsi: pointer to VSI structure

 * @fill: function pointer to fill ctx

/**

 * ice_vsi_ctx_set_antispoof - set antispoof function in VSI ctx

 * @ctx: pointer to VSI ctx structure

/**

 * ice_vsi_ctx_clear_antispoof - clear antispoof function in VSI ctx

 * @ctx: pointer to VSI ctx structure

/**

 * ice_vsi_ctx_set_allow_override - allow destination override on VSI

 * @ctx: pointer to VSI ctx structure

/**

 * ice_vsi_ctx_clear_allow_override - turn off destination override on VSI

 * @ctx: pointer to VSI ctx structure

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

/**

 * ice_aq_send_msg_to_vf

 * @hw: pointer to the hardware structure

 * @vfid: VF ID to send msg

 * @v_opcode: opcodes for VF-PF communication

 * @v_retval: return error code

 * @msg: pointer to the msg buffer

 * @msglen: msg length

 * @cd: pointer to command details

 *

 * Send message to VF driver (0x0802) using mailbox

 * queue and asynchronously sending message via

 * ice_sq_send_cmd() function

/**

 * ice_conv_link_speed_to_virtchnl

 * @adv_link_support: determines the format of the returned link speed

 * @link_speed: variable containing the link_speed to be converted

 *

 * Convert link speed supported by HW to link speed supported by virtchnl.

 * If adv_link_support is true, then return link speed in Mbps. Else return

 * link speed as a VIRTCHNL_LINK_SPEED_* casted to a u32. Note that the caller

 * needs to cast back to an enum virtchnl_link_speed in the case where

 * adv_link_support is false, but when adv_link_support is true the caller can

 * expect the speed in Mbps.

		/* Virtchnl speeds are not defined for every speed supported in

		 * the hardware. To maintain compatibility with older AVF

		 * drivers, while reporting the speed the new speed values are

		 * resolved to the closest known virtchnl speeds

/* The mailbox overflow detection algorithm helps to check if there

 * is a possibility of a malicious VF transmitting too many MBX messages to the

 * PF.

 * 1. The mailbox snapshot structure, ice_mbx_snapshot, is initialized during

 * driver initialization in ice_init_hw() using ice_mbx_init_snapshot().

 * The struct ice_mbx_snapshot helps to track and traverse a static window of

 * messages within the mailbox queue while looking for a malicious VF.

 *

 * 2. When the caller starts processing its mailbox queue in response to an

 * interrupt, the structure ice_mbx_snapshot is expected to be cleared before

 * the algorithm can be run for the first time for that interrupt. This can be

 * done via ice_mbx_reset_snapshot().

 *

 * 3. For every message read by the caller from the MBX Queue, the caller must

 * call the detection algorithm's entry function ice_mbx_vf_state_handler().

 * Before every call to ice_mbx_vf_state_handler() the struct ice_mbx_data is

 * filled as it is required to be passed to the algorithm.

 *

 * 4. Every time a message is read from the MBX queue, a VFId is received which

 * is passed to the state handler. The boolean output is_malvf of the state

 * handler ice_mbx_vf_state_handler() serves as an indicator to the caller

 * whether this VF is malicious or not.

 *

 * 5. When a VF is identified to be malicious, the caller can send a message

 * to the system administrator. The caller can invoke ice_mbx_report_malvf()

 * to help determine if a malicious VF is to be reported or not. This function

 * requires the caller to maintain a global bitmap to track all malicious VFs

 * and pass that to ice_mbx_report_malvf() along with the VFID which was identified

 * to be malicious by ice_mbx_vf_state_handler().

 *

 * 6. The global bitmap maintained by PF can be cleared completely if PF is in

 * reset or the bit corresponding to a VF can be cleared if that VF is in reset.

 * When a VF is shut down and brought back up, we assume that the new VF

 * brought up is not malicious and hence report it if found malicious.

 *

 * 7. The function ice_mbx_reset_snapshot() is called to reset the information

 * in ice_mbx_snapshot for every new mailbox interrupt handled.

 *

 * 8. The memory allocated for variables in ice_mbx_snapshot is de-allocated

 * when driver is unloaded.

/* Using the highest value for an unsigned 16-bit value 0xFFFF to indicate that

 * the max messages check must be ignored in the algorithm

/**

 * ice_mbx_traverse - Pass through mailbox snapshot

 * @hw: pointer to the HW struct

 * @new_state: new algorithm state

 *

 * Traversing the mailbox static snapshot without checking

 * for malicious VFs.

	/* As mailbox buffer is circular, applying a mask

	 * on the incremented iteration count.

	/* Checking either of the below conditions to exit snapshot traversal:

	 * Condition-1: If the number of iterations in the mailbox is equal to

	 * the mailbox head which would indicate that we have reached the end

	 * of the static snapshot.

	 * Condition-2: If the maximum messages serviced in the mailbox for a

	 * given interrupt is the highest possible value then there is no need

	 * to check if the number of messages processed is equal to it. If not

	 * check if the number of messages processed is greater than or equal

	 * to the maximum number of mailbox entries serviced in current work item.

/**

 * ice_mbx_detect_malvf - Detect malicious VF in snapshot

 * @hw: pointer to the HW struct

 * @vf_id: relative virtual function ID

 * @new_state: new algorithm state

 * @is_malvf: boolean output to indicate if VF is malicious

 *

 * This function tracks the number of asynchronous messages

 * sent per VF and marks the VF as malicious if it exceeds

 * the permissible number of messages to send.

 increment the message count in the VF array */

 continue to iterate through the mailbox snapshot */

/**

 * ice_mbx_reset_snapshot - Reset mailbox snapshot structure

 * @snap: pointer to mailbox snapshot structure in the ice_hw struct

 *

 * Reset the mailbox snapshot structure and clear VF counter array.

 Clear VF counters. */

 Reset mailbox snapshot for a new capture. */

/**

 * ice_mbx_vf_state_handler - Handle states of the overflow algorithm

 * @hw: pointer to the HW struct

 * @mbx_data: pointer to structure containing mailbox data

 * @vf_id: relative virtual function (VF) ID

 * @is_malvf: boolean output to indicate if VF is malicious

 *

 * The function serves as an entry point for the malicious VF

 * detection algorithm by handling the different states and state

 * transitions of the algorithm:

 * New snapshot: This state is entered when creating a new static

 * snapshot. The data from any previous mailbox snapshot is

 * cleared and a new capture of the mailbox head and tail is

 * logged. This will be the new static snapshot to detect

 * asynchronous messages sent by VFs. On capturing the snapshot

 * and depending on whether the number of pending messages in that

 * snapshot exceed the watermark value, the state machine enters

 * traverse or detect states.

 * Traverse: If pending message count is below watermark then iterate

 * through the snapshot without any action on VF.

 * Detect: If pending message count exceeds watermark traverse

 * the static snapshot and look for a malicious VF.

	/* When entering the mailbox state machine assume that the VF

	 * is not malicious until detected.

	 /* Checking if max messages allowed to be processed while servicing current

	  * interrupt is not less than the defined AVF message threshold.

	/* The watermark value should not be lesser than the threshold limit

	 * set for the number of asynchronous messages a VF can send to mailbox

	 * nor should it be greater than the maximum number of messages in the

	 * mailbox serviced in current interrupt.

 Clear any previously held data in mailbox snapshot structure. */

		/* Collect the pending ARQ count, number of messages processed and

		 * the maximum number of messages allowed to be processed from the

		 * Mailbox for current interrupt.

		/* Capture a new static snapshot of the mailbox by logging the

		 * head and tail of snapshot and set num_iterations to the tail

		 * value to mark the start of the iteration through the snapshot.

		/* Pending ARQ messages returned by ice_clean_rq_elem

		 * is the difference between the head and tail of the

		 * mailbox queue. Comparing this value against the watermark

		 * helps to check if we potentially have malicious VFs.

/**

 * ice_mbx_report_malvf - Track and note malicious VF

 * @hw: pointer to the HW struct

 * @all_malvfs: all malicious VFs tracked by PF

 * @bitmap_len: length of bitmap in bits

 * @vf_id: relative virtual function ID of the malicious VF

 * @report_malvf: boolean to indicate if malicious VF must be reported

 *

 * This function will update a bitmap that keeps track of the malicious

 * VFs attached to the PF. A malicious VF must be reported only once if

 * discovered between VF resets or loading so the function checks

 * the input vf_id against the bitmap to verify if the VF has been

 * detected in any previous mailbox iterations.

 If the vf_id is found in the bitmap set bit and boolean to true */

/**

 * ice_mbx_clear_malvf - Clear VF bitmap and counter for VF ID

 * @snap: pointer to the mailbox snapshot structure

 * @all_malvfs: all malicious VFs tracked by PF

 * @bitmap_len: length of bitmap in bits

 * @vf_id: relative virtual function ID of the malicious VF

 *

 * In case of a VF reset, this function can be called to clear

 * the bit corresponding to the VF ID in the bitmap tracking all

 * malicious VFs attached to the PF. The function also clears the

 * VF counter array at the index of the VF ID. This is to ensure

 * that the new VF loaded is not considered malicious before going

 * through the overflow detection algorithm.

 Ensure VF ID value is not larger than bitmap or VF counter length */

 Clear VF ID bit in the bitmap tracking malicious VFs attached to PF */

	/* Clear the VF counter in the mailbox snapshot structure for that VF ID.

	 * This is to ensure that if a VF is unloaded and a new one brought back

	 * up with the same VF ID for a snapshot currently in traversal or detect

	 * state the counter for that VF ID does not increment on top of existing

	 * values in the mailbox overflow detection algorithm.

/**

 * ice_mbx_init_snapshot - Initialize mailbox snapshot structure

 * @hw: pointer to the hardware structure

 * @vf_count: number of VFs allocated on a PF

 *

 * Clear the mailbox snapshot structure and allocate memory

 * for the VF counter array based on the number of VFs allocated

 * on that PF.

 *

 * Assumption: This function will assume ice_get_caps() has already been

 * called to ensure that the vf_count can be compared against the number

 * of VFs supported as defined in the functional capabilities of the device.

	/* Ensure that the number of VFs allocated is non-zero and

	 * is not greater than the number of supported VFs defined in

	 * the functional capabilities of the PF.

	/* Setting the VF counter length to the number of allocated

	 * VFs for given PF's functional capabilities.

	/* Clear mbx_buf in the mailbox snaphot structure and setting the

	 * mailbox snapshot state to a new capture.

/**

 * ice_mbx_deinit_snapshot - Free mailbox snapshot structure

 * @hw: pointer to the hardware structure

 *

 * Clear the mailbox snapshot structure and free the VF counter array.

 Free VF counter array and reset VF counter length */

 Clear mbx_buf in the mailbox snaphot structure */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2021, Intel Corporation. */

 name    idx   func         chan */

/**

 * ice_get_sma_config_e810t

 * @hw: pointer to the hw struct

 * @ptp_pins: pointer to the ptp_pin_desc struture

 *

 * Read the configuration of the SMA control logic and put it into the

 * ptp_pin_desc structure

 Read initial pin state */

 initialize with defaults */

 Parse SMA1/UFL1 */

 Parse SMA2/UFL2 */

/**

 * ice_ptp_set_sma_config_e810t

 * @hw: pointer to the hw struct

 * @ptp_pins: pointer to the ptp_pin_desc struture

 *

 * Set the configuration of the SMA control logic based on the configuration in

 * num_pins parameter

 SMA1 and UFL1 cannot be set to TX at the same time */

 SMA2 and UFL2 cannot be set to RX at the same time */

 Read initial pin state value */

 Set the right sate based on the desired configuration */

 U.FL 1 TX will always enable SMA 1 RX */

/**

 * ice_ptp_set_sma_e810t

 * @info: the driver's PTP info structure

 * @pin: pin index in kernel structure

 * @func: Pin function to be set (PTP_PF_NONE, PTP_PF_EXTTS or PTP_PF_PEROUT)

 *

 * Set the configuration of a single SMA pin

 Disable the same function on the other pin sharing the channel */

 Set up new pin function in the temp table */

/**

 * ice_verify_pin_e810t

 * @info: the driver's PTP info structure

 * @pin: Pin index

 * @func: Assigned function

 * @chan: Assigned channel

 *

 * Verify if pin supports requested pin function. If the Check pins consistency.

 * Reconfigure the SMA logic attached to the given pin to enable its

 * desired functionality

 Don't allow channel reassignment */

 Check if functions are properly assigned */

/**

 * ice_set_tx_tstamp - Enable or disable Tx timestamping

 * @pf: The PF pointer to search in

 * @on: bool value for whether timestamps are enabled or disabled

 Set the timestamp enable flag for all the Tx rings */

 Configure the Tx timestamp interrupt */

/**

 * ice_set_rx_tstamp - Enable or disable Rx timestamping

 * @pf: The PF pointer to search in

 * @on: bool value for whether timestamps are enabled or disabled

 Set the timestamp flag for all the Rx rings */

/**

 * ice_ptp_cfg_timestamp - Configure timestamp for init/deinit

 * @pf: Board private structure

 * @ena: bool value to enable or disable time stamp

 *

 * This function will configure timestamping during PTP initialization

 * and deinitialization

/**

 * ice_get_ptp_clock_index - Get the PTP clock index

 * @pf: the PF pointer

 *

 * Determine the clock index of the PTP clock associated with this device. If

 * this is the PF controlling the clock, just use the local access to the

 * clock device pointer.

 *

 * Otherwise, read from the driver shared parameters to determine the clock

 * index value.

 *

 * Returns: the index of the PTP clock associated with this device, or -1 if

 * there is no associated clock.

 Use the ptp_clock structure if we're the main PF */

	/* The PTP clock index is an integer, and will be between 0 and

	 * INT_MAX. The highest bit of the driver shared parameter is used to

	 * indicate whether or not the currently stored clock index is valid.

/**

 * ice_set_ptp_clock_index - Set the PTP clock index

 * @pf: the PF pointer

 *

 * Set the PTP clock index for this device into the shared driver parameters,

 * so that other PFs associated with this device can read it.

 *

 * If the PF is unable to store the clock index, it will log an error, but

 * will continue operating PTP.

/**

 * ice_clear_ptp_clock_index - Clear the PTP clock index

 * @pf: the PF pointer

 *

 * Clear the PTP clock index for this device. Must be called when

 * unregistering the PTP clock, in order to ensure other PFs stop reporting

 * a clock object that no longer exists.

 Do not clear the index if we don't own the timer */

/**

 * ice_ptp_read_src_clk_reg - Read the source clock register

 * @pf: Board private structure

 * @sts: Optional parameter for holding a pair of system timestamps from

 *       the system clock. Will be ignored if NULL is given.

 Read the system timestamp pre PHC read */

 Read the system timestamp post PHC read */

		/* if TIME_L rolled over read TIME_L again and update

		 * system timestamps

/**

 * ice_ptp_update_cached_phctime - Update the cached PHC time values

 * @pf: Board specific private structure

 *

 * This function updates the system time values which are cached in the PF

 * structure and the Rx rings.

 *

 * This function must be called periodically to ensure that the cached value

 * is never more than 2 seconds old. It must also be called whenever the PHC

 * time has been changed.

 Read the current PHC time */

 Update the cached PHC time stored in the PF structure */

/**

 * ice_ptp_extend_32b_ts - Convert a 32b nanoseconds timestamp to 64b

 * @cached_phc_time: recently cached copy of PHC time

 * @in_tstamp: Ingress/egress 32b nanoseconds timestamp value

 *

 * Hardware captures timestamps which contain only 32 bits of nominal

 * nanoseconds, as opposed to the 64bit timestamps that the stack expects.

 * Note that the captured timestamp values may be 40 bits, but the lower

 * 8 bits are sub-nanoseconds and generally discarded.

 *

 * Extend the 32bit nanosecond timestamp using the following algorithm and

 * assumptions:

 *

 * 1) have a recently cached copy of the PHC time

 * 2) assume that the in_tstamp was captured 2^31 nanoseconds (~2.1

 *    seconds) before or after the PHC time was captured.

 * 3) calculate the delta between the cached time and the timestamp

 * 4) if the delta is smaller than 2^31 nanoseconds, then the timestamp was

 *    captured after the PHC time. In this case, the full timestamp is just

 *    the cached PHC time plus the delta.

 * 5) otherwise, if the delta is larger than 2^31 nanoseconds, then the

 *    timestamp was captured *before* the PHC time, i.e. because the PHC

 *    cache was updated after the timestamp was captured by hardware. In this

 *    case, the full timestamp is the cached time minus the inverse delta.

 *

 * This algorithm works even if the PHC time was updated after a Tx timestamp

 * was requested, but before the Tx timestamp event was reported from

 * hardware.

 *

 * This calculation primarily relies on keeping the cached PHC time up to

 * date. If the timestamp was captured more than 2^31 nanoseconds after the

 * PHC time, it is possible that the lower 32bits of PHC time have

 * overflowed more than once, and we might generate an incorrect timestamp.

 *

 * This is prevented by (a) periodically updating the cached PHC time once

 * a second, and (b) discarding any Tx timestamp packet if it has waited for

 * a timestamp for more than one second.

 Extract the lower 32 bits of the PHC time */

	/* Calculate the delta between the lower 32bits of the cached PHC

	 * time and the in_tstamp value

	/* Do not assume that the in_tstamp is always more recent than the

	 * cached PHC time. If the delta is large, it indicates that the

	 * in_tstamp was taken in the past, and should be converted

	 * forward.

 reverse the delta calculation here */

/**

 * ice_ptp_extend_40b_ts - Convert a 40b timestamp to 64b nanoseconds

 * @pf: Board private structure

 * @in_tstamp: Ingress/egress 40b timestamp value

 *

 * The Tx and Rx timestamps are 40 bits wide, including 32 bits of nominal

 * nanoseconds, 7 bits of sub-nanoseconds, and a valid bit.

 *

 *  *--------------------------------------------------------------*

 *  | 32 bits of nanoseconds | 7 high bits of sub ns underflow | v |

 *  *--------------------------------------------------------------*

 *

 * The low bit is an indicator of whether the timestamp is valid. The next

 * 7 bits are a capture of the upper 7 bits of the sub-nanosecond underflow,

 * and the remaining 32 bits are the lower 32 bits of the PHC timer.

 *

 * It is assumed that the caller verifies the timestamp is valid prior to

 * calling this function.

 *

 * Extract the 32bit nominal nanoseconds and extend them. Use the cached PHC

 * time stored in the device private PTP structure as the basis for timestamp

 * extension.

 *

 * See ice_ptp_extend_32b_ts for a detailed explanation of the extension

 * algorithm.

/**

 * ice_ptp_read_time - Read the time from the device

 * @pf: Board private structure

 * @ts: timespec structure to hold the current time value

 * @sts: Optional parameter for holding a pair of system timestamps from

 *       the system clock. Will be ignored if NULL is given.

 *

 * This function reads the source clock registers and stores them in a timespec.

 * However, since the registers are 64 bits of nanoseconds, we must convert the

 * result to a timespec before we can return.

/**

 * ice_ptp_write_init - Set PHC time to provided value

 * @pf: Board private structure

 * @ts: timespec structure that holds the new time value

 *

 * Set the PHC time to the specified time provided in the timespec.

/**

 * ice_ptp_write_adj - Adjust PHC clock time atomically

 * @pf: Board private structure

 * @adj: Adjustment in nanoseconds

 *

 * Perform an atomic adjustment of the PHC time by the specified number of

 * nanoseconds.

/**

 * ice_ptp_adjfine - Adjust clock increment rate

 * @info: the driver's PTP info structure

 * @scaled_ppm: Parts per million with 16-bit fractional field

 *

 * Adjust the frequency of the clock by the indicated scaled ppm from the

 * base frequency.

		/* handle overflow by scaling down the scaled_ppm and

		 * the divisor, losing some precision

/**

 * ice_ptp_extts_work - Workqueue task function

 * @work: external timestamp work structure

 *

 * Service for PTP external clock event

	/* Event time is captured by one of the two matched registers

	 *      GLTSYN_EVNT_L: 32 LSB of sampled time event

	 *      GLTSYN_EVNT_H: 32 MSB of sampled time event

	 * Event is defined in GLTSYN_EVNT_0 register

 Check if channel is enabled */

 Fire event */

/**

 * ice_ptp_cfg_extts - Configure EXTTS pin and channel

 * @pf: Board private structure

 * @ena: true to enable; false to disable

 * @chan: GPIO channel (0-3)

 * @gpio_pin: GPIO pin

 * @extts_flags: request flags from the ptp_extts_request.flags

 Enable the interrupt */

 set event level to requested edge */

		/* Write GPIO CTL reg.

		 * 0x1 is input sampled by EVENT register(channel)

		 * + num_in_channels * tmr_idx

 clear the values we set to reset defaults */

/**

 * ice_ptp_cfg_clkout - Configure clock to generate periodic wave

 * @pf: Board private structure

 * @chan: GPIO channel (0-3)

 * @config: desired periodic clk configuration. NULL will disable channel

 * @store: If set to true the values will be stored

 *

 * Configure the internal clock generator modules to generate the clock wave of

 * specified period.

 0. Reset mode & out_en in AUX_OUT */

	/* If we're disabling the output, clear out CLKO and TGT and keep

	 * output level low

 Store the value if requested */

 1. Write clkout with half of required period value */

	/* For proper operation, the GLTSYN_CLKO must be larger than clock tick

 Allow time for programming before start_time is hit */

	/* if start time is in the past start the timer at the nearest second

	 * maintaining phase

 2. Write TARGET time */

 3. Write AUX_OUT register */

 4. write GPIO CTL reg */

 Store the value if requested */

/**

 * ice_ptp_disable_all_clkout - Disable all currently configured outputs

 * @pf: pointer to the PF structure

 *

 * Disable all currently configured clock outputs. This is necessary before

 * certain changes to the PTP hardware clock. Use ice_ptp_enable_all_clkout to

 * re-enable the clocks again.

/**

 * ice_ptp_enable_all_clkout - Enable all configured periodic clock outputs

 * @pf: pointer to the PF structure

 *

 * Enable all currently configured clock outputs. Use this after

 * ice_ptp_disable_all_clkout to reconfigure the output signals according to

 * their configuration.

/**

 * ice_ptp_gpio_enable_e810 - Enable/disable ancillary features of PHC

 * @info: the driver's PTP info structure

 * @rq: The requested feature to change

 * @on: Enable/disable flag

/**

 * ice_ptp_gettimex64 - Get the time of the clock

 * @info: the driver's PTP info structure

 * @ts: timespec64 structure to hold the current time value

 * @sts: Optional parameter for holding a pair of system timestamps from

 *       the system clock. Will be ignored if NULL is given.

 *

 * Read the device clock and return the correct value on ns, after converting it

 * into a timespec struct.

/**

 * ice_ptp_settime64 - Set the time of the clock

 * @info: the driver's PTP info structure

 * @ts: timespec64 structure that holds the new time value

 *

 * Set the device clock to the user input value. The conversion from timespec

 * to ns happens in the write function.

 Disable periodic outputs */

 Reenable periodic outputs */

/**

 * ice_ptp_adjtime_nonatomic - Do a non-atomic clock adjustment

 * @info: the driver's PTP info structure

 * @delta: Offset in nanoseconds to adjust the time by

/**

 * ice_ptp_adjtime - Adjust the time of the clock by the indicated delta

 * @info: the driver's PTP info structure

 * @delta: Offset in nanoseconds to adjust the time by

	/* Hardware only supports atomic adjustments using signed 32-bit

	 * integers. For any adjustment outside this range, perform

	 * a non-atomic get->adjust->set flow.

 Disable periodic outputs */

 Reenable periodic outputs */

/**

 * ice_ptp_get_ts_config - ioctl interface to read the timestamping config

 * @pf: Board private structure

 * @ifr: ioctl data

 *

 * Copy the timestamping config to user buffer

/**

 * ice_ptp_set_timestamp_mode - Setup driver for requested timestamp mode

 * @pf: Board private structure

 * @config: hwtstamp settings requested or saved

 Reserved for future extensions. */

/**

 * ice_ptp_set_ts_config - ioctl interface to control the timestamping

 * @pf: Board private structure

 * @ifr: ioctl data

 *

 * Get the user config and store it

 Save these settings for future reference */

/**

 * ice_ptp_rx_hwtstamp - Check for an Rx timestamp

 * @rx_ring: Ring to get the VSI info

 * @rx_desc: Receive descriptor

 * @skb: Particular skb to send timestamp with

 *

 * The driver receives a notification in the receive descriptor with timestamp.

 * The timestamp is in ns, so we must convert the result first.

 Populate timesync data into skb */

		/* Use ice_ptp_extend_32b_ts directly, using the ring-specific

		 * cached PHC value, rather than accessing the PF. This also

		 * allows us to simply pass the upper 32bits of nanoseconds

		 * directly. Calling ice_ptp_extend_40b_ts is unnecessary as

		 * it would just discard these bits itself.

/**

 * ice_ptp_disable_sma_pins_e810t - Disable E810-T SMA pins

 * @pf: pointer to the PF structure

 * @info: PTP clock info structure

 *

 * Disable the OS access to the SMA pins. Called to clear out the OS

 * indications of pin support when we fail to setup the E810-T SMA control

 * register.

/**

 * ice_ptp_setup_sma_pins_e810t - Setup the SMA pins

 * @pf: pointer to the PF structure

 * @info: PTP clock info structure

 *

 * Finish setting up the SMA pins by allocating pin_config, and setting it up

 * according to the current status of the SMA. On failure, disable all of the

 * extended SMA pin support.

 Allocate memory for kernel pins interface */

 Read current SMA status */

/**

 * ice_ptp_setup_pins_e810t - Setup PTP pins in sysfs

 * @pf: pointer to the PF instance

 * @info: PTP clock capabilities

 Check if SMA controller is in the netlist */

 Complete setup of the SMA pins */

/**

 * ice_ptp_setup_pins_e810 - Setup PTP pins in sysfs

 * @info: PTP clock capabilities

/**

 * ice_ptp_set_funcs_e810 - Set specialized functions for E810 support

 * @pf: Board private structure

 * @info: PTP info to fill

 *

 * Assign functions to the PTP capabiltiies structure for E810 devices.

 * Functions which operate across all device families should be set directly

 * in ice_ptp_set_caps. Only add functions here which are distinct for e810

 * devices.

/**

 * ice_ptp_set_caps - Set PTP capabilities

 * @pf: Board private structure

/**

 * ice_ptp_create_clock - Create PTP clock device for userspace

 * @pf: Board private structure

 *

 * This function creates a new PTP clock device. It only creates one if we

 * don't already have one. Will return error if it can't create one, but success

 * if we already have a device. Should be used by ice_ptp_init to create clock

 * initially, and prevent global resets from creating new clock devices.

 No need to create a clock device if we already have one */

 Attempt to register the clock before enabling the hardware. */

/**

 * ice_ptp_tx_tstamp_work - Process Tx timestamps for a port

 * @work: pointer to the kthread_work struct

 *

 * Process timestamps captured by the PHY associated with this port. To do

 * this, loop over each index with a waiting skb.

 *

 * If a given index has a valid timestamp, perform the following steps:

 *

 * 1) copy the timestamp out of the PHY register

 * 4) clear the timestamp valid bit in the PHY register

 * 5) unlock the index by clearing the associated in_use bit.

 * 2) extend the 40b timestamp value to get a 64bit timestamp

 * 3) send that timestamp to the stack

 *

 * After looping, if we still have waiting SKBs, then re-queue the work. This

 * may cause us effectively poll even when not strictly necessary. We do this

 * because it's possible a new timestamp was requested around the same time as

 * the interrupt. In some cases hardware might not interrupt us again when the

 * timestamp is captured.

 *

 * Note that we only take the tracking lock when clearing the bit and when

 * checking if we need to re-queue this task. The only place where bits can be

 * set is the hard xmit routine where an SKB has a request flag set. The only

 * places where we clear bits are this work function, or the periodic cleanup

 * thread. If the cleanup thread clears a bit we're processing we catch it

 * when we lock to clear the bit and then grab the SKB pointer. If a Tx thread

 * starts a new timestamp, we might not begin processing it right away but we

 * will notice it at the end when we re-queue the work item. If a Tx thread

 * starts a new timestamp just after this function exits without re-queuing,

 * the interrupt when the timestamp finishes should trigger. Avoiding holding

 * the lock for the entire function is important in order to ensure that Tx

 * threads do not get blocked while waiting for the lock.

 Check if the timestamp is valid */

		/* clear the timestamp register, so that it won't show valid

		 * again when re-used.

		/* The timestamp is valid, so we'll go ahead and clear this

		 * index and then send the timestamp up to the stack.

		/* it's (unlikely but) possible we raced with the cleanup

		 * thread for discarding old timestamp requests.

 Extend the timestamp using cached PHC time */

	/* Check if we still have work to do. If so, re-queue this task to

	 * poll for remaining timestamps.

/**

 * ice_ptp_request_ts - Request an available Tx timestamp index

 * @tx: the PTP Tx timestamp tracker to request from

 * @skb: the SKB to associate with this timestamp request

 Check if this tracker is initialized */

 Find and set the first available index */

		/* We got a valid index that no other thread could have set. Store

		 * a reference to the skb and the start time to allow discarding old

		 * requests.

	/* return the appropriate PHY timestamp register index, -1 if no

	 * indexes were available.

/**

 * ice_ptp_process_ts - Spawn kthread work to handle timestamps

 * @pf: Board private structure

 *

 * Queue work required to process the PTP Tx timestamps outside of interrupt

 * context.

/**

 * ice_ptp_alloc_tx_tracker - Initialize tracking for Tx timestamps

 * @tx: Tx tracking structure to initialize

 *

 * Assumes that the length has already been initialized. Do not call directly,

 * use the ice_ptp_init_tx_e822 or ice_ptp_init_tx_e810 instead.

/**

 * ice_ptp_flush_tx_tracker - Flush any remaining timestamps from the tracker

 * @pf: Board private structure

 * @tx: the tracker to flush

 Clear any potential residual timestamp in the PHY block */

/**

 * ice_ptp_release_tx_tracker - Release allocated memory for Tx tracker

 * @pf: Board private structure

 * @tx: Tx tracking structure to release

 *

 * Free memory associated with the Tx timestamp tracker.

/**

 * ice_ptp_init_tx_e810 - Initialize tracking for Tx timestamps

 * @pf: Board private structure

 * @tx: the Tx tracking structure to initialize

 *

 * Initialize the Tx timestamp tracker for this PF. For E810 devices, each

 * port has its own block of timestamps, independent of the other ports.

/**

 * ice_ptp_tx_tstamp_cleanup - Cleanup old timestamp requests that got dropped

 * @tx: PTP Tx tracker to clean up

 *

 * Loop through the Tx timestamp requests and see if any of them have been

 * waiting for a long time. Discard any SKBs that have been waiting for more

 * than 2 seconds. This is long enough to be reasonably sure that the

 * timestamp will never be captured. This might happen if the packet gets

 * discarded before it reaches the PHY timestamping block.

 Check if this SKB has been waiting for too long */

 Free the SKB after we've cleared the bit */

 Run twice a second */

/**

 * ice_ptp_init_owner - Initialize PTP_1588_CLOCK device

 * @pf: Board private structure

 *

 * Setup and initialize a PTP clock device that represents the device hardware

 * clock. Save the clock index for other functions connected to the same

 * hardware resource.

 Clear some HW residue and enable source clock */

 Enable source clocks */

 Enable PHY time sync */

 Clear event status indications for auxiliary pins */

 Acquire the global hardware lock */

 Write the increment time value to PHY and LAN */

 Write the initial Time value to PHY and LAN */

 Release the global hardware lock */

 Ensure we have a clock device */

 Store the PTP clock index for other PFs */

/**

 * ice_ptp_init - Initialize the PTP support after device probe or reset

 * @pf: Board private structure

 *

 * This function sets device up for PTP support. The first time it is run, it

 * will create a clock device. It does not create a clock device if one

 * already exists. It also reconfigures the device after a reset.

 PTP is currently only supported on E810 devices */

 Check if this PF owns the source timer */

 Disable timestamping for both Tx and Rx */

 Initialize the PTP port Tx timestamp tracker */

 Initialize work functions */

	/* Allocate a kworker for handling work required for the ports

	 * connected to the PTP hardware clock.

 Start periodic work going */

 If we registered a PTP clock, release it */

/**

 * ice_ptp_release - Disable the driver/HW support and unregister the clock

 * @pf: Board private structure

 *

 * This function handles the cleanup work required from the initialization by

 * clearing out the important information and unregistering the clock

 Disable timestamping for both Tx and Rx */

 Disable periodic outputs */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2019-2021, Intel Corporation. */

/**

 * ice_repr_get_sw_port_id - get port ID associated with representor

 * @repr: pointer to port representor

/**

 * ice_repr_get_phys_port_name - get phys port name

 * @netdev: pointer to port representor netdev

 * @buf: write here port name

 * @len: max length of buf

 Devlink port is registered and devlink core is taking care of name formatting. */

/**

 * ice_repr_get_stats64 - get VF stats for VFPR use

 * @netdev: pointer to port representor netdev

 * @stats: pointer to struct where stats can be stored

/**

 * ice_netdev_to_repr - Get port representor for given netdevice

 * @netdev: pointer to port representor netdev

/**

 * ice_repr_open - Enable port representor's network interface

 * @netdev: network interface device structure

 *

 * The open entry point is called when a port representor's network

 * interface is made active by the system (IFF_UP). Corresponding

 * VF is notified about link status change.

 *

 * Returns 0 on success

/**

 * ice_repr_stop - Disable port representor's network interface

 * @netdev: network interface device structure

 *

 * The stop entry point is called when a port representor's network

 * interface is de-activated by the system. Corresponding

 * VF is notified about link status change.

 *

 * Returns 0 on success

/**

 * ice_is_port_repr_netdev - Check if a given netdevice is a port representor netdev

 * @netdev: pointer to netdev

/**

 * ice_repr_reg_netdev - register port representor netdev

 * @netdev: pointer to port representor netdev

/**

 * ice_repr_add - add representor for VF

 * @vf: pointer to VF structure

/**

 * ice_repr_rem - remove representor from VF

 * @vf: pointer to VF structure

/**

 * ice_repr_add_for_all_vfs - add port representor for all VFs

 * @pf: pointer to PF structure

/**

 * ice_repr_rem_from_all_vfs - remove port representor for all VFs

 * @pf: pointer to PF structure

/**

 * ice_repr_start_tx_queues - start Tx queues of port representor

 * @repr: pointer to repr structure

/**

 * ice_repr_stop_tx_queues - stop Tx queues of port representor

 * @repr: pointer to repr structure

/**

 * ice_repr_set_traffic_vsi - set traffic VSI for port representor

 * @repr: repr on with VSI will be set

 * @vsi: pointer to VSI that will be used by port representor to pass traffic

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018-2020, Intel Corporation. */

/**

 * ice_is_arfs_active - helper to check is aRFS is active

 * @vsi: VSI to check

/**

 * ice_is_arfs_using_perfect_flow - check if aRFS has active perfect filters

 * @hw: pointer to the HW structure

 * @flow_type: flow type as Flow Director understands it

 *

 * Flow Director will query this function to see if aRFS is currently using

 * the specified flow_type for perfect (4-tuple) filters.

 active counters can be updated by multiple CPUs */

/**

 * ice_arfs_update_active_fltr_cntrs - update active filter counters for aRFS

 * @vsi: VSI that aRFS is active on

 * @entry: aRFS entry used to change counters

 * @add: true to increment counter, false to decrement

/**

 * ice_arfs_del_flow_rules - delete the rules passed in from HW

 * @vsi: VSI for the flow rules that need to be deleted

 * @del_list_head: head of the list of ice_arfs_entry(s) for rule deletion

 *

 * Loop through the delete list passed in and remove the rules from HW. After

 * each rule is deleted, disconnect and free the ice_arfs_entry because it is no

 * longer being referenced by the aRFS hash table.

 The aRFS hash table is no longer referencing this entry */

/**

 * ice_arfs_add_flow_rules - add the rules passed in from HW

 * @vsi: VSI for the flow rules that need to be added

 * @add_list_head: head of the list of ice_arfs_entry_ptr(s) for rule addition

 *

 * Loop through the add list passed in and remove the rules from HW. After each

 * rule is added, disconnect and free the ice_arfs_entry_ptr node. Don't free

 * the ice_arfs_entry(s) because they are still being referenced in the aRFS

 * hash table.

/**

 * ice_arfs_is_flow_expired - check if the aRFS entry has expired

 * @vsi: VSI containing the aRFS entry

 * @arfs_entry: aRFS entry that's being checked for expiration

 *

 * Return true if the flow has expired, else false. This function should be used

 * to determine whether or not an aRFS entry should be removed from the hardware

 * and software structures.

 expiration timer only used for UDP filters */

/**

 * ice_arfs_update_flow_rules - add/delete aRFS rules in HW

 * @vsi: the VSI to be forwarded to

 * @idx: index into the table of aRFS filter lists. Obtained from skb->hash

 * @add_list: list to populate with filters to be added to Flow Director

 * @del_list: list to populate with filters to be deleted from Flow Director

 *

 * Iterate over the hlist at the index given in the aRFS hash table and

 * determine if there are any aRFS entries that need to be either added or

 * deleted in the HW. If the aRFS entry is marked as ICE_ARFS_INACTIVE the

 * filter needs to be added to HW, else if it's marked as ICE_ARFS_ACTIVE and

 * the flow has expired delete the filter from HW. The caller of this function

 * is expected to add/delete rules on the add_list/del_list respectively.

 go through the aRFS hlist at this idx and check for needed updates */

 check if filter needs to be added to HW */

 reference aRFS entry to add HW filter */

 expiration timer only used for UDP flows */

 check if filter needs to be removed from HW */

				/* remove aRFS entry from hash table for delete

				 * and to prevent referencing it the next time

				 * through this hlist index

 save reference to aRFS entry for delete */

/**

 * ice_sync_arfs_fltrs - update all aRFS filters

 * @pf: board private structure

 Once we process aRFS for the PF VSI get out */

 use list of ice_arfs_entry(s) for delete */

 use list of ice_arfs_entry_ptr(s) for add */

/**

 * ice_arfs_build_entry - builds an aRFS entry based on input

 * @vsi: destination VSI for this flow

 * @fk: flow dissector keys for creating the tuple

 * @rxq_idx: Rx queue to steer this flow to

 * @flow_id: passed down from the stack and saved for flow expiration

 *

 * returns an aRFS entry on success and NULL on failure

 ETH_P_IPV6 */

/**

 * ice_arfs_is_perfect_flow_set - Check to see if perfect flow is set

 * @hw: pointer to HW structure

 * @l3_proto: ETH_P_IP or ETH_P_IPV6 in network order

 * @l4_proto: IPPROTO_UDP or IPPROTO_TCP

 *

 * We only support perfect (4-tuple) filters for aRFS. This function allows aRFS

 * to check if perfect (4-tuple) flow rules are currently in place by Flow

 * Director.

 advanced Flow Director disabled, perfect filters always supported */

/**

 * ice_rx_flow_steer - steer the Rx flow to where application is being run

 * @netdev: ptr to the netdev being adjusted

 * @skb: buffer with required header information

 * @rxq_idx: queue to which the flow needs to move

 * @flow_id: flow identifier provided by the netdev

 *

 * Based on the skb, rxq_idx, and flow_id passed in add/update an entry in the

 * aRFS hash table. Iterate over one of the hlists in the aRFS hash table and

 * if the flow_id already exists in the hash table but the rxq_idx has changed

 * mark the entry as ICE_ARFS_INACTIVE so it can get updated in HW, else

 * if the entry is marked as ICE_ARFS_TODEL delete it from the aRFS hash table.

 * If neither of the previous conditions are true then add a new entry in the

 * aRFS hash table, which gets set to ICE_ARFS_INACTIVE by default so it can be

 * added to HW.

 failed to allocate memory for aRFS so don't crash */

 Support only IPV4 and IPV6 */

 Support only TCP and UDP */

 only support 4-tuple filters for aRFS */

 choose the aRFS list bucket based on skb hash */

 search for entry in the bucket */

 keep searching for the already existing arfs_entry flow */

 update the queue to forward to on an already existing flow */

/**

 * ice_init_arfs_cntrs - initialize aRFS counter values

 * @vsi: VSI that aRFS counters need to be initialized on

/**

 * ice_init_arfs - initialize aRFS resources

 * @vsi: the VSI to be forwarded to

/**

 * ice_clear_arfs - clear the aRFS hash table and any memory used for aRFS

 * @vsi: the VSI to be forwarded to

/**

 * ice_free_cpu_rx_rmap - free setup CPU reverse map

 * @vsi: the VSI to be forwarded to

/**

 * ice_set_cpu_rx_rmap - setup CPU reverse map for each queue

 * @vsi: the VSI to be forwarded to

/**

 * ice_remove_arfs - remove/clear all aRFS resources

 * @pf: device private structure

/**

 * ice_rebuild_arfs - remove/clear all aRFS resources and rebuild after reset

 * @pf: device private structure

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

/**

 * ice_adminq_init_regs - Initialize AdminQ registers

 * @hw: pointer to the hardware structure

 *

 * This assumes the alloc_sq and alloc_rq functions have already been called

/**

 * ice_mailbox_init_regs - Initialize Mailbox registers

 * @hw: pointer to the hardware structure

 *

 * This assumes the alloc_sq and alloc_rq functions have already been called

/**

 * ice_sb_init_regs - Initialize Sideband registers

 * @hw: pointer to the hardware structure

 *

 * This assumes the alloc_sq and alloc_rq functions have already been called

/**

 * ice_check_sq_alive

 * @hw: pointer to the HW struct

 * @cq: pointer to the specific Control queue

 *

 * Returns true if Queue is enabled else false.

 check both queue-length and queue-enable fields */

/**

 * ice_alloc_ctrlq_sq_ring - Allocate Control Transmit Queue (ATQ) rings

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

/**

 * ice_alloc_ctrlq_rq_ring - Allocate Control Receive Queue (ARQ) rings

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

/**

 * ice_free_cq_ring - Free control queue ring

 * @hw: pointer to the hardware structure

 * @ring: pointer to the specific control queue ring

 *

 * This assumes the posted buffers have already been cleaned

 * and de-allocated

/**

 * ice_alloc_rq_bufs - Allocate pre-posted buffers for the ARQ

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

	/* We'll be allocating the buffer info memory first, then we can

	 * allocate the mapped buffers for the event processing

 allocate the mapped buffers */

 now configure the descriptors for use */

		/* This is in accordance with Admin queue design, there is no

		 * register for buffer size configuration

 don't try to free the one that failed... */

/**

 * ice_alloc_sq_bufs - Allocate empty buffer structs for the ATQ

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

 No mapped memory needed yet, just the buffer info structures */

 allocate the mapped buffers */

 don't try to free the one that failed... */

 Clear Head and Tail */

 set starting point */

 Check one register to verify that config was applied */

/**

 * ice_cfg_sq_regs - configure Control ATQ registers

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

 *

 * Configure base address and length registers for the transmit queue

/**

 * ice_cfg_rq_regs - configure Control ARQ register

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

 *

 * Configure base address and length registers for the receive (event queue)

 Update tail in the HW to post pre-allocated buffers */

 free descriptors */						\

 free the buffer info list */					\

 free DMA head */						\

/**

 * ice_init_sq - main initialization routine for Control ATQ

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

 *

 * This is the main initialization routine for the Control Send Queue

 * Prior to calling this function, the driver *MUST* set the following fields

 * in the cq->structure:

 *     - cq->num_sq_entries

 *     - cq->sq_buf_size

 *

 * Do *NOT* hold the lock when calling this as the memory allocation routines

 * called are not going to be atomic context safe

 queue already initialized */

 verify input for valid configuration */

 allocate the ring memory */

 allocate buffers in the rings */

 initialize base registers */

 success! */

/**

 * ice_init_rq - initialize ARQ

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

 *

 * The main initialization routine for the Admin Receive (Event) Queue.

 * Prior to calling this function, the driver *MUST* set the following fields

 * in the cq->structure:

 *     - cq->num_rq_entries

 *     - cq->rq_buf_size

 *

 * Do *NOT* hold the lock when calling this as the memory allocation routines

 * called are not going to be atomic context safe

 queue already initialized */

 verify input for valid configuration */

 allocate the ring memory */

 allocate buffers in the rings */

 initialize base registers */

 success! */

/**

 * ice_shutdown_sq - shutdown the Control ATQ

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

 *

 * The main shutdown routine for the Control Transmit Queue

 Stop firmware AdminQ processing */

 to indicate uninitialized queue */

 free ring buffers and the ring itself */

/**

 * ice_aq_ver_check - Check the reported AQ API version.

 * @hw: pointer to the hardware structure

 *

 * Checks if the driver should load on a given AQ API version.

 *

 * Return: 'true' iff the driver should attempt to load. 'false' otherwise.

 Major API version is newer than expected, don't load */

 Major API version is older than expected, log a warning */

/**

 * ice_shutdown_rq - shutdown Control ARQ

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

 *

 * The main shutdown routine for the Control Receive Queue

 Stop Control Queue processing */

 set rq.count to 0 to indicate uninitialized queue */

 free ring buffers and the ring itself */

/**

 * ice_init_check_adminq - Check version for Admin Queue to know if its alive

 * @hw: pointer to the hardware structure

/**

 * ice_init_ctrlq - main initialization routine for any control Queue

 * @hw: pointer to the hardware structure

 * @q_type: specific Control queue type

 *

 * Prior to calling this function, the driver *MUST* set the following fields

 * in the cq->structure:

 *     - cq->num_sq_entries

 *     - cq->num_rq_entries

 *     - cq->rq_buf_size

 *     - cq->sq_buf_size

 *

 * NOTE: this function does not initialize the controlq locks

 verify input for valid configuration */

 setup SQ command write back timeout */

 allocate the ATQ */

 allocate the ARQ */

 success! */

/**

 * ice_is_sbq_supported - is the sideband queue supported

 * @hw: pointer to the hardware structure

 *

 * Returns true if the sideband control queue interface is

 * supported for the device, false otherwise

	/* The device sideband queue is only supported on devices with the

	 * generic MAC type.

/**

 * ice_get_sbq - returns the right control queue to use for sideband

 * @hw: pointer to the hardware structure

/**

 * ice_shutdown_ctrlq - shutdown routine for any control queue

 * @hw: pointer to the hardware structure

 * @q_type: specific Control queue type

 *

 * NOTE: this function does not destroy the control queue locks.

/**

 * ice_shutdown_all_ctrlq - shutdown routine for all control queues

 * @hw: pointer to the hardware structure

 *

 * NOTE: this function does not destroy the control queue locks. The driver

 * may call this at runtime to shutdown and later restart control queues, such

 * as in response to a reset event.

 Shutdown FW admin queue */

 Shutdown PHY Sideband */

 Shutdown PF-VF Mailbox */

/**

 * ice_init_all_ctrlq - main initialization routine for all control queues

 * @hw: pointer to the hardware structure

 *

 * Prior to calling this function, the driver MUST* set the following fields

 * in the cq->structure for all control queues:

 *     - cq->num_sq_entries

 *     - cq->num_rq_entries

 *     - cq->rq_buf_size

 *     - cq->sq_buf_size

 *

 * NOTE: this function does not initialize the controlq locks.

 Init FW admin queue */

	/* sideband control queue (SBQ) interface is not supported on some

	 * devices. Initialize if supported, else fallback to the admin queue

	 * interface

 Init Mailbox queue */

/**

 * ice_init_ctrlq_locks - Initialize locks for a control queue

 * @cq: pointer to the control queue

 *

 * Initializes the send and receive queue locks for a given control queue.

/**

 * ice_create_all_ctrlq - main initialization routine for all control queues

 * @hw: pointer to the hardware structure

 *

 * Prior to calling this function, the driver *MUST* set the following fields

 * in the cq->structure for all control queues:

 *     - cq->num_sq_entries

 *     - cq->num_rq_entries

 *     - cq->rq_buf_size

 *     - cq->sq_buf_size

 *

 * This function creates all the control queue locks and then calls

 * ice_init_all_ctrlq. It should be called once during driver load. If the

 * driver needs to re-initialize control queues at run time it should call

 * ice_init_all_ctrlq instead.

/**

 * ice_destroy_ctrlq_locks - Destroy locks for a control queue

 * @cq: pointer to the control queue

 *

 * Destroys the send and receive queue locks for a given control queue.

/**

 * ice_destroy_all_ctrlq - exit routine for all control queues

 * @hw: pointer to the hardware structure

 *

 * This function shuts down all the control queues and then destroys the

 * control queue locks. It should be called once during driver unload. The

 * driver should call ice_shutdown_all_ctrlq if it needs to shut down and

 * reinitialize control queues, such as in response to a reset event.

 shut down all the control queues first */

/**

 * ice_clean_sq - cleans Admin send queue (ATQ)

 * @hw: pointer to the hardware structure

 * @cq: pointer to the specific Control queue

 *

 * returns the number of free desc

/**

 * ice_debug_cq

 * @hw: pointer to the hardware structure

 * @desc: pointer to control queue descriptor

 * @buf: pointer to command buffer

 * @buf_len: max length of buf

 *

 * Dumps debug log about control command with descriptor contents.

/**

 * ice_sq_done - check if FW has processed the Admin Send Queue (ATQ)

 * @hw: pointer to the HW struct

 * @cq: pointer to the specific Control queue

 *

 * Returns true if the firmware has processed all descriptors on the

 * admin send queue. Returns false if there are still requests pending.

	/* AQ designers suggest use of head for better

	 * timing reliability than DD bit

/**

 * ice_sq_send_cmd - send command to Control Queue (ATQ)

 * @hw: pointer to the HW struct

 * @cq: pointer to the specific Control queue

 * @desc: prefilled descriptor describing the command

 * @buf: buffer to use for indirect commands (or NULL for direct commands)

 * @buf_size: size of buffer for indirect commands (or 0 for direct commands)

 * @cd: pointer to command details structure

 *

 * This is the main send command routine for the ATQ. It runs the queue,

 * cleans the queue, etc.

 if reset is in progress return a soft error */

	/* Call clean and check queue available function to reclaim the

	 * descriptors that were processed by FW/MBX; the function returns the

	 * number of desc available. The clean function called here could be

	 * called in a separate thread in case of asynchronous completions.

 initialize the temp desc pointer with the right desc */

 if the desc is available copy the temp desc to the right place */

 if buf is not NULL assume indirect command */

 copy the user buf into the respective DMA buf */

		/* Update the address values in the desc with the pa value

		 * for respective buffer

 Debug desc and buffer */

 if ready, copy the desc back to temp */

 get returned length to copy */

 strip off FW internal code */

 save writeback AQ if requested */

 update the error if time out occurred */

/**

 * ice_fill_dflt_direct_cmd_desc - AQ descriptor helper function

 * @desc: pointer to the temp descriptor (non DMA mem)

 * @opcode: the opcode can be used to decide which flags to turn off or on

 *

 * Fill the desc with default values

 zero out the desc */

/**

 * ice_clean_rq_elem

 * @hw: pointer to the HW struct

 * @cq: pointer to the specific Control queue

 * @e: event info from the receive descriptor, includes any buffers

 * @pending: number of events that could be left to process

 *

 * This function cleans one Admin Receive Queue element and returns

 * the contents through e. It can also return how many events are

 * left to process through 'pending'.

 pre-clean the event info */

 take the lock before we start messing with the ring */

 set next_to_use to head */

 nothing to do - shouldn't need to update ring's values */

 now clean the next descriptor */

	/* Restore the original datalen and buffer address in the desc,

	 * FW updates datalen to indicate the event message size

 set tail = the last cleaned desc index. */

 ntc is updated to tail + 1 */

 Set pending if needed, unlock and return */

 re-read HW head to calculate actual pending messages */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018-2020, Intel Corporation. */

/**

 * ice_fltr_free_list - free filter lists helper

 * @dev: pointer to the device struct

 * @h: pointer to the list head to be freed

 *

 * Helper function to free filter lists previously created using

 * ice_fltr_add_mac_to_list

/**

 * ice_fltr_add_entry_to_list - allocate and add filter entry to list

 * @dev: pointer to device needed by alloc function

 * @info: filter info struct that gets added to the passed in list

 * @list: pointer to the list which contains MAC filters entry

/**

 * ice_fltr_add_mac_list - add list of MAC filters

 * @vsi: pointer to VSI struct

 * @list: list of filters

/**

 * ice_fltr_remove_mac_list - remove list of MAC filters

 * @vsi: pointer to VSI struct

 * @list: list of filters

/**

 * ice_fltr_add_vlan_list - add list of VLAN filters

 * @vsi: pointer to VSI struct

 * @list: list of filters

/**

 * ice_fltr_remove_vlan_list - remove list of VLAN filters

 * @vsi: pointer to VSI struct

 * @list: list of filters

/**

 * ice_fltr_add_eth_list - add list of ethertype filters

 * @vsi: pointer to VSI struct

 * @list: list of filters

/**

 * ice_fltr_remove_eth_list - remove list of ethertype filters

 * @vsi: pointer to VSI struct

 * @list: list of filters

/**

 * ice_fltr_remove_all - remove all filters associated with VSI

 * @vsi: pointer to VSI struct

/**

 * ice_fltr_add_mac_to_list - add MAC filter info to exsisting list

 * @vsi: pointer to VSI struct

 * @list: list to add filter info to

 * @mac: MAC address to add

 * @action: filter action

/**

 * ice_fltr_add_vlan_to_list - add VLAN filter info to exsisting list

 * @vsi: pointer to VSI struct

 * @list: list to add filter info to

 * @vlan_id: VLAN ID to add

 * @action: filter action

/**

 * ice_fltr_add_eth_to_list - add ethertype filter info to exsisting list

 * @vsi: pointer to VSI struct

 * @list: list to add filter info to

 * @ethertype: ethertype of packet that matches filter

 * @flag: filter direction, Tx or Rx

 * @action: filter action

/**

 * ice_fltr_prepare_mac - add or remove MAC rule

 * @vsi: pointer to VSI struct

 * @mac: MAC address to add

 * @action: action to be performed on filter match

 * @mac_action: pointer to add or remove MAC function

/**

 * ice_fltr_prepare_mac_and_broadcast - add or remove MAC and broadcast filter

 * @vsi: pointer to VSI struct

 * @mac: MAC address to add

 * @action: action to be performed on filter match

 * @mac_action: pointer to add or remove MAC function

/**

 * ice_fltr_prepare_vlan - add or remove VLAN filter

 * @vsi: pointer to VSI struct

 * @vlan_id: VLAN ID to add

 * @action: action to be performed on filter match

 * @vlan_action: pointer to add or remove VLAN function

/**

 * ice_fltr_prepare_eth - add or remove ethertype filter

 * @vsi: pointer to VSI struct

 * @ethertype: ethertype of packet to be filtered

 * @flag: direction of packet, Tx or Rx

 * @action: action to be performed on filter match

 * @eth_action: pointer to add or remove ethertype function

/**

 * ice_fltr_add_mac - add single MAC filter

 * @vsi: pointer to VSI struct

 * @mac: MAC to add

 * @action: action to be performed on filter match

/**

 * ice_fltr_add_mac_and_broadcast - add single MAC and broadcast

 * @vsi: pointer to VSI struct

 * @mac: MAC to add

 * @action: action to be performed on filter match

/**

 * ice_fltr_remove_mac - remove MAC filter

 * @vsi: pointer to VSI struct

 * @mac: filter MAC to remove

 * @action: action to remove

/**

 * ice_fltr_add_vlan - add single VLAN filter

 * @vsi: pointer to VSI struct

 * @vlan_id: VLAN ID to add

 * @action: action to be performed on filter match

/**

 * ice_fltr_remove_vlan - remove VLAN filter

 * @vsi: pointer to VSI struct

 * @vlan_id: filter VLAN to remove

 * @action: action to remove

/**

 * ice_fltr_add_eth - add specyfic ethertype filter

 * @vsi: pointer to VSI struct

 * @ethertype: ethertype of filter

 * @flag: direction of packet to be filtered, Tx or Rx

 * @action: action to be performed on filter match

/**

 * ice_fltr_remove_eth - remove ethertype filter

 * @vsi: pointer to VSI struct

 * @ethertype: ethertype of filter

 * @flag: direction of filter

 * @action: action to remove

/**

 * ice_fltr_update_rule_flags - update lan_en/lb_en flags

 * @hw: pointer to hw

 * @rule_id: id of rule being updated

 * @recipe_id: recipe id of rule

 * @act: current action field

 * @type: Rx or Tx

 * @src: source VSI

 * @new_flags: combinations of lb_en and lan_en

/**

 * ice_fltr_build_action - build action for rule

 * @vsi_id: id of VSI which is use to build action

/**

 * ice_fltr_update_flags_dflt_rule - update flags on default rule

 * @vsi: pointer to VSI

 * @rule_id: id of rule

 * @direction: Tx or Rx

 * @new_flags: flags to update

 *

 * Function updates flags on default rule with ICE_SW_LKUP_DFLT.

 *

 * Flags should be a combination of ICE_SINGLE_ACT_LB_ENABLE and

 * ICE_SINGLE_ACT_LAN_ENABLE.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

/**

 * ice_aq_read_nvm

 * @hw: pointer to the HW struct

 * @module_typeid: module pointer location in words from the NVM beginning

 * @offset: byte offset from the module beginning

 * @length: length of the section to be read (in bytes from the offset)

 * @data: command buffer (size [bytes] = length)

 * @last_command: tells if this is the last command in a series

 * @read_shadow_ram: tell if this is a shadow RAM read

 * @cd: pointer to command details structure or NULL

 *

 * Read the NVM using the admin queue commands (0x0701)

 If this is the last command in a series, set the proper flag. */

/**

 * ice_read_flat_nvm - Read portion of NVM by flat offset

 * @hw: pointer to the HW struct

 * @offset: offset from beginning of NVM

 * @length: (in) number of bytes to read; (out) number of bytes actually read

 * @data: buffer to return data in (sized to fit the specified length)

 * @read_shadow_ram: if true, read from shadow RAM instead of NVM

 *

 * Reads a portion of the NVM, as a flat memory space. This function correctly

 * breaks read requests across Shadow RAM sectors and ensures that no single

 * read request exceeds the maximum 4KB read for a single AdminQ command.

 *

 * Returns a status code on failure. Note that the data pointer may be

 * partially updated if some reads succeed before a failure.

 Verify the length of the read if this is for the Shadow RAM */

		/* ice_aq_read_nvm cannot read more than 4KB at a time.

		 * Additionally, a read from the Shadow RAM may not cross over

		 * a sector boundary. Conveniently, the sector size is also

		 * 4KB.

/**

 * ice_aq_update_nvm

 * @hw: pointer to the HW struct

 * @module_typeid: module pointer location in words from the NVM beginning

 * @offset: byte offset from the module beginning

 * @length: length of the section to be written (in bytes from the offset)

 * @data: command buffer (size [bytes] = length)

 * @last_command: tells if this is the last command in a series

 * @command_flags: command parameters

 * @cd: pointer to command details structure or NULL

 *

 * Update the NVM using the admin queue commands (0x0703)

 In offset the highest byte must be zeroed. */

 If this is the last command in a series, set the proper flag. */

/**

 * ice_aq_erase_nvm

 * @hw: pointer to the HW struct

 * @module_typeid: module pointer location in words from the NVM beginning

 * @cd: pointer to command details structure or NULL

 *

 * Erase the NVM sector using the admin queue commands (0x0702)

/**

 * ice_read_sr_word_aq - Reads Shadow RAM via AQ

 * @hw: pointer to the HW structure

 * @offset: offset of the Shadow RAM word to read (0x000000 - 0x001FFF)

 * @data: word read from the Shadow RAM

 *

 * Reads one 16 bit word from the Shadow RAM using ice_read_flat_nvm.

	/* Note that ice_read_flat_nvm takes into account the 4Kb AdminQ and

	 * Shadow RAM sector restrictions necessary when reading from the NVM.

/**

 * ice_acquire_nvm - Generic request for acquiring the NVM ownership

 * @hw: pointer to the HW structure

 * @access: NVM access type (read or write)

 *

 * This function will request NVM ownership.

/**

 * ice_release_nvm - Generic request for releasing the NVM ownership

 * @hw: pointer to the HW structure

 *

 * This function will release NVM ownership.

/**

 * ice_get_flash_bank_offset - Get offset into requested flash bank

 * @hw: pointer to the HW structure

 * @bank: whether to read from the active or inactive flash bank

 * @module: the module to read from

 *

 * Based on the module, lookup the module offset from the beginning of the

 * flash.

 *

 * Returns the flash offset. Note that a value of zero is invalid and must be

 * treated as an error.

	/* The second flash bank is stored immediately following the first

	 * bank. Based on whether the 1st or 2nd bank is active, and whether

	 * we want the active or inactive bank, calculate the desired offset.

/**

 * ice_read_flash_module - Read a word from one of the main NVM modules

 * @hw: pointer to the HW structure

 * @bank: which bank of the module to read

 * @module: the module to read

 * @offset: the offset into the module in bytes

 * @data: storage for the word read from the flash

 * @length: bytes of data to read

 *

 * Read data from the specified flash module. The bank parameter indicates

 * whether or not to read from the active bank or the inactive bank of that

 * module.

 *

 * The word will be read using flat NVM access, and relies on the

 * hw->flash.banks data being setup by ice_determine_active_flash_banks()

 * during initialization.

/**

 * ice_read_nvm_module - Read from the active main NVM module

 * @hw: pointer to the HW structure

 * @bank: whether to read from active or inactive NVM module

 * @offset: offset into the NVM module to read, in words

 * @data: storage for returned word value

 *

 * Read the specified word from the active NVM module. This includes the CSS

 * header at the start of the NVM module.

/**

 * ice_read_nvm_sr_copy - Read a word from the Shadow RAM copy in the NVM bank

 * @hw: pointer to the HW structure

 * @bank: whether to read from the active or inactive NVM module

 * @offset: offset into the Shadow RAM copy to read, in words

 * @data: storage for returned word value

 *

 * Read the specified word from the copy of the Shadow RAM found in the

 * specified NVM module.

/**

 * ice_read_netlist_module - Read data from the netlist module area

 * @hw: pointer to the HW structure

 * @bank: whether to read from the active or inactive module

 * @offset: offset into the netlist to read from

 * @data: storage for returned word value

 *

 * Read a word from the specified netlist bank.

/**

 * ice_read_sr_word - Reads Shadow RAM word and acquire NVM if necessary

 * @hw: pointer to the HW structure

 * @offset: offset of the Shadow RAM word to read (0x000000 - 0x001FFF)

 * @data: word read from the Shadow RAM

 *

 * Reads one 16 bit word from the Shadow RAM using the ice_read_sr_word_aq.

/**

 * ice_get_pfa_module_tlv - Reads sub module TLV from NVM PFA

 * @hw: pointer to hardware structure

 * @module_tlv: pointer to module TLV to return

 * @module_tlv_len: pointer to module TLV length to return

 * @module_type: module type requested

 *

 * Finds the requested sub module TLV type from the Preserved Field

 * Area (PFA) and returns the TLV pointer and length. The caller can

 * use these to read the variable length TLV value.

	/* Starting with first TLV after PFA length, iterate through the list

	 * of TLVs to find the requested one.

 Read TLV type */

 Read TLV length */

		/* Check next TLV, i.e. current TLV pointer + length + 2 words

		 * (for current TLV's type and length)

 Module does not exist */

/**

 * ice_read_pba_string - Reads part number string from NVM

 * @hw: pointer to hardware structure

 * @pba_num: stores the part number string from the NVM

 * @pba_num_size: part number string buffer length

 *

 * Reads the part number string from the NVM.

 pba_size is the next word */

	/* Subtract one to get PBA word count (PBA Size word is included in

	 * total size)

/**

 * ice_get_nvm_ver_info - Read NVM version information

 * @hw: pointer to the HW struct

 * @bank: whether to read from the active or inactive flash bank

 * @nvm: pointer to NVM info structure

 *

 * Read the NVM EETRACK ID and map version of the main NVM image bank, filling

 * in the NVM info structure.

/**

 * ice_get_inactive_nvm_ver - Read Option ROM version from the inactive bank

 * @hw: pointer to the HW structure

 * @nvm: storage for Option ROM version information

 *

 * Reads the NVM EETRACK ID, Map version, and security revision of the

 * inactive NVM bank. Used to access version data for a pending update that

 * has not yet been activated.

/**

 * ice_get_orom_civd_data - Get the combo version information from Option ROM

 * @hw: pointer to the HW struct

 * @bank: whether to read from the active or inactive flash module

 * @civd: storage for the Option ROM CIVD data.

 *

 * Searches through the Option ROM flash contents to locate the CIVD data for

 * the image.

	/* The CIVD section is located in the Option ROM aligned to 512 bytes.

	 * The first 4 bytes must contain the ASCII characters "$CIV".

	 * A simple modulo 256 sum of all of the bytes of the structure must

	 * equal 0.

 Skip forward until we find a matching signature */

 Verify that the simple checksum is zero */

 cppcheck-suppress objectIndex */

/**

 * ice_get_orom_ver_info - Read Option ROM version information

 * @hw: pointer to the HW struct

 * @bank: whether to read from the active or inactive flash module

 * @orom: pointer to Option ROM info structure

 *

 * Read Option ROM version and security revision from the Option ROM flash

 * section.

/**

 * ice_get_inactive_orom_ver - Read Option ROM version from the inactive bank

 * @hw: pointer to the HW structure

 * @orom: storage for Option ROM version information

 *

 * Reads the Option ROM version and security revision data for the inactive

 * section of flash. Used to access version data for a pending update that has

 * not yet been activated.

/**

 * ice_get_netlist_info

 * @hw: pointer to the HW struct

 * @bank: whether to read from the active or inactive flash bank

 * @netlist: pointer to netlist version info structure

 *

 * Get the netlist version information from the requested bank. Reads the Link

 * Topology section to find the Netlist ID block and extract the relevant

 * information into the netlist version structure.

 sanity check that we have at least enough words to store the netlist ID block */

 Read out the entire Netlist ID Block at once. */

 Read the left most 4 bytes of SHA */

/**

 * ice_get_inactive_netlist_ver

 * @hw: pointer to the HW struct

 * @netlist: pointer to netlist version info structure

 *

 * Read the netlist version data from the inactive netlist bank. Used to

 * extract version data of a pending flash update in order to display the

 * version data.

/**

 * ice_discover_flash_size - Discover the available flash size.

 * @hw: pointer to the HW struct

 *

 * The device flash could be up to 16MB in size. However, it is possible that

 * the actual size is smaller. Use bisection to determine the accessible size

 * of flash memory.

 an unexpected error occurred */

/**

 * ice_read_sr_pointer - Read the value of a Shadow RAM pointer word

 * @hw: pointer to the HW structure

 * @offset: the word offset of the Shadow RAM word to read

 * @pointer: pointer value read from Shadow RAM

 *

 * Read the given Shadow RAM word, and convert it to a pointer value specified

 * in bytes. This function assumes the specified offset is a valid pointer

 * word.

 *

 * Each pointer word specifies whether it is stored in word size or 4KB

 * sector size by using the highest bit. The reported pointer value will be in

 * bytes, intended for flat NVM reads.

 Determine if the pointer is in 4KB or word units */

/**

 * ice_read_sr_area_size - Read an area size from a Shadow RAM word

 * @hw: pointer to the HW structure

 * @offset: the word offset of the Shadow RAM to read

 * @size: size value read from the Shadow RAM

 *

 * Read the given Shadow RAM word, and convert it to an area size value

 * specified in bytes. This function assumes the specified offset is a valid

 * area size word.

 *

 * Each area size word is specified in 4KB sector units. This function reports

 * the size in bytes, intended for flat NVM reads.

 Area sizes are always specified in 4KB units */

/**

 * ice_determine_active_flash_banks - Discover active bank for each module

 * @hw: pointer to the HW struct

 *

 * Read the Shadow RAM control word and determine which banks are active for

 * the NVM, OROM, and Netlist modules. Also read and calculate the associated

 * pointer and size. These values are then cached into the ice_flash_info

 * structure for later use in order to calculate the correct offset to read

 * from the active module.

 Check that the control word indicates validity */

/**

 * ice_init_nvm - initializes NVM setting

 * @hw: pointer to the HW struct

 *

 * This function reads and populates NVM settings such as Shadow RAM size,

 * max_timeout, and blank_nvm_mode

	/* The SR size is stored regardless of the NVM programming mode

	 * as the blank mode may be used in the factory line.

 Switching to words (sr_size contains power of 2) */

 Check if we are in the normal or blank NVM programming mode */

 Normal programming mode */

 Blank programming mode */

 read the netlist version information */

/**

 * ice_nvm_validate_checksum

 * @hw: pointer to the HW struct

 *

 * Verify NVM PFA checksum validity (0x0706)

/**

 * ice_nvm_write_activate

 * @hw: pointer to the HW struct

 * @cmd_flags: NVM activate admin command bits (banks to be validated)

 *

 * Update the control word with the required banks' validity bits

 * and dumps the Shadow RAM to flash (0x0707)

/**

 * ice_aq_nvm_update_empr

 * @hw: pointer to the HW struct

 *

 * Update empr (0x0709). This command allows SW to

 * request an EMPR to activate new FW.

/* ice_nvm_set_pkg_data

 * @hw: pointer to the HW struct

 * @del_pkg_data_flag: If is set then the current pkg_data store by FW

 *		       is deleted.

 *		       If bit is set to 1, then buffer should be size 0.

 * @data: pointer to buffer

 * @length: length of the buffer

 * @cd: pointer to command details structure or NULL

 *

 * Set package data (0x070A). This command is equivalent to the reception

 * of a PLDM FW Update GetPackageData cmd. This command should be sent

 * as part of the NVM update as the first cmd in the flow.

/* ice_nvm_pass_component_tbl

 * @hw: pointer to the HW struct

 * @data: pointer to buffer

 * @length: length of the buffer

 * @transfer_flag: parameter for determining stage of the update

 * @comp_response: a pointer to the response from the 0x070B AQC.

 * @comp_response_code: a pointer to the response code from the 0x070B AQC.

 * @cd: pointer to command details structure or NULL

 *

 * Pass component table (0x070B). This command is equivalent to the reception

 * of a PLDM FW Update PassComponentTable cmd. This command should be sent once

 * per component. It can be only sent after Set Package Data cmd and before

 * actual update. FW will assume these commands are going to be sent until

 * the TransferFlag is set to End or StartAndEnd.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

/**

 * ice_sched_add_root_node - Insert the Tx scheduler root node in SW DB

 * @pi: port information structure

 * @info: Scheduler element information from firmware

 *

 * This function inserts the root node of the scheduling tree topology

 * to the SW DB.

 coverity[suspicious_sizeof] */

/**

 * ice_sched_find_node_by_teid - Find the Tx scheduler node in SW DB

 * @start_node: pointer to the starting ice_sched_node struct in a sub-tree

 * @teid: node TEID to search

 *

 * This function searches for a node matching the TEID in the scheduling tree

 * from the SW DB. The search is recursive and is restricted by the number of

 * layers it has searched through; stopping at the max supported layer.

 *

 * This function needs to be called when holding the port_info->sched_lock

 The TEID is same as that of the start_node */

 The node has no children or is at the max layer */

 Check if TEID matches to any of the children nodes */

 Search within each child's sub-tree */

/**

 * ice_aqc_send_sched_elem_cmd - send scheduling elements cmd

 * @hw: pointer to the HW struct

 * @cmd_opc: cmd opcode

 * @elems_req: number of elements to request

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @elems_resp: returns total number of elements response

 * @cd: pointer to command details structure or NULL

 *

 * This function sends a scheduling elements cmd (cmd_opc)

/**

 * ice_aq_query_sched_elems - query scheduler elements

 * @hw: pointer to the HW struct

 * @elems_req: number of elements to query

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @elems_ret: returns total number of elements returned

 * @cd: pointer to command details structure or NULL

 *

 * Query scheduling elements (0x0404)

/**

 * ice_sched_add_node - Insert the Tx scheduler node in SW DB

 * @pi: port information structure

 * @layer: Scheduler layer of the node

 * @info: Scheduler element information from firmware

 *

 * This function inserts a scheduler node to the SW DB.

 A valid parent node should be there */

	/* query the current node information from FW before adding it

	 * to the SW DB

 coverity[suspicious_sizeof] */

/**

 * ice_aq_delete_sched_elems - delete scheduler elements

 * @hw: pointer to the HW struct

 * @grps_req: number of groups to delete

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @grps_del: returns total number of elements deleted

 * @cd: pointer to command details structure or NULL

 *

 * Delete scheduling elements (0x040F)

/**

 * ice_sched_remove_elems - remove nodes from HW

 * @hw: pointer to the HW struct

 * @parent: pointer to the parent node

 * @num_nodes: number of nodes

 * @node_teids: array of node teids to be deleted

 *

 * This function remove nodes from HW

/**

 * ice_sched_get_first_node - get the first node of the given layer

 * @pi: port information structure

 * @parent: pointer the base node of the subtree

 * @layer: layer number

 *

 * This function retrieves the first node of the given layer from the subtree

/**

 * ice_sched_get_tc_node - get pointer to TC node

 * @pi: port information structure

 * @tc: TC number

 *

 * This function returns the TC node pointer

/**

 * ice_free_sched_node - Free a Tx scheduler node from SW DB

 * @pi: port information structure

 * @node: pointer to the ice_sched_node struct

 *

 * This function frees up a node from SW DB as well as from HW

 *

 * This function needs to be called with the port_info->sched_lock held

	/* Free the children before freeing up the parent node

	 * The parent array is updated below and that shifts the nodes

	 * in the array. So always pick the first child if num children > 0

 Leaf, TC and root nodes can't be deleted by SW */

 root has no parent */

 update the parent */

 update the sibling head if head is getting removed */

 leaf nodes have no children */

/**

 * ice_aq_get_dflt_topo - gets default scheduler topology

 * @hw: pointer to the HW struct

 * @lport: logical port number

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @num_branches: returns total number of queue to port branches

 * @cd: pointer to command details structure or NULL

 *

 * Get default scheduler topology (0x400)

/**

 * ice_aq_add_sched_elems - adds scheduling element

 * @hw: pointer to the HW struct

 * @grps_req: the number of groups that are requested to be added

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @grps_added: returns total number of groups added

 * @cd: pointer to command details structure or NULL

 *

 * Add scheduling elements (0x0401)

/**

 * ice_aq_cfg_sched_elems - configures scheduler elements

 * @hw: pointer to the HW struct

 * @elems_req: number of elements to configure

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @elems_cfgd: returns total number of elements configured

 * @cd: pointer to command details structure or NULL

 *

 * Configure scheduling elements (0x0403)

/**

 * ice_aq_move_sched_elems - move scheduler elements

 * @hw: pointer to the HW struct

 * @grps_req: number of groups to move

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @grps_movd: returns total number of groups moved

 * @cd: pointer to command details structure or NULL

 *

 * Move scheduling elements (0x0408)

/**

 * ice_aq_suspend_sched_elems - suspend scheduler elements

 * @hw: pointer to the HW struct

 * @elems_req: number of elements to suspend

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @elems_ret: returns total number of elements suspended

 * @cd: pointer to command details structure or NULL

 *

 * Suspend scheduling elements (0x0409)

/**

 * ice_aq_resume_sched_elems - resume scheduler elements

 * @hw: pointer to the HW struct

 * @elems_req: number of elements to resume

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @elems_ret: returns total number of elements resumed

 * @cd: pointer to command details structure or NULL

 *

 * resume scheduling elements (0x040A)

/**

 * ice_aq_query_sched_res - query scheduler resource

 * @hw: pointer to the HW struct

 * @buf_size: buffer size in bytes

 * @buf: pointer to buffer

 * @cd: pointer to command details structure or NULL

 *

 * Query scheduler resource allocation (0x0412)

/**

 * ice_sched_suspend_resume_elems - suspend or resume HW nodes

 * @hw: pointer to the HW struct

 * @num_nodes: number of nodes

 * @node_teids: array of node teids to be suspended or resumed

 * @suspend: true means suspend / false means resume

 *

 * This function suspends or resumes HW nodes

/**

 * ice_alloc_lan_q_ctx - allocate LAN queue contexts for the given VSI and TC

 * @hw: pointer to the HW struct

 * @vsi_handle: VSI handle

 * @tc: TC number

 * @new_numqs: number of queues

 allocate LAN queue contexts */

 num queues are increased, update the queue contexts */

/**

 * ice_alloc_rdma_q_ctx - allocate RDMA queue contexts for the given VSI and TC

 * @hw: pointer to the HW struct

 * @vsi_handle: VSI handle

 * @tc: TC number

 * @new_numqs: number of queues

 allocate RDMA queue contexts */

 num queues are increased, update the queue contexts */

/**

 * ice_aq_rl_profile - performs a rate limiting task

 * @hw: pointer to the HW struct

 * @opcode: opcode for add, query, or remove profile(s)

 * @num_profiles: the number of profiles

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @num_processed: number of processed add or remove profile(s) to return

 * @cd: pointer to command details structure

 *

 * RL profile function to add, query, or remove profile(s)

/**

 * ice_aq_add_rl_profile - adds rate limiting profile(s)

 * @hw: pointer to the HW struct

 * @num_profiles: the number of profile(s) to be add

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @num_profiles_added: total number of profiles added to return

 * @cd: pointer to command details structure

 *

 * Add RL profile (0x0410)

/**

 * ice_aq_remove_rl_profile - removes RL profile(s)

 * @hw: pointer to the HW struct

 * @num_profiles: the number of profile(s) to remove

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @num_profiles_removed: total number of profiles removed to return

 * @cd: pointer to command details structure or NULL

 *

 * Remove RL profile (0x0415)

/**

 * ice_sched_del_rl_profile - remove RL profile

 * @hw: pointer to the HW struct

 * @rl_info: rate limit profile information

 *

 * If the profile ID is not referenced anymore, it removes profile ID with

 * its associated parameters from HW DB,and locally. The caller needs to

 * hold scheduler lock.

 Safe to remove profile ID */

 Delete stale entry now */

/**

 * ice_sched_clear_rl_prof - clears RL prof entries

 * @pi: port information structure

 *

 * This function removes all RL profile from HW as well as from SW DB.

 On error, free mem required */

/**

 * ice_sched_clear_agg - clears the aggregator related information

 * @hw: pointer to the hardware structure

 *

 * This function removes aggregator list and free up aggregator related memory

 * previously allocated.

/**

 * ice_sched_clear_tx_topo - clears the scheduler tree nodes

 * @pi: port information structure

 *

 * This function removes all the nodes from HW as well as from SW DB.

 remove RL profiles related lists */

/**

 * ice_sched_clear_port - clear the scheduler elements from SW DB for a port

 * @pi: port information structure

 *

 * Cleanup scheduling elements from SW DB

/**

 * ice_sched_cleanup_all - cleanup scheduler elements from SW DB for all ports

 * @hw: pointer to the HW struct

 *

 * Cleanup scheduling elements from SW DB for all the ports

/**

 * ice_sched_add_elems - add nodes to HW and SW DB

 * @pi: port information structure

 * @tc_node: pointer to the branch node

 * @parent: pointer to the parent node

 * @layer: layer number to add nodes

 * @num_nodes: number of nodes

 * @num_nodes_added: pointer to num nodes added

 * @first_node_teid: if new nodes are added then return the TEID of first node

 *

 * This function add nodes to HW as well as to SW DB for a given layer

 add nodes to the SW DB */

 add it to previous node sibling pointer */

 Note: siblings are not linked across branches */

 initialize the sibling head */

/**

 * ice_sched_add_nodes_to_hw_layer - Add nodes to HW layer

 * @pi: port information structure

 * @tc_node: pointer to TC node

 * @parent: pointer to parent node

 * @layer: layer number to add nodes

 * @num_nodes: number of nodes to be added

 * @first_node_teid: pointer to the first node TEID

 * @num_nodes_added: pointer to number of nodes added

 *

 * Add nodes into specific HW layer.

 max children per node per layer */

 current number of children + required nodes exceed max children */

 Fail if the parent is a TC node */

/**

 * ice_sched_add_nodes_to_layer - Add nodes to a given layer

 * @pi: port information structure

 * @tc_node: pointer to TC node

 * @parent: pointer to parent node

 * @layer: layer number to add nodes

 * @num_nodes: number of nodes to be added

 * @first_node_teid: pointer to the first node TEID

 * @num_nodes_added: pointer to number of nodes added

 *

 * This function add nodes to a given layer.

 cppcheck-suppress unusedVariable */

 added more nodes than requested ? */

 break if all the nodes are added successfully */

 break if the error is not max limit */

 Exceeded the max children */

 utilize all the spaces if the parent is not full */

 This parent is full, try the next sibling */

			/* Don't modify the first node TEID memory if the

			 * first node was added already in the above call.

			 * Instead send some temp memory for all other

			 * recursive calls.

/**

 * ice_sched_get_qgrp_layer - get the current queue group layer number

 * @hw: pointer to the HW struct

 *

 * This function returns the current queue group layer number

 It's always total layers - 1, the array is 0 relative so -2 */

/**

 * ice_sched_get_vsi_layer - get the current VSI layer number

 * @hw: pointer to the HW struct

 *

 * This function returns the current VSI layer number

	/* Num Layers       VSI layer

	 *     9               6

	 *     7               4

	 *     5 or less       sw_entry_point_layer

 calculate the VSI layer based on number of layers. */

/**

 * ice_sched_get_agg_layer - get the current aggregator layer number

 * @hw: pointer to the HW struct

 *

 * This function returns the current aggregator layer number

	/* Num Layers       aggregator layer

	 *     9               4

	 *     7 or less       sw_entry_point_layer

 calculate the aggregator layer based on number of layers. */

/**

 * ice_rm_dflt_leaf_node - remove the default leaf node in the tree

 * @pi: port information structure

 *

 * This function removes the leaf node that was created by the FW

 * during initialization

 remove the default leaf node */

/**

 * ice_sched_rm_dflt_nodes - free the default nodes in the tree

 * @pi: port information structure

 *

 * This function frees all the nodes except root and TC that were created by

 * the FW during initialization

 remove the default nodes except TC and root nodes */

/**

 * ice_sched_init_port - Initialize scheduler by querying information from FW

 * @pi: port info structure for the tree to cleanup

 *

 * This function is the initial call to find the total number of Tx scheduler

 * resources, default topology created by firmware and storing the information

 * in SW DB.

 Query the Default Topology from FW */

 Query default scheduling tree topology */

 num_branches should be between 1-8 */

 get the number of elements on the default/first branch */

 num_elems should always be between 1-9 */

	/* If the last node is a leaf node then the index of the queue group

	 * layer is two less than the number of elements.

 Insert the Tx Sched root node */

 Parse the default tree and cache the information */

 Skip root element as already inserted */

 update the sw entry point */

 Remove the default nodes. */

 initialize the port for handling the scheduler tree */

/**

 * ice_sched_query_res_alloc - query the FW for num of logical sched layers

 * @hw: pointer to the HW struct

 *

 * query FW for allocated scheduler resources and store in HW struct

	/* max sibling group size of current layer refers to the max children

	 * of the below layer node.

	 * layer 1 node max children will be layer 2 max sibling group size

	 * layer 2 node max children will be layer 3 max sibling group size

	 * and so on. This array will be populated from root (index 0) to

	 * qgroup layer 7. Leaf node has no children.

/**

 * ice_sched_get_psm_clk_freq - determine the PSM clock frequency

 * @hw: pointer to the HW struct

 *

 * Determine the PSM clock frequency and store in HW struct

 fall back to a safe default */

/**

 * ice_sched_find_node_in_subtree - Find node in part of base node subtree

 * @hw: pointer to the HW struct

 * @base: pointer to the base node

 * @node: pointer to the node to search

 *

 * This function checks whether a given node is part of the base node

 * subtree or not

		/* this recursion is intentional, and wouldn't

		 * go more than 8 calls

/**

 * ice_sched_get_free_qgrp - Scan all queue group siblings and find a free node

 * @pi: port information structure

 * @vsi_node: software VSI handle

 * @qgrp_node: first queue group node identified for scanning

 * @owner: LAN or RDMA

 *

 * This function retrieves a free LAN or RDMA queue group node by scanning

 * qgrp_node and its siblings for the queue group with the fewest number

 * of queues currently assigned.

	/* scan all queue groups until find a node which has less than the

	 * minimum number of children. This way all queue group nodes get

	 * equal number of shares and active. The bandwidth will be equally

	 * distributed across all queues.

 make sure the qgroup node is part of the VSI subtree */

 replace the new min queue group node */

 break if it has no children, */

/**

 * ice_sched_get_free_qparent - Get a free LAN or RDMA queue group node

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc: branch number

 * @owner: LAN or RDMA

 *

 * This function retrieves a free LAN or RDMA queue group node

 validate invalid VSI ID */

 get the first queue group node from VSI sub-tree */

 make sure the qgroup node is part of the VSI subtree */

 Select the best queue group */

/**

 * ice_sched_get_vsi_node - Get a VSI node based on VSI ID

 * @pi: pointer to the port information structure

 * @tc_node: pointer to the TC node

 * @vsi_handle: software VSI handle

 *

 * This function retrieves a VSI node for a given VSI ID from a given

 * TC branch

 Check whether it already exists */

/**

 * ice_sched_get_agg_node - Get an aggregator node based on aggregator ID

 * @pi: pointer to the port information structure

 * @tc_node: pointer to the TC node

 * @agg_id: aggregator ID

 *

 * This function retrieves an aggregator node for a given aggregator ID from

 * a given TC branch

 Check whether it already exists */

/**

 * ice_sched_calc_vsi_child_nodes - calculate number of VSI child nodes

 * @hw: pointer to the HW struct

 * @num_qs: number of queues

 * @num_nodes: num nodes array

 *

 * This function calculates the number of VSI child nodes based on the

 * number of queues.

 calculate num nodes from queue group to VSI layer */

 round to the next integer if there is a remainder */

 need at least one node */

/**

 * ice_sched_add_vsi_child_nodes - add VSI child nodes to tree

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc_node: pointer to the TC node

 * @num_nodes: pointer to the num nodes that needs to be added per layer

 * @owner: node owner (LAN or RDMA)

 *

 * This function adds the VSI child nodes to tree. It gets called for

 * LAN and RDMA separately.

		/* The newly added node can be a new parent for the next

		 * layer nodes

/**

 * ice_sched_calc_vsi_support_nodes - calculate number of VSI support nodes

 * @pi: pointer to the port info structure

 * @tc_node: pointer to TC node

 * @num_nodes: pointer to num nodes array

 *

 * This function calculates the number of supported nodes needed to add this

 * VSI into Tx tree including the VSI, parent and intermediate nodes in below

 * layers

		/* Add intermediate nodes if TC has no children and

		 * need at least one node for VSI

			/* If intermediate nodes are reached max children

			 * then add a new one.

 scan all the siblings */

			/* tree has one intermediate node to add this new VSI.

			 * So no need to calculate supported nodes for below

			 * layers.

 all the nodes are full, allocate a new one */

/**

 * ice_sched_add_vsi_support_nodes - add VSI supported nodes into Tx tree

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc_node: pointer to TC node

 * @num_nodes: pointer to num nodes array

 *

 * This function adds the VSI supported nodes into Tx tree including the

 * VSI, its parent and intermediate nodes in below layers

		/* The newly added node can be a new parent for the next

		 * layer nodes

/**

 * ice_sched_add_vsi_to_topo - add a new VSI into tree

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc: TC number

 *

 * This function adds a new VSI into scheduler tree

 calculate number of supported nodes needed for this VSI */

 add VSI supported nodes to TC subtree */

/**

 * ice_sched_update_vsi_child_nodes - update VSI child nodes

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc: TC number

 * @new_numqs: new number of max queues

 * @owner: owner of this subtree

 *

 * This function updates the VSI child nodes based on the number of queues

 num queues are not changed or less than the previous number */

	/* Keep the max number of queue configuration all the time. Update the

	 * tree only if number of queues > previous number of queues. This may

	 * leave some extra nodes in the tree if number of queues < previous

	 * number but that wouldn't harm anything. Removing those extra nodes

	 * may complicate the code if those nodes are part of SRL or

	 * individually rate limited.

/**

 * ice_sched_cfg_vsi - configure the new/existing VSI

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc: TC number

 * @maxqs: max number of queues

 * @owner: LAN or RDMA

 * @enable: TC enabled or disabled

 *

 * This function adds/updates VSI nodes based on the number of queues. If TC is

 * enabled and VSI is in suspended state then resume the VSI back. If TC is

 * disabled then suspend the VSI if it is not already.

 suspend the VSI if TC is not enabled */

 TC is enabled, if it is a new VSI then add it to the tree */

		/* invalidate the max queues whenever VSI gets added first time

		 * into the scheduler tree (boot or after reset). We need to

		 * recreate the child nodes all the time in these cases.

 update the VSI child nodes */

 TC is enabled, resume the VSI if it is in the suspend state */

/**

 * ice_sched_rm_agg_vsi_info - remove aggregator related VSI info entry

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 *

 * This function removes single aggregator VSI info entry from

 * aggregator list.

/**

 * ice_sched_is_leaf_node_present - check for a leaf node in the sub-tree

 * @node: pointer to the sub-tree node

 *

 * This function checks for a leaf node presence in a given sub-tree node.

 check for a leaf node */

/**

 * ice_sched_rm_vsi_cfg - remove the VSI and its children nodes

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @owner: LAN or RDMA

 *

 * This function removes the VSI and its LAN or RDMA children nodes from the

 * scheduler tree.

				/* reset the counter again since the num

				 * children will be updated after node removal

 remove the VSI if it has no children */

 clean up aggregator related VSI info if any */

/**

 * ice_rm_vsi_lan_cfg - remove VSI and its LAN children nodes

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 *

 * This function clears the VSI and its LAN children nodes from scheduler tree

 * for all TCs.

/**

 * ice_rm_vsi_rdma_cfg - remove VSI and its RDMA children nodes

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 *

 * This function clears the VSI and its RDMA children nodes from scheduler tree

 * for all TCs.

/**

 * ice_get_agg_info - get the aggregator ID

 * @hw: pointer to the hardware structure

 * @agg_id: aggregator ID

 *

 * This function validates aggregator ID. The function returns info if

 * aggregator ID is present in list otherwise it returns null.

/**

 * ice_sched_get_free_vsi_parent - Find a free parent node in aggregator subtree

 * @hw: pointer to the HW struct

 * @node: pointer to a child node

 * @num_nodes: num nodes count array

 *

 * This function walks through the aggregator subtree to find a free parent

 * node

 Is it VSI parent layer ? */

	/* We have intermediate nodes. Let's walk through the subtree. If the

	 * intermediate node has space to add a new node then clear the count

	/* The below recursive call is intentional and wouldn't go more than

	 * 2 or 3 iterations.

/**

 * ice_sched_update_parent - update the new parent in SW DB

 * @new_parent: pointer to a new parent node

 * @node: pointer to a child node

 *

 * This function removes the child from the old parent and adds it to a new

 * parent

 update the old parent children */

 now move the node to a new parent */

/**

 * ice_sched_move_nodes - move child nodes to a given parent

 * @pi: port information structure

 * @parent: pointer to parent node

 * @num_items: number of child nodes to be moved

 * @list: pointer to child node teids

 *

 * This function move the child nodes to a given parent.

 Does parent have enough space */

 update the SW DB */

/**

 * ice_sched_move_vsi_to_agg - move VSI to aggregator node

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @agg_id: aggregator ID

 * @tc: TC number

 *

 * This function moves a VSI to an aggregator node or its subtree.

 * Intermediate nodes may be created if required.

 Is this VSI already part of given aggregator? */

 set intermediate node count to 1 between aggregator and VSI layers */

 Check if the aggregator subtree has any free node to add the VSI */

 add new nodes */

		/* The newly added node can be a new parent for the next

		 * layer nodes

/**

 * ice_move_all_vsi_to_dflt_agg - move all VSI(s) to default aggregator

 * @pi: port information structure

 * @agg_info: aggregator info

 * @tc: traffic class number

 * @rm_vsi_info: true or false

 *

 * This function move all the VSI(s) to the default aggregator and delete

 * aggregator VSI info based on passed in boolean parameter rm_vsi_info. The

 * caller holds the scheduler lock.

 Move VSI to default aggregator */

/**

 * ice_sched_is_agg_inuse - check whether the aggregator is in use or not

 * @pi: port information structure

 * @node: node pointer

 *

 * This function checks whether the aggregator is attached with any VSI or not.

/**

 * ice_sched_rm_agg_cfg - remove the aggregator node

 * @pi: port information structure

 * @agg_id: aggregator ID

 * @tc: TC number

 *

 * This function removes the aggregator node and intermediate nodes if any

 * from the given TC

 Can't remove the aggregator node if it has children */

	/* need to remove the whole subtree if aggregator node is the

	 * only child.

/**

 * ice_rm_agg_cfg_tc - remove aggregator configuration for TC

 * @pi: port information structure

 * @agg_info: aggregator ID

 * @tc: TC number

 * @rm_vsi_info: bool value true or false

 *

 * This function removes aggregator reference to VSI of given TC. It removes

 * the aggregator configuration completely for requested TC. The caller needs

 * to hold the scheduler lock.

 If nothing to remove - return success */

 Delete aggregator node(s) */

/**

 * ice_save_agg_tc_bitmap - save aggregator TC bitmap

 * @pi: port information structure

 * @agg_id: aggregator ID

 * @tc_bitmap: 8 bits TC bitmap

 *

 * Save aggregator TC bitmap. This function needs to be called with scheduler

 * lock held.

/**

 * ice_sched_add_agg_cfg - create an aggregator node

 * @pi: port information structure

 * @agg_id: aggregator ID

 * @tc: TC number

 *

 * This function creates an aggregator node and intermediate nodes if required

 * for the given TC

 Does Agg node already exist ? */

 need one node in Agg layer */

	/* Check whether the intermediate nodes have space to add the

	 * new aggregator. If they are full, then SW needs to allocate a new

	 * intermediate node on those layers

 scan all the siblings */

 all the nodes are full, reserve one for this layer */

 add the aggregator node */

		/* The newly added node can be a new parent for the next

		 * layer nodes

 register aggregator ID with the aggregator node */

/**

 * ice_sched_cfg_agg - configure aggregator node

 * @pi: port information structure

 * @agg_id: aggregator ID

 * @agg_type: aggregator type queue, VSI, or aggregator group

 * @tc_bitmap: bits TC bitmap

 *

 * It registers a unique aggregator node into scheduler services. It

 * allows a user to register with a unique ID to track it's resources.

 * The aggregator type determines if this is a queue group, VSI group

 * or aggregator group. It then creates the aggregator node(s) for requested

 * TC(s) or removes an existing aggregator node including its configuration

 * if indicated via tc_bitmap. Call ice_rm_agg_cfg to release aggregator

 * resources and remove aggregator ID.

 * This function needs to be called with scheduler lock held.

 Create new entry for new aggregator ID */

 Initialize the aggregator VSI list head */

 Add new entry in aggregator list */

 Create aggregator node(s) for requested TC(s) */

 Delete aggregator cfg TC if it exists previously */

 Check if aggregator node for TC already exists */

 Create new aggregator node for TC */

 Save aggregator node's TC information */

/**

 * ice_cfg_agg - config aggregator node

 * @pi: port information structure

 * @agg_id: aggregator ID

 * @agg_type: aggregator type queue, VSI, or aggregator group

 * @tc_bitmap: bits TC bitmap

 *

 * This function configures aggregator node(s).

/**

 * ice_get_agg_vsi_info - get the aggregator ID

 * @agg_info: aggregator info

 * @vsi_handle: software VSI handle

 *

 * The function returns aggregator VSI info based on VSI handle. This function

 * needs to be called with scheduler lock held.

/**

 * ice_get_vsi_agg_info - get the aggregator info of VSI

 * @hw: pointer to the hardware structure

 * @vsi_handle: Sw VSI handle

 *

 * The function returns aggregator info of VSI represented via vsi_handle. The

 * VSI has in this case a different aggregator than the default one. This

 * function needs to be called with scheduler lock held.

/**

 * ice_save_agg_vsi_tc_bitmap - save aggregator VSI TC bitmap

 * @pi: port information structure

 * @agg_id: aggregator ID

 * @vsi_handle: software VSI handle

 * @tc_bitmap: TC bitmap of enabled TC(s)

 *

 * Save VSI to aggregator TC bitmap. This function needs to call with scheduler

 * lock held.

 check if entry already exist */

/**

 * ice_sched_assoc_vsi_to_agg - associate/move VSI to new/default aggregator

 * @pi: port information structure

 * @agg_id: aggregator ID

 * @vsi_handle: software VSI handle

 * @tc_bitmap: TC bitmap of enabled TC(s)

 *

 * This function moves VSI to a new or default aggregator node. If VSI is

 * already associated to the aggregator node then no operation is performed on

 * the tree. This function needs to be called with scheduler lock held.

	/* If the VSI is already part of another aggregator then update

	 * its VSI info list

 check if entry already exist */

 Create new entry for VSI under aggregator list */

 add VSI ID into the aggregator list */

 Move VSI node to new aggregator node for requested TC(s) */

 Move VSI to new aggregator */

/**

 * ice_sched_rm_unused_rl_prof - remove unused RL profile

 * @pi: port information structure

 *

 * This function removes unused rate limit profiles from the HW and

 * SW DB. The caller needs to hold scheduler lock.

/**

 * ice_sched_update_elem - update element

 * @hw: pointer to the HW struct

 * @node: pointer to node

 * @info: node info to update

 *

 * Update the HW DB, and local SW DB of node. Update the scheduling

 * parameters of node from argument info data buffer (Info->data buf) and

 * returns success or error on config sched element failure. The caller

 * needs to hold scheduler lock.

 Parent TEID is reserved field in this aq call */

 Element type is reserved field in this aq call */

 Flags is reserved field in this aq call */

 Update HW DB */

 Configure element node */

 Config success case */

 Now update local SW DB */

 Only copy the data portion of info buffer */

/**

 * ice_sched_cfg_node_bw_alloc - configure node BW weight/alloc params

 * @hw: pointer to the HW struct

 * @node: sched node to configure

 * @rl_type: rate limit type CIR, EIR, or shared

 * @bw_alloc: BW weight/allocation

 *

 * This function configures node element's BW allocation.

 Configure element */

/**

 * ice_move_vsi_to_agg - moves VSI to new or default aggregator

 * @pi: port information structure

 * @agg_id: aggregator ID

 * @vsi_handle: software VSI handle

 * @tc_bitmap: TC bitmap of enabled TC(s)

 *

 * Move or associate VSI to a new or default aggregator node.

/**

 * ice_set_clear_cir_bw - set or clear CIR BW

 * @bw_t_info: bandwidth type information structure

 * @bw: bandwidth in Kbps - Kilo bits per sec

 *

 * Save or clear CIR bandwidth (BW) in the passed param bw_t_info.

 Save type of BW information */

/**

 * ice_set_clear_eir_bw - set or clear EIR BW

 * @bw_t_info: bandwidth type information structure

 * @bw: bandwidth in Kbps - Kilo bits per sec

 *

 * Save or clear EIR bandwidth (BW) in the passed param bw_t_info.

		/* EIR BW and Shared BW profiles are mutually exclusive and

		 * hence only one of them may be set for any given element.

		 * First clear earlier saved shared BW information.

 save EIR BW information */

/**

 * ice_set_clear_shared_bw - set or clear shared BW

 * @bw_t_info: bandwidth type information structure

 * @bw: bandwidth in Kbps - Kilo bits per sec

 *

 * Save or clear shared bandwidth (BW) in the passed param bw_t_info.

		/* EIR BW and Shared BW profiles are mutually exclusive and

		 * hence only one of them may be set for any given element.

		 * First clear earlier saved EIR BW information.

 save shared BW information */

/**

 * ice_sched_save_vsi_bw - save VSI node's BW information

 * @pi: port information structure

 * @vsi_handle: sw VSI handle

 * @tc: traffic class

 * @rl_type: rate limit type min, max, or shared

 * @bw: bandwidth in Kbps - Kilo bits per sec

 *

 * Save BW information of VSI type node for post replay use.

/**

 * ice_sched_calc_wakeup - calculate RL profile wakeup parameter

 * @hw: pointer to the HW struct

 * @bw: bandwidth in Kbps

 *

 * This function calculates the wakeup parameter of RL profile.

 Get the wakeup integer value */

		/* Calculate fraction value up to 4 decimals

		 * Convert Integer value to a constant multiplier

 Get Fraction value */

 Round up the Fractional value via Ceil(Fractional value) */

/**

 * ice_sched_bw_to_rl_profile - convert BW to profile parameters

 * @hw: pointer to the HW struct

 * @bw: bandwidth in Kbps

 * @profile: profile parameters to return

 *

 * This function converts the BW to profile structure format.

 Bw settings range is from 0.5Mb/sec to 100Gb/sec */

 Bytes per second from Kbps */

 encode is 6 bits but really useful are 5 bits */

 Multiplier value */

 Round to the nearest ICE_RL_PROF_MULTIPLIER */

		/* First multiplier value greater than the given

		 * accuracy bytes

/**

 * ice_sched_add_rl_profile - add RL profile

 * @pi: port information structure

 * @rl_type: type of rate limit BW - min, max, or shared

 * @bw: bandwidth in Kbps - Kilo bits per sec

 * @layer_num: specifies in which layer to create profile

 *

 * This function first checks the existing list for corresponding BW

 * parameter. If it exists, it returns the associated profile otherwise

 * it creates a new rate limit profile for requested BW, and adds it to

 * the HW DB and local list. It returns the new profile or null on error.

 * The caller needs to hold the scheduler lock.

 Return existing profile ID info */

 Create new profile ID */

 layer_num is zero relative, and fw expects level from 1 to 9 */

 Create new entry in HW DB */

 Good entry - add in the list */

/**

 * ice_sched_cfg_node_bw_lmt - configure node sched params

 * @hw: pointer to the HW struct

 * @node: sched node to configure

 * @rl_type: rate limit type CIR, EIR, or shared

 * @rl_prof_id: rate limit profile ID

 *

 * This function configures node element's BW limit.

		/* EIR BW and Shared BW profiles are mutually exclusive and

		 * hence only one of them may be set for any given element

 Check for removing shared BW */

 remove shared profile */

 clear SRL field */

 enable back EIR to default profile */

		/* EIR BW and Shared BW profiles are mutually exclusive and

		 * hence only one of them may be set for any given element

 EIR BW is set to default, disable it */

 Okay to enable shared BW now */

 Unknown rate limit type */

 Configure element */

/**

 * ice_sched_get_node_rl_prof_id - get node's rate limit profile ID

 * @node: sched node

 * @rl_type: rate limit type

 *

 * If existing profile matches, it returns the corresponding rate

 * limit profile ID, otherwise it returns an invalid ID as error.

/**

 * ice_sched_get_rl_prof_layer - selects rate limit profile creation layer

 * @pi: port information structure

 * @rl_type: type of rate limit BW - min, max, or shared

 * @layer_index: layer index

 *

 * This function returns requested profile creation layer.

		/* if current layer doesn't support SRL profile creation

		 * then try a layer up or down.

/**

 * ice_sched_get_srl_node - get shared rate limit node

 * @node: tree node

 * @srl_layer: shared rate limit layer

 *

 * This function returns SRL node to be used for shared rate limit purpose.

 * The caller needs to hold scheduler lock.

		/* Node can't be created without a parent. It will always

		 * have a valid parent except root node.

/**

 * ice_sched_rm_rl_profile - remove RL profile ID

 * @pi: port information structure

 * @layer_num: layer number where profiles are saved

 * @profile_type: profile type like EIR, CIR, or SRL

 * @profile_id: profile ID to remove

 *

 * This function removes rate limit profile from layer 'layer_num' of type

 * 'profile_type' and profile ID as 'profile_id'. The caller needs to hold

 * scheduler lock.

 Check the existing list for RL profile */

 Remove old profile ID from database */

/**

 * ice_sched_set_node_bw_dflt - set node's bandwidth limit to default

 * @pi: port information structure

 * @node: pointer to node structure

 * @rl_type: rate limit type min, max, or shared

 * @layer_num: layer number where RL profiles are saved

 *

 * This function configures node element's BW rate limit profile ID of

 * type CIR, EIR, or SRL to default. This function needs to be called

 * with the scheduler lock held.

 No SRL is configured for default case */

 Save existing RL prof ID for later clean up */

 Configure BW scheduling parameters */

 Remove stale RL profile ID */

/**

 * ice_sched_set_eir_srl_excl - set EIR/SRL exclusiveness

 * @pi: port information structure

 * @node: pointer to node structure

 * @layer_num: layer number where rate limit profiles are saved

 * @rl_type: rate limit type min, max, or shared

 * @bw: bandwidth value

 *

 * This function prepares node element's bandwidth to SRL or EIR exclusively.

 * EIR BW and Shared BW profiles are mutually exclusive and hence only one of

 * them may be set for any given element. This function needs to be called

 * with the scheduler lock held.

 SRL node passed in this case, it may be different node */

			/* SRL being removed, ice_sched_cfg_node_bw_lmt()

			 * enables EIR to default. EIR is not set in this

			 * case, so no additional action is required.

		/* SRL being configured, set EIR to default here.

		 * ice_sched_cfg_node_bw_lmt() disables EIR when it

		 * configures SRL

		/* Remove Shared profile. Set default shared BW call

		 * removes shared profile for a node.

/**

 * ice_sched_set_node_bw - set node's bandwidth

 * @pi: port information structure

 * @node: tree node

 * @rl_type: rate limit type min, max, or shared

 * @bw: bandwidth in Kbps - Kilo bits per sec

 * @layer_num: layer number

 *

 * This function adds new profile corresponding to requested BW, configures

 * node's RL profile ID of type CIR, EIR, or SRL, and removes old profile

 * ID from local database. The caller needs to hold scheduler lock.

 Save existing RL prof ID for later clean up */

 Configure BW scheduling parameters */

 New changes has been applied */

 Increment the profile ID reference count */

 Check for old ID removal */

/**

 * ice_sched_set_node_bw_lmt - set node's BW limit

 * @pi: port information structure

 * @node: tree node

 * @rl_type: rate limit type min, max, or shared

 * @bw: bandwidth in Kbps - Kilo bits per sec

 *

 * It updates node's BW limit parameters like BW RL profile ID of type CIR,

 * EIR, or SRL. The caller needs to hold scheduler lock.

 Remove unused RL profile IDs from HW and SW DB */

 SRL node may be different */

	/* EIR BW and Shared BW profiles are mutually exclusive and

	 * hence only one of them may be set for any given element

/**

 * ice_sched_set_node_bw_dflt_lmt - set node's BW limit to default

 * @pi: port information structure

 * @node: pointer to node structure

 * @rl_type: rate limit type min, max, or shared

 *

 * This function configures node element's BW rate limit profile ID of

 * type CIR, EIR, or SRL to default. This function needs to be called

 * with the scheduler lock held.

/**

 * ice_sched_validate_srl_node - Check node for SRL applicability

 * @node: sched node to configure

 * @sel_layer: selected SRL layer

 *

 * This function checks if the SRL can be applied to a selected layer node on

 * behalf of the requested node (first argument). This function needs to be

 * called with scheduler lock held.

	/* SRL profiles are not available on all layers. Check if the

	 * SRL profile can be applied to a node above or below the

	 * requested node. SRL configuration is possible only if the

	 * selected layer's node has single child.

/**

 * ice_sched_save_q_bw - save queue node's BW information

 * @q_ctx: queue context structure

 * @rl_type: rate limit type min, max, or shared

 * @bw: bandwidth in Kbps - Kilo bits per sec

 *

 * Save BW information of queue type node for post replay use.

/**

 * ice_sched_set_q_bw_lmt - sets queue BW limit

 * @pi: port information structure

 * @vsi_handle: sw VSI handle

 * @tc: traffic class

 * @q_handle: software queue handle

 * @rl_type: min, max, or shared

 * @bw: bandwidth in Kbps

 *

 * This function sets BW limit of queue scheduling node.

 Return error if it is not a leaf node */

 SRL bandwidth layer selection */

 selected layer */

/**

 * ice_cfg_q_bw_lmt - configure queue BW limit

 * @pi: port information structure

 * @vsi_handle: sw VSI handle

 * @tc: traffic class

 * @q_handle: software queue handle

 * @rl_type: min, max, or shared

 * @bw: bandwidth in Kbps

 *

 * This function configures BW limit of queue scheduling node.

/**

 * ice_cfg_q_bw_dflt_lmt - configure queue BW default limit

 * @pi: port information structure

 * @vsi_handle: sw VSI handle

 * @tc: traffic class

 * @q_handle: software queue handle

 * @rl_type: min, max, or shared

 *

 * This function configures BW default limit of queue scheduling node.

/**

 * ice_sched_get_node_by_id_type - get node from ID type

 * @pi: port information structure

 * @id: identifier

 * @agg_type: type of aggregator

 * @tc: traffic class

 *

 * This function returns node identified by ID of type aggregator, and

 * based on traffic class (TC). This function needs to be called with

 * the scheduler lock held.

 Get sched_vsi_info */

/**

 * ice_sched_set_node_bw_lmt_per_tc - set node BW limit per TC

 * @pi: port information structure

 * @id: ID (software VSI handle or AGG ID)

 * @agg_type: aggregator type (VSI or AGG type node)

 * @tc: traffic class

 * @rl_type: min or max

 * @bw: bandwidth in Kbps

 *

 * This function sets BW limit of VSI or Aggregator scheduling node

 * based on TC information from passed in argument BW.

/**

 * ice_cfg_vsi_bw_lmt_per_tc - configure VSI BW limit per TC

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc: traffic class

 * @rl_type: min or max

 * @bw: bandwidth in Kbps

 *

 * This function configures BW limit of VSI scheduling node based on TC

 * information.

/**

 * ice_cfg_vsi_bw_dflt_lmt_per_tc - configure default VSI BW limit per TC

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc: traffic class

 * @rl_type: min or max

 *

 * This function configures default BW limit of VSI scheduling node based on TC

 * information.

/**

 * ice_cfg_rl_burst_size - Set burst size value

 * @hw: pointer to the HW struct

 * @bytes: burst size in bytes

 *

 * This function configures/set the burst size to requested new value. The new

 * burst size value is used for future rate limit calls. It doesn't change the

 * existing or previously created RL profiles.

 64 byte granularity case */

 Disable MSB granularity bit */

 round number to nearest 64 byte granularity */

 The value is in 64 byte chunks */

 k bytes granularity case */

 Enable MSB granularity bit */

 round number to nearest 1024 granularity */

 check rounding doesn't go beyond allowed */

 The value is in k bytes */

/**

 * ice_sched_replay_node_prio - re-configure node priority

 * @hw: pointer to the HW struct

 * @node: sched node to configure

 * @priority: priority value

 *

 * This function configures node element's priority value. It

 * needs to be called with scheduler lock held.

 Configure element */

/**

 * ice_sched_replay_node_bw - replay node(s) BW

 * @hw: pointer to the HW struct

 * @node: sched node to configure

 * @bw_t_info: BW type information

 *

 * This function restores node's BW from bw_t_info. The caller needs

 * to hold the scheduler lock.

/**

 * ice_sched_get_ena_tc_bitmap - get enabled TC bitmap

 * @pi: port info struct

 * @tc_bitmap: 8 bits TC bitmap to check

 * @ena_tc_bitmap: 8 bits enabled TC bitmap to return

 *

 * This function returns enabled TC bitmap in variable ena_tc_bitmap. Some TCs

 * may be missing, it returns enabled TCs. This function needs to be called with

 * scheduler lock held.

 Some TC(s) may be missing after reset, adjust for replay */

/**

 * ice_sched_replay_agg - recreate aggregator node(s)

 * @hw: pointer to the HW struct

 *

 * This function recreate aggregator type nodes which are not replayed earlier.

 * It also replay aggregator BW information. These aggregator nodes are not

 * associated with VSI type node yet.

 replay aggregator (re-create aggregator node) */

 Move on to next one */

/**

 * ice_sched_replay_agg_vsi_preinit - Agg/VSI replay pre initialization

 * @hw: pointer to the HW struct

 *

 * This function initialize aggregator(s) TC bitmap to zero. A required

 * preinit step for replaying aggregators.

/**

 * ice_sched_replay_vsi_agg - replay aggregator & VSI to aggregator node(s)

 * @hw: pointer to the HW struct

 * @vsi_handle: software VSI handle

 *

 * This function replays aggregator node, VSI to aggregator type nodes, and

 * their node bandwidth information. This function needs to be called with

 * scheduler lock held.

 Not present in list - default Agg case */

 Not present in list - default Agg case */

 Replay aggregator node associated to vsi_handle */

 Move this VSI (vsi_handle) to above aggregator */

/**

 * ice_replay_vsi_agg - replay VSI to aggregator node

 * @hw: pointer to the HW struct

 * @vsi_handle: software VSI handle

 *

 * This function replays association of VSI to aggregator type nodes, and

 * node bandwidth information.

/**

 * ice_sched_replay_q_bw - replay queue type node BW

 * @pi: port information structure

 * @q_ctx: queue context structure

 *

 * This function replays queue type node bandwidth. This function needs to be

 * called with scheduler lock held.

 Following also checks the presence of node in tree */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018-2020, Intel Corporation. */

 flow director ethtool support for ice */

/* calls to ice_flow_add_prof require the number of segments in the array

 * for segs_cnt. In this code that is one more than the index.

/**

 * ice_fltr_to_ethtool_flow - convert filter type values to ethtool

 * flow type values

 * @flow: filter type to be converted

 *

 * Returns the corresponding ethtool flow type.

 0 is undefined ethtool flow */

/**

 * ice_ethtool_flow_to_fltr - convert ethtool flow type to filter enum

 * @eth: Ethtool flow type to be converted

 *

 * Returns flow enum

/**

 * ice_is_mask_valid - check mask field set

 * @mask: full mask to check

 * @field: field for which mask should be valid

 *

 * If the mask is fully set return true. If it is not valid for field return

 * false.

/**

 * ice_get_ethtool_fdir_entry - fill ethtool structure with fdir filter data

 * @hw: hardware structure that contains filter list

 * @cmd: ethtool command data structure to receive the filter data

 *

 * Returns 0 on success and -EINVAL on failure

/**

 * ice_get_fdir_fltr_ids - fill buffer with filter IDs of active filters

 * @hw: hardware structure containing the filter list

 * @cmd: ethtool command data structure

 * @rule_locs: ethtool array passed in from OS to receive filter IDs

 *

 * Returns 0 as expected for success by ethtool

 report total rule count */

/**

 * ice_fdir_get_hw_prof - return the ice_fd_hw_proc associated with a flow

 * @hw: hardware structure containing the filter list

 * @blk: hardware block

 * @flow: FDir flow type to release

/**

 * ice_fdir_erase_flow_from_hw - remove a flow from the HW profile tables

 * @hw: hardware structure containing the filter list

 * @blk: hardware block

 * @flow: FDir flow type to release

/**

 * ice_fdir_rem_flow - release the ice_flow structures for a filter type

 * @hw: hardware structure containing the filter list

 * @blk: hardware block

 * @flow_type: FDir flow type to release

/**

 * ice_fdir_release_flows - release all flows in use for later replay

 * @hw: pointer to HW instance

 release Flow Director HW table entries */

/**

 * ice_fdir_replay_flows - replay HW Flow Director filter info

 * @hw: pointer to HW instance

/**

 * ice_parse_rx_flow_user_data - deconstruct user-defined data

 * @fsp: pointer to ethtool Rx flow specification

 * @data: pointer to userdef data structure for storage

 *

 * Returns 0 on success, negative error value on failure

	/* 0x1fe is the maximum value for offsets stored in the internal

	 * filtering tables.

/**

 * ice_fdir_num_avail_fltr - return the number of unused flow director filters

 * @hw: pointer to hardware structure

 * @vsi: software VSI structure

 *

 * There are 2 filter pools: guaranteed and best effort(shared). Each VSI can

 * use filters from either pool. The guaranteed pool is divided between VSIs.

 * The best effort filter pool is common to all VSIs and is a device shared

 * resource pool. The number of filters available to this VSI is the sum of

 * the VSIs guaranteed filter pool and the global available best effort

 * filter pool.

 *

 * Returns the number of available flow director filters to this VSI

 total guaranteed filters assigned to this VSI */

 minus the guaranteed filters programed by this VSI */

 total global best effort filters */

 minus the global best effort filters programmed */

/**

 * ice_fdir_alloc_flow_prof - allocate FDir flow profile structure(s)

 * @hw: HW structure containing the FDir flow profile structure(s)

 * @flow: flow type to allocate the flow profile for

 *

 * Allocate the fdir_prof and fdir_prof[flow] if not already created. Return 0

 * on success and negative on error.

/**

 * ice_fdir_set_hw_fltr_rule - Configure HW tables to generate a FDir rule

 * @pf: pointer to the PF structure

 * @seg: protocol header description pointer

 * @flow: filter enum

 * @tun: FDir segment to program

		/* This flow_type already has a changed input set.

		 * If it matches the requested input set then we are

		 * done. Or, if it's different then it's an error.

		/* if there are FDir filters using this flow,

		 * then return error.

 remove HW filter definition */

	/* Adding a profile, but there is only one header supported.

	 * That is the final parameters are 1 header (segment), no

	 * actions (NULL) and zero actions 0.

/**

 * ice_set_init_fdir_seg

 * @seg: flow segment for programming

 * @l3_proto: ICE_FLOW_SEG_HDR_IPV4 or ICE_FLOW_SEG_HDR_IPV6

 * @l4_proto: ICE_FLOW_SEG_HDR_TCP or ICE_FLOW_SEG_HDR_UDP

 *

 * Set the configuration for perfect filters to the provided flow segment for

 * programming the HW filter. This is to be called only when initializing

 * filters as this function it assumes no filters exist.

 IP source address */

 IP destination address */

 Layer 4 source port */

 Layer 4 destination port */

/**

 * ice_create_init_fdir_rule

 * @pf: PF structure

 * @flow: filter enum

 *

 * Return error value or 0 on success.

 if there is already a filter rule for kind return -EINVAL */

 add filter for outer headers */

 could not write filter, free memory */

 make tunneled filter HW entries if possible */

		/* could not write tunnel filter, but outer header filter

		 * exists

/**

 * ice_set_fdir_ip4_seg

 * @seg: flow segment for programming

 * @tcp_ip4_spec: mask data from ethtool

 * @l4_proto: Layer 4 protocol to program

 * @perfect_fltr: only valid on success; returns true if perfect filter,

 *		  false if not

 *

 * Set the mask data into the flow segment to be used to program HW

 * table based on provided L4 protocol for IPv4

 make sure we don't have any empty rule */

 filtering on TOS not supported */

 IP source address */

 IP destination address */

 Layer 4 source port */

 Layer 4 destination port */

/**

 * ice_set_fdir_ip4_usr_seg

 * @seg: flow segment for programming

 * @usr_ip4_spec: ethtool userdef packet offset

 * @perfect_fltr: only valid on success; returns true if perfect filter,

 *		  false if not

 *

 * Set the offset data into the flow segment to be used to program HW

 * table for IPv4

 first 4 bytes of Layer 4 header */

 Filtering on Layer 4 protocol not supported */

 empty rules are not valid */

 IP source address */

 IP destination address */

/**

 * ice_set_fdir_ip6_seg

 * @seg: flow segment for programming

 * @tcp_ip6_spec: mask data from ethtool

 * @l4_proto: Layer 4 protocol to program

 * @perfect_fltr: only valid on success; returns true if perfect filter,

 *		  false if not

 *

 * Set the mask data into the flow segment to be used to program HW

 * table based on provided L4 protocol for IPv6

 make sure we don't have any empty rule */

 filtering on TC not supported */

 Layer 4 source port */

 Layer 4 destination port */

/**

 * ice_set_fdir_ip6_usr_seg

 * @seg: flow segment for programming

 * @usr_ip6_spec: ethtool userdef packet offset

 * @perfect_fltr: only valid on success; returns true if perfect filter,

 *		  false if not

 *

 * Set the offset data into the flow segment to be used to program HW

 * table for IPv6

 filtering on Layer 4 bytes not supported */

 filtering on TC not supported */

 filtering on Layer 4 protocol not supported */

 empty rules are not valid */

/**

 * ice_cfg_fdir_xtrct_seq - Configure extraction sequence for the given filter

 * @pf: PF structure

 * @fsp: pointer to ethtool Rx flow specification

 * @user: user defined data from flow specification

 *

 * Returns 0 on success.

 tunnel segments are shifted up one. */

 add filter for outer headers */

 Rule already exists, free memory and continue */

 could not write filter, free memory */

 make tunneled filter HW entries if possible */

 Rule already exists, free memory and count as success */

 could not write tunnel filter, but outer filter exists */

/**

 * ice_fdir_write_fltr - send a flow director filter to the hardware

 * @pf: PF data structure

 * @input: filter structure

 * @add: true adds filter and false removed filter

 * @is_tun: true adds inner filter on tunnel and false outer headers

 *

 * returns 0 on success and negative value on error

 repeat for fragment packet */

 does not return error */

/**

 * ice_fdir_write_all_fltr - send a flow director filter to the hardware

 * @pf: PF data structure

 * @input: filter structure

 * @add: true adds filter and false removed filter

 *

 * returns 0 on success and negative value on error

/**

 * ice_fdir_replay_fltrs - replay filters from the HW filter list

 * @pf: board private structure

/**

 * ice_fdir_create_dflt_rules - create default perfect filters

 * @pf: PF data structure

 *

 * Returns 0 for success or error.

 Create perfect TCP and UDP rules in hardware. */

/**

 * ice_vsi_manage_fdir - turn on/off flow director

 * @vsi: the VSI being changed

 * @ena: boolean value indicating if this is an enable or disable request

 ignore return value */

/**

 * ice_fdir_do_rem_flow - delete flow and possibly add perfect flow

 * @pf: PF structure

 * @flow_type: FDir flow type to release

/**

 * ice_fdir_update_list_entry - add or delete a filter from the filter list

 * @pf: PF structure

 * @input: filter structure

 * @fltr_idx: ethtool index of filter to modify

 *

 * returns 0 on success and negative on errors

 Do not update filters during reset */

			/* we just deleted the last filter of flow_type so we

			 * should also delete the HW filter info.

/**

 * ice_del_fdir_ethtool - delete Flow Director filter

 * @vsi: pointer to target VSI

 * @cmd: command to add or delete Flow Director filter

 *

 * Returns 0 on success and negative values for failure

 Do not delete filters during reset */

/**

 * ice_set_fdir_input_set - Set the input set for Flow Director

 * @vsi: pointer to target VSI

 * @fsp: pointer to ethtool Rx flow specification

 * @input: filter structure

 if no protocol requested, use IPPROTO_NONE */

 not doing un-parsed flow types */

/**

 * ice_add_fdir_ethtool - Add/Remove Flow Director filter

 * @vsi: pointer to target VSI

 * @cmd: command to add or delete Flow Director filter

 *

 * Returns 0 on success and negative values for failure

 Do not program filters during reset */

 return error if not an update and no available filters */

 input struct is added to the HW filter list */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019, Intel Corporation. */

/**

 * __ice_vsi_get_qs_contig - Assign a contiguous chunk of queues to VSI

 * @qs_cfg: gathered variables needed for PF->VSI queues assignment

 *

 * Return 0 on success and -ENOMEM in case of no left space in PF queue bitmap

/**

 * __ice_vsi_get_qs_sc - Assign a scattered queues from PF to VSI

 * @qs_cfg: gathered variables needed for pf->vsi queues assignment

 *

 * Return 0 on success and -ENOMEM in case of no left space in PF queue bitmap

/**

 * ice_pf_rxq_wait - Wait for a PF's Rx queue to be enabled or disabled

 * @pf: the PF being configured

 * @pf_q: the PF queue

 * @ena: enable or disable state of the queue

 *

 * This routine will wait for the given Rx queue of the PF to reach the

 * enabled or disabled state.

 * Returns -ETIMEDOUT in case of failing to reach the requested state after

 * multiple retries; else will return 0 in case of success.

/**

 * ice_vsi_alloc_q_vector - Allocate memory for a single interrupt vector

 * @vsi: the VSI being configured

 * @v_idx: index of the vector in the VSI struct

 *

 * We allocate one q_vector and set default value for ITR setting associated

 * with this q_vector. If allocation fails we return -ENOMEM.

 allocate q_vector */

 only set affinity_mask if the CPU is online */

	/* This will not be called in the driver load path because the netdev

	 * will not be created yet. All other cases with register the NAPI

	 * handler here (i.e. resume, reset/rebuild, etc.)

 tie q_vector and VSI together */

/**

 * ice_free_q_vector - Free memory allocated for a specific interrupt vector

 * @vsi: VSI having the memory freed

 * @v_idx: index of the vector to be freed

 only VSI with an associated netdev is set up with NAPI */

/**

 * ice_cfg_itr_gran - set the ITR granularity to 2 usecs if not already set

 * @hw: board specific structure

 no need to update global register if ITR gran is already set */

/**

 * ice_calc_txq_handle - calculate the queue handle

 * @vsi: VSI that ring belongs to

 * @ring: ring to get the absolute queue index

 * @tc: traffic class number

	/* Idea here for calculation is that we subtract the number of queue

	 * count from TC that ring belongs to from it's absolute queue index

	 * and as a result we get the queue's index within TC.

/**

 * ice_eswitch_calc_txq_handle

 * @ring: pointer to ring which unique index is needed

 *

 * To correctly work with many netdevs ring->q_index of Tx rings on switchdev

 * VSI can repeat. Hardware ring setup requires unique q_index. Calculate it

 * here by finding index in vsi->tx_rings of this ring.

 *

 * Return ICE_INVAL_Q_INDEX when index wasn't found. Should never happen,

 * because VSI is get from ring->vsi, so it has to be present in this VSI.

/**

 * ice_cfg_xps_tx_ring - Configure XPS for a Tx ring

 * @ring: The Tx ring to configure

 *

 * This enables/disables XPS for a given Tx descriptor ring

 * based on the TCs enabled for the VSI that ring belongs to.

 We only initialize XPS once, so as not to overwrite user settings */

/**

 * ice_setup_tx_ctx - setup a struct ice_tlan_ctx instance

 * @ring: The Tx ring to configure

 * @tlan_ctx: Pointer to the Tx LAN queue context structure to be initialized

 * @pf_q: queue index in the PF space

 *

 * Configure the Tx descriptor ring in TLAN context.

 Transmit Queue Length */

 PF number */

	/* queue belongs to a specific VSI type

	 * VF / VM index should be programmed per vmvf_type setting:

	 * for vmvf_type = VF, it is VF number between 0-256

	 * for vmvf_type = VM, it is VM number between 0-767

	 * for PF or EMP this field should be set to zero

 Firmware expects vmvf_num to be absolute VF ID */

 make sure the context is associated with the right VSI */

 Restrict Tx timestamps to the PF VSI */

	/* Legacy or Advanced Host Interface:

	 * 0: Advanced Host Interface

	 * 1: Legacy Host Interface

/**

 * ice_rx_offset - Return expected offset into page to access data

 * @rx_ring: Ring we are requesting offset of

 *

 * Returns the offset value for ring into the data buffer.

/**

 * ice_setup_rx_ctx - Configure a receive ring context

 * @ring: The Rx ring to configure

 *

 * Configure the Rx descriptor ring in RLAN context.

 what is Rx queue number in global space of 2K Rx queues */

 clear the context structure first */

	/* Receive Queue Base Address.

	 * Indicates the starting address of the descriptor queue defined in

	 * 128 Byte units.

	/* Receive Packet Data Buffer Size.

	 * The Packet Data Buffer Size is defined in 128 byte units.

 use 32 byte descriptors */

	/* Strip the Ethernet CRC bytes before the packet is posted to host

	 * memory.

 L2TSEL flag defines the reported L2 Tags in the receive descriptor */

	/* This controls whether VLAN is stripped from inner headers

	 * The VLAN in the inner L2 header is stripped to the receive

	 * descriptor if enabled by this flag.

	/* For AF_XDP ZC, we disallow packets to span on

	 * multiple buffers, thus letting us skip that

	 * handling in the fast-path.

	/* Max packet size for this queue - must not be set to a larger value

	 * than 5 x DBUF

 Rx queue threshold in units of 64 */

	/* Enable Flexible Descriptors in the queue context which

	 * allows this driver to select a specific receive descriptor format

	 * increasing context priority to pick up profile ID; default is 0x01;

	 * setting to 0x03 to ensure profile is programming if prev context is

	 * of same priority

 Absolute queue number out of 2K needs to be passed */

 configure Rx buffer alignment */

 init queue specific tail register */

/**

 * ice_vsi_cfg_rxq - Configure an Rx queue

 * @ring: the ring being configured

 *

 * Return 0 on success and a negative value on error.

 coverity[check_return] */

 coverity[check_return] */

/**

 * __ice_vsi_get_qs - helper function for assigning queues from PF to VSI

 * @qs_cfg: gathered variables needed for pf->vsi queues assignment

 *

 * This function first tries to find contiguous space. If it is not successful,

 * it tries with the scatter approach.

 *

 * Return 0 on success and -ENOMEM in case of no left space in PF queue bitmap

 contig failed, so try with scatter approach */

/**

 * ice_vsi_ctrl_one_rx_ring - start/stop VSI's Rx ring with no busy wait

 * @vsi: the VSI being configured

 * @ena: start or stop the Rx ring

 * @rxq_idx: 0-based Rx queue index for the VSI passed in

 * @wait: wait or don't wait for configuration to finish in hardware

 *

 * Return 0 on success and negative on error.

 Skip if the queue is already in the requested state */

 turn on/off the queue */

/**

 * ice_vsi_wait_one_rx_ring - wait for a VSI's Rx ring to be stopped/started

 * @vsi: the VSI being configured

 * @ena: true/false to verify Rx ring has been enabled/disabled respectively

 * @rxq_idx: 0-based Rx queue index for the VSI passed in

 *

 * This routine will wait for the given Rx queue of the VSI to reach the

 * enabled or disabled state. Returns -ETIMEDOUT in case of failing to reach

 * the requested state after multiple retries; else will return 0 in case of

 * success.

/**

 * ice_vsi_alloc_q_vectors - Allocate memory for interrupt vectors

 * @vsi: the VSI being configured

 *

 * We allocate one q_vector per queue interrupt. If allocation fails we

 * return -ENOMEM.

/**

 * ice_vsi_map_rings_to_vectors - Map VSI rings to interrupt vectors

 * @vsi: the VSI being configured

 *

 * This function maps descriptor rings to the queue-specific vectors allotted

 * through the MSI-X enabling code. On a constrained vector budget, we map Tx

 * and Rx rings to the vector as "efficiently" as possible.

 initially assigning remaining rings count to VSIs num queue value */

 Tx rings mapping to vector */

 Rx rings mapping to vector */

/**

 * ice_vsi_free_q_vectors - Free memory allocated for interrupt vectors

 * @vsi: the VSI having memory freed

/**

 * ice_vsi_cfg_txq - Configure single Tx queue

 * @vsi: the VSI that queue belongs to

 * @ring: Tx ring to be configured

 * @qg_buf: queue group buffer

 Configure XPS */

 copy context contents into the qg_buf */

	/* init queue specific tail reg. It is referred as

	 * transmit comm scheduler queue doorbell.

	/* Add unique software queue handle of the Tx queue per

	 * TC into the VSI Tx ring

	/* Add Tx Queue TEID into the VSI Tx ring from the

	 * response. This will complete configuring and

	 * enabling the queue.

/**

 * ice_cfg_itr - configure the initial interrupt throttle values

 * @hw: pointer to the HW structure

 * @q_vector: interrupt vector that's being configured

 *

 * Configure interrupt throttling values for the ring containers that are

 * associated with the interrupt vector passed in.

/**

 * ice_cfg_txq_interrupt - configure interrupt on Tx queue

 * @vsi: the VSI being configured

 * @txq: Tx queue being mapped to MSI-X vector

 * @msix_idx: MSI-X vector index within the function

 * @itr_idx: ITR index of the interrupt cause

 *

 * Configure interrupt on Tx queue by associating Tx queue to MSI-X vector

 * within the function space.

/**

 * ice_cfg_rxq_interrupt - configure interrupt on Rx queue

 * @vsi: the VSI being configured

 * @rxq: Rx queue being mapped to MSI-X vector

 * @msix_idx: MSI-X vector index within the function

 * @itr_idx: ITR index of the interrupt cause

 *

 * Configure interrupt on Rx queue by associating Rx queue to MSI-X vector

 * within the function space.

/**

 * ice_trigger_sw_intr - trigger a software interrupt

 * @hw: pointer to the HW structure

 * @q_vector: interrupt vector to trigger the software interrupt for

/**

 * ice_vsi_stop_tx_ring - Disable single Tx ring

 * @vsi: the VSI being configured

 * @rst_src: reset source

 * @rel_vmvf_num: Relative ID of VF/VM

 * @ring: Tx ring to be stopped

 * @txq_meta: Meta data of Tx ring to be stopped

 clear cause_ena bit for disabled queues */

 software is expected to wait for 100 ns */

	/* trigger a software interrupt for the vector

	 * associated to the queue to schedule NAPI handler

	/* if the disable queue command was exercised during an

	 * active reset flow, ICE_ERR_RESET_ONGOING is returned.

	 * This is not an error as the reset operation disables

	 * queues at the hardware level anyway.

/**

 * ice_fill_txq_meta - Prepare the Tx queue's meta data

 * @vsi: VSI that ring belongs to

 * @ring: ring that txq_meta will be based on

 * @txq_meta: a helper struct that wraps Tx queue's information

 *

 * Set up a helper struct that will contain all the necessary fields that

 * are needed for stopping Tx queue

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2021, Intel Corporation. */

/* Purpose of this file is to share functionality to allowlist or denylist

 * opcodes used in PF <-> VF communication. Group of opcodes:

 * - default -> should be always allowed after creating VF,

 *   default_allowlist_opcodes

 * - opcodes needed by VF to work correctly, but not associated with caps ->

 *   should be allowed after successful VF resources allocation,

 *   working_allowlist_opcodes

 * - opcodes needed by VF when caps are activated

 *

 * Caps that don't use new opcodes (no opcodes should be allowed):

 * - VIRTCHNL_VF_OFFLOAD_RSS_AQ

 * - VIRTCHNL_VF_OFFLOAD_RSS_REG

 * - VIRTCHNL_VF_OFFLOAD_WB_ON_ITR

 * - VIRTCHNL_VF_OFFLOAD_CRC

 * - VIRTCHNL_VF_OFFLOAD_RX_POLLING

 * - VIRTCHNL_VF_OFFLOAD_RSS_PCTYPE_V2

 * - VIRTCHNL_VF_OFFLOAD_ENCAP

 * - VIRTCHNL_VF_OFFLOAD_ENCAP_CSUM

 * - VIRTCHNL_VF_OFFLOAD_RX_ENCAP_CSUM

 * - VIRTCHNL_VF_OFFLOAD_USO

 default opcodes to communicate with VF */

 opcodes supported after successful VIRTCHNL_OP_GET_VF_RESOURCES */

 VIRTCHNL_VF_OFFLOAD_L2 */

 VIRTCHNL_VF_OFFLOAD_REQ_QUEUES */

 VIRTCHNL_VF_OFFLOAD_VLAN */

 VIRTCHNL_VF_OFFLOAD_RSS_PF */

 VIRTCHNL_VF_OFFLOAD_ADV_RSS_PF */

 VIRTCHNL_VF_OFFLOAD_FDIR_PF */

/**

 * ice_vc_is_opcode_allowed - check if this opcode is allowed on this VF

 * @vf: pointer to VF structure

 * @opcode: virtchnl opcode

 *

 * Return true if message is allowed on this VF

/**

 * ice_vc_allowlist_opcodes - allowlist selected opcodes

 * @vf: pointer to VF structure

 * @opcodes: array of opocodes to allowlist

 * @size: size of opcodes array

 *

 * Function should be called to allowlist opcodes on VF.

/**

 * ice_vc_clear_allowlist - clear all allowlist opcodes

 * @vf: pointer to VF structure

/**

 * ice_vc_set_default_allowlist - allowlist default opcodes for VF

 * @vf: pointer to VF structure

/**

 * ice_vc_set_working_allowlist - allowlist opcodes needed to by VF to work

 * @vf: pointer to VF structure

 *

 * allowlist opcodes that aren't associated with specific caps, but

 * are needed by VF to work.

/**

 * ice_vc_set_caps_allowlist - allowlist VF opcodes according caps

 * @vf: pointer to VF structure

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2021, Intel Corporation. */

 Inter-Driver Communication */

/**

 * ice_get_auxiliary_drv - retrieve iidc_auxiliary_drv struct

 * @pf: pointer to PF struct

 *

 * This function has to be called with a device_lock on the

 * pf->adev.dev to avoid race conditions.

/**

 * ice_send_event_to_aux - send event to RDMA AUX driver

 * @pf: pointer to PF struct

 * @event: event struct

/**

 * ice_find_vsi - Find the VSI from VSI ID

 * @pf: The PF pointer to search in

 * @vsi_num: The VSI ID to search for

/**

 * ice_add_rdma_qset - Add Leaf Node for RDMA Qset

 * @pf: PF struct

 * @qset: Resource to be allocated

/**

 * ice_del_rdma_qset - Delete leaf node for RDMA Qset

 * @pf: PF struct

 * @qset: Resource to be freed

/**

 * ice_rdma_request_reset - accept request from RDMA to perform a reset

 * @pf: struct for PF

 * @reset_type: type of reset

/**

 * ice_rdma_update_vsi_filter - update main VSI filters for RDMA

 * @pf: pointer to struct for PF

 * @vsi_id: VSI HW idx to update filter on

 * @enable: bool whether to enable or disable filters

/**

 * ice_get_qos_params - parse QoS params for RDMA consumption

 * @pf: pointer to PF struct

 * @qos: set of QoS values

/**

 * ice_reserve_rdma_qvector - Reserve vector resources for RDMA driver

 * @pf: board private structure to initialize

/**

 * ice_adev_release - function to be mapped to AUX dev's release op

 * @dev: pointer to device to free

/**

 * ice_plug_aux_dev - allocate and register AUX device

 * @pf: pointer to pf struct

	/* if this PF doesn't support a technology that requires auxiliary

	 * devices, then gracefully exit

/* ice_unplug_aux_dev - unregister and free AUX device

 * @pf: pointer to pf struct

/**

 * ice_init_rdma - initializes PF for RDMA use

 * @pf: ptr to ice_pf

 Reserve vector resources */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

 The driver transmit and receive code */

/**

 * ice_prgm_fdir_fltr - Program a Flow Director filter

 * @vsi: VSI to send dummy packet

 * @fdir_desc: flow director descriptor

 * @raw_packet: allocated buffer for flow director

 VSI and Tx ring */

 we are using two descriptors to add/del a filter and we can wait */

 grab the next descriptor */

	/* Force memory write to complete before letting h/w know

	 * there are new descriptors to fetch.

 mark the data descriptor to be watched */

/**

 * ice_unmap_and_free_tx_buf - Release a Tx buffer

 * @ring: the ring that owns the buffer

 * @tx_buf: the buffer to free

 tx_buf must be completely set up in the transmit path */

/**

 * ice_clean_tx_ring - Free any empty Tx buffers

 * @tx_ring: ring to be cleaned

 ring already cleared, nothing to do */

 Free all the Tx ring sk_buffs */

 Zero out the descriptor ring */

 cleanup Tx queue statistics */

/**

 * ice_free_tx_ring - Free Tx resources per queue

 * @tx_ring: Tx descriptor ring for a specific queue

 *

 * Free all transmit software resources

/**

 * ice_clean_tx_irq - Reclaim resources after transmit completes

 * @tx_ring: Tx ring to clean

 * @napi_budget: Used to determine if we are in netpoll

 *

 * Returns true if there's any budget left (e.g. the clean is finished)

 if next_to_watch is not set then there is no work pending */

 prevent any other reads prior to eop_desc */

 if the descriptor isn't done, no work yet to do */

 clear next_to_watch to prevent false hangs */

 update the statistics for this packet */

 free the skb */

 unmap skb header data */

 clear tx_buf data */

 unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 update budget accounting */

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

/**

 * ice_setup_tx_ring - Allocate the Tx descriptors

 * @tx_ring: the Tx ring to set up

 *

 * Return 0 on success, negative on error

 warn if we are about to overwrite the pointer */

 round up to nearest page */

/**

 * ice_clean_rx_ring - Free Rx buffers

 * @rx_ring: ring to be cleaned

 ring already cleared, nothing to do */

 Free all the Rx ring sk_buffs */

		/* Invalidate cache lines that may have been written to by

		 * device so that we avoid corrupting memory.

 free resources associated with mapping */

 Zero out the descriptor ring */

/**

 * ice_free_rx_ring - Free Rx resources

 * @rx_ring: ring to clean the resources from

 *

 * Free all receive software resources

/**

 * ice_setup_rx_ring - Allocate the Rx descriptors

 * @rx_ring: the Rx ring to set up

 *

 * Return 0 on success, negative on error

 warn if we are about to overwrite the pointer */

 round up to nearest page */

 Must be power-of-2 */

/**

 * ice_run_xdp - Executes an XDP program on initialized xdp_buff

 * @rx_ring: Rx ring

 * @xdp: xdp_buff used as input to the XDP program

 * @xdp_prog: XDP program to run

 * @xdp_ring: ring to be used for XDP_TX action

 *

 * Returns any of ICE_XDP_{PASS, CONSUMED, TX, REDIR}

/**

 * ice_xdp_xmit - submit packets to XDP ring for transmission

 * @dev: netdev

 * @n: number of XDP frames to be transmitted

 * @frames: XDP frames to be transmitted

 * @flags: transmit flags

 *

 * Returns number of frames successfully sent. Failed frames

 * will be free'ed by XDP core.

 * For error cases, a negative errno code is returned and no-frames

 * are transmitted (caller must handle freeing frames).

/**

 * ice_alloc_mapped_page - recycle or make a new page

 * @rx_ring: ring to use

 * @bi: rx_buf struct to modify

 *

 * Returns true if the page was successfully allocated or

 * reused.

 since we are recycling buffers we should seldom need to alloc */

 alloc new page for storage */

 map page for use */

	/* if mapping failed free memory back to system since

	 * there isn't much point in holding memory we can't use

/**

 * ice_alloc_rx_bufs - Replace used receive buffers

 * @rx_ring: ring to place buffers on

 * @cleaned_count: number of buffers to replace

 *

 * Returns false if all allocations were successful, true if any fail. Returning

 * true signals to the caller that we didn't replace cleaned_count buffers and

 * there is more work to do.

 *

 * First, try to clean "cleaned_count" Rx buffers. Then refill the cleaned Rx

 * buffers. Then bump tail at most one time. Grouping like this lets us avoid

 * multiple tail writes per call.

 do nothing if no valid netdev defined */

 get the Rx descriptor and buffer based on next_to_use */

 if we fail here, we have work remaining */

 sync the buffer for use by the device */

		/* Refresh the desc even if buffer_addrs didn't change

		 * because each write-back erases this info.

 clear the status bits for the next_to_use descriptor */

/**

 * ice_rx_buf_adjust_pg_offset - Prepare Rx buffer for reuse

 * @rx_buf: Rx buffer to adjust

 * @size: Size of adjustment

 *

 * Update the offset within page so that Rx buf will be ready to be reused.

 * For systems with PAGE_SIZE < 8192 this function will flip the page offset

 * so the second half of page assigned to Rx buffer will be used, otherwise

 * the offset is moved by "size" bytes

 flip page offset to other buffer */

 move offset up to the next cache line */

/**

 * ice_can_reuse_rx_page - Determine if page can be reused for another Rx

 * @rx_buf: buffer containing the page

 * @rx_buf_pgcnt: rx_buf page refcount pre xdp_do_redirect() call

 *

 * If page is reusable, we have a green light for calling ice_reuse_rx_page,

 * which will assign the current buffer to the buffer that next_to_alloc is

 * pointing to; otherwise, the DMA mapping needs to be destroyed and

 * page freed

 avoid re-using remote and pfmemalloc pages */

 if we are only owner of page we can reuse it */

 PAGE_SIZE < 8192) */

	/* If we have drained the page fragment pool we need to update

	 * the pagecnt_bias and page count so that we fully restock the

	 * number of references the driver holds.

/**

 * ice_add_rx_frag - Add contents of Rx buffer to sk_buff as a frag

 * @rx_ring: Rx descriptor ring to transact packets on

 * @rx_buf: buffer containing page to add

 * @skb: sk_buff to place the data into

 * @size: packet length from rx_desc

 *

 * This function will add the data contained in rx_buf->page to the skb.

 * It will just attach the page as a frag to the skb.

 * The function will then update the page offset.

 page is being used so we must update the page offset */

/**

 * ice_reuse_rx_page - page flip buffer and store it back on the ring

 * @rx_ring: Rx descriptor ring to store buffers on

 * @old_buf: donor buffer to have page reused

 *

 * Synchronizes page for reuse by the adapter

 update, and store next to alloc */

	/* Transfer page from old buffer to new buffer.

	 * Move each member individually to avoid possible store

	 * forwarding stalls and unnecessary copy of skb.

/**

 * ice_get_rx_buf - Fetch Rx buffer and synchronize data for use

 * @rx_ring: Rx descriptor ring to transact packets on

 * @size: size of buffer to add to skb

 * @rx_buf_pgcnt: rx_buf page refcount

 *

 * This function will pull an Rx buffer from the ring and synchronize it

 * for use by the CPU.

 we are reusing so sync this buffer for CPU use */

 We have pulled a buffer for use, so decrement pagecnt_bias */

/**

 * ice_build_skb - Build skb around an existing buffer

 * @rx_ring: Rx descriptor ring to transact packets on

 * @rx_buf: Rx buffer to pull data from

 * @xdp: xdp_buff pointing to the data

 *

 * This function builds an skb around an existing Rx buffer, taking care

 * to set up the skb correctly and avoid any memcpy overhead.

	/* Prefetch first cache line of first page. If xdp->data_meta

	 * is unused, this points exactly as xdp->data, otherwise we

	 * likely have a consumer accessing first few bytes of meta

	 * data, and then actual data.

 build an skb around the page buffer */

	/* must to record Rx queue, otherwise OS features such as

	 * symmetric queue won't work

 update pointers within the skb to store the data */

 buffer is used by skb, update page_offset */

/**

 * ice_construct_skb - Allocate skb and populate it

 * @rx_ring: Rx descriptor ring to transact packets on

 * @rx_buf: Rx buffer to pull data from

 * @xdp: xdp_buff pointing to the data

 *

 * This function allocates an skb. It then populates it with the page

 * data from the current receive descriptor, taking care to set up the

 * skb correctly.

 prefetch first cache line of first page */

 allocate a skb to store the frags */

 Determine available headroom for copy */

 align pull length to size of long to optimize memcpy performance */

 if we exhaust the linear part then add what is left as a frag */

 buffer is used by skb, update page_offset */

		/* buffer is unused, reset bias back to rx_buf; data was copied

		 * onto skb's linear part so there's no need for adjusting

		 * page offset and we can reuse this buffer as-is

/**

 * ice_put_rx_buf - Clean up used buffer and either recycle or free

 * @rx_ring: Rx descriptor ring to transact packets on

 * @rx_buf: Rx buffer to pull data from

 * @rx_buf_pgcnt: Rx buffer page count pre xdp_do_redirect()

 *

 * This function will update next_to_clean and then clean up the contents

 * of the rx_buf. It will either recycle the buffer or unmap it and free

 * the associated resources.

 fetch, update, and store next to clean */

 hand second half of page back to the ring */

 we are not reusing the buffer so unmap it */

 clear contents of buffer_info */

/**

 * ice_is_non_eop - process handling of non-EOP buffers

 * @rx_ring: Rx ring being processed

 * @rx_desc: Rx descriptor for current buffer

 *

 * If the buffer is an EOP buffer, this function exits returning false,

 * otherwise return true indicating that this is in fact a non-EOP buffer.

 if we are the last buffer then there is nothing else to do */

/**

 * ice_clean_rx_irq - Clean completed descriptors from Rx ring - bounce buf

 * @rx_ring: Rx descriptor ring to transact packets on

 * @budget: Total limit on number of packets to process

 *

 * This function provides a "bounce buffer" approach to Rx interrupt

 * processing. The advantage to this is that on systems that have

 * expensive overhead for IOMMU access this provides a means of avoiding

 * it by maintaining the mapping of the page to the system.

 *

 * Returns amount of work completed

 Frame size depend on rx_ring setup when PAGE_SIZE=4K */

 start the loop to process Rx packets bounded by 'budget' */

 get the Rx desc from Rx ring based on 'next_to_clean' */

		/* status_error_len will always be zero for unused descriptors

		 * because it's cleared in cleanup, and overlaps with hdr_addr

		 * which is always zero because packet split isn't used, if the

		 * hardware wrote DD then it will be non-zero

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we know the

		 * DD bit is set.

 retrieve a buffer from the ring */

 At larger PAGE_SIZE, frame_sz depend on len size */

 exit if we failed to retrieve a buffer */

 skip if it is NOP desc */

 pad the skb if needed, to make a valid ethernet frame */

 probably a little skewed due to removing CRC */

 populate checksum, VLAN, and protocol */

 send completed skb up the stack */

 update budget accounting */

 return up to cleaned_count buffers to hardware */

 guarantee a trip back through this routine if there was a failure */

	/* if dim settings get stale, like when not updated for 1

	 * second or longer, force it to start again. This addresses the

	 * frequent case of an idle queue being switched to by the

	 * scheduler. The 1,000 here means 1,000 milliseconds.

/**

 * ice_net_dim - Update net DIM algorithm

 * @q_vector: the vector associated with the interrupt

 *

 * Create a DIM sample and notify net_dim() so that it can possibly decide

 * a new ITR value based on incoming packets, bytes, and interrupts.

 *

 * This function is a no-op if the ring is not configured to dynamic ITR.

/**

 * ice_buildreg_itr - build value for writing to the GLINT_DYN_CTL register

 * @itr_idx: interrupt throttling index

 * @itr: interrupt throttling value in usecs

	/* The ITR value is reported in microseconds, and the register value is

	 * recorded in 2 microsecond units. For this reason we only need to

	 * shift by the GLINT_DYN_CTL_INTERVAL_S - ICE_ITR_GRAN_S to apply this

	 * granularity as a shift instead of division. The mask makes sure the

	 * ITR value is never odd so we don't accidentally write into the field

	 * prior to the ITR field.

/**

 * ice_enable_interrupt - re-enable MSI-X interrupt

 * @q_vector: the vector associated with the interrupt to enable

 *

 * If the VSI is down, the interrupt will not be re-enabled. Also,

 * when enabling the interrupt always reset the wb_on_itr to false

 * and trigger a software interrupt to clean out internal state.

	/* trigger an ITR delayed software interrupt when exiting busy poll, to

	 * make sure to catch any pending cleanups that might have been missed

	 * due to interrupt state transition. If busy poll or poll isn't

	 * enabled, then don't update ITR, and just enable the interrupt.

		/* do two things here with a single write. Set up the third ITR

		 * index to be used for software interrupt moderation, and then

		 * trigger a software interrupt with a rate limit of 20K on

		 * software interrupts, this will help avoid high interrupt

		 * loads due to frequently polling and exiting polling.

/**

 * ice_set_wb_on_itr - set WB_ON_ITR for this q_vector

 * @q_vector: q_vector to set WB_ON_ITR on

 *

 * We need to tell hardware to write-back completed descriptors even when

 * interrupts are disabled. Descriptors will be written back on cache line

 * boundaries without WB_ON_ITR enabled, but if we don't enable WB_ON_ITR

 * descriptors may not be written back if they don't fill a cache line until

 * the next interrupt.

 *

 * This sets the write-back frequency to whatever was set previously for the

 * ITR indices. Also, set the INTENA_MSK bit to make sure hardware knows we

 * aren't meddling with the INTENA_M bit.

 already in wb_on_itr mode no need to change it */

	/* use previously set ITR values for all of the ITR indices by

	 * specifying ICE_ITR_NONE, which will vary in adaptive (AIM) mode and

	 * be static in non-adaptive mode (user configured)

/**

 * ice_napi_poll - NAPI polling Rx/Tx cleanup routine

 * @napi: napi struct with our devices info in it

 * @budget: amount of work driver is allowed to do this pass, in packets

 *

 * This function will clean all queues associated with a q_vector.

 *

 * Returns the amount of work done

	/* Since the actual Tx work is minimal, we can give the Tx a larger

	 * budget and be more aggressive about cleaning up the Tx descriptors.

 Handle case where we are called by netpoll with a budget of 0 */

 normally we have 1 Rx ring per q_vector */

		/* We attempt to distribute budget to each Rx queue fairly, but

		 * don't allow the budget to go below 1 because that would exit

		 * polling early.

 Max of 1 Rx ring in this q_vector so give it the budget */

		/* A dedicated path for zero-copy allows making a single

		 * comparison in the irq context instead of many inside the

		 * ice_clean_rx_irq function and makes the codebase cleaner.

 if we clean as many as budgeted, we must not be done */

 If work not completed, return budget and polling will return */

		/* Set the writeback on ITR so partial completions of

		 * cache-lines will still continue even if we're polling.

	/* Exit the polling mode, but don't re-enable interrupts if stack might

	 * poll us due to busy-polling

/**

 * __ice_maybe_stop_tx - 2nd level check for Tx stop conditions

 * @tx_ring: the ring to be checked

 * @size: the size buffer we want to assure is available

 *

 * Returns -EBUSY if a stop is needed, else 0

 Memory barrier before checking head and tail */

 Check again in a case another CPU has just made room available. */

 A reprieve! - use start_subqueue because it doesn't call schedule */

/**

 * ice_maybe_stop_tx - 1st level check for Tx stop conditions

 * @tx_ring: the ring to be checked

 * @size:    the size buffer we want to assure is available

 *

 * Returns 0 if stop is not needed

/**

 * ice_tx_map - Build the Tx descriptor

 * @tx_ring: ring to send buffer on

 * @first: first buffer info buffer to use

 * @off: pointer to struct that holds offload parameters

 *

 * This function loops over the skb data pointed to by *first

 * and gets a physical address for each memory location and programs

 * it and the length into the transmit descriptor.

 record length, and DMA address */

 align size to end of page */

		/* account for data chunks larger than the hardware

		 * can handle

 record bytecount for BQL */

 record SW timestamp if HW timestamp is not available */

 write last descriptor with RS and EOP bits */

	/* Force memory writes to complete before letting h/w know there

	 * are new descriptors to fetch.

	 *

	 * We also use this memory barrier to make certain all of the

	 * status bits have been updated before next_to_watch is written.

 set next_to_watch value indicating a packet is present */

 notify HW of packet */

 clear DMA mappings for failed tx_buf map */

/**

 * ice_tx_csum - Enable Tx checksum offloads

 * @first: pointer to the first descriptor

 * @off: pointer to struct that holds offload parameters

 *

 * Returns 0 or error (negative) if checksum offload can't happen, 1 otherwise.

 compute outer L2 header size */

 define outer network header type */

 define outer transport */

 compute outer L3 header size */

 switch IP header pointer from outer to inner header */

 compute tunnel header size */

 indicate if we need to offload outer UDP header */

 record tunnel offload values */

		/* set DTYP=1 to indicate that it's an Tx context descriptor

		 * in IPsec tunnel mode with Tx offloads in Quad word 1

 switch L4 header pointer from outer to inner */

 reset type as we transition from outer to inner headers */

 Enable IP checksum offloads */

		/* the stack computes the IP header already, the only time we

		 * need the hardware to recompute it is in the case of TSO.

 compute inner L3 header size */

 Enable L4 checksum offloads */

 enable checksum offloads */

 enable UDP checksum offload */

 enable SCTP checksum offload */

/**

 * ice_tx_prepare_vlan_flags - prepare generic Tx VLAN tagging flags for HW

 * @tx_ring: ring to send buffer on

 * @first: pointer to struct ice_tx_buf

 *

 * Checks the skb and set up correspondingly several generic transmit flags

 * related to VLAN tagging for the HW, such as VLAN, DCB, etc.

 nothing left to do, software offloaded VLAN */

	/* currently, we always assume 802.1Q for VLAN insertion as VLAN

	 * insertion for 802.1AD is not supported

/**

 * ice_tso - computes mss and TSO length to prepare for TSO

 * @first: pointer to struct ice_tx_buf

 * @off: pointer to struct that holds offload parameters

 *

 * Returns 0 or error (negative) if TSO can't happen, 1 otherwise.

 cppcheck-suppress unreadVariable */

 initialize outer IP header fields */

 determine offset of outer transport header */

 remove payload length from outer checksum */

 reset pointers to inner headers */

 cppcheck-suppress unreadVariable */

 initialize inner IP header fields */

 determine offset of transport header */

 remove payload length from checksum */

 compute length of UDP segmentation header */

 compute length of TCP segmentation header */

 update gso_segs and bytecount */

 record cdesc_qw1 with TSO parameters */

/**

 * ice_txd_use_count  - estimate the number of descriptors needed for Tx

 * @size: transmit request size in bytes

 *

 * Due to hardware alignment restrictions (4K alignment), we need to

 * assume that we can have no more than 12K of data per descriptor, even

 * though each descriptor can take up to 16K - 1 bytes of aligned memory.

 * Thus, we need to divide by 12K. But division is slow! Instead,

 * we decompose the operation into shifts and one relatively cheap

 * multiply operation.

 *

 * To divide by 12K, we first divide by 4K, then divide by 3:

 *     To divide by 4K, shift right by 12 bits

 *     To divide by 3, multiply by 85, then divide by 256

 *     (Divide by 256 is done by shifting right by 8 bits)

 * Finally, we add one to round up. Because 256 isn't an exact multiple of

 * 3, we'll underestimate near each multiple of 12K. This is actually more

 * accurate as we have 4K - 1 of wiggle room that we can fit into the last

 * segment. For our purposes this is accurate out to 1M which is orders of

 * magnitude greater than our largest possible GSO size.

 *

 * This would then be implemented as:

 *     return (((size >> 12) * 85) >> 8) + ICE_DESCS_FOR_SKB_DATA_PTR;

 *

 * Since multiplication and division are commutative, we can reorder

 * operations into:

 *     return ((size * 85) >> 20) + ICE_DESCS_FOR_SKB_DATA_PTR;

/**

 * ice_xmit_desc_count - calculate number of Tx descriptors needed

 * @skb: send buffer

 *

 * Returns number of data descriptors needed for this skb.

/**

 * __ice_chk_linearize - Check if there are more than 8 buffers per packet

 * @skb: send buffer

 *

 * Note: This HW can't DMA more than 8 buffers to build a packet on the wire

 * and so we need to figure out the cases where we need to linearize the skb.

 *

 * For TSO we need to count the TSO header and segment payload separately.

 * As such we need to check cases where we have 7 fragments or more as we

 * can potentially require 9 DMA transactions, 1 for the TSO header, 1 for

 * the segment payload in the first descriptor, and another 7 for the

 * fragments.

 no need to check if number of frags is less than 7 */

	/* We need to walk through the list and validate that each group

	 * of 6 fragments totals at least gso_size.

	/* Initialize size to the negative value of gso_size minus 1. We

	 * use this as the worst case scenario in which the frag ahead

	 * of us only provides one byte which is why we are limited to 6

	 * descriptors for a single transmit as the header and previous

	 * fragment are already consuming 2 descriptors.

 Add size of frags 0 through 4 to create our initial sum */

	/* Walk through fragments adding latest fragment, testing it, and

	 * then removing stale fragments from the sum.

		/* The stale fragment may present us with a smaller

		 * descriptor than the actual fragment size. To account

		 * for that we need to remove all the data on the front and

		 * figure out what the remainder would be in the last

		 * descriptor associated with the fragment.

 if sum is negative we failed to make sufficient progress */

/**

 * ice_chk_linearize - Check if there are more than 8 fragments per packet

 * @skb:      send buffer

 * @count:    number of buffers used

 *

 * Note: Our HW can't scatter-gather more than 8 fragments to build

 * a packet on the wire and so we need to figure out the cases where we

 * need to linearize the skb.

 Both TSO and single send will work if count is less than 8 */

 we can support up to 8 data buffers for a single send */

/**

 * ice_tstamp - set up context descriptor for hardware timestamp

 * @tx_ring: pointer to the Tx ring to send buffer on

 * @skb: pointer to the SKB we're sending

 * @first: Tx buffer

 * @off: Tx offload parameters

 only timestamp the outbound packet if the user has requested it */

 Tx timestamps cannot be sampled when doing TSO */

 Grab an open timestamp slot */

/**

 * ice_xmit_frame_ring - Sends buffer on Tx ring

 * @skb: send buffer

 * @tx_ring: ring to send buffer on

 *

 * Returns NETDEV_TX_OK if sent, else an error code

	/* need: 1 descriptor per page * PAGE_SIZE/ICE_MAX_DATA_PER_TXD,

	 *       + 1 desc for skb_head_len/ICE_MAX_DATA_PER_TXD,

	 *       + 4 desc gap to avoid the cache line where head is,

	 *       + 1 desc for context descriptor,

	 * otherwise try next time

 record the location of the first descriptor for this packet */

 prepare the VLAN tagging flags for Tx */

 set up TSO offload */

 always set up Tx checksum offload */

 allow CONTROL frames egress from main VSI if FW LLDP disabled */

 grab the next descriptor */

 setup context descriptor */

/**

 * ice_start_xmit - Selects the correct VSI and Tx queue to send buffer

 * @skb: send buffer

 * @netdev: network interface device structure

 *

 * Returns NETDEV_TX_OK if sent, else an error code

	/* hardware can't handle really short frames, hardware padding works

	 * beyond this point

/**

 * ice_get_dscp_up - return the UP/TC value for a SKB

 * @dcbcfg: DCB config that contains DSCP to UP/TC mapping

 * @skb: SKB to query for info to determine UP/TC

 *

 * This function is to only be called when the PF is in L3 DSCP PFC mode

/**

 * ice_clean_ctrl_tx_irq - interrupt handler for flow director Tx queue

 * @tx_ring: tx_ring to clean

 if next_to_watch is not set then there is no pending work */

 prevent any other reads prior to eop_desc */

 if the descriptor isn't done, no work to do */

 clear next_to_watch to prevent false hangs */

 move past filter desc */

 unmap the data header */

 clear next_to_watch to prevent false hangs */

 move past eop_desc for start of next FD desc */

 re-enable interrupt if needed */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2021, Intel Corporation. */

/* Low level functions for interacting with and managing the device clock used

 * for the Precision Time Protocol.

 *

 * The ice hardware represents the current time using three registers:

 *

 *    GLTSYN_TIME_H     GLTSYN_TIME_L     GLTSYN_TIME_R

 *  +---------------+ +---------------+ +---------------+

 *  |    32 bits    | |    32 bits    | |    32 bits    |

 *  +---------------+ +---------------+ +---------------+

 *

 * The registers are incremented every clock tick using a 40bit increment

 * value defined over two registers:

 *

 *                     GLTSYN_INCVAL_H   GLTSYN_INCVAL_L

 *                    +---------------+ +---------------+

 *                    |    8 bit s    | |    32 bits    |

 *                    +---------------+ +---------------+

 *

 * The increment value is added to the GLSTYN_TIME_R and GLSTYN_TIME_L

 * registers every clock source tick. Depending on the specific device

 * configuration, the clock source frequency could be one of a number of

 * values.

 *

 * For E810 devices, the increment frequency is 812.5 MHz

 *

 * The hardware captures timestamps in the PHY for incoming packets, and for

 * outgoing packets on request. To support this, the PHY maintains a timer

 * that matches the lower 64 bits of the global source timer.

 *

 * In order to ensure that the PHY timers and the source timer are equivalent,

 * shadow registers are used to prepare the desired initial values. A special

 * sync command is issued to trigger copying from the shadow registers into

 * the appropriate source and PHY registers simultaneously.

/**

 * ice_get_ptp_src_clock_index - determine source clock index

 * @hw: pointer to HW struct

 *

 * Determine the source clock index currently in use, based on device

 * capabilities reported during initialization.

/* E810 functions

 *

 * The following functions operate on the E810 series devices which use

 * a separate external PHY.

/**

 * ice_read_phy_reg_e810 - Read register from external PHY on E810

 * @hw: pointer to the HW struct

 * @addr: the address to read from

 * @val: On return, the value read from the PHY

 *

 * Read a register from the external PHY on the E810 device.

/**

 * ice_write_phy_reg_e810 - Write register on external PHY on E810

 * @hw: pointer to the HW struct

 * @addr: the address to writem to

 * @val: the value to write to the PHY

 *

 * Write a value to a register of the external PHY on the E810 device.

/**

 * ice_read_phy_tstamp_e810 - Read a PHY timestamp out of the external PHY

 * @hw: pointer to the HW struct

 * @lport: the lport to read from

 * @idx: the timestamp index to read

 * @tstamp: on return, the 40bit timestamp value

 *

 * Read a 40bit timestamp value out of the timestamp block of the external PHY

 * on the E810 device.

	/* For E810 devices, the timestamp is reported with the lower 32 bits

	 * in the low register, and the upper 8 bits in the high register.

/**

 * ice_clear_phy_tstamp_e810 - Clear a timestamp from the external PHY

 * @hw: pointer to the HW struct

 * @lport: the lport to read from

 * @idx: the timestamp index to reset

 *

 * Clear a timestamp, resetting its valid bit, from the timestamp block of the

 * external PHY on the E810 device.

/**

 * ice_ptp_init_phy_e810 - Enable PTP function on the external PHY

 * @hw: pointer to HW struct

 *

 * Enable the timesync PTP functionality for the external PHY connected to

 * this function.

/**

 * ice_ptp_prep_phy_time_e810 - Prepare PHY port with initial time

 * @hw: Board private structure

 * @time: Time to initialize the PHY port clock to

 *

 * Program the PHY port ETH_GLTSYN_SHTIME registers in preparation setting the

 * initial clock time. The time will not actually be programmed until the

 * driver issues an INIT_TIME command.

 *

 * The time value is the upper 32 bits of the PHY timer, usually in units of

 * nominal nanoseconds.

/**

 * ice_ptp_prep_phy_adj_e810 - Prep PHY port for a time adjustment

 * @hw: pointer to HW struct

 * @adj: adjustment value to program

 *

 * Prepare the PHY port for an atomic adjustment by programming the PHY

 * ETH_GLTSYN_SHADJ_L and ETH_GLTSYN_SHADJ_H registers. The actual adjustment

 * is completed by issuing an ADJ_TIME sync command.

 *

 * The adjustment value only contains the portion used for the upper 32bits of

 * the PHY timer, usually in units of nominal nanoseconds. Negative

 * adjustments are supported using 2s complement arithmetic.

	/* Adjustments are represented as signed 2's complement values in

	 * nanoseconds. Sub-nanosecond adjustment is not supported.

/**

 * ice_ptp_prep_phy_incval_e810 - Prep PHY port increment value change

 * @hw: pointer to HW struct

 * @incval: The new 40bit increment value to prepare

 *

 * Prepare the PHY port for a new increment value by programming the PHY

 * ETH_GLTSYN_SHADJ_L and ETH_GLTSYN_SHADJ_H registers. The actual change is

 * completed by issuing an INIT_INCVAL command.

/**

 * ice_ptp_port_cmd_e810 - Prepare all external PHYs for a timer command

 * @hw: pointer to HW struct

 * @cmd: Command to be sent to the port

 *

 * Prepare the external PHYs connected to this device for a timer sync

 * command.

 Read, modify, write */

 Modify necessary bits only and perform write */

/* Device agnostic functions

 *

 * The following functions implement useful behavior to hide the differences

 * between E810 and other devices. They call the device-specific

 * implementations where necessary.

 *

 * Currently, the driver only supports E810, but future work will enable

 * support for E822-based devices.

/**

 * ice_ptp_lock - Acquire PTP global semaphore register lock

 * @hw: pointer to the HW struct

 *

 * Acquire the global PTP hardware semaphore lock. Returns true if the lock

 * was acquired, false otherwise.

 *

 * The PFTSYN_SEM register sets the busy bit on read, returning the previous

 * value. If software sees the busy bit cleared, this means that this function

 * acquired the lock (and the busy bit is now set). If software sees the busy

 * bit set, it means that another function acquired the lock.

 *

 * Software must clear the busy bit with a write to release the lock for other

 * functions when done.

 Somebody is holding the lock */

/**

 * ice_ptp_unlock - Release PTP global semaphore register lock

 * @hw: pointer to the HW struct

 *

 * Release the global PTP hardware semaphore lock. This is done by writing to

 * the PFTSYN_SEM register.

/**

 * ice_ptp_src_cmd - Prepare source timer for a timer command

 * @hw: pointer to HW structure

 * @cmd: Timer command

 *

 * Prepare the source timer for an upcoming timer sync command.

/**

 * ice_ptp_tmr_cmd - Prepare and trigger a timer sync command

 * @hw: pointer to HW struct

 * @cmd: the command to issue

 *

 * Prepare the source timer and PHY timers and then trigger the requested

 * command. This causes the shadow registers previously written in preparation

 * for the command to be synchronously applied to both the source and PHY

 * timers.

 First, prepare the source timer */

 Next, prepare the ports */

	/* Write the sync command register to drive both source and PHY timer commands

	 * synchronously

/**

 * ice_ptp_init_time - Initialize device time to provided value

 * @hw: pointer to HW struct

 * @time: 64bits of time (GLTSYN_TIME_L and GLTSYN_TIME_H)

 *

 * Initialize the device to the specified time provided. This requires a three

 * step process:

 *

 * 1) write the new init time to the source timer shadow registers

 * 2) write the new init time to the PHY timer shadow registers

 * 3) issue an init_time timer command to synchronously switch both the source

 *    and port timers to the new init time value at the next clock cycle.

 Source timers */

 PHY timers */

 Fill Rx and Tx ports and send msg to PHY */

/**

 * ice_ptp_write_incval - Program PHC with new increment value

 * @hw: pointer to HW struct

 * @incval: Source timer increment value per clock cycle

 *

 * Program the PHC with a new increment value. This requires a three-step

 * process:

 *

 * 1) Write the increment value to the source timer shadow registers

 * 2) Write the increment value to the PHY timer shadow registers

 * 3) Issue an INIT_INCVAL timer command to synchronously switch both the

 *    source and port timers to the new increment value at the next clock

 *    cycle.

 Shadow Adjust */

/**

 * ice_ptp_write_incval_locked - Program new incval while holding semaphore

 * @hw: pointer to HW struct

 * @incval: Source timer increment value per clock cycle

 *

 * Program a new PHC incval while holding the PTP semaphore.

/**

 * ice_ptp_adj_clock - Adjust PHC clock time atomically

 * @hw: pointer to HW struct

 * @adj: Adjustment in nanoseconds

 *

 * Perform an atomic adjustment of the PHC time by the specified number of

 * nanoseconds. This requires a three-step process:

 *

 * 1) Write the adjustment to the source timer shadow registers

 * 2) Write the adjustment to the PHY timer shadow registers

 * 3) Issue an ADJ_TIME timer command to synchronously apply the adjustment to

 *    both the source and port timers at the next clock cycle.

	/* Write the desired clock adjustment into the GLTSYN_SHADJ register.

	 * For an ADJ_TIME command, this set of registers represents the value

	 * to add to the clock time. It supports subtraction by interpreting

	 * the value as a 2's complement integer.

/**

 * ice_read_phy_tstamp - Read a PHY timestamp from the timestamo block

 * @hw: pointer to the HW struct

 * @block: the block to read from

 * @idx: the timestamp index to read

 * @tstamp: on return, the 40bit timestamp value

 *

 * Read a 40bit timestamp value out of the timestamp block.

/**

 * ice_clear_phy_tstamp - Clear a timestamp from the timestamp block

 * @hw: pointer to the HW struct

 * @block: the block to read from

 * @idx: the timestamp index to reset

 *

 * Clear a timestamp, resetting its valid bit, from the timestamp block.

/* E810T SMA functions

 *

 * The following functions operate specifically on E810T hardware and are used

 * to access the extended GPIOs available.

/**

 * ice_get_pca9575_handle

 * @hw: pointer to the hw struct

 * @pca9575_handle: GPIO controller's handle

 *

 * Find and return the GPIO controller's handle in the netlist.

 * When found - the value will be cached in the hw structure and following calls

 * will return cached value

 If handle was read previously return cached value */

 If handle was not detected read it from the netlist */

 Set node type to GPIO controller */

 Check if the SW IO expander controlling SMA exists in the netlist. */

 Verify if we found the right IO expander type */

 If present save the handle and return it */

/**

 * ice_read_sma_ctrl_e810t

 * @hw: pointer to the hw struct

 * @data: pointer to data to be read from the GPIO controller

 *

 * Read the SMA controller state. It is connected to pins 3-7 of Port 1 of the

 * PCA9575 expander, so only bits 3-7 in data are valid.

/**

 * ice_write_sma_ctrl_e810t

 * @hw: pointer to the hw struct

 * @data: data to be written to the GPIO controller

 *

 * Write the data to the SMA controller. It is connected to pins 3-7 of Port 1

 * of the PCA9575 expander, so only bits 3-7 in data are valid.

/**

 * ice_is_pca9575_present

 * @hw: pointer to the hw struct

 *

 * Check if the SW IO expander is present in the netlist

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019, Intel Corporation. */

/**

 * ice_aq_get_lldp_mib

 * @hw: pointer to the HW struct

 * @bridge_type: type of bridge requested

 * @mib_type: Local, Remote or both Local and Remote MIBs

 * @buf: pointer to the caller-supplied buffer to store the MIB block

 * @buf_size: size of the buffer (in bytes)

 * @local_len: length of the returned Local LLDP MIB

 * @remote_len: length of the returned Remote LLDP MIB

 * @cd: pointer to command details structure or NULL

 *

 * Requests the complete LLDP MIB (entire packet). (0x0A00)

/**

 * ice_aq_cfg_lldp_mib_change

 * @hw: pointer to the HW struct

 * @ena_update: Enable or Disable event posting

 * @cd: pointer to command details structure or NULL

 *

 * Enable or Disable posting of an event on ARQ when LLDP MIB

 * associated with the interface changes (0x0A01)

/**

 * ice_aq_stop_lldp

 * @hw: pointer to the HW struct

 * @shutdown_lldp_agent: True if LLDP Agent needs to be Shutdown

 *			 False if LLDP Agent needs to be Stopped

 * @persist: True if Stop/Shutdown of LLDP Agent needs to be persistent across

 *	     reboots

 * @cd: pointer to command details structure or NULL

 *

 * Stop or Shutdown the embedded LLDP Agent (0x0A05)

/**

 * ice_aq_start_lldp

 * @hw: pointer to the HW struct

 * @persist: True if Start of LLDP Agent needs to be persistent across reboots

 * @cd: pointer to command details structure or NULL

 *

 * Start the embedded LLDP Agent on all ports. (0x0A06)

/**

 * ice_get_dcbx_status

 * @hw: pointer to the HW struct

 *

 * Get the DCBX status from the Firmware

/**

 * ice_parse_ieee_ets_common_tlv

 * @buf: Data buffer to be parsed for ETS CFG/REC data

 * @ets_cfg: Container to store parsed data

 *

 * Parses the common data of IEEE 802.1Qaz ETS CFG/REC TLV

	/* Priority Assignment Table (4 octets)

	 * Octets:|    1    |    2    |    3    |    4    |

	 *        -----------------------------------------

	 *        |pri0|pri1|pri2|pri3|pri4|pri5|pri6|pri7|

	 *        -----------------------------------------

	 *   Bits:|7  4|3  0|7  4|3  0|7  4|3  0|7  4|3  0|

	 *        -----------------------------------------

	/* TC Bandwidth Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

	 *

	 * TSA Assignment Table (8 octets)

	 * Octets:| 9 | 10| 11| 12| 13| 14| 15| 16|

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

/**

 * ice_parse_ieee_etscfg_tlv

 * @tlv: IEEE 802.1Qaz ETS CFG TLV

 * @dcbcfg: Local store to update ETS CFG data

 *

 * Parses IEEE 802.1Qaz ETS CFG TLV

	/* First Octet post subtype

	 * --------------------------

	 * |will-|CBS  | Re-  | Max |

	 * |ing  |     |served| TCs |

	 * --------------------------

	 * |1bit | 1bit|3 bits|3bits|

 Begin parsing at Priority Assignment Table (offset 1 in buf) */

/**

 * ice_parse_ieee_etsrec_tlv

 * @tlv: IEEE 802.1Qaz ETS REC TLV

 * @dcbcfg: Local store to update ETS REC data

 *

 * Parses IEEE 802.1Qaz ETS REC TLV

 Begin parsing at Priority Assignment Table (offset 1 in buf) */

/**

 * ice_parse_ieee_pfccfg_tlv

 * @tlv: IEEE 802.1Qaz PFC CFG TLV

 * @dcbcfg: Local store to update PFC CFG data

 *

 * Parses IEEE 802.1Qaz PFC CFG TLV

	/* ----------------------------------------

	 * |will-|MBC  | Re-  | PFC |  PFC Enable  |

	 * |ing  |     |served| cap |              |

	 * -----------------------------------------

	 * |1bit | 1bit|2 bits|4bits| 1 octet      |

/**

 * ice_parse_ieee_app_tlv

 * @tlv: IEEE 802.1Qaz APP TLV

 * @dcbcfg: Local store to update APP PRIO data

 *

 * Parses IEEE 802.1Qaz APP PRIO TLV

	/* Removing sizeof(ouisubtype) and reserved byte from len.

	 * Remaining len div 3 is number of APP TLVs.

 Move offset to App Priority Table */

	/* Application Priority Table (3 octets)

	 * Octets:|         1          |    2    |    3    |

	 *        -----------------------------------------

	 *        |Priority|Rsrvd| Sel |    Protocol ID    |

	 *        -----------------------------------------

	 *   Bits:|23    21|20 19|18 16|15                0|

	 *        -----------------------------------------

 Move to next app */

/**

 * ice_parse_ieee_tlv

 * @tlv: IEEE 802.1Qaz TLV

 * @dcbcfg: Local store to update ETS REC data

 *

 * Get the TLV subtype and send it to parsing function

 * based on the subtype value

/**

 * ice_parse_cee_pgcfg_tlv

 * @tlv: CEE DCBX PG CFG TLV

 * @dcbcfg: Local store to update ETS CFG data

 *

 * Parses CEE DCBX PG CFG TLV

	/* Priority Group Table (4 octets)

	 * Octets:|    1    |    2    |    3    |    4    |

	 *        -----------------------------------------

	 *        |pri0|pri1|pri2|pri3|pri4|pri5|pri6|pri7|

	 *        -----------------------------------------

	 *   Bits:|7  4|3  0|7  4|3  0|7  4|3  0|7  4|3  0|

	 *        -----------------------------------------

	/* PG Percentage Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |pg0|pg1|pg2|pg3|pg4|pg5|pg6|pg7|

	 *        ---------------------------------

 Number of TCs supported (1 octet) */

/**

 * ice_parse_cee_pfccfg_tlv

 * @tlv: CEE DCBX PFC CFG TLV

 * @dcbcfg: Local store to update PFC CFG data

 *

 * Parses CEE DCBX PFC CFG TLV

	/* ------------------------

	 * | PFC Enable | PFC TCs |

	 * ------------------------

	 * | 1 octet    | 1 octet |

/**

 * ice_parse_cee_app_tlv

 * @tlv: CEE DCBX APP TLV

 * @dcbcfg: Local store to update APP PRIO data

 *

 * Parses CEE DCBX APP PRIO TLV

 Get Selector from lower 2 bits, and convert to IEEE */

 Keep selector as it is for unknown types */

 Move to next app */

/**

 * ice_parse_cee_tlv

 * @tlv: CEE DCBX TLV

 * @dcbcfg: Local store to update DCBX config data

 *

 * Get the TLV subtype and send it to parsing function

 * based on the subtype value

 Return if not CEE DCBX */

 Return if no CEE DCBX Feature TLVs */

 Invalid Sub-type return */

 Move to next sub TLV */

/**

 * ice_parse_org_tlv

 * @tlv: Organization specific TLV

 * @dcbcfg: Local store to update ETS REC data

 *

 * Currently only IEEE 802.1Qaz TLV is supported, all others

 * will be returned

/**

 * ice_lldp_to_dcb_cfg

 * @lldpmib: LLDPDU to be parsed

 * @dcbcfg: store for LLDPDU data

 *

 * Parse DCB configuration from the LLDPDU

 set to the start of LLDPDU */

 END TLV or beyond LLDPDU size */

 Move to next TLV */

/**

 * ice_aq_get_dcb_cfg

 * @hw: pointer to the HW struct

 * @mib_type: MIB type for the query

 * @bridgetype: bridge type for the query (remote)

 * @dcbcfg: store for LLDPDU data

 *

 * Query DCB configuration from the firmware

 Allocate the LLDPDU */

 Parse LLDP MIB to get DCB configuration */

/**

 * ice_aq_start_stop_dcbx - Start/Stop DCBX service in FW

 * @hw: pointer to the HW struct

 * @start_dcbx_agent: True if DCBX Agent needs to be started

 *		      False if DCBX Agent needs to be stopped

 * @dcbx_agent_status: FW indicates back the DCBX agent status

 *		       True if DCBX Agent is active

 *		       False if DCBX Agent is stopped

 * @cd: pointer to command details structure or NULL

 *

 * Start/Stop the embedded dcbx Agent. In case that this wrapper function

 * returns ICE_SUCCESS, caller will need to check if FW returns back the same

 * value as stated in dcbx_agent_status, and react accordingly. (0x0A09)

/**

 * ice_aq_get_cee_dcb_cfg

 * @hw: pointer to the HW struct

 * @buff: response buffer that stores CEE operational configuration

 * @cd: pointer to command details structure or NULL

 *

 * Get CEE DCBX mode operational configuration from firmware (0x0A07)

/**

 * ice_aq_set_pfc_mode - Set PFC mode

 * @hw: pointer to the HW struct

 * @pfc_mode: value of PFC mode to set

 * @cd: pointer to command details structure or NULL

 *

 * This AQ call configures the PFC mode to DSCP-based PFC mode or

 * VLAN-based PFC (0x0303)

	/* FW will write the PFC mode set back into cmd->pfc_mode, but if DCB is

	 * disabled, FW will write back 0 to cmd->pfc_mode. After the AQ has

	 * been executed, check if cmd->pfc_mode is what was requested. If not,

	 * return an error.

/**

 * ice_cee_to_dcb_cfg

 * @cee_cfg: pointer to CEE configuration struct

 * @pi: port information structure

 *

 * Convert CEE configuration from firmware to DCB configuration

 CEE PG data */

	/* Note that the FW creates the oper_prio_tc nibbles reversed

	 * from those in the CEE Priority Group sub-TLV.

 Map it to next empty TC */

 CEE PFC data */

 CEE APP TLV data */

 FCoE APP */

 iSCSI APP */

 FIP APP */

		/* Add FCoE/iSCSI/FIP APP if Error is False and

		 * Oper/Sync is True

/**

 * ice_get_ieee_or_cee_dcb_cfg

 * @pi: port information structure

 * @dcbx_mode: mode of DCBX (IEEE or CEE)

 *

 * Get IEEE or CEE mode DCB configuration from the Firmware

	/* Get Local DCB Config in case of ICE_DCBX_MODE_IEEE

	 * or get CEE DCB Desired Config in case of ICE_DCBX_MODE_CEE

 Get Remote DCB Config */

 Don't treat ENOENT as an error for Remote MIBs */

/**

 * ice_get_dcb_cfg

 * @pi: port information structure

 *

 * Get DCB configuration from the Firmware

 CEE mode */

 CEE mode not enabled try querying IEEE data */

/**

 * ice_init_dcb

 * @hw: pointer to the HW struct

 * @enable_mib_change: enable MIB change event

 *

 * Update DCB configuration from the Firmware

 Get DCBX status */

 Get current DCBX configuration */

 Configure the LLDP MIB change event */

/**

 * ice_cfg_lldp_mib_change

 * @hw: pointer to the HW struct

 * @ena_mib: enable/disable MIB change event

 *

 * Configure (disable/enable) MIB

 Get DCBX status */

/**

 * ice_add_ieee_ets_common_tlv

 * @buf: Data buffer to be populated with ice_dcb_ets_cfg data

 * @ets_cfg: Container for ice_dcb_ets_cfg data

 *

 * Populate the TLV buffer with ice_dcb_ets_cfg data

	/* Priority Assignment Table (4 octets)

	 * Octets:|    1    |    2    |    3    |    4    |

	 *        -----------------------------------------

	 *        |pri0|pri1|pri2|pri3|pri4|pri5|pri6|pri7|

	 *        -----------------------------------------

	 *   Bits:|7  4|3  0|7  4|3  0|7  4|3  0|7  4|3  0|

	 *        -----------------------------------------

	/* TC Bandwidth Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

	 *

	 * TSA Assignment Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

/**

 * ice_add_ieee_ets_tlv - Prepare ETS TLV in IEEE format

 * @tlv: Fill the ETS config data in IEEE format

 * @dcbcfg: Local store which holds the DCB Config

 *

 * Prepare IEEE 802.1Qaz ETS CFG TLV

	/* First Octet post subtype

	 * --------------------------

	 * |will-|CBS  | Re-  | Max |

	 * |ing  |     |served| TCs |

	 * --------------------------

	 * |1bit | 1bit|3 bits|3bits|

 Begin adding at Priority Assignment Table (offset 1 in buf) */

/**

 * ice_add_ieee_etsrec_tlv - Prepare ETS Recommended TLV in IEEE format

 * @tlv: Fill ETS Recommended TLV in IEEE format

 * @dcbcfg: Local store which holds the DCB Config

 *

 * Prepare IEEE 802.1Qaz ETS REC TLV

 First Octet is reserved */

 Begin adding at Priority Assignment Table (offset 1 in buf) */

/**

 * ice_add_ieee_pfc_tlv - Prepare PFC TLV in IEEE format

 * @tlv: Fill PFC TLV in IEEE format

 * @dcbcfg: Local store which holds the PFC CFG data

 *

 * Prepare IEEE 802.1Qaz PFC CFG TLV

	/* ----------------------------------------

	 * |will-|MBC  | Re-  | PFC |  PFC Enable  |

	 * |ing  |     |served| cap |              |

	 * -----------------------------------------

	 * |1bit | 1bit|2 bits|4bits| 1 octet      |

/**

 * ice_add_ieee_app_pri_tlv -  Prepare APP TLV in IEEE format

 * @tlv: Fill APP TLV in IEEE format

 * @dcbcfg: Local store which holds the APP CFG data

 *

 * Prepare IEEE 802.1Qaz APP CFG TLV

 No APP TLVs then just return */

 Move offset to App Priority Table */

	/* Application Priority Table (3 octets)

	 * Octets:|         1          |    2    |    3    |

	 *        -----------------------------------------

	 *        |Priority|Rsrvd| Sel |    Protocol ID    |

	 *        -----------------------------------------

	 *   Bits:|23    21|20 19|18 16|15                0|

	 *        -----------------------------------------

 Move to next app */

 len includes size of ouisubtype + 1 reserved + 3*numapps */

/**

 * ice_add_dscp_up_tlv - Prepare DSCP to UP TLV

 * @tlv: location to build the TLV data

 * @dcbcfg: location of data to convert to TLV

 bytes 0 - 63 - IPv4 DSCP2UP LUT */

 IPv4 mapping */

 IPv6 mapping */

 byte 64 - IPv4 untagged traffic */

 byte 144 - IPv6 untagged traffic */

/**

 * ice_add_dscp_enf_tlv - Prepare DSCP Enforcement TLV

 * @tlv: location to build the TLV data

 Allow all DSCP values to be valid for all TC's (IPv4 and IPv6) */

/**

 * ice_add_dscp_tc_bw_tlv - Prepare DSCP BW for TC TLV

 * @tlv: location to build the TLV data

 * @dcbcfg: location of the data to convert to TLV

	/* First Octect after subtype

	 * ----------------------------

	 * | RSV | CBS | RSV | Max TCs |

	 * | 1b  | 1b  | 3b  | 3b      |

	 * ----------------------------

 bytes 1 - 4 reserved */

	/* TC BW table

	 * bytes 0 - 7 for TC 0 - 7

	 *

	 * TSA Assignment table

	 * bytes 8 - 15 for TC 0 - 7

/**

 * ice_add_dscp_pfc_tlv - Prepare DSCP PFC TLV

 * @tlv: Fill PFC TLV in IEEE format

 * @dcbcfg: Local store which holds the PFC CFG data

/**

 * ice_add_dcb_tlv - Add all IEEE or DSCP TLVs

 * @tlv: Fill TLV data in IEEE format

 * @dcbcfg: Local store which holds the DCB Config

 * @tlvid: Type of IEEE TLV

 *

 * Add tlv information

 pfc_mode == ICE_QOS_MODE_DSCP */

/**

 * ice_dcb_cfg_to_lldp - Convert DCB configuration to MIB format

 * @lldpmib: pointer to the HW struct

 * @miblen: length of LLDP MIB

 * @dcbcfg: Local store which holds the DCB Config

 *

 * Convert the DCB configuration to MIB format

 END TLV or beyond LLDPDU size */

 Move to next TLV */

/**

 * ice_set_dcb_cfg - Set the local LLDP MIB to FW

 * @pi: port information structure

 *

 * Set DCB configuration to the Firmware

 update the HW local config */

 Allocate the LLDPDU */

/**

 * ice_aq_query_port_ets - query port ETS configuration

 * @pi: port information structure

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @cd: pointer to command details structure or NULL

 *

 * query current port ETS configuration

/**

 * ice_update_port_tc_tree_cfg - update TC tree configuration

 * @pi: port information structure

 * @buf: pointer to buffer

 *

 * update the SW DB with the new TC changes

 suspend the missing TC nodes */

 TC is missing */

 add the new TC nodes */

 Is it already present in the tree ? */

 new TC */

 update the TC number */

/**

 * ice_query_port_ets - query port ETS configuration

 * @pi: port information structure

 * @buf: pointer to buffer

 * @buf_size: buffer size in bytes

 * @cd: pointer to command details structure or NULL

 *

 * query current port ETS configuration and update the

 * SW DB with the TC changes

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2021, Intel Corporation. */

/* Flow profile ID format:

 * [0:31] - flow type, flow + tun_offs

 * [32:63] - VSI index

/**

 * ice_vc_fdir_param_check

 * @vf: pointer to the VF structure

 * @vsi_id: VF relative VSI ID

 *

 * Check for the valid VSI ID, PF's state and VF's state

 *

 * Return: 0 on success, and -EINVAL on error.

/**

 * ice_vf_start_ctrl_vsi

 * @vf: pointer to the VF structure

 *

 * Allocate ctrl_vsi for the first time and open the ctrl_vsi port for VF

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_alloc_prof - allocate profile for this filter flow type

 * @vf: pointer to the VF structure

 * @flow: filter flow type

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_free_prof - free profile for this filter flow type

 * @vf: pointer to the VF structure

 * @flow: filter flow type

/**

 * ice_vc_fdir_free_prof_all - free all the profile for this VF

 * @vf: pointer to the VF structure

/**

 * ice_vc_fdir_parse_flow_fld

 * @proto_hdr: virtual channel protocol filter header

 * @conf: FDIR configuration for each filter

 * @fld: field type array

 * @fld_cnt: field counter

 *

 * Parse the virtual channel filter header and store them into field type array

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_set_flow_fld

 * @vf: pointer to the VF structure

 * @fltr: virtual channel add cmd buffer

 * @conf: FDIR configuration for each filter

 * @seg: array of one or more packet segments that describe the flow

 *

 * Parse the virtual channel add msg buffer's field vector and store them into

 * flow's packet segment field

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_set_flow_hdr - config the flow's packet segment header

 * @vf: pointer to the VF structure

 * @conf: FDIR configuration for each filter

 * @seg: array of one or more packet segments that describe the flow

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_rem_prof - remove profile for this filter flow type

 * @vf: pointer to the VF structure

 * @flow: filter flow type

 * @tun: 0 implies non-tunnel type filter, 1 implies tunnel type filter

/**

 * ice_vc_fdir_rem_prof_all - remove profile for this VF

 * @vf: pointer to the VF structure

/**

 * ice_vc_fdir_write_flow_prof

 * @vf: pointer to the VF structure

 * @flow: filter flow type

 * @seg: array of one or more packet segments that describe the flow

 * @tun: 0 implies non-tunnel type filter, 1 implies tunnel type filter

 *

 * Write the flow's profile config and packet segment into the hardware

 *

 * Return: 0 on success, and other on error.

 remove previously allocated profile */

/**

 * ice_vc_fdir_config_input_set

 * @vf: pointer to the VF structure

 * @fltr: virtual channel add cmd buffer

 * @conf: FDIR configuration for each filter

 * @tun: 0 implies non-tunnel type filter, 1 implies tunnel type filter

 *

 * Config the input set type and value for virtual channel add msg buffer

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_match_pattern

 * @fltr: virtual channel add cmd buffer

 * @type: virtual channel protocol filter header type

 *

 * Matching the header type by comparing fltr and type's value.

 *

 * Return: true on success, and false on error.

/**

 * ice_vc_fdir_get_pattern - get while list pattern

 * @vf: pointer to the VF info

 * @len: filter list length

 *

 * Return: pointer to allowed filter list

/**

 * ice_vc_fdir_search_pattern

 * @vf: pointer to the VF info

 * @fltr: virtual channel add cmd buffer

 *

 * Search for matched pattern from supported pattern list

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_parse_pattern

 * @vf: pointer to the VF info

 * @fltr: virtual channel add cmd buffer

 * @conf: FDIR configuration for each filter

 *

 * Parse the virtual channel filter's pattern and store them into conf

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_parse_action

 * @vf: pointer to the VF info

 * @fltr: virtual channel add cmd buffer

 * @conf: FDIR configuration for each filter

 *

 * Parse the virtual channel filter's action and store them into conf

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_validate_fdir_fltr - validate the virtual channel filter

 * @vf: pointer to the VF info

 * @fltr: virtual channel add cmd buffer

 * @conf: FDIR configuration for each filter

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_comp_rules - compare if two filter rules have the same value

 * @conf_a: FDIR configuration for filter a

 * @conf_b: FDIR configuration for filter b

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_is_dup_fltr

 * @vf: pointer to the VF info

 * @conf: FDIR configuration for each filter

 *

 * Check if there is duplicated rule with same conf value

 *

 * Return: 0 true success, and false on error.

/**

 * ice_vc_fdir_insert_entry

 * @vf: pointer to the VF info

 * @conf: FDIR configuration for each filter

 * @id: pointer to ID value allocated by driver

 *

 * Insert FDIR conf entry into list and allocate ID for this filter

 *

 * Return: 0 true success, and other on error.

 alloc ID corresponding with conf */

/**

 * ice_vc_fdir_remove_entry - remove FDIR conf entry by ID value

 * @vf: pointer to the VF info

 * @conf: FDIR configuration for each filter

 * @id: filter rule's ID

/**

 * ice_vc_fdir_lookup_entry - lookup FDIR conf entry by ID value

 * @vf: pointer to the VF info

 * @id: filter rule's ID

 *

 * Return: NULL on error, and other on success.

/**

 * ice_vc_fdir_flush_entry - remove all FDIR conf entry

 * @vf: pointer to the VF info

/**

 * ice_vc_fdir_write_fltr - write filter rule into hardware

 * @vf: pointer to the VF info

 * @conf: FDIR configuration for each filter

 * @add: true implies add rule, false implies del rules

 * @is_tun: false implies non-tunnel type filter, true implies tunnel filter

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vf_fdir_timer - FDIR program waiting timer interrupt handler

 * @t: pointer to timer_list

/**

 * ice_vc_fdir_irq_handler - ctrl_vsi Rx queue interrupt handler

 * @ctrl_vsi: pointer to a VF's CTRL VSI

 * @rx_desc: pointer to FDIR Rx queue descriptor

/**

 * ice_vf_fdir_dump_info - dump FDIR information for diagnosis

 * @vf: pointer to the VF info

/**

 * ice_vf_verify_rx_desc - verify received FDIR programming status descriptor

 * @vf: pointer to the VF info

 * @ctx: FDIR context info for post processing

 * @status: virtchnl FDIR program status

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_add_fdir_fltr_post

 * @vf: pointer to the VF structure

 * @ctx: FDIR context info for post processing

 * @status: virtchnl FDIR program status

 * @success: true implies success, false implies failure

 *

 * Post process for flow director add command. If success, then do post process

 * and send back success msg by virtchnl. Otherwise, do context reversion and

 * send back failure msg by virtchnl.

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_del_fdir_fltr_post

 * @vf: pointer to the VF structure

 * @ctx: FDIR context info for post processing

 * @status: virtchnl FDIR program status

 * @success: true implies success, false implies failure

 *

 * Post process for flow director del command. If success, then do post process

 * and send back success msg by virtchnl. Otherwise, do context reversion and

 * send back failure msg by virtchnl.

 *

 * Return: 0 on success, and other on error.

/**

 * ice_flush_fdir_ctx

 * @pf: pointer to the PF structure

 *

 * Flush all the pending event on ctx_done list and process them.

/**

 * ice_vc_fdir_set_irq_ctx - set FDIR context info for later IRQ handler

 * @vf: pointer to the VF structure

 * @conf: FDIR configuration for each filter

 * @v_opcode: virtual channel operation code

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_fdir_clear_irq_ctx - clear FDIR context info for IRQ handler

 * @vf: pointer to the VF structure

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_add_fdir_fltr - add a FDIR filter for VF by the msg buffer

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Return: 0 on success, and other on error.

/**

 * ice_vc_del_fdir_fltr - delete a FDIR filter for VF by the msg buffer

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Return: 0 on success, and other on error.

 Just return failure when ctrl_vsi idx is invalid */

/**

 * ice_vf_fdir_init - init FDIR resource for VF

 * @vf: pointer to the VF info

/**

 * ice_vf_fdir_exit - destroy FDIR resource for VF

 * @vf: pointer to the VF info

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2020, Intel Corporation. */

 context for devlink info version reporting */

/* The following functions are used to format specific strings for various

 * devlink info versions. The ctx parameter is used to provide the storage

 * buffer, as well as any ancillary information calculated when the info

 * request was made.

 *

 * If a version does not exist, for example when attempting to get the

 * inactive version of flash when there is no pending update, the function

 * should leave the buffer in the ctx structure empty.

 Copy the DSN into an array in Big Endian format */

 We failed to locate the PBA, so just skip this entry */

 The netlist version fields are BCD formatted */

 The netlist version fields are BCD formatted */

/* The combined() macro inserts both the running entry as well as a stored

 * entry. The running entry will always report the version from the active

 * handler. The stored entry will first try the pending handler, and fallback

 * to the active handler if the pending function does not report a version.

 * The pending handler should check the status of a pending update for the

 * relevant flash component. It should only fill in the buffer in the case

 * where a valid pending version is available. This ensures that the related

 * stored and running versions remain in sync, and that stored versions are

 * correctly reported as expected.

/**

 * ice_devlink_info_get - .info_get devlink handler

 * @devlink: devlink instance structure

 * @req: the devlink info request

 * @extack: extended netdev ack structure

 *

 * Callback for the devlink .info_get operation. Reports information about the

 * device.

 *

 * Return: zero on success or an error code on failure.

 discover capabilities first */

 disable display of pending Option ROM */

 disable display of pending Option ROM */

 disable display of pending Option ROM */

		/* If the default getter doesn't report a version, use the

		 * fallback function. This is primarily useful in the case of

		 * "stored" versions that want to report the same value as the

		 * running version in the normal case of no pending update.

 Do not report missing versions */

/**

 * ice_devlink_flash_update - Update firmware stored in flash on the device

 * @devlink: pointer to devlink associated with device to update

 * @params: flash update parameters

 * @extack: netlink extended ACK structure

 *

 * Perform a device flash update. The bulk of the update logic is contained

 * within the ice_flash_pldm_image function.

 *

 * Returns: zero on success, or an error code on failure.

 preserve all settings and identifiers */

 overwrite settings, but preserve the vital device identifiers */

 overwrite both settings and identifiers, preserve nothing */

/**

 * ice_allocate_pf - Allocate devlink and return PF structure pointer

 * @dev: the device to allocate for

 *

 * Allocate a devlink instance for this device and return the private area as

 * the PF structure. The devlink memory is kept track of through devres by

 * adding an action to remove it when unwinding.

 Add an action to teardown the devlink when unwinding the driver */

/**

 * ice_devlink_register - Register devlink interface for this PF

 * @pf: the PF to register the devlink for.

 *

 * Register the devlink instance associated with this physical function.

 *

 * Return: zero on success or an error code on failure.

/**

 * ice_devlink_unregister - Unregister devlink resources for this PF.

 * @pf: the PF structure to cleanup

 *

 * Releases resources used by devlink and cleans up associated memory.

/**

 * ice_devlink_create_pf_port - Create a devlink port for this PF

 * @pf: the PF to create a devlink port for

 *

 * Create and register a devlink_port for this PF.

 *

 * Return: zero on success or an error code on failure.

/**

 * ice_devlink_destroy_pf_port - Destroy the devlink_port for this PF

 * @pf: the PF to cleanup

 *

 * Unregisters the devlink_port structure associated with this PF.

/**

 * ice_devlink_create_vf_port - Create a devlink port for this VF

 * @vf: the VF to create a port for

 *

 * Create and register a devlink_port for this VF.

 *

 * Return: zero on success or an error code on failure.

/**

 * ice_devlink_destroy_vf_port - Destroy the devlink_port for this VF

 * @vf: the VF to cleanup

 *

 * Unregisters the devlink_port structure associated with this VF.

/**

 * ice_devlink_nvm_snapshot - Capture a snapshot of the Shadow RAM contents

 * @devlink: the devlink instance

 * @ops: the devlink region being snapshotted

 * @extack: extended ACK response structure

 * @data: on exit points to snapshot data buffer

 *

 * This function is called in response to the DEVLINK_CMD_REGION_TRIGGER for

 * the shadow-ram devlink region. It captures a snapshot of the shadow ram

 * contents. This snapshot can later be viewed via the devlink-region

 * interface.

 *

 * @returns zero on success, and updates the data pointer. Returns a non-zero

 * error code on failure.

/**

 * ice_devlink_devcaps_snapshot - Capture snapshot of device capabilities

 * @devlink: the devlink instance

 * @ops: the devlink region being snapshotted

 * @extack: extended ACK response structure

 * @data: on exit points to snapshot data buffer

 *

 * This function is called in response to the DEVLINK_CMD_REGION_TRIGGER for

 * the device-caps devlink region. It captures a snapshot of the device

 * capabilities reported by firmware.

 *

 * @returns zero on success, and updates the data pointer. Returns a non-zero

 * error code on failure.

/**

 * ice_devlink_init_regions - Initialize devlink regions

 * @pf: the PF device structure

 *

 * Create devlink regions used to enable access to dump the contents of the

 * flash memory on the device.

/**

 * ice_devlink_destroy_regions - Destroy devlink regions

 * @pf: the PF device structure

 *

 * Remove previously created regions for this PF.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019, Intel Corporation. */

/**

 * ice_dcb_get_ena_tc - return bitmap of enabled TCs

 * @dcbcfg: DCB config to evaluate for enabled TCs

/**

 * ice_is_pfc_causing_hung_q

 * @pf: pointer to PF structure

 * @txqueue: Tx queue which is supposedly hung queue

 *

 * find if PFC is causing the hung queue, if yes return true else false

 first find out the TC to which the hung queue belongs to */

	/* Build a bit map of all UPs associated to the suspect hung queue TC,

	 * so that we check for its counter increment.

	/* Now that we figured out that hung queue is PFC enabled, still the

	 * Tx timeout can be legitimate. So to make sure Tx timeout is

	 * absolutely caused by PFC storm, check if the counters are

	 * incrementing.

/**

 * ice_dcb_get_mode - gets the DCB mode

 * @port_info: pointer to port info structure

 * @host: if set it's HOST if not it's MANAGED

/**

 * ice_dcb_get_num_tc - Get the number of TCs from DCBX config

 * @dcbcfg: config to retrieve number of TCs from

	/* Scan the ETS Config Priority Table to find traffic classes

	 * enabled and create a bitmask of enabled TCs

 Scan bitmask for contiguous TCs starting with TC0 */

 There is always at least 1 TC */

/**

 * ice_get_first_droptc - returns number of first droptc

 * @vsi: used to find the first droptc

 *

 * This function returns the value of first_droptc.

 * When DCB is enabled, first droptc information is derived from enabled_tc

 * and PFC enabled bits. otherwise this function returns 0 as there is one

 * TC without DCB (tc0)

 get bitmap of enabled TCs */

 get bitmap of PFC enabled TCs */

 get first TC that is not PFC enabled */

/**

 * ice_vsi_set_dcb_tc_cfg - Set VSI's TC based on DCB configuration

 * @vsi: pointer to the VSI instance

/**

 * ice_dcb_get_tc - Get the TC associated with the queue

 * @vsi: ptr to the VSI

 * @queue_index: queue number associated with VSI

/**

 * ice_vsi_cfg_dcb_rings - Update rings to reflect DCB TC

 * @vsi: VSI owner of rings being updated

 Reset the TC information */

	/* applicable only if "all_enatc" is set, which will be set from

	 * setup_tc method as part of configuring channels

		/* When DCB is configured, TC for ADQ queues (which are really

		 * PF queues) should be the first drop TC of the main VSI

/**

 * ice_dcb_ena_dis_vsi - disable certain VSIs for DCB config/reconfig

 * @pf: pointer to the PF instance

 * @ena: true to enable VSIs, false to disable

 * @locked: true if caller holds RTNL lock, false otherwise

 *

 * Before a new DCB configuration can be applied, VSIs of type PF, SWITCHDEV

 * and CHNL need to be brought down. Following completion of DCB configuration

 * the VSIs that were downed need to be brought up again. This helper function

 * does both.

/**

 * ice_dcb_bwchk - check if ETS bandwidth input parameters are correct

 * @pf: pointer to the PF struct

 * @dcbcfg: pointer to DCB config structure

	/* returns number of contigous TCs and 1 TC for non-contigous TCs,

	 * since at least 1 TC has to be configured

	/* no bandwidth checks required if there's only one TC, so assign

	 * all bandwidth to TC0 and return

/**

 * ice_pf_dcb_cfg - Apply new DCB configuration

 * @pf: pointer to the PF struct

 * @new_cfg: DCBX config to apply

 * @locked: is the RTNL held

 FW does not care if change happened */

 Enable DCB tagging only when more than one TC */

 Store old config in case FW config fails */

 Notify AUX drivers about impending change to TCs */

	/* avoid race conditions by holding the lock while disabling and

	 * re-enabling the VSI

 disable VSIs affected by DCB changes */

	/* Only send new config to HW if we are in SW LLDP mode. Otherwise,

	 * the new config came from the HW in the first place.

 Restore previous settings to local config */

 enable previously downed VSIs */

/**

 * ice_cfg_etsrec_defaults - Set default ETS recommended DCB config

 * @pi: port information structure

 Ensure ETS recommended DCB configuration is not already set */

 In CEE mode, set the default to 1 TC */

/**

 * ice_dcb_need_recfg - Check if DCB needs reconfig

 * @pf: board private structure

 * @old_cfg: current DCB config

 * @new_cfg: new DCB config

 Check if ETS configuration has changed */

 If Priority Table has changed reconfig is needed */

 Check if PFC configuration has changed */

 Check if APP Table has changed */

/**

 * ice_dcb_rebuild - rebuild DCB post reset

 * @pf: physical function instance

	/* Coverity warns the return code of ice_pf_dcb_cfg() is not checked

	 * here as is done for other calls to that function. That check is

	 * not necessary since this is in this function's error cleanup path.

	 * Suppress the Coverity warning with the following comment...

 coverity[check_return] */

/**

 * ice_dcb_init_cfg - set the initial DCB config in SW

 * @pf: PF to apply config to

 * @locked: Is the RTNL held

/**

 * ice_dcb_sw_dflt_cfg - Apply a default DCB config

 * @pf: PF to apply config to

 * @ets_willing: configure ETS willing

 * @locked: was this function called with RTNL held

/**

 * ice_dcb_tc_contig - Check that TCs are contiguous

 * @prio_table: pointer to priority table

 *

 * Check if TCs begin with TC0 and are contiguous

 Create a bitmap of used TCs */

/**

 * ice_dcb_noncontig_cfg - Configure DCB for non-contiguous TCs

 * @pf: pointer to the PF struct

 *

 * If non-contiguous TCs, then configure SW DCB with TC0 and ETS non-willing

 Configure SW DCB default with ETS non-willing */

 Reconfigure with ETS willing so that FW will send LLDP MIB event */

/**

 * ice_pf_dcb_recfg - Reconfigure all VEBs and VSIs

 * @pf: pointer to the PF struct

 *

 * Assumed caller has already disabled all VSIs before

 * calling this function. Reconfiguring DCB based on

 * local_dcbx_cfg.

 Update each VSI */

			/* If DCBX request non-contiguous TC, then configure

			 * default TC

		/* no need to proceed with remaining cfg if it is CHNL

		 * or switchdev VSI

 Notify the AUX drivers that TC change is finished */

/**

 * ice_init_pf_dcb - initialize DCB for a PF

 * @pf: PF to initialize DCB for

 * @locked: Was function called with RTNL held

 FW LLDP is disabled, activate SW DCBX/LLDP mode */

		/* If the FW DCBX engine is not running then Rx LLDP packets

		 * need to be redirected up the stack.

 DCBX/LLDP enabled in FW, set DCBNL mode advertisement */

/**

 * ice_update_dcb_stats - Update DCB stats counters

 * @pf: PF whose stats needs to be updated

/**

 * ice_tx_prepare_vlan_flags_dcb - prepare VLAN tagging for DCB

 * @tx_ring: ring to send buffer on

 * @first: pointer to struct ice_tx_buf

 *

 * This should not be called if the outer VLAN is software offloaded as the VLAN

 * tag will already be configured with the correct ID and priority bits

 Insert 802.1p priority into VLAN header */

 Mask the lower 3 bits to set the 802.1p priority */

		/* if this is not already set it means a VLAN 0 + priority needs

		 * to be offloaded

/**

 * ice_dcb_process_lldp_set_mib_change - Process MIB change

 * @pf: ptr to ice_pf

 * @event: pointer to the admin queue receive event

 Not DCB capable or capability disabled */

 Ignore if event is not for Nearest Bridge */

 Check MIB Type and return if event for Remote MIB update */

 Update the remote cached instance and return */

 store the old configuration */

 Reset the old DCBX configuration data */

 Get updated DCBX data from firmware */

 No change detected in DCBX configs */

 Enable DCB tagging only when more than one TC */

 disable VSIs affected by DCB changes */

 changes in configuration update VSI */

 enable previously downed VSIs */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018-2019, Intel Corporation. */

 Track which NVM banks to activate at the end of the update */

/**

 * ice_send_package_data - Send record package data to firmware

 * @context: PLDM fw update structure

 * @data: pointer to the package data

 * @length: length of the package data

 *

 * Send a copy of the package data associated with the PLDM record matching

 * this device to the firmware.

 *

 * Note that this function sends an AdminQ command that will fail unless the

 * NVM resource has been acquired.

 *

 * Returns: zero on success, or a negative error code on failure.

/**

 * ice_check_component_response - Report firmware response to a component

 * @pf: device private data structure

 * @id: component id being checked

 * @response: indicates whether this component can be updated

 * @code: code indicating reason for response

 * @extack: netlink extended ACK structure

 *

 * Check whether firmware indicates if this component can be updated. Report

 * a suitable error message over the netlink extended ACK if the component

 * cannot be updated.

 *

 * Returns: zero if the component can be updated, or -ECANCELED of the

 * firmware indicates the component cannot be updated.

 firmware indicated this update is good to proceed */

/**

 * ice_send_component_table - Send PLDM component table to firmware

 * @context: PLDM fw update structure

 * @component: the component to process

 * @transfer_flag: relative transfer order of this component

 *

 * Read relevant data from the component and forward it to the device

 * firmware. Check the response to determine if the firmware indicates that

 * the update can proceed.

 *

 * This function sends AdminQ commands related to the NVM, and assumes that

 * the NVM resource has been acquired.

 *

 * Returns: zero on success, or a negative error code on failure.

/**

 * ice_write_one_nvm_block - Write an NVM block and await completion response

 * @pf: the PF data structure

 * @module: the module to write to

 * @offset: offset in bytes

 * @block_size: size of the block to write, up to 4k

 * @block: pointer to block of data to write

 * @last_cmd: whether this is the last command

 * @extack: netlink extended ACK structure

 *

 * Write a block of data to a flash module, and await for the completion

 * response message from firmware.

 *

 * Note this function assumes the caller has acquired the NVM resource.

 *

 * Returns: zero on success, or a negative error code on failure.

	/* In most cases, firmware reports a write completion within a few

	 * milliseconds. However, it has been observed that a completion might

	 * take more than a second to complete in some cases. The timeout here

	 * is conservative and is intended to prevent failure to update when

	 * firmware is slow to respond.

/**

 * ice_write_nvm_module - Write data to an NVM module

 * @pf: the PF driver structure

 * @module: the module id to program

 * @component: the name of the component being updated

 * @image: buffer of image data to write to the NVM

 * @length: length of the buffer

 * @extack: netlink extended ACK structure

 *

 * Loop over the data for a given NVM module and program it in 4 Kb

 * blocks. Notify devlink core of progress after each block is programmed.

 * Loops over a block of data and programs the NVM in 4k block chunks.

 *

 * Note this function assumes the caller has acquired the NVM resource.

 *

 * Returns: zero on success, or a negative error code on failure.

		/* ice_aq_update_nvm may copy the firmware response into the

		 * buffer, so we must make a copy since the source data is

		 * constant.

/* Length in seconds to wait before timing out when erasing a flash module.

 * Yes, erasing really can take minutes to complete.

/**

 * ice_erase_nvm_module - Erase an NVM module and await firmware completion

 * @pf: the PF data structure

 * @module: the module to erase

 * @component: name of the component being updated

 * @extack: netlink extended ACK structure

 *

 * Erase the inactive NVM bank associated with this module, and await for

 * a completion response message from firmware.

 *

 * Note this function assumes the caller has acquired the NVM resource.

 *

 * Returns: zero on success, or a negative error code on failure.

/**

 * ice_switch_flash_banks - Tell firmware to switch NVM banks

 * @pf: Pointer to the PF data structure

 * @activate_flags: flags used for the activation command

 * @extack: netlink extended ACK structure

 *

 * Notify firmware to activate the newly written flash banks, and wait for the

 * firmware response.

 *

 * Returns: zero on success or an error code on failure.

/**

 * ice_flash_component - Flash a component of the NVM

 * @context: PLDM fw update structure

 * @component: the component table to program

 *

 * Program the flash contents for a given component. First, determine the

 * module id. Then, erase the secondary bank for this module. Finally, write

 * the contents of the component to the NVM.

 *

 * Note this function assumes the caller has acquired the NVM resource.

 *

 * Returns: zero on success, or a negative error code on failure.

		/* This should not trigger, since we check the id before

		 * sending the component table to firmware.

 Mark this component for activating at the end */

/**

 * ice_finalize_update - Perform last steps to complete device update

 * @context: PLDM fw update structure

 *

 * Called as the last step of the update process. Complete the update by

 * telling the firmware to switch active banks, and perform a reset of

 * configured.

 *

 * Returns: 0 on success, or an error code on failure.

 Finally, notify firmware to activate the written NVM banks */

/**

 * ice_flash_pldm_image - Write a PLDM-formatted firmware image to the device

 * @pf: private device driver structure

 * @fw: firmware object pointing to the relevant firmware file

 * @preservation: preservation level to request from firmware

 * @extack: netlink extended ACK structure

 *

 * Parse the data for a given firmware file, verifying that it is a valid PLDM

 * formatted image that matches this device.

 *

 * Extract the device record Package Data and Component Tables and send them

 * to the firmware. Extract and write the flash data for each of the three

 * main flash components, "fw.mgmt", "fw.undi", and "fw.netlist". Notify

 * firmware once the data is written to the inactive banks.

 *

 * Returns: zero on success or a negative error code on failure.

		/* Do not set a generic extended ACK message here. A more

		 * specific message may already have been set by one of our

		 * ops.

/**

 * ice_check_for_pending_update - Check for a pending flash update

 * @pf: the PF driver structure

 * @component: if not NULL, the name of the component being updated

 * @extack: Netlink extended ACK structure

 *

 * Check whether the device already has a pending flash update. If such an

 * update is found, cancel it so that the requested update may proceed.

 *

 * Returns: zero on success, or a negative error code on failure.

	/* Read the most recent device capabilities from firmware. Do not use

	 * the cached values in hw->dev_caps, because the pending update flag

	 * may have changed, e.g. if an update was previously completed and

	 * the system has not yet rebooted.

	/* If the flash_update request is for a specific component, ignore all

	 * of the other components.

 There is no previous pending update, so this request may continue */

	/* In order to allow overwriting a previous pending update, notify

	 * firmware to cancel that update by issuing the appropriate command.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

 Intel(R) Ethernet Connection E800 Series Linux Driver */

/* Including ice_trace.h with CREATE_TRACE_POINTS defined will generate the

 * ice tracepoint functions. This must be done exactly once across the

 * ice driver.

 DDP Package file located in firmware search paths (e.g. /lib/firmware/) */

 !CONFIG_DYNAMIC_DEBUG */

/**

 * ice_get_tx_pending - returns number of Tx descriptors not processed

 * @ring: the ring of descriptors

/**

 * ice_check_for_hang_subtask - check for and recover hung queues

 * @pf: pointer to PF struct

			/* If packet counter has not changed the queue is

			 * likely stalled, so force an interrupt for this

			 * queue.

			 *

			 * prev_pkt would be negative if there was no

			 * pending work.

 Trigger sw interrupt to revive the queue */

			/* Memory barrier between read of packet count and call

			 * to ice_get_tx_pending()

/**

 * ice_init_mac_fltr - Set initial MAC filters

 * @pf: board private structure

 *

 * Set initial set of MAC filters for PF VSI; configure filters for permanent

 * address and broadcast address. If an error is encountered, netdevice will be

 * unregistered.

/**

 * ice_add_mac_to_sync_list - creates list of MAC addresses to be synced

 * @netdev: the net device on which the sync is happening

 * @addr: MAC address to sync

 *

 * This is a callback function which is called by the in kernel device sync

 * functions (like __dev_uc_sync, __dev_mc_sync, etc). This function only

 * populates the tmp_sync_list, which is later used by ice_add_mac to add the

 * MAC filters from the hardware.

/**

 * ice_add_mac_to_unsync_list - creates list of MAC addresses to be unsynced

 * @netdev: the net device on which the unsync is happening

 * @addr: MAC address to unsync

 *

 * This is a callback function which is called by the in kernel device unsync

 * functions (like __dev_uc_unsync, __dev_mc_unsync, etc). This function only

 * populates the tmp_unsync_list, which is later used by ice_remove_mac to

 * delete the MAC filters from the hardware.

	/* Under some circumstances, we might receive a request to delete our

	 * own device address from our uc list. Because we store the device

	 * address in the VSI's MAC filter list, we need to ignore such

	 * requests and not delete our device address from this list.

/**

 * ice_vsi_fltr_changed - check if filter state changed

 * @vsi: VSI to be checked

 *

 * returns true if filter state has changed, false otherwise.

/**

 * ice_cfg_promisc - Enable or disable promiscuous mode for a given PF

 * @vsi: the VSI being configured

 * @promisc_m: mask of promiscuous config bits

 * @set_promisc: enable or disable promisc flag request

 *

/**

 * ice_vsi_sync_fltr - Update the VSI filter list to the HW

 * @vsi: ptr to the VSI

 *

 * Push any outstanding VSI filter changes through the AdminQ.

 grab the netdev's addr_list_lock */

 our temp lists are populated. release lock */

 Remove MAC addresses in the unsync list */

 if we failed because of alloc failures, just bail */

 Add MAC addresses in the sync list */

	/* If filter is added successfully or already exists, do not go into

	 * 'if' condition and report it as error. Instead continue processing

	 * rest of the function.

		/* If there is no more space for new umac filters, VSI

		 * should go into promiscuous mode. There should be some

		 * space reserved for promiscuous filters.

 check for changes in promiscuous modes */

 !(vsi->current_netdev_flags & IFF_ALLMULTI) */

 Apply Rx filter rule to get traffic from wire */

 Clear Rx filter to remove traffic from wire */

 if something went wrong then set the changed flag so we try again */

/**

 * ice_sync_fltr_subtask - Sync the VSI filter list with HW

 * @pf: board private structure

 come back and try again later */

/**

 * ice_pf_dis_all_vsi - Pause all VSIs on a PF

 * @pf: the PF

 * @locked: is the rtnl_lock already held

/**

 * ice_prepare_for_reset - prep for reset

 * @pf: board private structure

 * @reset_type: reset type requested

 *

 * Inform or close all dependent features in prep for reset.

 already prepared for reset */

 Notify VFs of impending reset */

 Disable VFs until reset is completed */

 release ADQ specific HW and SW resources */

	/* to be on safe side, reset orig_rss_size so that normal flow

	 * of deciding rss_size can take precedence

			/* for other reset type, do not support channel rebuild

			 * hence reset needed info

 clear SW filtering DB */

 disable the VSIs and their queues that are not already DOWN */

/**

 * ice_do_reset - Initiate one of many types of resets

 * @pf: board private structure

 * @reset_type: reset type requested before this function was called.

 trigger the reset */

	/* PFR is a bit of a special case because it doesn't result in an OICR

	 * interrupt. So for PFR, rebuild after the reset and clear the reset-

	 * associated state bits.

/**

 * ice_reset_subtask - Set up for resetting the device and driver

 * @pf: board private structure

	/* When a CORER/GLOBR/EMPR is about to happen, the hardware triggers an

	 * OICR interrupt. The OICR handler (ice_misc_intr) determines what type

	 * of reset is pending and sets bits in pf->state indicating the reset

	 * type and ICE_RESET_OICR_RECV. So, if the latter bit is set

	 * prepare for pending reset if not already (for PF software-initiated

	 * global resets the software should already be prepared for it as

	 * indicated by ICE_PREPARED_FOR_RESET; for global resets initiated

	 * by firmware or software on other PFs, that bit is not set so prepare

	 * for the reset now), poll for reset done, rebuild and return.

 Perform the largest reset requested */

 return if no valid reset type requested */

 make sure we are ready to rebuild */

 done with reset. start rebuild */

			/* clear bit to resume normal operations, but

			 * ICE_NEEDS_RESTART bit is set in case rebuild failed

 No pending resets to finish processing. Check for new resets */

 If no valid reset type requested just return */

 reset if not already down or busy */

/**

 * ice_print_topo_conflict - print topology conflict message

 * @vsi: the VSI whose topology status is being checked

/**

 * ice_print_link_msg - print link up or down message

 * @vsi: the VSI whose link status is being queried

 * @isup: boolean for if the link is now up or down

 Get FEC mode based on negotiated link info */

 check if autoneg completed, might be false due to not supported */

 Get FEC mode requested based on PHY caps last SW configuration */

/**

 * ice_vsi_link_event - update the VSI's netdev

 * @vsi: the VSI on which the link event occurred

 * @link_up: whether or not the VSI needs to be set up or down

/**

 * ice_set_dflt_mib - send a default config MIB to the FW

 * @pf: private PF struct

 *

 * This function sends a default configuration MIB to the FW.

 *

 * If this function errors out at any point, the driver is still able to

 * function.  The main impact is that LFC may not operate as expected.

 * Therefore an error state in this function should be treated with a DBG

 * message and continue on with driver rebuild/reenable.

 Add ETS CFG TLV */

	/* ETS CFG all UPs map to TC 0. Next 4 (1 - 4) Octets = 0.

	 * Octets 5 - 12 are BW values, set octet 5 to 100% BW.

	 * Octets 13 - 20 are TSA values - leave as zeros

 Add ETS REC TLV */

	/* First octet of buf is reserved

	 * Octets 1 - 4 map UP to TC - all UPs map to zero

	 * Octets 5 - 12 are BW values - set TC 0 to 100%.

	 * Octets 13 - 20 are TSA value - leave as zeros

 Add PFC CFG TLV */

 Octet 1 left as all zeros - PFC disabled */

/**

 * ice_check_phy_fw_load - check if PHY FW load failed

 * @pf: pointer to PF struct

 * @link_cfg_err: bitmap from the link info structure

 *

 * check if external PHY FW load failed and print an error message if it did

/**

 * ice_check_module_power

 * @pf: pointer to PF struct

 * @link_cfg_err: bitmap from the link info structure

 *

 * check module power level returned by a previous call to aq_get_link_info

 * and print error messages if module power level is not supported

 if module power level is supported, clear the flag */

	/* if ICE_FLAG_MOD_POWER_UNSUPPORTED was previously set and the

	 * above block didn't clear this bit, there's nothing to do

/**

 * ice_check_link_cfg_err - check if link configuration failed

 * @pf: pointer to the PF struct

 * @link_cfg_err: bitmap from the link info structure

 *

 * print if any link configuration failure happens due to the value in the

 * link_cfg_err parameter in the link info structure

/**

 * ice_link_event - process the link event

 * @pf: PF that the link event is associated with

 * @pi: port_info for the port that the link event is associated with

 * @link_up: true if the physical link is up and false if it is down

 * @link_speed: current link speed received from the link event

 *

 * Returns 0 on success and negative on failure

	/* update the link info structures and re-enable link events,

	 * don't bail on failure due to other book keeping needed

	/* Check if the link state is up after updating link info, and treat

	 * this event as an UP event since the link is actually UP now.

 turn off PHY if media was removed */

 if the old link up/down and speed is the same as the new */

/**

 * ice_watchdog_subtask - periodic tasks not using event driven scheduling

 * @pf: board private structure

 if interface is down do nothing */

 make sure we don't do these things too often */

	/* Update the stats for active netdevs so the network stack

	 * can look at updated numbers whenever it cares to

/**

 * ice_init_link_events - enable/initialize link events

 * @pi: pointer to the port_info instance

 *

 * Returns -EIO on failure, 0 on success

/**

 * ice_handle_link_event - handle link event via ARQ

 * @pf: PF that the link event is associated with

 * @event: event structure containing link status info

/**

 * ice_aq_wait_for_event - Wait for an AdminQ event from firmware

 * @pf: pointer to the PF private structure

 * @opcode: the opcode to wait for

 * @timeout: how long to wait, in jiffies

 * @event: storage for the event info

 *

 * Waits for a specific AdminQ completion event on the ARQ for a given PF. The

 * current thread will be put to sleep until the specified event occurs or

 * until the given timeout is reached.

 *

 * To obtain only the descriptor contents, pass an event without an allocated

 * msg_buf. If the complete data buffer is desired, allocate the

 * event->msg_buf with enough space ahead of time.

 *

 * Returns: zero on success, or a negative error code on failure.

/**

 * ice_aq_check_events - Check if any thread is waiting for an AdminQ event

 * @pf: pointer to the PF private structure

 * @opcode: the opcode of the event

 * @event: the event to check

 *

 * Loops over the current list of pending threads waiting for an AdminQ event.

 * For each matching task, copy the contents of the event into the task

 * structure and wake up the thread.

 *

 * If multiple threads wait for the same opcode, they will all be woken up.

 *

 * Note that event->msg_buf will only be duplicated if the event has a buffer

 * with enough space already allocated. Otherwise, only the descriptor and

 * message length will be copied.

 *

 * Returns: true if an event was found, false otherwise

 Only copy the data buffer if a destination was set */

/**

 * ice_aq_cancel_waiting_tasks - Immediately cancel all waiting tasks

 * @pf: the PF private structure

 *

 * Set all waiting tasks to ICE_AQ_TASK_CANCELED, and wake up their threads.

 * This will then cause ice_aq_wait_for_event to exit with -ECANCELED.

/**

 * __ice_clean_ctrlq - helper function to clean controlq rings

 * @pf: ptr to struct ice_pf

 * @q_type: specific Control queue type

 Do not clean control queue if/when PF reset fails */

		/* we are going to try to detect a malicious VF, so set the

		 * state to begin detection

	/* check for error indications - PF_xx_AxQLEN register layout for

	 * FW/MBX/SB are identical so just use defines for PF_FW_AxQLEN.

 Notify any thread that might be waiting for this event */

/**

 * ice_ctrlq_pending - check if there is a difference between ntc and ntu

 * @hw: pointer to hardware info

 * @cq: control queue information

 *

 * returns true if there are pending messages in a queue, false if there aren't

/**

 * ice_clean_adminq_subtask - clean the AdminQ rings

 * @pf: board private structure

	/* There might be a situation where new messages arrive to a control

	 * queue between processing the last message and clearing the

	 * EVENT_PENDING bit. So before exiting, check queue head again (using

	 * ice_ctrlq_pending) and process new messages if any.

/**

 * ice_clean_mailboxq_subtask - clean the MailboxQ rings

 * @pf: board private structure

/**

 * ice_clean_sbq_subtask - clean the Sideband Queue rings

 * @pf: board private structure

 Nothing to do here if sideband queue is not supported */

/**

 * ice_service_task_schedule - schedule the service task to wake up

 * @pf: board private structure

 *

 * If not already scheduled, this puts the task into the work queue.

/**

 * ice_service_task_complete - finish up the service task

 * @pf: board private structure

 force memory (pf->state) to sync before next service task */

/**

 * ice_service_task_stop - stop service task and cancel works

 * @pf: board private structure

 *

 * Return 0 if the ICE_SERVICE_DIS bit was not already set,

 * 1 otherwise.

/**

 * ice_service_task_restart - restart service task and schedule works

 * @pf: board private structure

 *

 * This function is needed for suspend and resume works (e.g WoL scenario)

/**

 * ice_service_timer - timer callback to schedule service task

 * @t: pointer to timer_list

/**

 * ice_handle_mdd_event - handle malicious driver detect event

 * @pf: pointer to the PF structure

 *

 * Called from service task. OICR interrupt handler indicates MDD event.

 * VF MDD logging is guarded by net_ratelimit. Additional PF and VF log

 * messages are wrapped by netif_msg_[rx|tx]_err. Since VF Rx MDD events

 * disable the queue, the PF can be configured to reset the VF using ethtool

 * private flag mdd-auto-reset-vf.

		/* Since the VF MDD event logging is rate limited, check if

		 * there are pending MDD events.

 find what triggered an MDD event */

 check to see if this PF caused an MDD event */

	/* Check to see if one of the VFs caused an MDD event, and then

	 * increment counters and set print pending

			/* Since the queue is disabled on VF Rx MDD events, the

			 * PF can be configured to reset the VF through ethtool

			 * private flag mdd-auto-reset-vf.

				/* VF MDD event counters will be cleared by

				 * reset, so print the event prior to reset.

/**

 * ice_force_phys_link_state - Force the physical link state

 * @vsi: VSI to force the physical link state to up/down

 * @link_up: true/false indicates to set the physical link to up/down

 *

 * Force the physical link state by getting the current PHY capabilities from

 * hardware and setting the PHY config based on the determined capabilities. If

 * link changes a link event will be triggered because both the Enable Automatic

 * Link Update and LESM Enable bits are set when setting the PHY capabilities.

 *

 * Returns 0 on success, negative on failure

 No change in link */

	/* Use the current user PHY configuration. The current user PHY

	 * configuration is initialized during probe from PHY capabilities

	 * software mode, and updated on set PHY configuration.

/**

 * ice_init_nvm_phy_type - Initialize the NVM PHY type

 * @pi: port info structure

 *

 * Initialize nvm_phy_type_[low|high] for link lenient mode support

/**

 * ice_init_link_dflt_override - Initialize link default override

 * @pi: port info structure

 *

 * Initialize link default override and PHY total port shutdown during probe

	/* Enable Total Port Shutdown (override/replace link-down-on-close

	 * ethtool private flag) for ports with Port Disable bit set.

/**

 * ice_init_phy_cfg_dflt_override - Initialize PHY cfg default override settings

 * @pi: port info structure

 *

 * If default override is enabled, initialize the user PHY cfg speed and FEC

 * settings using the default override mask from the NVM.

 *

 * The PHY should only be configured with the default override settings the

 * first time media is available. The ICE_LINK_DEFAULT_OVERRIDE_PENDING state

 * is used to indicate that the user PHY cfg default override is initialized

 * and the PHY has not been configured with the default override settings. The

 * state is set here, and cleared in ice_configure_phy the first time the PHY is

 * configured.

 *

 * This function should be called only if the FW doesn't support default

 * configuration mode, as reported by ice_fw_supports_report_dflt_cfg.

	/* If link default override is enabled, use to mask NVM PHY capabilities

	 * for speed and FEC default configuration.

/**

 * ice_init_phy_user_cfg - Initialize the PHY user configuration

 * @pi: port info structure

 *

 * Initialize the current user PHY configuration, speed, FEC, and FC requested

 * mode to default. The PHY defaults are from get PHY capabilities topology

 * with media so call when media is first available. An error is returned if

 * called when media is not available. The PHY initialization completed state is

 * set here.

 *

 * These configurations are used when setting PHY

 * configuration. The user PHY configuration is updated on set PHY

 * configuration. Returns 0 on success, negative on failure

 check if lenient mode is supported and enabled */

		/* if the FW supports default PHY configuration mode, then the driver

		 * does not have to apply link override settings. If not,

		 * initialize user PHY configuration with link override values

	/* if link default override is not enabled, set user flow control and

	 * FEC settings based on what get_phy_caps returned

/**

 * ice_configure_phy - configure PHY

 * @vsi: VSI of PHY

 *

 * Set the PHY configuration. If the current PHY configuration is the same as

 * the curr_user_phy_cfg, then do nothing to avoid link flap. Otherwise

 * configure the based get PHY capabilities for topology with media.

 Ensure we have media as we cannot configure a medialess port */

 Get current PHY config */

	/* If PHY enable link is configured and configuration has not changed,

	 * there's nothing to do

 Use PHY topology as baseline for configuration */

	/* Speed - If default override pending, use curr_user_phy_cfg set in

	 * ice_init_phy_user_cfg_ldo.

 Can't provide what was requested; use PHY capabilities */

 FEC */

 Can't provide what was requested; use PHY capabilities */

	/* Flow Control - always supported; no need to check against

	 * capabilities

 Enable link and link update */

/**

 * ice_check_media_subtask - Check for media

 * @pf: pointer to PF struct

 *

 * If media is available, then initialize PHY user configuration if it is not

 * been, and configure the PHY if the interface is up.

 No need to check for media if it's already present */

 Refresh link info and check if media is present */

		/* PHY settings are reset on media insertion, reconfigure

		 * PHY to preserve settings.

		/* A Link Status Event will be generated; the event handler

		 * will complete bringing the interface up

/**

 * ice_service_task - manage and run subtasks

 * @work: pointer to work_struct contained by the PF struct

 subtasks */

 process reset requests first */

 bail if a reset/recovery cycle is pending or rebuild failed */

 Clear ICE_SERVICE_SCHED flag to allow scheduling next event */

	/* If the tasks have taken longer than one service timer period

	 * or there is more work to be done, reset the service timer to

	 * schedule the service task now.

/**

 * ice_set_ctrlq_len - helper function to set controlq length

 * @hw: pointer to the HW instance

/**

 * ice_schedule_reset - schedule a reset

 * @pf: board private structure

 * @reset: reset being requested

 bail out if earlier reset has failed */

 bail if reset/recovery already in progress */

/**

 * ice_irq_affinity_notify - Callback for affinity changes

 * @notify: context as to what irq was changed

 * @mask: the new affinity mask

 *

 * This is a callback function used by the irq_set_affinity_notifier function

 * so that we may register to receive changes to the irq affinity masks.

/**

 * ice_irq_affinity_release - Callback for affinity notifier release

 * @ref: internal core kernel usage

 *

 * This is a callback function used by the irq_set_affinity_notifier function

 * to inform the current notification subscriber that they will no longer

 * receive notifications.

/**

 * ice_vsi_ena_irq - Enable IRQ for the given VSI

 * @vsi: the VSI being configured

/**

 * ice_vsi_req_irq_msix - get MSI-X vectors from the OS for the VSI

 * @vsi: the VSI being configured

 * @basename: name for the vector

 skip this unused q_vector */

 register for affinity change notifications */

 assign the mask for this irq */

/**

 * ice_xdp_alloc_setup_rings - Allocate and setup Tx rings for XDP

 * @vsi: VSI to setup Tx rings used by XDP

 *

 * Return 0 on success and negative value on error

/**

 * ice_vsi_assign_bpf_prog - set or clear bpf prog pointer on VSI

 * @vsi: VSI to set the bpf prog on

 * @prog: the bpf prog pointer

/**

 * ice_prepare_xdp_rings - Allocate, configure and setup Tx rings for XDP

 * @vsi: VSI to bring up Tx rings used by XDP

 * @prog: bpf program that will be assigned to VSI

 *

 * Return 0 on success and negative value on error

 follow the logic from ice_vsi_map_rings_to_vectors */

	/* omit the scheduler update if in reset path; XDP queues will be

	 * taken into account at the end of ice_vsi_rebuild, where

	 * ice_cfg_vsi_lan is being called

	/* tell the Tx scheduler that right now we have

	 * additional queues

/**

 * ice_destroy_xdp_rings - undo the configuration made by ice_prepare_xdp_rings

 * @vsi: VSI to remove XDP rings

 *

 * Detach XDP rings from irq vectors, clean up the PF bitmap and free

 * resources

	/* q_vectors are freed in reset path so there's no point in detaching

	 * rings; in case of rebuild being triggered not from reset bits

	 * in pf->state won't be set, so additionally check first q_vector

	 * against NULL

 restore the value of last node prior to XDP setup */

	/* notify Tx scheduler that we destroyed XDP queues and bring

	 * back the old number of child nodes

 change number of XDP Tx queues to 0 */

/**

 * ice_vsi_rx_napi_schedule - Schedule napi on RX queues from VSI

 * @vsi: VSI to schedule napi on

/**

 * ice_vsi_determine_xdp_res - figure out how many Tx qs can XDP have

 * @vsi: VSI to determine the count of XDP Tx qs

 *

 * returns 0 if Tx qs count is higher than at least half of CPU count,

 * -ENOMEM otherwise

/**

 * ice_xdp_setup_prog - Add or remove XDP eBPF program

 * @vsi: VSI to setup XDP for

 * @prog: XDP program

 * @extack: netlink extended ack

 need to stop netdev while setting up the program for Rx rings */

/**

 * ice_xdp_safe_mode - XDP handler for safe mode

 * @dev: netdevice

 * @xdp: XDP command

/**

 * ice_xdp - implements XDP handler

 * @dev: netdevice

 * @xdp: XDP command

/**

 * ice_ena_misc_vector - enable the non-queue interrupts

 * @pf: board private structure

	/* Disable anti-spoof detection interrupt to prevent spurious event

	 * interrupts during a function reset. Anti-spoof functionally is

	 * still supported.

 clear things first */

 disable all */

 read to clear */

 SW_ITR_IDX = 0, but don't change INTENA */

/**

 * ice_misc_intr - misc interrupt handler

 * @irq: interrupt number

 * @data: pointer to a q_vector

 disable any further VFLR event notifications */

 we have a reset warning */

		/* If a reset cycle isn't already in progress, we set a bit in

		 * pf->state so that the service task can start a reset/rebuild.

			/* There are couple of different bits at play here.

			 * hw->reset_ongoing indicates whether the hardware is

			 * in reset. This is set to true when a reset interrupt

			 * is received and set back to false after the driver

			 * has determined that the hardware is out of reset.

			 *

			 * ICE_RESET_OICR_RECV in pf->state indicates

			 * that a post reset rebuild is required before the

			 * driver is operational again. This is set above.

			 *

			 * As this is the start of the reset/rebuild cycle, set

			 * both to indicate that.

 Save EVENTs from GTSYN register */

 report the entire OICR value to AUX driver */

 Report any remaining unexpected interrupts */

		/* If a critical error is pending there is no choice but to

		 * reset the device.

/**

 * ice_dis_ctrlq_interrupts - disable control queue interrupts

 * @hw: pointer to HW structure

 disable Admin queue Interrupt causes */

 disable Mailbox queue Interrupt causes */

 disable Control queue Interrupt causes */

/**

 * ice_free_irq_msix_misc - Unroll misc vector setup

 * @pf: board private structure

 disable OICR interrupt */

/**

 * ice_ena_ctrlq_interrupts - enable control queue interrupts

 * @hw: pointer to HW structure

 * @reg_idx: HW vector index to associate the control queue interrupts with

 enable Admin queue Interrupt causes */

 enable Mailbox queue Interrupt causes */

 This enables Sideband queue Interrupt causes */

/**

 * ice_req_irq_msix_misc - Setup the misc vector to handle non queue events

 * @pf: board private structure

 *

 * This sets up the handler for MSIX 0, which is used to manage the

 * non-queue interrupts, e.g. AdminQ and errors. This is not used

 * when in MSI or Legacy interrupt mode.

	/* Do not request IRQ but do enable OICR interrupt since settings are

	 * lost during reset. Note that this function is called only during

	 * rebuild path and not while reset is in progress.

 reserve one vector in irq_tracker for misc interrupts */

/**

 * ice_napi_add - register NAPI handler for the VSI

 * @vsi: VSI for which NAPI handler is to be registered

 *

 * This function is only called in the driver's load path. Registering the NAPI

 * handler is done in ice_vsi_alloc_q_vector() for all other cases (i.e. resume,

 * reset/rebuild, etc.)

/**

 * ice_set_ops - set netdev and ethtools ops for the given netdev

 * @netdev: netdev instance

/**

 * ice_set_netdev_features - set features for the given netdev

 * @netdev: netdev instance

 safe mode */

 set features that user can change */

 add support for HW_CSUM on packets with MPLS header */

 enable features */

 encap and VLAN devices inherit default, csumo and tso features */

/**

 * ice_cfg_netdev - Allocate, configure and register a netdev

 * @vsi: the VSI associated with the new netdev

 *

 * Returns 0 on success, negative value on failure

 Setup netdev TC information */

 setup watchdog timeout value to be 5 second */

/**

 * ice_fill_rss_lut - Fill the RSS lookup table with default values

 * @lut: Lookup table

 * @rss_table_size: Lookup table size

 * @rss_size: Range of queue number for hashing

/**

 * ice_pf_vsi_setup - Set up a PF VSI

 * @pf: board private structure

 * @pi: pointer to the port_info instance

 *

 * Returns pointer to the successfully allocated VSI software struct

 * on success, otherwise returns NULL on failure.

/**

 * ice_ctrl_vsi_setup - Set up a control VSI

 * @pf: board private structure

 * @pi: pointer to the port_info instance

 *

 * Returns pointer to the successfully allocated VSI software struct

 * on success, otherwise returns NULL on failure.

/**

 * ice_lb_vsi_setup - Set up a loopback VSI

 * @pf: board private structure

 * @pi: pointer to the port_info instance

 *

 * Returns pointer to the successfully allocated VSI software struct

 * on success, otherwise returns NULL on failure.

/**

 * ice_vlan_rx_add_vid - Add a VLAN ID filter to HW offload

 * @netdev: network interface to be adjusted

 * @proto: unused protocol

 * @vid: VLAN ID to be added

 *

 * net_device_ops implementation for adding VLAN IDs

 VLAN 0 is added by default during load/reset */

 Enable VLAN pruning when a VLAN other than 0 is added */

	/* Add a switch rule for this VLAN ID so its corresponding VLAN tagged

	 * packets aren't pruned by the device's internal switch on Rx

/**

 * ice_vlan_rx_kill_vid - Remove a VLAN ID filter from HW offload

 * @netdev: network interface to be adjusted

 * @proto: unused protocol

 * @vid: VLAN ID to be removed

 *

 * net_device_ops implementation for removing VLAN IDs

 don't allow removal of VLAN 0 */

	/* Make sure ice_vsi_kill_vlan is successful before updating VLAN

	 * information

 Disable pruning when VLAN 0 is the only VLAN rule */

/**

 * ice_rep_indr_tc_block_unbind

 * @cb_priv: indirection block private data

/**

 * ice_tc_indir_block_unregister - Unregister TC indirect block notifications

 * @vsi: VSI struct which has the netdev

/**

 * ice_tc_indir_block_remove - clean indirect TC block notifications

 * @pf: PF structure

/**

 * ice_tc_indir_block_register - Register TC indirect block notifications

 * @vsi: VSI struct which has the netdev

 *

 * Returns 0 on success, negative value on failure

/**

 * ice_setup_pf_sw - Setup the HW switch on startup or after reset

 * @pf: board private structure

 *

 * Returns 0 on success, negative value on failure

 init channel list */

 netdev has to be configured before setting frame size */

 init indirect block notifications */

 Setup DCB netlink interface */

	/* registering the NAPI handler requires both the queues and

	 * netdev to be created, which are done in ice_pf_vsi_setup()

	 * and ice_cfg_netdev() respectively

/**

 * ice_get_avail_q_count - Get count of queues in use

 * @pf_qmap: bitmap to get queue use count from

 * @lock: pointer to a mutex that protects access to pf_qmap

 * @size: size of the bitmap

/**

 * ice_get_avail_txq_count - Get count of Tx queues in use

 * @pf: pointer to an ice_pf instance

/**

 * ice_get_avail_rxq_count - Get count of Rx queues in use

 * @pf: pointer to an ice_pf instance

/**

 * ice_deinit_pf - Unrolls initialziations done by ice_init_pf

 * @pf: board private structure to initialize

/**

 * ice_set_pf_caps - set PFs capability flags

 * @pf: pointer to the PF instance

		/* ctrl_vsi_idx will be set to a valid value when flow director

		 * is setup by ice_init_fdir

 force guaranteed filter pool for PF */

 force shared filter pool for PF */

/**

 * ice_init_pf - Initialize general software structures (struct ice_pf)

 * @pf: board private structure to initialize

 setup service timer and periodic service task */

/**

 * ice_ena_msix_range - Request a range of MSIX vectors from the OS

 * @pf: board private structure

 *

 * compute the number of MSIX vectors required (v_budget) and request from

 * the OS. Return the number of vectors reserved or negative on failure

 reserve for LAN miscellaneous handler */

 reserve for flow director */

 reserve for switchdev */

 total used for non-traffic vectors */

 reserve vectors for LAN traffic */

 reserve vectors for RDMA auxiliary driver */

 actually reserve the vectors */

 error if we can't get minimum vectors */

				/* Need at least 1 interrupt in addition to

				 * AEQ MSIX

				/* Support minimum RDMA and give remaining

				 * vectors to LAN MSIX

				/* Split remaining MSIX with RDMA after

				 * accounting for AEQ MSIX

/**

 * ice_dis_msix - Disable MSI-X interrupt setup in OS

 * @pf: board private structure

/**

 * ice_clear_interrupt_scheme - Undo things done by ice_init_interrupt_scheme

 * @pf: board private structure

/**

 * ice_init_interrupt_scheme - Determine proper interrupt scheme

 * @pf: board private structure to initialize

 set up vector assignment tracking */

 populate SW interrupts pool with number of OS granted IRQs. */

/**

 * ice_is_wol_supported - check if WoL is supported

 * @hw: pointer to hardware info

 *

 * Check if WoL is supported based on the HW configuration.

 * Returns true if NVM supports and enables WoL for this port, false otherwise

	/* A bit set to 1 in the NVM Software Reserved Word 2 (WoL control

	 * word) indicates WoL is not supported on the corresponding PF ID.

/**

 * ice_vsi_recfg_qs - Change the number of queues on a VSI

 * @vsi: VSI being changed

 * @new_rx: new number of Rx queues

 * @new_tx: new number of Tx queues

 *

 * Only change the number of queues if new_tx, or new_rx is non-0.

 *

 * Returns 0 on success.

 set for the next time the netdev is started */

/**

 * ice_set_safe_mode_vlan_cfg - configure PF VSI to allow all VLANs in safe mode

 * @pf: PF to configure

 *

 * No VLAN offloads/filtering are advertised in safe mode so make sure the PF

 * VSI can still Tx/Rx VLAN tagged packets.

 disable VLAN anti-spoof */

 disable VLAN pruning and keep all other settings */

 allow all VLANs on Tx and don't strip on Rx */

/**

 * ice_log_pkg_init - log result of DDP package load

 * @hw: pointer to hardware info

 * @status: status of package load

		/* The package download AdminQ command returned success because

		 * this download succeeded or ICE_ERR_AQ_NO_WORK since there is

		 * already a package loaded on the device.

 Package File version not supported */

 poll for reset to complete */

/**

 * ice_load_pkg - load/reload the DDP Package file

 * @firmware: firmware structure when firmware requested or NULL for reload

 * @pf: pointer to the PF instance

 *

 * Called on probe and post CORER/GLOBR rebuild to load DDP Package and

 * initialize HW tables.

 Load DDP Package */

 Reload package during rebuild after CORER/GLOBR reset */

 Safe Mode */

	/* Successful download package is the precondition for advanced

	 * features, hence setting the ICE_FLAG_ADV_FEATURES flag

/**

 * ice_verify_cacheline_size - verify driver's assumption of 64 Byte cache lines

 * @pf: pointer to the PF structure

 *

 * There is no error returned here because the driver should be able to handle

 * 128 Byte cache lines, so we only print a warning in case issues are seen,

 * specifically with Tx.

/**

 * ice_send_version - update firmware with driver version

 * @pf: PF struct

 *

 * Returns ICE_SUCCESS on success, else error code

/**

 * ice_init_fdir - Initialize flow director VSI and configuration

 * @pf: pointer to the PF instance

 *

 * returns 0 on success, negative on error

	/* Side Band Flow Director needs to have a control VSI.

	 * Allocate it and store it in the PF.

/**

 * ice_get_opt_fw_name - return optional firmware file name or NULL

 * @pf: pointer to the PF instance

	/* Optional firmware name same as default with additional dash

	 * followed by a EUI-64 identifier (PCIe Device Serial Number)

	/* Determine the name of the optional file using the DSN (two

	 * dwords following the start of the DSN Capability).

/**

 * ice_request_fw - Device initialization routine

 * @pf: pointer to the PF instance

	/* optional device-specific DDP (if present) overrides the default DDP

	 * package file. kernel logs a debug message if the file doesn't exist,

	 * and warning messages for other errors.

 request for firmware was successful. Download to device */

 request for firmware was successful. Download to device */

/**

 * ice_print_wake_reason - show the wake up cause in the log

 * @pf: pointer to the PF struct

 if no wake event, nothing to print */

/**

 * ice_register_netdev - register netdev and devlink port

 * @pf: pointer to the PF struct

/**

 * ice_probe - Device initialization routine

 * @pdev: PCI device information struct

 * @ent: entry in ice_pci_tbl

 *

 * Returns 0 on success, negative on failure

	/* this driver uses devres, see

	 * Documentation/driver-api/driver-model/devres.rst

 initialize Auxiliary index to invalid value */

 set up for high or low DMA */

 Disable service task until DOWN bit is cleared */

	/* if ice_request_fw fails, ICE_FLAG_ADV_FEATURES bit won't be

	 * set in pf->state, which will cause ice_is_safe_mode to return

	 * true

		/* we already got function/device capabilities but these don't

		 * reflect what the driver needs to do in safe mode. Instead of

		 * adding conditional logic everywhere to ignore these

		 * device/function capabilities, override them.

	/* In case of MSIX we are going to setup the misc vector right here

	 * to handle admin queue events etc. In case of legacy and MSI

	 * the misc functionality and queue processing is combined in

	 * the same vector and that gets setup at open.

 create switch struct for the switch element created by FW on boot */

 record the sw_id available for later use */

 tell the firmware we are up */

 since everything is good, start the service timer */

 not a fatal error if this fails */

 not a fatal error if this fails */

 if media available, initialize PHY settings */

 not a fatal error if this fails */

 Save wakeup reason register for later use */

 check for a power management event */

 clear wake status, all bits */

 Disable WoL at init, wait for user to enable */

 initialize DDP driven features */

 Note: Flow director init failure is non-fatal to load */

 Note: DCB init failure is non-fatal to load */

 print PCI link speed and width */

 ready to go, so clear down state bit */

/**

 * ice_set_wake - enable or disable Wake on LAN

 * @pf: pointer to the PF struct

 *

 * Simple helper for WoL control

 clear wake state, otherwise new wake events won't fire */

 enable / disable APM wake up, no RMW needed */

 set magic packet filter enabled */

/**

 * ice_setup_mc_magic_wake - setup device to wake on multicast magic packet

 * @pf: pointer to the PF struct

 *

 * Issue firmware command to enable multicast magic wake, making

 * sure that any locally administered address (LAA) is used for

 * wake, and that PF reset doesn't undo the LAA.

 Get current MAC address in case it's an LAA */

/**

 * ice_remove - Device removal routine

 * @pdev: PCI device information struct

	/* Issue a PFR as part of the prescribed driver unload flow.  Do not

	 * do it via ice_schedule_reset() since there is no need to rebuild

	 * and the service task is already stopped.

/**

 * ice_shutdown - PCI callback for shutting down device

 * @pdev: PCI device information struct

/**

 * ice_prepare_for_shutdown - prep for PCI shutdown

 * @pf: board private structure

 *

 * Inform or close all dependent features in prep for PCI device shutdown

 Notify VFs of impending reset */

 disable the VSIs and their queues that are not already DOWN */

/**

 * ice_reinit_interrupt_scheme - Reinitialize interrupt scheme

 * @pf: board private structure to reinitialize

 *

 * This routine reinitialize interrupt scheme that was cleared during

 * power management suspend callback.

 *

 * This should be called during resume routine to re-allocate the q_vectors

 * and reacquire interrupts.

	/* Since we clear MSIX flag during suspend, we need to

	 * set it back during resume...

 Remap vectors and rings, after successful re-init interrupts */

/**

 * ice_suspend

 * @dev: generic device information structure

 *

 * Power Management callback to quiesce the device and prepare

 * for D3 transition.

	/* Stop watchdog tasks until resume completion.

	 * Even though it is most likely that the service task is

	 * disabled if the device is suspended or down, the service task's

	 * state is controlled by a different state bit, and we should

	 * store and honor whatever state that bit is in at this point.

 Already suspended?, then there is nothing to do */

	/* Free vectors, clear the interrupt scheme and release IRQs

	 * for proper hibernation, especially with large number of CPUs.

	 * Otherwise hibernation might fail when mapping all the vectors back

	 * to CPU0.

/**

 * ice_resume - PM callback for waking up from D3

 * @dev: generic device information structure

	/* We cleared the interrupt scheme when we suspended, so we need to

	 * restore it now to resume device functionality.

 Now perform PF reset and rebuild */

 re-enable service task for reset, but allow reset to schedule it */

 Restart the service task */

 CONFIG_PM */

/**

 * ice_pci_err_detected - warning that PCI error has been detected

 * @pdev: PCI device information struct

 * @err: the type of PCI error

 *

 * Called to warn that something happened on the PCI bus and the error handling

 * is in progress.  Allows the driver to gracefully prepare/handle PCI errors.

/**

 * ice_pci_err_slot_reset - a PCI slot reset has just happened

 * @pdev: PCI device information struct

 *

 * Called to determine if the driver can recover from the PCI slot reset by

 * using a register read to determine if the device is recoverable.

 Check for life */

 non-fatal, continue */

/**

 * ice_pci_err_resume - restart operations after PCI error recovery

 * @pdev: PCI device information struct

 *

 * Called to allow the driver to bring things back up after PCI error and/or

 * reset recovery have finished

/**

 * ice_pci_err_reset_prepare - prepare device driver for PCI reset

 * @pdev: PCI device information struct

/**

 * ice_pci_err_reset_done - PCI reset done, device driver reset can begin

 * @pdev: PCI device information struct

/* ice_pci_tbl - PCI Device ID Table

 *

 * Wildcard entries (PCI_ANY_ID) should come last

 * Last entry must be all 0s

 *

 * { Vendor ID, Device ID, SubVendor ID, SubDevice ID,

 *   Class, Class Mask, private data (not used) }

 required last entry */

 CONFIG_PM */

/**

 * ice_module_init - Driver registration routine

 *

 * ice_module_init is the first routine called when the driver is

 * loaded. All it does is register with the PCI subsystem.

/**

 * ice_module_exit - Driver exit cleanup routine

 *

 * ice_module_exit is called just before the driver is removed

 * from memory.

/**

 * ice_set_mac_address - NDO callback to set MAC address

 * @netdev: network interface device structure

 * @pi: pointer to an address structure

 *

 * Returns 0 on success, negative on failure

 change the netdev's MAC address */

 Clean up old MAC filter. Not an error if old filter doesn't exist */

 Add filter for new MAC. If filter exists, return success */

		/* Although this MAC filter is already present in hardware it's

		 * possible in some cases (e.g. bonding) that dev_addr was

		 * modified outside of the driver and needs to be restored back

		 * to this value.

 error if the new filter addition failed */

 write new MAC address to the firmware */

/**

 * ice_set_rx_mode - NDO callback to set the netdev filters

 * @netdev: network interface device structure

	/* Set the flags to synchronize filters

	 * ndo_set_rx_mode may be triggered even without a change in netdev

	 * flags

	/* schedule our worker thread which will take care of

	 * applying the new filter changes

/**

 * ice_set_tx_maxrate - NDO callback to set the maximum per-queue bitrate

 * @netdev: network interface device structure

 * @queue_index: Queue ID

 * @maxrate: maximum bandwidth in Mbps

 Validate maxrate requested is within permitted range */

 Set BW back to default, when user set maxrate to 0 */

/**

 * ice_fdb_add - add an entry to the hardware database

 * @ndm: the input from the stack

 * @tb: pointer to array of nladdr (unused)

 * @dev: the net device pointer

 * @addr: the MAC address entry being added

 * @vid: VLAN ID

 * @flags: instructions from stack about fdb operation

 * @extack: netlink extended ack

 Only return duplicate errors if NLM_F_EXCL is set */

/**

 * ice_fdb_del - delete an entry from the hardware database

 * @ndm: the input from the stack

 * @tb: pointer to array of nladdr (unused)

 * @dev: the net device pointer

 * @addr: the MAC address entry being added

 * @vid: VLAN ID

/**

 * ice_set_features - set the netdev feature flags

 * @netdev: ptr to the netdev being adjusted

 * @features: the feature set that the stack is suggesting

 Don't set any netdev advanced features with device in Safe Mode */

 Do not change setting during reset */

	/* Multiple features can be changed in one call so keep features in

	 * separate if/else statements to guarantee each feature is checked

 don't turn off hw_tc_offload when ADQ is already enabled */

/**

 * ice_vsi_vlan_setup - Setup VLAN offload properties on a VSI

 * @vsi: VSI to setup VLAN properties for

/**

 * ice_vsi_cfg - Setup the VSI

 * @vsi: the VSI being configured

 *

 * Return 0 on success and negative value on error

/* THEORY OF MODERATION:

 * The ice driver hardware works differently than the hardware that DIMLIB was

 * originally made for. ice hardware doesn't have packet count limits that

 * can trigger an interrupt, but it *does* have interrupt rate limit support,

 * which is hard-coded to a limit of 250,000 ints/second.

 * If not using dynamic moderation, the INTRL value can be modified

 * by ethtool rx-usecs-high.

	/* the throttle rate for interrupts, basically worst case delay before

	 * an initial interrupt fires, value is stored in microseconds.

/* Make a different profile for Rx that doesn't allow quite so aggressive

 * moderation at the high end (it maxes out at 126us or about 8k interrupts a

 * second.

 500,000 ints/s, capped at 250K by INTRL */

 125,000 ints/s */

  62,500 ints/s */

  16,129 ints/s */

   7,936 ints/s */

/* The transmit profile, which has the same sorts of values

 * as the previous struct

 500,000 ints/s, capped at 250K by INTRL */

 125,000 ints/s */

  16,125 ints/s */

   7,812 ints/s */

   3,906 ints/s */

 look up the values in our local table */

 look up the values in our local table */

/**

 * ice_init_moderation - set up interrupt moderation

 * @q_vector: the vector containing rings to be configured

 *

 * Set up interrupt moderation registers, with the intent to do the right thing

 * when called from reset or from probe, and whether or not dynamic moderation

 * is enabled or not. Take special care to write all the registers in both

 * dynamic moderation mode or not in order to make sure hardware is in a known

 * state.

 set the initial TX ITR to match the above */

 set the initial RX ITR to match the above */

/**

 * ice_napi_enable_all - Enable NAPI for all q_vectors in the VSI

 * @vsi: the VSI being configured

/**

 * ice_up_complete - Finish the last steps of bringing up a connection

 * @vsi: The VSI being configured

 *

 * Return 0 on success and negative value on error

	/* Enable only Rx rings, Tx rings were enabled by the FW when the

	 * Tx queue group list was configured and the context bits were

	 * programmed using ice_vsi_cfg_txqs

/**

 * ice_up - Bring the connection back up after being down

 * @vsi: VSI being configured

/**

 * ice_fetch_u64_stats_per_ring - get packets and bytes stats per ring

 * @syncp: pointer to u64_stats_sync

 * @stats: stats that pkts and bytes count will be taken from

 * @pkts: packets stats counter

 * @bytes: bytes stats counter

 *

 * This function fetches stats from the ring considering the atomic operations

 * that needs to be performed to read u64 values in 32 bit machine.

/**

 * ice_update_vsi_tx_ring_stats - Update VSI Tx ring stats counters

 * @vsi: the VSI to be updated

 * @rings: rings to work on

 * @count: number of rings

/**

 * ice_update_vsi_ring_stats - Update VSI stats counters

 * @vsi: the VSI to be updated

 reset netdev stats */

 reset non-netdev (extended) stats */

 update Tx rings counters */

 update Rx rings counters */

 update XDP Tx rings counters */

/**

 * ice_update_vsi_stats - Update VSI stats counters

 * @vsi: the VSI to be updated

 get stats as recorded by Tx/Rx rings */

 get VSI stats as recorded by the hardware */

 update some more netdev stats if this is main VSI */

 record drops from the port level */

/**

 * ice_update_pf_stats - Update PF port stats counters

 * @pf: PF whose stats needs to be updated

/**

 * ice_get_stats64 - get statistics for network device structure

 * @netdev: network interface device structure

 * @stats: main device statistics structure

	/* netdev packet/byte stats come from ring counter. These are obtained

	 * by summing up ring counters (done by ice_update_vsi_ring_stats).

	 * But, only call the update routine and read the registers if VSI is

	 * not down.

	/* The rest of the stats can be read from the hardware but instead we

	 * just return values that the watchdog task has already obtained from

	 * the hardware.

/**

 * ice_napi_disable_all - Disable NAPI for all q_vectors in the VSI

 * @vsi: VSI having NAPI disabled

/**

 * ice_down - Shutdown the connection

 * @vsi: The VSI being stopped

	/* Caller of this function is expected to set the

	 * vsi->state ICE_DOWN bit

/**

 * ice_vsi_setup_tx_rings - Allocate VSI Tx queue resources

 * @vsi: VSI having resources allocated

 *

 * Return 0 on success, negative on failure

/**

 * ice_vsi_setup_rx_rings - Allocate VSI Rx queue resources

 * @vsi: VSI having resources allocated

 *

 * Return 0 on success, negative on failure

/**

 * ice_vsi_open_ctrl - open control VSI for use

 * @vsi: the VSI to open

 *

 * Initialization of the Control VSI

 *

 * Returns 0 on success, negative value on error

 allocate descriptors */

/**

 * ice_vsi_open - Called when a network interface is made active

 * @vsi: the VSI to open

 *

 * Initialization of the VSI

 *

 * Returns 0 on success, negative value on error

 allocate descriptors */

 Notify the stack of the actual queue counts. */

/**

 * ice_vsi_release_all - Delete all VSIs

 * @pf: PF from which all VSIs are being removed

/**

 * ice_vsi_rebuild_by_type - Rebuild VSI of a given type

 * @pf: pointer to the PF instance

 * @type: VSI type to rebuild

 *

 * Iterates through the pf->vsi array and rebuilds VSIs of the requested type

 rebuild the VSI */

 replay filters for the VSI */

		/* Re-map HW VSI number, using VSI handle that has been

		 * previously validated in ice_replay_vsi() call above

 enable the VSI */

/**

 * ice_update_pf_netdev_link - Update PF netdev link status

 * @pf: pointer to the PF instance

/**

 * ice_rebuild - rebuild after reset

 * @pf: PF to rebuild

 * @reset_type: type of reset

 *

 * Do not rebuild VF VSI in this flow because that is already handled via

 * ice_reset_all_vfs(). This is because requirements for resetting a VF after a

 * PFR/CORER/GLOBER/etc. are different than the normal flow. Also, we don't want

 * to reset/rebuild all the VF VSI twice.

 if DDP was previously loaded successfully */

 reload the SW DB of filter tables */

 Reload DDP Package after CORER/GLOBR reset */

 clear the default VSI configuration if it exists */

 start misc vector */

 force guaranteed filter pool for PF */

 force shared filter pool for PF */

	/* If the PF previously had enabled PTP, PTP init needs to happen before

	 * the VSI rebuild. If not, this causes the PTP link status events to

	 * fail.

 rebuild PF VSI */

 If Flow Director is active */

 replay HW Flow Director recipes */

 replay Flow Director filters */

 tell the firmware we are up */

 if we get here, reset flow is successful */

 set this bit in PF state to control service task scheduling */

/**

 * ice_max_xdp_frame_size - returns the maximum allowed frame size for XDP

 * @vsi: Pointer to VSI structure

/**

 * ice_change_mtu - NDO callback to change the MTU

 * @netdev: network interface device structure

 * @new_mtu: new value for maximum frame size

 *

 * Returns 0 on success, negative on failure

 if a reset is in progress, wait for some time for it to complete */

 if VSI is up, bring it down and then back up */

/**

 * ice_eth_ioctl - Access the hwtstamp interface

 * @netdev: network interface device structure

 * @ifr: interface request data

 * @cmd: ioctl command

/**

 * ice_aq_str - convert AQ err code to a string

 * @aq_err: the AQ error code to convert

/**

 * ice_stat_str - convert status err code to a string

 * @stat_err: the status error code to convert

/**

 * ice_set_rss_lut - Set RSS LUT

 * @vsi: Pointer to VSI structure

 * @lut: Lookup table

 * @lut_size: Lookup table size

 *

 * Returns 0 on success, negative on failure

/**

 * ice_set_rss_key - Set RSS key

 * @vsi: Pointer to the VSI structure

 * @seed: RSS hash seed

 *

 * Returns 0 on success, negative on failure

/**

 * ice_get_rss_lut - Get RSS LUT

 * @vsi: Pointer to VSI structure

 * @lut: Buffer to store the lookup table entries

 * @lut_size: Size of buffer to store the lookup table entries

 *

 * Returns 0 on success, negative on failure

/**

 * ice_get_rss_key - Get RSS key

 * @vsi: Pointer to VSI structure

 * @seed: Buffer to store the key in

 *

 * Returns 0 on success, negative on failure

/**

 * ice_bridge_getlink - Get the hardware bridge mode

 * @skb: skb buff

 * @pid: process ID

 * @seq: RTNL message seq

 * @dev: the netdev being configured

 * @filter_mask: filter mask passed in

 * @nlflags: netlink flags passed in

 *

 * Return the bridge mode (VEB/VEPA)

/**

 * ice_vsi_update_bridge_mode - Update VSI for switching bridge mode (VEB/VEPA)

 * @vsi: Pointer to VSI structure

 * @bmode: Hardware bridge mode (VEB/VEPA)

 *

 * Returns 0 on success, negative on failure

 change from VEPA to VEB mode */

 change from VEB to VEPA mode */

 Update sw flags for book keeping */

/**

 * ice_bridge_setlink - Set the hardware bridge mode

 * @dev: the netdev being configured

 * @nlh: RTNL message

 * @flags: bridge setlink flags

 * @extack: netlink extended ack

 *

 * Sets the bridge mode (VEB/VEPA) of the switch to which the netdev (VSI) is

 * hooked up to. Iterates through the PF VSI list and sets the loopback mode (if

 * not already set for all VSIs connected to this switch. And also update the

 * unicast switch filter rules for the corresponding switch of the netdev.

 find the attribute in the netlink message */

 Continue  if bridge mode is not being flipped */

		/* Iterates through the PF VSI list and update the loopback

		 * mode of the VSI

		/* Update the unicast switch filter rules for the corresponding

		 * switch of the netdev

 revert hw->evb_veb */

/**

 * ice_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: Tx queue

	/* Check if PFC is enabled for the TC to which the queue belongs

	 * to. If yes then Tx timeout is not caused by a hung queue, no

	 * need to reset and rebuild

 now that we have an index, find the tx_ring struct */

	/* Reset recovery level if enough time has elapsed after last timeout.

	 * Also ensure no new reset action happens before next timeout period.

 Read interrupt register */

/**

 * ice_setup_tc_cls_flower - flower classifier offloads

 * @np: net device to configure

 * @filter_dev: device on which filter is added

 * @cls_flower: offload data

/**

 * ice_setup_tc_block_cb - callback handler registered for TC block

 * @type: TC SETUP type

 * @type_data: TC flower offload data that contains user input

 * @cb_priv: netdev private data

/**

 * ice_validate_mqprio_qopt - Validate TCF input parameters

 * @vsi: Pointer to VSI

 * @mqprio_qopt: input parameters for mqprio queue configuration

 *

 * This function validates MQPRIO params, such as qcount (power of 2 wherever

 * needed), and make sure user doesn't specify qcount and BW rate limit

 * for TCs, which are more than "num_tc"

		/* TC command takes input in K/N/Gbps or K/M/Gbit etc but

		 * converts the bandwidth rate limit into Bytes/s when

		 * passing it down to the driver. So convert input bandwidth

		 * from Bytes/s to Kbps

 min_rate is minimum guaranteed rate and it can't be zero */

		/* min_rate can't be more than max_rate, except when max_rate

		 * is zero (implies max_rate sought is max line rate). In such

		 * a case min_rate can be more than max.

 make sure vsi->ch_rss_size is set correctly based on TC's qcount */

/**

 * ice_add_channel - add a channel by adding VSI

 * @pf: ptr to PF device

 * @sw_id: underlying HW switching element ID

 * @ch: ptr to channel structure

 *

 * Add a channel (VSI) using add_vsi and queue_map

 set the back pointer of channel for newly created VSI */

/**

 * ice_chnl_cfg_res

 * @vsi: the VSI being setup

 * @ch: ptr to channel structure

 *

 * Configure channel specific resources such as rings, vector.

 setup ring being channel enabled */

 following code block sets up vector specific attributes */

 setup Tx and Rx ITR setting if DIM is off */

 setup Tx and Rx ITR setting if DIM is off */

	/* it is safe to assume that, if channel has non-zero num_t[r]xq, then

	 * GLINT_ITR register would have written to perform in-context

	 * update, hence perform flush

/**

 * ice_cfg_chnl_all_res - configure channel resources

 * @vsi: pte to main_vsi

 * @ch: ptr to channel structure

 *

 * This function configures channel specific resources such as flow-director

 * counter index, and other resources such as queues, vectors, ITR settings

	/* configure channel (aka ADQ) resources such as queues, vectors,

	 * ITR settings for channel specific vectors and anything else

/**

 * ice_setup_hw_channel - setup new channel

 * @pf: ptr to PF device

 * @vsi: the VSI being setup

 * @ch: ptr to channel structure

 * @sw_id: underlying HW switching element ID

 * @type: type of channel to be created (VMDq2/VF)

 *

 * Setup new channel (VSI) based on specified type (VMDq2/VF)

 * and configures Tx rings accordingly

 configure/setup ADQ specific resources */

	/* make sure to update the next_base_q so that subsequent channel's

	 * (aka ADQ) VSI queue map is correct

/**

 * ice_setup_channel - setup new channel using uplink element

 * @pf: ptr to PF device

 * @vsi: the VSI being setup

 * @ch: ptr to channel structure

 *

 * Setup new channel (VSI) based on specified type (VMDq2/VF)

 * and uplink switching element

 create channel (VSI) */

/**

 * ice_set_bw_limit - setup BW limit for Tx traffic based on max_tx_rate

 * @vsi: VSI to be configured

 * @max_tx_rate: max Tx rate in Kbps to be configured as maximum BW limit

 * @min_tx_rate: min Tx rate in Kbps to be configured as minimum BW limit

/**

 * ice_create_q_channel - function to create channel

 * @vsi: VSI to be configured

 * @ch: ptr to channel (it contains channel specific params)

 *

 * This function creates channel (VSI) using num_queues specified by user,

 * reconfigs RSS if needed.

 configure BW rate limit */

/**

 * ice_rem_all_chnl_fltrs - removes all channel filters

 * @pf: ptr to PF, TC-flower based filter are tracked at PF level

 *

 * Remove all advanced switch filters only if they are channel specific

 * tc-flower based filter

 to remove all channel filters, iterate an ordered list of filters */

 for now process only channel specific filters */

 update advanced switch filter count */

/**

 * ice_remove_q_channels - Remove queue channels for the TCs

 * @vsi: VSI to be configured

 * @rem_fltr: delete advanced switch filter or not

 *

 * Remove queue channels for the TCs

 remove all tc-flower based filter if they are channel filters only */

 perform cleanup for channels if they exist */

 Reset queue contexts */

 clear the VSI from scheduler tree */

 Delete VSI from FW */

 Delete VSI from PF and HW VSI arrays */

 free the channel */

 clear the channel VSI map which is stored in main VSI */

 reset main VSI's all TC information */

/**

 * ice_rebuild_channels - rebuild channel

 * @pf: ptr to PF

 *

 * Recreate channel VSIs and replay filters

 nothing to be done */

	/* reconfigure main VSI based on old value of TC and cached values

	 * for MQPRIO opts

 rebuild ADQ VSIs */

 rebuild ADQ VSI */

		/* Re-map HW VSI number, using VSI handle that has been

		 * previously validated in ice_replay_vsi() call above

 replay filters for the VSI */

		/* store ADQ VSI at correct TC index in main VSI's

		 * map of TC to VSI

	/* ADQ VSI(s) has been rebuilt successfully, so setup

	 * channel for main VSI's Tx and Rx rings

 reconfig channel resources */

 replay BW rate limit if it is non-zero */

 reconfig RSS for main VSI */

/**

 * ice_create_q_channels - Add queue channel for the given TCs

 * @vsi: VSI to be configured

 *

 * Configures queue channel mapping to the given TCs

 convert to Kbits/s */

/**

 * ice_setup_tc_mqprio_qdisc - configure multiple traffic classes

 * @netdev: net device to configure

 * @type_data: TC offload data

 Generate queue region map for number of TCF requested */

		/* don't assume state of hw_tc_offload during driver load

		 * and set the flag for TC flower filter if hw_tc_offload

		 * already ON

 Requesting same TCF configuration as already enabled */

 Pause VSI queues */

 logic to rebuild VSI, same like ethtool -L */

		/* store away original rss_size info, so that it gets reused

		 * form ice_vsi_rebuild during tc-qdisc delete stage - to

		 * determine, what should be the rss_sizefor main VSI

	/* save current values of Tx and Rx queues before calling VSI rebuild

	 * for fallback option

 proceed with rebuild main VSI using correct number of queues */

 fallback to current number of queues */

 set TC0 rate limit if specified */

 convert to Kbits/s */

 if error, reset the all_numtc and all_enatc */

 resume VSI */

 setup traffic classifier for receive side */

/**

 * ice_open - Called when a network interface becomes active

 * @netdev: network interface device structure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP). At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the netdev watchdog is enabled,

 * and the stack is notified that the interface is ready.

 *

 * Returns 0 on success, negative value on failure

/**

 * ice_open_internal - Called when a network interface becomes active

 * @netdev: network interface device structure

 *

 * Internal ice_open implementation. Should not be used directly except for ice_open and reset

 * handling routine

 *

 * Returns 0 on success, negative value on failure

 Set PHY if there is media, otherwise, turn off PHY */

 Update existing tunnels information */

/**

 * ice_stop - Disables a network interface

 * @netdev: network interface device structure

 *

 * The stop entry point is called when an interface is de-activated by the OS,

 * and the netdevice enters the DOWN state. The hardware is still under the

 * driver's control, but the netdev interface is disabled.

 *

 * Returns success only - not allowed to fail

/**

 * ice_features_check - Validate encapsulated packet conforms to limits

 * @skb: skb buffer

 * @netdev: This port's netdev

 * @features: Offload features that the stack believes apply

	/* No point in doing any of this if neither checksum nor GSO are

	 * being requested for this frame. We can rule out both by just

	 * checking for CHECKSUM_PARTIAL

	/* We cannot support GSO if the MSS is going to be less than

	 * 64 bytes. If it is then we need to drop support for GSO.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019, Intel Corporation. */

/* To support tunneling entries by PF, the package will append the PF number to

 * the label; for example TNL_VXLAN_PF0, TNL_VXLAN_PF1, TNL_VXLAN_PF2, etc.

 SWITCH */

 ACL */

 FD */

 RSS */

 PE */

/**

 * ice_sect_id - returns section ID

 * @blk: block type

 * @sect: section type

 *

 * This helper function returns the proper section ID given a block type and a

 * section type.

/**

 * ice_pkg_val_buf

 * @buf: pointer to the ice buffer

 *

 * This helper function validates a buffer's header.

 verify data */

/**

 * ice_find_buf_table

 * @ice_seg: pointer to the ice segment

 *

 * Returns the address of the buffer table within the ice segment.

/**

 * ice_pkg_enum_buf

 * @ice_seg: pointer to the ice segment (or NULL on subsequent calls)

 * @state: pointer to the enum state

 *

 * This function will enumerate all the buffers in the ice segment. The first

 * call is made with the ice_seg parameter non-NULL; on subsequent calls,

 * ice_seg is set to NULL which continues the enumeration. When the function

 * returns a NULL pointer, then the end of the buffers has been reached, or an

 * unexpected value has been detected (for example an invalid section count or

 * an invalid buffer end value).

/**

 * ice_pkg_advance_sect

 * @ice_seg: pointer to the ice segment (or NULL on subsequent calls)

 * @state: pointer to the enum state

 *

 * This helper function will advance the section within the ice segment,

 * also advancing the buffer if needed.

 start of new buffer, reset section index */

/**

 * ice_pkg_enum_section

 * @ice_seg: pointer to the ice segment (or NULL on subsequent calls)

 * @state: pointer to the enum state

 * @sect_type: section type to enumerate

 *

 * This function will enumerate all the sections of a particular type in the

 * ice segment. The first call is made with the ice_seg parameter non-NULL;

 * on subsequent calls, ice_seg is set to NULL which continues the enumeration.

 * When the function returns a NULL pointer, then the end of the matching

 * sections has been reached.

 scan for next matching section */

 validate section */

 make sure the section fits in the buffer */

 calc pointer to this section */

/**

 * ice_pkg_enum_entry

 * @ice_seg: pointer to the ice segment (or NULL on subsequent calls)

 * @state: pointer to the enum state

 * @sect_type: section type to enumerate

 * @offset: pointer to variable that receives the offset in the table (optional)

 * @handler: function that handles access to the entries into the section type

 *

 * This function will enumerate all the entries in particular section type in

 * the ice segment. The first call is made with the ice_seg parameter non-NULL;

 * on subsequent calls, ice_seg is set to NULL which continues the enumeration.

 * When the function returns a NULL pointer, then the end of the entries has

 * been reached.

 *

 * Since each section may have a different header and entry size, the handler

 * function is needed to determine the number and location entries in each

 * section.

 *

 * The offset parameter is optional, but should be used for sections that

 * contain an offset for each section table. For such cases, the section handler

 * function must return the appropriate offset + index to give the absolution

 * offset for each entry. For example, if the base for a section's header

 * indicates a base offset of 10, and the index for the entry is 2, then

 * section handler function should set the offset to 10 + 2 = 12.

 get entry */

 end of a section, look for another section of this type */

/**

 * ice_boost_tcam_handler

 * @sect_type: section type

 * @section: pointer to section

 * @index: index of the boost TCAM entry to be returned

 * @offset: pointer to receive absolute offset, always 0 for boost TCAM sections

 *

 * This is a callback function that can be passed to ice_pkg_enum_entry.

 * Handles enumeration of individual boost TCAM entries.

 cppcheck-suppress nullPointer */

/**

 * ice_find_boost_entry

 * @ice_seg: pointer to the ice segment (non-NULL)

 * @addr: Boost TCAM address of entry to search for

 * @entry: returns pointer to the entry

 *

 * Finds a particular Boost TCAM entry and returns a pointer to that entry

 * if it is found. The ice_seg parameter must not be NULL since the first call

 * to ice_pkg_enum_entry requires a pointer to an actual ice_segment structure.

/**

 * ice_label_enum_handler

 * @sect_type: section type

 * @section: pointer to section

 * @index: index of the label entry to be returned

 * @offset: pointer to receive absolute offset, always zero for label sections

 *

 * This is a callback function that can be passed to ice_pkg_enum_entry.

 * Handles enumeration of individual label entries.

 cppcheck-suppress nullPointer */

/**

 * ice_enum_labels

 * @ice_seg: pointer to the ice segment (NULL on subsequent calls)

 * @type: the section type that will contain the label (0 on subsequent calls)

 * @state: ice_pkg_enum structure that will hold the state of the enumeration

 * @value: pointer to a value that will return the label's value if found

 *

 * Enumerates a list of labels in the package. The caller will call

 * ice_enum_labels(ice_seg, type, ...) to start the enumeration, then call

 * ice_enum_labels(NULL, 0, ...) to continue. When the function returns a NULL

 * the end of the list has been reached.

 Check for valid label section on first call */

/**

 * ice_init_pkg_hints

 * @hw: pointer to the HW structure

 * @ice_seg: pointer to the segment of the package scan (non-NULL)

 *

 * This function will scan the package and save off relevant information

 * (hints or metadata) for driver use. The ice_seg parameter must not be NULL

 * since the first call to ice_enum_labels requires a pointer to an actual

 * ice_seg structure.

 Look for matching label start, before continuing */

			/* Make sure this label matches our PF. Note that the PF

			 * character ('0' - '7') will be located where our

			 * prefix string's null terminator is located.

 Cache the appropriate boost TCAM entry pointers */

 Key creation */

 don't care */

 never match */

 match 0 */

 match 1 */

/**

 * ice_gen_key_word - generate 16-bits of a key/mask word

 * @val: the value

 * @valid: valid bits mask (change only the valid bits)

 * @dont_care: don't care mask

 * @nvr_mtch: never match mask

 * @key: pointer to an array of where the resulting key portion

 * @key_inv: pointer to an array of where the resulting key invert portion

 *

 * This function generates 16-bits from a 8-bit value, an 8-bit don't care mask

 * and an 8-bit never match mask. The 16-bits of output are divided into 8 bits

 * of key and 8 bits of key invert.

 *

 *     '0' =    b01, always match a 0 bit

 *     '1' =    b10, always match a 1 bit

 *     '?' =    b11, don't care bit (always matches)

 *     '~' =    b00, never match bit

 *

 * Input:

 *          val:         b0  1  0  1  0  1

 *          dont_care:   b0  0  1  1  0  0

 *          never_mtch:  b0  0  0  0  1  1

 *          ------------------------------

 * Result:  key:        b01 10 11 11 00 00

 'dont_care' and 'nvr_mtch' masks cannot overlap */

 encode the 8 bits into 8-bit key and 8-bit key invert */

 change only valid bits */

 don't care bit */

 never match bit */

 exact 1 match */

 exact 0 match */

/**

 * ice_bits_max_set - determine if the number of bits set is within a maximum

 * @mask: pointer to the byte array which is the mask

 * @size: the number of bytes in the mask

 * @max: the max number of set bits

 *

 * This function determines if there are at most 'max' number of bits set in an

 * array. Returns true if the number for bits set is <= max or will return false

 * otherwise.

 check each byte */

 if 0, go to next byte */

		/* We know there is at least one set bit in this byte because of

		 * the above check; if we already have found 'max' number of

		 * bits set, then we can return failure now.

 count the bits in this byte, checking threshold */

/**

 * ice_set_key - generate a variable sized key with multiples of 16-bits

 * @key: pointer to where the key will be stored

 * @size: the size of the complete key in bytes (must be even)

 * @val: array of 8-bit values that makes up the value portion of the key

 * @upd: array of 8-bit masks that determine what key portion to update

 * @dc: array of 8-bit masks that make up the don't care mask

 * @nm: array of 8-bit masks that make up the never match mask

 * @off: the offset of the first byte in the key to update

 * @len: the number of bytes in the key update

 *

 * This function generates a key from a value, a don't care mask and a never

 * match mask.

 * upd, dc, and nm are optional parameters, and can be NULL:

 *	upd == NULL --> upd mask is all 1's (update all bits)

 *	dc == NULL --> dc mask is all 0's (no don't care bits)

 *	nm == NULL --> nm mask is all 0's (no never match bits)

 size must be a multiple of 2 bytes. */

	/* Make sure at most one bit is set in the never match mask. Having more

	 * than one never match mask bit set will cause HW to consume excessive

	 * power otherwise; this is a power management efficiency check.

/**

 * ice_acquire_global_cfg_lock

 * @hw: pointer to the HW structure

 * @access: access type (read or write)

 *

 * This function will request ownership of the global config lock for reading

 * or writing of the package. When attempting to obtain write access, the

 * caller must check for the following two return values:

 *

 * ICE_SUCCESS        - Means the caller has acquired the global config lock

 *                      and can perform writing of the package.

 * ICE_ERR_AQ_NO_WORK - Indicates another driver has already written the

 *                      package or has found that no update was necessary; in

 *                      this case, the caller can just skip performing any

 *                      update of the package.

/**

 * ice_release_global_cfg_lock

 * @hw: pointer to the HW structure

 *

 * This function will release the global config lock.

/**

 * ice_acquire_change_lock

 * @hw: pointer to the HW structure

 * @access: access type (read or write)

 *

 * This function will request ownership of the change lock.

/**

 * ice_release_change_lock

 * @hw: pointer to the HW structure

 *

 * This function will release the change lock using the proper Admin Command.

/**

 * ice_aq_download_pkg

 * @hw: pointer to the hardware structure

 * @pkg_buf: the package buffer to transfer

 * @buf_size: the size of the package buffer

 * @last_buf: last buffer indicator

 * @error_offset: returns error offset

 * @error_info: returns error information

 * @cd: pointer to command details structure or NULL

 *

 * Download Package (0x0C40)

 Read error from buffer only when the FW returned an error */

/**

 * ice_aq_update_pkg

 * @hw: pointer to the hardware structure

 * @pkg_buf: the package cmd buffer

 * @buf_size: the size of the package cmd buffer

 * @last_buf: last buffer indicator

 * @error_offset: returns error offset

 * @error_info: returns error information

 * @cd: pointer to command details structure or NULL

 *

 * Update Package (0x0C42)

 Read error from buffer only when the FW returned an error */

/**

 * ice_find_seg_in_pkg

 * @hw: pointer to the hardware structure

 * @seg_type: the segment type to search for (i.e., SEGMENT_TYPE_CPK)

 * @pkg_hdr: pointer to the package header to be searched

 *

 * This function searches a package file for a particular segment type. On

 * success it returns a pointer to the segment header, otherwise it will

 * return NULL.

 Search all package segments for the requested segment type */

/**

 * ice_update_pkg

 * @hw: pointer to the hardware structure

 * @bufs: pointer to an array of buffers

 * @count: the number of buffers in the array

 *

 * Obtains change lock and updates package.

/**

 * ice_dwnld_cfg_bufs

 * @hw: pointer to the hardware structure

 * @bufs: pointer to an array of buffers

 * @count: the number of buffers in the array

 *

 * Obtains global config lock and downloads the package configuration buffers

 * to the firmware. Metadata buffers are skipped, and the first metadata buffer

 * found indicates that the rest of the buffers are all metadata buffers.

	/* If the first buffer's first section has its metadata bit set

	 * then there are no buffers to be downloaded, and the operation is

	 * considered a success.

	/* reset pkg_dwnld_status in case this function is called in the

	 * reset/rebuild flow

 check next buffer for metadata flag */

			/* A set metadata flag in the next buffer will signal

			 * that the current buffer will be the last buffer

			 * downloaded

 Save AQ status from download package */

/**

 * ice_aq_get_pkg_info_list

 * @hw: pointer to the hardware structure

 * @pkg_info: the buffer which will receive the information list

 * @buf_size: the size of the pkg_info information buffer

 * @cd: pointer to command details structure or NULL

 *

 * Get Package Info List (0x0C43)

/**

 * ice_download_pkg

 * @hw: pointer to the hardware structure

 * @ice_seg: pointer to the segment of the package to be downloaded

 *

 * Handles the download of a complete package.

/**

 * ice_init_pkg_info

 * @hw: pointer to the hardware structure

 * @pkg_hdr: pointer to the driver's package hdr

 *

 * Saves off the package details into the HW structure.

 Get package information from the Metadata Section */

/**

 * ice_get_pkg_info

 * @hw: pointer to the hardware structure

 *

 * Store details of the package currently loaded in HW into the HW structure.

/**

 * ice_verify_pkg - verify package

 * @pkg: pointer to the package buffer

 * @len: size of the package buffer

 *

 * Verifies various attributes of the package file, including length, format

 * version, and the requirement of at least one segment.

 pkg must have at least one segment */

 make sure segment array fits in package length */

 all segments must fit within length */

 segment header must fit */

 segment body must fit */

/**

 * ice_free_seg - free package segment pointer

 * @hw: pointer to the hardware structure

 *

 * Frees the package segment pointer in the proper manner, depending on if the

 * segment was allocated or just the passed in pointer was stored.

/**

 * ice_init_pkg_regs - initialize additional package registers

 * @hw: pointer to the hardware structure

 setup Switch block input mask, which is 48-bits in two parts */

/**

 * ice_chk_pkg_version - check package version for compatibility with driver

 * @pkg_ver: pointer to a version structure to check

 *

 * Check to make sure that the package about to be downloaded is compatible with

 * the driver. To be compatible, the major and minor components of the package

 * version must match our ICE_PKG_SUPP_VER_MAJ and ICE_PKG_SUPP_VER_MNR

 * definitions.

/**

 * ice_chk_pkg_compat

 * @hw: pointer to the hardware structure

 * @ospkg: pointer to the package hdr

 * @seg: pointer to the package segment hdr

 *

 * This function checks the package version compatibility with driver and NVM

 Check package version compatibility */

 find ICE segment in given package */

 Check if FW is compatible with the OS package */

 loop till we find the NVM package */

 done processing NVM package so break */

/**

 * ice_sw_fv_handler

 * @sect_type: section type

 * @section: pointer to section

 * @index: index of the field vector entry to be returned

 * @offset: ptr to variable that receives the offset in the field vector table

 *

 * This is a callback function that can be passed to ice_pkg_enum_entry.

 * This function treats the given section as of type ice_sw_fv_section and

 * enumerates offset field. "offset" is an index into the field vector table.

		/* "index" passed in to this function is relative to a given

		 * 4k block. To get to the true index into the field vector

		 * table need to add the relative index to the base_offset

		 * field of this section

/**

 * ice_get_prof_index_max - get the max profile index for used profile

 * @hw: pointer to the HW struct

 *

 * Calling this function will get the max profile index for used profile

 * and store the index number in struct ice_switch_info *switch_info

 * in HW for following use.

		/* in the profile that not be used, the prot_id is set to 0xff

		 * and the off is set to 0x1ff for all the field vectors.

/**

 * ice_init_pkg - initialize/download package

 * @hw: pointer to the hardware structure

 * @buf: pointer to the package buffer

 * @len: size of the package buffer

 *

 * This function initializes a package. The package contains HW tables

 * required to do packet processing. First, the function extracts package

 * information such as version. Then it finds the ice configuration segment

 * within the package; this function then saves a copy of the segment pointer

 * within the supplied package buffer. Next, the function will cache any hints

 * from the package, followed by downloading the package itself. Note, that if

 * a previous PF driver has already downloaded the package successfully, then

 * the current driver will not have to download the package again.

 *

 * The local package contents will be used to query default behavior and to

 * update specific sections of the HW's version of the package (e.g. to update

 * the parse graph to understand new protocols).

 *

 * This function stores a pointer to the package buffer memory, and it is

 * expected that the supplied buffer will not be freed immediately. If the

 * package buffer needs to be freed, such as when read from a file, use

 * ice_copy_and_init_pkg() instead of directly calling ice_init_pkg() in this

 * case.

 initialize package info */

	/* before downloading the package, check package version for

	 * compatibility with driver

 initialize package hints and then download package */

	/* Get information on the package currently loaded in HW, then make sure

	 * the driver is compatible with this version.

		/* on successful package download update other required

		 * registers to support the package and fill HW tables

		 * with package content.

/**

 * ice_copy_and_init_pkg - initialize/download a copy of the package

 * @hw: pointer to the hardware structure

 * @buf: pointer to the package buffer

 * @len: size of the package buffer

 *

 * This function copies the package buffer, and then calls ice_init_pkg() to

 * initialize the copied package contents.

 *

 * The copying is necessary if the package buffer supplied is constant, or if

 * the memory may disappear shortly after calling this function.

 *

 * If the package buffer resides in the data segment and can be modified, the

 * caller is free to use ice_init_pkg() instead of ice_copy_and_init_pkg().

 *

 * However, if the package buffer needs to be copied first, such as when being

 * read from a file, the caller should use ice_copy_and_init_pkg().

 *

 * This function will first copy the package buffer, before calling

 * ice_init_pkg(). The caller is free to immediately destroy the original

 * package buffer, as the new copy will be managed by this function and

 * related routines.

 Free the copy, since we failed to initialize the package */

 Track the copied pkg so we can free it later */

/**

 * ice_pkg_buf_alloc

 * @hw: pointer to the HW structure

 *

 * Allocates a package buffer and returns a pointer to the buffer header.

 * Note: all package contents must be in Little Endian form.

/**

 * ice_get_sw_prof_type - determine switch profile type

 * @hw: pointer to the HW structure

 * @fv: pointer to the switch field vector

 UDP tunnel will have UDP_OF protocol ID and VNI offset */

 GRE tunnel will have GRE protocol */

/**

 * ice_get_sw_fv_bitmap - Get switch field vector bitmap based on profile type

 * @hw: pointer to hardware structure

 * @req_profs: type of profiles requested

 * @bm: pointer to memory for returning the bitmap of field vectors

 Determine field vector type */

/**

 * ice_get_sw_fv_list

 * @hw: pointer to the HW structure

 * @prot_ids: field vector to search for with a given protocol ID

 * @ids_cnt: lookup/protocol count

 * @bm: bitmap of field vectors to consider

 * @fv_list: Head of a list

 *

 * Finds all the field vector entries from switch block that contain

 * a given protocol ID and returns a list of structures of type

 * "ice_sw_fv_list_entry". Every structure in the list has a field vector

 * definition and profile ID information

 * NOTE: The caller of the function is responsible for freeing the memory

 * allocated for every list entry.

		/* If field vector is not in the bitmap list, then skip this

		 * profile.

			/* This code assumes that if a switch field vector line

			 * has a matching protocol, then this line will contain

			 * the entries necessary to represent every field in

			 * that protocol header.

/**

 * ice_init_prof_result_bm - Initialize the profile result index bitmap

 * @hw: pointer to hardware structure

		/* Determine empty field vector indices, these can be

		 * used for recipe results. Skip index 0, since it is

		 * always used for Switch ID.

/**

 * ice_pkg_buf_free

 * @hw: pointer to the HW structure

 * @bld: pointer to pkg build (allocated by ice_pkg_buf_alloc())

 *

 * Frees a package buffer

/**

 * ice_pkg_buf_reserve_section

 * @bld: pointer to pkg build (allocated by ice_pkg_buf_alloc())

 * @count: the number of sections to reserve

 *

 * Reserves one or more section table entries in a package buffer. This routine

 * can be called multiple times as long as they are made before calling

 * ice_pkg_buf_alloc_section(). Once ice_pkg_buf_alloc_section()

 * is called once, the number of sections that can be allocated will not be able

 * to be increased; not using all reserved sections is fine, but this will

 * result in some wasted space in the buffer.

 * Note: all package contents must be in Little Endian form.

 already an active section, can't increase table size */

/**

 * ice_pkg_buf_alloc_section

 * @bld: pointer to pkg build (allocated by ice_pkg_buf_alloc())

 * @type: the section type value

 * @size: the size of the section to reserve (in bytes)

 *

 * Reserves memory in the buffer for a section's content and updates the

 * buffers' status accordingly. This routine returns a pointer to the first

 * byte of the section start within the buffer, which is used to fill in the

 * section contents.

 * Note: all package contents must be in Little Endian form.

 check for enough space left in buffer */

 section start must align on 4 byte boundary */

 check for more available section table entries */

 no free section table entries */

/**

 * ice_pkg_buf_get_active_sections

 * @bld: pointer to pkg build (allocated by ice_pkg_buf_alloc())

 *

 * Returns the number of active sections. Before using the package buffer

 * in an update package command, the caller should make sure that there is at

 * least one active section - otherwise, the buffer is not legal and should

 * not be used.

 * Note: all package contents must be in Little Endian form.

/**

 * ice_pkg_buf

 * @bld: pointer to pkg build (allocated by ice_pkg_buf_alloc())

 *

 * Return a pointer to the buffer's header

/**

 * ice_get_open_tunnel_port - retrieve an open tunnel port

 * @hw: pointer to the HW structure

 * @port: returns open port

/**

 * ice_tunnel_idx_to_entry - convert linear index to the sparse one

 * @hw: pointer to the HW structure

 * @type: type of tunnel

 * @idx: linear index

 *

 * Stack assumes we have 2 linear tables with indexes [0, count_valid),

 * but really the port table may be sprase, and types are mixed, so convert

 * the stack index into the device index.

/**

 * ice_create_tunnel

 * @hw: pointer to the HW structure

 * @index: device table entry

 * @type: type of tunnel

 * @port: port of tunnel to create

 *

 * Create a tunnel by updating the parse graph in the parser. We do that by

 * creating a package buffer with the tunnel info and issuing an update package

 * command.

 allocate 2 sections, one for Rx parser, one for Tx parser */

 copy original boost entry to update package buffer */

	/* over-write the never-match dest port key bits with the encoded port

	 * bits

 exact copy of entry to Tx section entry */

/**

 * ice_destroy_tunnel

 * @hw: pointer to the HW structure

 * @index: device table entry

 * @type: type of tunnel

 * @port: port of tunnel to destroy (ignored if the all parameter is true)

 *

 * Destroys a tunnel or all tunnels by creating an update package buffer

 * targeting the specific updates requested and then performing an update

 * package.

 allocate 2 sections, one for Rx parser, one for Tx parser */

	/* copy original boost entry to update package buffer, one copy to Rx

	 * section, another copy to the Tx section

/**

 * ice_find_prot_off - find prot ID and offset pair, based on prof and FV index

 * @hw: pointer to the hardware structure

 * @blk: hardware block

 * @prof: profile ID

 * @fv_idx: field vector word index

 * @prot: variable to receive the protocol ID

 * @off: variable to receive the protocol offset

 PTG Management */

/**

 * ice_ptg_find_ptype - Search for packet type group using packet type (ptype)

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @ptype: the ptype to search for

 * @ptg: pointer to variable that receives the PTG

 *

 * This function will search the PTGs for a particular ptype, returning the

 * PTG ID that contains it through the PTG parameter, with the value of

 * ICE_DEFAULT_PTG (0) meaning it is part the default PTG.

/**

 * ice_ptg_alloc_val - Allocates a new packet type group ID by value

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @ptg: the PTG to allocate

 *

 * This function allocates a given packet type group ID specified by the PTG

 * parameter.

/**

 * ice_ptg_remove_ptype - Removes ptype from a particular packet type group

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @ptype: the ptype to remove

 * @ptg: the PTG to remove the ptype from

 *

 * This function will remove the ptype from the specific PTG, and move it to

 * the default PTG (ICE_DEFAULT_PTG).

 Should not happen if .in_use is set, bad config */

 find the ptype within this PTG, and bypass the link over it */

/**

 * ice_ptg_add_mv_ptype - Adds/moves ptype to a particular packet type group

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @ptype: the ptype to add or move

 * @ptg: the PTG to add or move the ptype to

 *

 * This function will either add or move a ptype to a particular PTG depending

 * on if the ptype is already part of another group. Note that using a

 * a destination PTG ID of ICE_DEFAULT_PTG (0) will move the ptype to the

 * default PTG.

 Is ptype already in the correct PTG? */

 Remove from original PTG and move back to the default PTG */

 Moving to default PTG? Then we're done with this request */

 Add ptype to PTG at beginning of list */

 Block / table size info */

 # XLT1 entries */

 # XLT2 entries */

 # profile ID TCAM entries */

 # profile IDs */

 # CDID one-hot bits used in key */

 # profile redirection entries */

 # extraction sequence entries */

 # field vector words */

 overwrite existing entries allowed */

 reverse FV order */

	/**

	 * Table Definitions

	 * XLT1 - Number of entries in XLT1 table

	 * XLT2 - Number of entries in XLT2 table

	 * TCAM - Number of entries Profile ID TCAM table

	 * CDID - Control Domain ID of the hardware block

	 * PRED - Number of entries in the Profile Redirection Table

	 * FV   - Number of entries in the Field Vector

	 * FVW  - Width (in WORDs) of the Field Vector

	 * OVR  - Overwrite existing table entries

	 * REV  - Reverse FV

          XLT1        , XLT2        ,TCAM, PID,CDID,PRED,   FV, FVW */

          Overwrite   , Reverse FV */

 SW  */ { ICE_XLT1_CNT, ICE_XLT2_CNT, 512, 256,   0,  256, 256,  48,

 ACL */ { ICE_XLT1_CNT, ICE_XLT2_CNT, 512, 128,   0,  128, 128,  32,

 FD  */ { ICE_XLT1_CNT, ICE_XLT2_CNT, 512, 128,   0,  128, 128,  24,

 RSS */ { ICE_XLT1_CNT, ICE_XLT2_CNT, 512, 128,   0,  128, 128,  24,

 PE  */ { ICE_XLT1_CNT, ICE_XLT2_CNT,  64,  32,   0,   32,  32,  24,

 Characteristic handling */

/**

 * ice_match_prop_lst - determine if properties of two lists match

 * @list1: first properties list

 * @list2: second properties list

 *

 * Count, cookies and the order must match in order to be considered equivalent.

 compare counts */

 cppcheck-suppress knownConditionTrueFalse */

	/* profile cookies must compare, and in the exact same order to take

	 * into account priority

 VSIG Management */

/**

 * ice_vsig_find_vsi - find a VSIG that contains a specified VSI

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @vsi: VSI of interest

 * @vsig: pointer to receive the VSI group

 *

 * This function will lookup the VSI entry in the XLT2 list and return

 * the VSI group its associated with.

	/* As long as there's a default or valid VSIG associated with the input

	 * VSI, the functions returns a success. Any handling of VSIG will be

	 * done by the following add, update or remove functions.

/**

 * ice_vsig_alloc_val - allocate a new VSIG by value

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @vsig: the VSIG to allocate

 *

 * This function will allocate a given VSIG specified by the VSIG parameter.

/**

 * ice_vsig_alloc - Finds a free entry and allocates a new VSIG

 * @hw: pointer to the hardware structure

 * @blk: HW block

 *

 * This function will iterate through the VSIG list and mark the first

 * unused entry for the new VSIG entry as used and return that value.

/**

 * ice_find_dup_props_vsig - find VSI group with a specified set of properties

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @chs: characteristic list

 * @vsig: returns the VSIG with the matching profiles, if found

 *

 * Each VSIG is associated with a characteristic set; i.e. all VSIs under

 * a group have the same characteristic set. To check if there exists a VSIG

 * which has the same characteristics as the input characteristics; this

 * function will iterate through the XLT2 list and return the VSIG that has a

 * matching configuration. In order to make sure that priorities are accounted

 * for, the list must match exactly, including the order in which the

 * characteristics are listed.

/**

 * ice_vsig_free - free VSI group

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @vsig: VSIG to remove

 *

 * The function will remove all VSIs associated with the input VSIG and move

 * them to the DEFAULT_VSIG and mark the VSIG available.

	/* If the VSIG has at least 1 VSI then iterate through the

	 * list and remove the VSIs before deleting the group.

 remove all vsis associated with this VSIG XLT2 entry */

 NULL terminate head of VSI list */

 free characteristic list */

	/* if VSIG characteristic list was cleared for reset

	 * re-initialize the list head

/**

 * ice_vsig_remove_vsi - remove VSI from VSIG

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @vsi: VSI to remove

 * @vsig: VSI group to remove from

 *

 * The function will remove the input VSI from its VSI group and move it

 * to the DEFAULT_VSIG.

 entry already in default VSIG, don't have to remove */

 iterate the VSI list, skip over the entry to be removed */

 verify if VSI was removed from group list */

/**

 * ice_vsig_add_mv_vsi - add or move a VSI to a VSI group

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @vsi: VSI to move

 * @vsig: destination VSI group

 *

 * This function will move or add the input VSI to the target VSIG.

 * The function will find the original VSIG the VSI belongs to and

 * move the entry to the DEFAULT_VSIG, update the original VSIG and

 * then move entry to the new VSIG.

	/* if VSIG not in use and VSIG is not default type this VSIG

	 * doesn't exist.

 no update required if vsigs match */

 remove entry from orig_vsig and add to default VSIG */

 Create VSI entry and add VSIG and prop_mask values */

 Add new entry to the head of the VSIG list */

/**

 * ice_prof_has_mask_idx - determine if profile index masking is identical

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @prof: profile to check

 * @idx: profile index to check

 * @mask: mask to match

 If mask is 0x0000 or 0xffff, then there is no masking */

 Scan the enabled masks on this profile, for the specified idx */

/**

 * ice_prof_has_mask - determine if profile masking is identical

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @prof: profile to check

 * @masks: masks to match

 es->mask_ena[prof] will have the mask */

/**

 * ice_find_prof_id_with_mask - find profile ID for a given field vector

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @fv: field vector to search for

 * @masks: masks for FV

 * @prof_id: receives the profile ID

	/* For FD, we don't want to re-use a existed profile with the same

	 * field vector and mask. This will cause rule interference.

 check if masks settings are the same for this profile */

/**

 * ice_prof_id_rsrc_type - get profile ID resource type for a block type

 * @blk: the block type

 * @rsrc_type: pointer to variable to receive the resource type

/**

 * ice_tcam_ent_rsrc_type - get TCAM entry resource type for a block type

 * @blk: the block type

 * @rsrc_type: pointer to variable to receive the resource type

/**

 * ice_alloc_tcam_ent - allocate hardware TCAM entry

 * @hw: pointer to the HW struct

 * @blk: the block to allocate the TCAM for

 * @btm: true to allocate from bottom of table, false to allocate from top

 * @tcam_idx: pointer to variable to receive the TCAM entry

 *

 * This function allocates a new entry in a Profile ID TCAM for a specific

 * block.

/**

 * ice_free_tcam_ent - free hardware TCAM entry

 * @hw: pointer to the HW struct

 * @blk: the block from which to free the TCAM entry

 * @tcam_idx: the TCAM entry to free

 *

 * This function frees an entry in a Profile ID TCAM for a specific block.

/**

 * ice_alloc_prof_id - allocate profile ID

 * @hw: pointer to the HW struct

 * @blk: the block to allocate the profile ID for

 * @prof_id: pointer to variable to receive the profile ID

 *

 * This function allocates a new profile ID, which also corresponds to a Field

 * Vector (Extraction Sequence) entry.

/**

 * ice_free_prof_id - free profile ID

 * @hw: pointer to the HW struct

 * @blk: the block from which to free the profile ID

 * @prof_id: the profile ID to free

 *

 * This function frees a profile ID, which also corresponds to a Field Vector.

/**

 * ice_prof_inc_ref - increment reference count for profile

 * @hw: pointer to the HW struct

 * @blk: the block from which to free the profile ID

 * @prof_id: the profile ID for which to increment the reference count

/**

 * ice_write_prof_mask_reg - write profile mask register

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @mask_idx: mask index

 * @idx: index of the FV which will use the mask

 * @mask: the 16-bit mask

/**

 * ice_write_prof_mask_enable_res - write profile mask enable register

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @prof_id: profile ID

 * @enable_mask: enable mask

/**

 * ice_init_prof_masks - initial prof masks

 * @hw: pointer to the HW struct

 * @blk: hardware block

/**

 * ice_init_all_prof_masks - initialize all prof masks

 * @hw: pointer to the HW struct

/**

 * ice_alloc_prof_mask - allocate profile mask

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @idx: index of FV which will use the mask

 * @mask: the 16-bit mask

 * @mask_idx: variable to receive the mask index

			/* if mask is in use and it exactly duplicates the

			 * desired mask and index, then in can be reused

			/* save off unused index, but keep searching in case

			 * there is an exact match later on

 update mask for a new entry */

/**

 * ice_free_prof_mask - free profile mask

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @mask_idx: index of mask

 remove mask */

 update mask as unused entry */

/**

 * ice_free_prof_masks - free all profile masks for a profile

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @prof_id: profile ID

/**

 * ice_shutdown_prof_masks - releases lock for masking

 * @hw: pointer to the HW struct

 * @blk: hardware block

 *

 * This should be called before unloading the driver

/**

 * ice_shutdown_all_prof_masks - releases all locks for masking

 * @hw: pointer to the HW struct

 *

 * This should be called before unloading the driver

/**

 * ice_update_prof_masking - set registers according to masking

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @prof_id: profile ID

 * @masks: masks

 Only support FD and RSS masking, otherwise nothing to be done */

 not enough bitmaps */

 free any bitmaps we have allocated */

 enable the masks for this profile */

 store enabled masks with profile so that they can be freed later */

/**

 * ice_write_es - write an extraction sequence to hardware

 * @hw: pointer to the HW struct

 * @blk: the block in which to write the extraction sequence

 * @prof_id: the profile ID to write

 * @fv: pointer to the extraction sequence to write - NULL to clear extraction

/**

 * ice_prof_dec_ref - decrement reference count for profile

 * @hw: pointer to the HW struct

 * @blk: the block from which to free the profile ID

 * @prof_id: the profile ID for which to decrement the reference count

 Block / table section IDs */

 SWITCH */

 ACL */

 FD */

 RSS */

 PE */

/**

 * ice_init_sw_xlt1_db - init software XLT1 database from HW tables

 * @hw: pointer to the hardware structure

 * @blk: the HW block to initialize

/**

 * ice_init_sw_xlt2_db - init software XLT2 database from HW tables

 * @hw: pointer to the hardware structure

 * @blk: the HW block to initialize

			/* no changes at this time, since this has been

			 * initialized from the original package

/**

 * ice_init_sw_db - init software database from HW tables

 * @hw: pointer to the hardware structure

/**

 * ice_fill_tbl - Reads content of a single table type into database

 * @hw: pointer to the hardware structure

 * @block_id: Block ID of the table to copy

 * @sid: Section ID of the table to copy

 *

 * Will attempt to read the entire content of a given table of a single block

 * into the driver database. We assume that the buffer will always

 * be as large or larger than the data contained in the package. If

 * this condition is not met, there is most likely an error in the package

 * contents.

	/* if the HW segment pointer is null then the first iteration of

	 * ice_pkg_enum_section() will fail. In this case the HW tables will

	 * not be filled and return success.

		/* if the section offset exceeds destination length, terminate

		 * table fill.

		/* if the sum of section size and offset exceed destination size

		 * then we are out of bounds of the HW table size for that PF.

		 * Changing section length to fill the remaining table space

		 * of that PF.

/**

 * ice_fill_blk_tbls - Read package context for tables

 * @hw: pointer to the hardware structure

 *

 * Reads the current package contents and populates the driver

 * database with the data iteratively for all advanced feature

 * blocks. Assume that the HW tables have been allocated.

/**

 * ice_free_prof_map - free profile map

 * @hw: pointer to the hardware structure

 * @blk_idx: HW block index

/**

 * ice_free_flow_profs - free flow profile entries

 * @hw: pointer to the hardware structure

 * @blk_idx: HW block index

	/* if driver is in reset and tables are being cleared

	 * re-initialize the flow profile list heads

/**

 * ice_free_vsig_tbl - free complete VSIG table entries

 * @hw: pointer to the hardware structure

 * @blk: the HW block on which to free the VSIG table entries

/**

 * ice_free_hw_tbls - free hardware table memory

 * @hw: pointer to the hardware structure

/**

 * ice_init_flow_profs - init flow profile locks and list heads

 * @hw: pointer to the hardware structure

 * @blk_idx: HW block index

/**

 * ice_clear_hw_tbls - clear HW tables and flow profiles

 * @hw: pointer to the hardware structure

/**

 * ice_init_hw_tbls - init hardware table memory

 * @hw: pointer to the hardware structure

/**

 * ice_prof_gen_key - generate profile ID key

 * @hw: pointer to the HW struct

 * @blk: the block in which to write profile ID to

 * @ptg: packet type group (PTG) portion of key

 * @vsig: VSIG portion of key

 * @cdid: CDID portion of key

 * @flags: flag portion of key

 * @vl_msk: valid mask

 * @dc_msk: don't care mask

 * @nm_msk: never match mask

 * @key: output of profile ID key

/**

 * ice_tcam_write_entry - write TCAM entry

 * @hw: pointer to the HW struct

 * @blk: the block in which to write profile ID to

 * @idx: the entry index to write to

 * @prof_id: profile ID

 * @ptg: packet type group (PTG) portion of key

 * @vsig: VSIG portion of key

 * @cdid: CDID portion of key

 * @flags: flag portion of key

 * @vl_msk: valid mask

 * @dc_msk: don't care mask

 * @nm_msk: never match mask

/**

 * ice_vsig_get_ref - returns number of VSIs belong to a VSIG

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @vsig: VSIG to query

 * @refs: pointer to variable to receive the reference count

/**

 * ice_has_prof_vsig - check to see if VSIG has a specific profile

 * @hw: pointer to the hardware structure

 * @blk: HW block

 * @vsig: VSIG to check against

 * @hdl: profile handle

/**

 * ice_prof_bld_es - build profile ID extraction sequence changes

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @bld: the update package buffer build to add to

 * @chgs: the list of changes to make in hardware

/**

 * ice_prof_bld_tcam - build profile ID TCAM changes

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @bld: the update package buffer build to add to

 * @chgs: the list of changes to make in hardware

/**

 * ice_prof_bld_xlt1 - build XLT1 changes

 * @blk: hardware block

 * @bld: the update package buffer build to add to

 * @chgs: the list of changes to make in hardware

/**

 * ice_prof_bld_xlt2 - build XLT2 changes

 * @blk: hardware block

 * @bld: the update package buffer build to add to

 * @chgs: the list of changes to make in hardware

/**

 * ice_upd_prof_hw - update hardware using the change list

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @chgs: the list of changes to make in hardware

 count number of sections we need */

 Build update package buffer */

 Preserve order of table update: ES, TCAM, PTG, VSIG */

	/* After package buffer build check if the section count in buffer is

	 * non-zero and matches the number of sections detected for package

	 * update.

 update package */

/**

 * ice_update_fd_mask - set Flow Director Field Vector mask for a profile

 * @hw: pointer to the HW struct

 * @prof_id: profile ID

 * @mask_sel: mask select

 *

 * This function enable any of the masks selected by the mask select parameter

 * for the profile specified.

 These are defined in pairs */

/**

 * ice_update_fd_swap - set register appropriately for a FD FV extraction

 * @hw: pointer to the HW struct

 * @prof_id: profile ID

 * @es: extraction sequence (length of array is determined by the block)

	/* This code assumes that the Flow Director field vectors are assigned

	 * from the end of the FV indexes working towards the zero index, that

	 * only complete fields will be included and will be consecutive, and

	 * that there are no gaps between valid indexes.

 Determine swap fields present */

		/* Find the first free entry, assuming right to left population.

		 * This is where we can start adding additional pairs if needed.

 determine missing swap fields that need to be added */

 add the appropriate 'paired' entry */

 check for room */

 place in extraction sequence */

 keep track of non-relevant fields */

 fill in the swap array */

 assume flat at this index */

 check for a swap location */

 determine the appropriate matching field */

	/* for each set of 4 swap and 4 inset indexes, write the appropriate

	 * register

 write the appropriate swap register set */

 write the appropriate inset register set */

 initially clear the mask select for this profile */

 The entries here needs to match the order of enum ice_ptype_attrib */

/**

 * ice_get_ptype_attrib_info - get PTYPE attribute information

 * @type: attribute type

 * @info: pointer to variable to the attribute information

/**

 * ice_add_prof_attrib - add any PTG with attributes to profile

 * @prof: pointer to the profile to which PTG entries will be added

 * @ptg: PTG to be added

 * @ptype: PTYPE that needs to be looked up

 * @attr: array of attributes that will be considered

 * @attr_cnt: number of elements in the attribute array

/**

 * ice_add_prof - add profile

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @id: profile tracking ID

 * @ptypes: array of bitmaps indicating ptypes (ICE_FLOW_PTYPE_MAX bits)

 * @attr: array of attributes

 * @attr_cnt: number of elements in attr array

 * @es: extraction sequence (length of array is determined by the block)

 * @masks: mask for extraction sequence

 *

 * This function registers a profile, which matches a set of PTYPES with a

 * particular extraction sequence. While the hardware profile is allocated

 * it will not be written until the first call to ice_add_flow that specifies

 * the ID value used here.

 search for existing profile */

 allocate profile ID */

			/* For Flow Director block, the extraction sequence may

			 * need to be altered in the case where there are paired

			 * fields that have no match. This is necessary because

			 * for Flow Director, src and dest fields need to paired

			 * for filter programming and these values are swapped

			 * during Tx.

 and write new es */

 add profile info */

 build list of ptgs */

 Examine 8 bits per byte */

			/* The package should place all ptypes in a non-zero

			 * PTG, so the following call should never fail.

 If PTG is already added, skip and continue */

			/* Check to see there are any attributes for

			 * this PTYPE, and add them if found.

				/* This is simple a PTYPE/PTG with no

				 * attribute

/**

 * ice_search_prof_id - Search for a profile tracking ID

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @id: profile tracking ID

 *

 * This will search for a profile tracking ID which was previously added.

 * The profile map lock should be held before calling this function.

/**

 * ice_vsig_prof_id_count - count profiles in a VSIG

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsig: VSIG to remove the profile from

/**

 * ice_rel_tcam_idx - release a TCAM index

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @idx: the index to release

 Masks to invoke a never match entry */

 write the TCAM entry */

 release the TCAM entry */

/**

 * ice_rem_prof_id - remove one profile from a VSIG

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @prof: pointer to profile structure to remove

/**

 * ice_rem_vsig - remove VSIG

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsig: the VSIG to remove

 * @chg: the change list

 remove TCAM entries */

 Move all VSIS associated with this VSIG to the default VSIG */

	/* If the VSIG has at least 1 VSI then iterate through the list

	 * and remove the VSIs before deleting the group.

/**

 * ice_rem_prof_id_vsig - remove a specific profile from a VSIG

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsig: VSIG to remove the profile from

 * @hdl: profile handle indicating which profile to remove

 * @chg: list to receive a record of changes

 this is the last profile, remove the VSIG */

/**

 * ice_rem_flow_all - remove all flows with a particular profile

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @id: profile tracking ID

/**

 * ice_rem_prof - remove profile

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @id: profile tracking ID

 *

 * This will remove the profile specified by the ID parameter, which was

 * previously created through ice_add_prof. If any existing entries

 * are associated with this profile, they will be removed as well.

 remove all flows with this profile */

 dereference profile, and possibly remove */

/**

 * ice_get_prof - get profile

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @hdl: profile handle

 * @chg: change list

 Get the details on the profile specified by the handle ID */

 add ES to change list */

 let caller clean up the change list */

/**

 * ice_get_profs_vsig - get a copy of the list of profiles from a VSIG

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsig: VSIG from which to copy the list

 * @lst: output list

 *

 * This routine makes a copy of the list of profiles in the specified VSIG.

 copy to the input list */

/**

 * ice_add_prof_to_lst - add profile entry to a list

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @lst: the list to be added to

 * @hdl: profile handle of entry to add

/**

 * ice_move_vsi - move VSI to another VSIG

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsi: the VSI to move

 * @vsig: the VSIG to move the VSI to

 * @chg: the change list

/**

 * ice_rem_chg_tcam_ent - remove a specific TCAM entry from change list

 * @hw: pointer to the HW struct

 * @idx: the index of the TCAM entry to remove

 * @chg: the list of change structures to search

/**

 * ice_prof_tcam_ena_dis - add enable or disable TCAM change

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @enable: true to enable, false to disable

 * @vsig: the VSIG of the TCAM entry

 * @tcam: pointer the TCAM info structure of the TCAM to disable

 * @chg: the change list

 *

 * This function appends an enable or disable TCAM entry in the change log

 if disabling, free the TCAM */

		/* if we have already created a change for this TCAM entry, then

		 * we need to remove that entry, in order to prevent writing to

		 * a TCAM entry we no longer will have ownership of.

 for re-enabling, reallocate a TCAM */

	/* for entries with empty attribute masks, allocate entry from

	 * the bottom of the TCAM table; otherwise, allocate from the

	 * top of the table in order to give it higher priority

 add TCAM to change list */

 log change */

/**

 * ice_adj_prof_priorities - adjust profile based on priorities

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsig: the VSIG for which to adjust profile priorities

 * @chg: the change list

	/* Priority is based on the order in which the profiles are added. The

	 * newest added profile has highest priority and the oldest added

	 * profile has the lowest priority. Since the profile property list for

	 * a VSIG is sorted from newest to oldest, this code traverses the list

	 * in order and enables the first of each PTG that it finds (that is not

	 * already enabled); it also disables any duplicate PTGs that it finds

	 * in the older profiles (that are currently enabled).

			/* Scan the priorities from newest to oldest.

			 * Make sure that the newest profiles take priority.

				/* need to mark this PTG as never match, as it

				 * was already in use and therefore duplicate

				 * (and lower priority)

				/* need to enable this PTG, as it in not in use

				 * and not enabled (highest priority)

 keep track of used ptgs */

/**

 * ice_add_prof_id_vsig - add profile to VSIG

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsig: the VSIG to which this profile is to be added

 * @hdl: the profile handle indicating the profile to add

 * @rev: true to add entries to the end of the list

 * @chg: the change list

 Masks that ignore flags */

 Error, if this VSIG already has this profile */

 new VSIG profile structure */

 Get the details on the profile specified by the handle ID */

 create TCAM entries */

 add TCAM to change list */

 allocate the TCAM entry index */

		/* for entries with empty attribute masks, allocate entry from

		 * the bottom of the TCAM table; otherwise, allocate from the

		 * top of the table in order to give it higher priority

 write the TCAM entry */

 log change */

 add profile to VSIG */

 let caller clean up the change list */

/**

 * ice_create_prof_id_vsig - add a new VSIG with a single profile

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsi: the initial VSI that will be in VSIG

 * @hdl: the profile handle of the profile that will be added to the VSIG

 * @chg: the change list

 let caller clean up the change list */

/**

 * ice_create_vsig_from_lst - create a new VSIG with a list of profiles

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsi: the initial VSI that will be in VSIG

 * @lst: the list of profile that will be added to the VSIG

 * @new_vsig: return of new VSIG

 * @chg: the change list

 Reverse the order here since we are copying the list */

/**

 * ice_find_prof_vsig - find a VSIG with a specific profile handle

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @hdl: the profile handle of the profile to search for

 * @vsig: returns the VSIG with the matching profile

/**

 * ice_add_prof_id_flow - add profile flow

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsi: the VSI to enable with the profile specified by ID

 * @hdl: profile handle

 *

 * Calling this function will update the hardware tables to enable the

 * profile indicated by the ID parameter for the VSIs specified in the VSI

 * array. Once successfully called, the flow will be enabled.

 Get profile */

 determine if VSI is already part of a VSIG */

 found in VSIG */

		/* make sure that there is no overlap/conflict between the new

		 * characteristics and the existing ones; we don't support that

		 * scenario

 last VSI in the VSIG? */

		/* create a union of the current profiles and the one being

		 * added

 search for an existing VSIG with an exact charc match */

 move VSI to the VSIG that matches */

			/* VSI has been moved out of or_vsig. If the or_vsig had

			 * only that VSI it is now empty and can be removed.

			/* If the original VSIG only contains one VSI, then it

			 * will be the requesting VSI. In this case the VSI is

			 * not sharing entries and we can simply add the new

			 * profile to the VSIG.

 Adjust priorities */

 No match, so we need a new VSIG */

 Adjust priorities */

 need to find or add a VSIG */

 search for an existing VSIG with an exact charc match */

 found an exact match */

 add or move VSI to the VSIG that matches */

 we did not find an exact match */

 we need to add a VSIG */

 update hardware */

/**

 * ice_rem_prof_from_list - remove a profile from list

 * @hw: pointer to the HW struct

 * @lst: list to remove the profile from

 * @hdl: the profile handle indicating the profile to remove

/**

 * ice_rem_prof_id_flow - remove flow

 * @hw: pointer to the HW struct

 * @blk: hardware block

 * @vsi: the VSI from which to remove the profile specified by ID

 * @hdl: profile tracking handle

 *

 * Calling this function will update the hardware tables to remove the

 * profile indicated by the ID parameter for the VSIs specified in the VSI

 * array. Once successfully called, the flow will be disabled.

 determine if VSI is already part of a VSIG */

 found in VSIG */

			/* If the original VSIG only contains one reference,

			 * which will be the requesting VSI, then the VSI is not

			 * sharing entries and we can simply remove the specific

			 * characteristics from the VSIG.

				/* If there are no profiles left for this VSIG,

				 * then simply remove the VSIG.

 Adjust priorities */

 Make a copy of the VSIG's list of Profiles */

 Remove specified profile entry from the list */

 found an exact match */

 add or move VSI to the VSIG that matches */

				/* Search for a VSIG with a matching profile

				 * list

 Found match, move VSI to the matching VSIG */

				/* since no existing VSIG supports this

				 * characteristic pattern, we need to create a

				 * new VSIG and TCAM entries

 Adjust priorities */

 update hardware tables */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018-2020, Intel Corporation. */

 These are training packet headers used to program flow director filters. */

 Flow Director no-op training packet table */

/**

 * ice_set_dflt_val_fd_desc

 * @fd_fltr_ctx: pointer to fd filter descriptor

/**

 * ice_set_fd_desc_val

 * @ctx: pointer to fd filter descriptor context

 * @fdir_desc: populated with fd filter descriptor values

 prep QW0 of FD filter programming desc */

 prep QW1 of FD filter programming desc */

/**

 * ice_fdir_get_prgm_desc - set a fdir descriptor from a fdir filter struct

 * @hw: pointer to the hardware structure

 * @input: filter

 * @fdesc: filter descriptor

 * @add: if add is true, this is an add operation, false implies delete

 set default context info */

 change sideband filtering values */

/**

 * ice_alloc_fd_res_cntr - obtain counter resource for FD type

 * @hw: pointer to the hardware structure

 * @cntr_id: returns counter index

/**

 * ice_free_fd_res_cntr - Free counter resource for FD type

 * @hw: pointer to the hardware structure

 * @cntr_id: counter index to be freed

/**

 * ice_alloc_fd_guar_item - allocate resource for FD guaranteed entries

 * @hw: pointer to the hardware structure

 * @cntr_id: returns counter index

 * @num_fltr: number of filter entries to be allocated

/**

 * ice_alloc_fd_shrd_item - allocate resource for flow director shared entries

 * @hw: pointer to the hardware structure

 * @cntr_id: returns counter index

 * @num_fltr: number of filter entries to be allocated

/**

 * ice_get_fdir_cnt_all - get the number of Flow Director filters

 * @hw: hardware data structure

 *

 * Returns the number of filters available on device

/**

 * ice_pkt_insert_ipv6_addr - insert a be32 IPv6 address into a memory buffer

 * @pkt: packet buffer

 * @offset: offset into buffer

 * @addr: IPv6 address to convert and insert into pkt at offset

/**

 * ice_pkt_insert_u6_qfi - insert a u6 value QFI into a memory buffer for GTPU

 * @pkt: packet buffer

 * @offset: offset into buffer

 * @data: 8 bit value to convert and insert into pkt at offset

 *

 * This function is designed for inserting QFI (6 bits) for GTPU.

/**

 * ice_pkt_insert_u8 - insert a u8 value into a memory buffer.

 * @pkt: packet buffer

 * @offset: offset into buffer

 * @data: 8 bit value to convert and insert into pkt at offset

/**

 * ice_pkt_insert_u8_tc - insert a u8 value into a memory buffer for TC ipv6.

 * @pkt: packet buffer

 * @offset: offset into buffer

 * @data: 8 bit value to convert and insert into pkt at offset

 *

 * This function is designed for inserting Traffic Class (TC) for IPv6,

 * since that TC is not aligned in number of bytes. Here we split it out

 * into two part and fill each byte with data copy from pkt, then insert

 * the two bytes data one by one.

/**

 * ice_pkt_insert_u16 - insert a be16 value into a memory buffer

 * @pkt: packet buffer

 * @offset: offset into buffer

 * @data: 16 bit value to convert and insert into pkt at offset

/**

 * ice_pkt_insert_u32 - insert a be32 value into a memory buffer

 * @pkt: packet buffer

 * @offset: offset into buffer

 * @data: 32 bit value to convert and insert into pkt at offset

/**

 * ice_pkt_insert_mac_addr - insert a MAC addr into a memory buffer.

 * @pkt: packet buffer

 * @addr: MAC address to convert and insert into pkt at offset

/**

 * ice_fdir_get_gen_prgm_pkt - generate a training packet

 * @hw: pointer to the hardware structure

 * @input: flow director filter data structure

 * @pkt: pointer to return filter packet

 * @frag: generate a fragment packet

 * @tun: true implies generate a tunnel packet

	/* Reverse the src and dst, since the HW expects them to be from Tx

	 * perspective. The input from user is from Rx filter perspective.

/**

 * ice_fdir_has_frag - does flow type have 2 ptypes

 * @flow: flow ptype

 *

 * returns true is there is a fragment packet for this ptype

/**

 * ice_fdir_find_fltr_by_idx - find filter with idx

 * @hw: pointer to hardware structure

 * @fltr_idx: index to find.

 *

 * Returns pointer to filter if found or null

 rule ID found in the list */

/**

 * ice_fdir_list_add_fltr - add a new node to the flow director filter list

 * @hw: hardware structure

 * @fltr: filter node to add to structure

 rule ID found or pass its spot in the list */

/**

 * ice_fdir_update_cntrs - increment / decrement filter counter

 * @hw: pointer to hardware structure

 * @flow: filter flow type

 * @add: true implies filters added

/**

 * ice_cmp_ipv6_addr - compare 2 IP v6 addresses

 * @a: IP v6 address

 * @b: IP v6 address

 *

 * Returns 0 on equal, returns non-0 if different

/**

 * ice_fdir_comp_rules - compare 2 filters

 * @a: a Flow Director filter data structure

 * @b: a Flow Director filter data structure

 * @v6: bool true if v6 filter

 *

 * Returns true if the filters match

	/* The calling function already checks that the two filters have the

	 * same flow_type.

/**

 * ice_fdir_is_dup_fltr - test if filter is already in list for PF

 * @hw: hardware data structure

 * @input: Flow Director filter data structure

 *

 * Returns true if the filter is found in the list

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019, Intel Corporation. */

 Describe properties of a protocol header field */

 Offset from start of a protocol header, in bits */

 Size of fields in bits */

 16-bit mask for field */

 Table containing properties of supported protocol header fields */

 Ether */

 ICE_FLOW_FIELD_IDX_ETH_DA */

 ICE_FLOW_FIELD_IDX_ETH_SA */

 ICE_FLOW_FIELD_IDX_S_VLAN */

 ICE_FLOW_FIELD_IDX_C_VLAN */

 ICE_FLOW_FIELD_IDX_ETH_TYPE */

 IPv4 / IPv6 */

 ICE_FLOW_FIELD_IDX_IPV4_DSCP */

 ICE_FLOW_FIELD_IDX_IPV6_DSCP */

 ICE_FLOW_FIELD_IDX_IPV4_TTL */

 ICE_FLOW_FIELD_IDX_IPV4_PROT */

 ICE_FLOW_FIELD_IDX_IPV6_TTL */

 ICE_FLOW_FIELD_IDX_IPV6_PROT */

 ICE_FLOW_FIELD_IDX_IPV4_SA */

 ICE_FLOW_FIELD_IDX_IPV4_DA */

 ICE_FLOW_FIELD_IDX_IPV6_SA */

 ICE_FLOW_FIELD_IDX_IPV6_DA */

 Transport */

 ICE_FLOW_FIELD_IDX_TCP_SRC_PORT */

 ICE_FLOW_FIELD_IDX_TCP_DST_PORT */

 ICE_FLOW_FIELD_IDX_UDP_SRC_PORT */

 ICE_FLOW_FIELD_IDX_UDP_DST_PORT */

 ICE_FLOW_FIELD_IDX_SCTP_SRC_PORT */

 ICE_FLOW_FIELD_IDX_SCTP_DST_PORT */

 ICE_FLOW_FIELD_IDX_TCP_FLAGS */

 ARP */

 ICE_FLOW_FIELD_IDX_ARP_SIP */

 ICE_FLOW_FIELD_IDX_ARP_DIP */

 ICE_FLOW_FIELD_IDX_ARP_SHA */

 ICE_FLOW_FIELD_IDX_ARP_DHA */

 ICE_FLOW_FIELD_IDX_ARP_OP */

 ICMP */

 ICE_FLOW_FIELD_IDX_ICMP_TYPE */

 ICE_FLOW_FIELD_IDX_ICMP_CODE */

 GRE */

 ICE_FLOW_FIELD_IDX_GRE_KEYID */

 GTP */

 ICE_FLOW_FIELD_IDX_GTPC_TEID */

 ICE_FLOW_FIELD_IDX_GTPU_IP_TEID */

 ICE_FLOW_FIELD_IDX_GTPU_EH_TEID */

 ICE_FLOW_FIELD_IDX_GTPU_EH_QFI */

 ICE_FLOW_FIELD_IDX_GTPU_UP_TEID */

 ICE_FLOW_FIELD_IDX_GTPU_DWN_TEID */

 PPPoE */

 ICE_FLOW_FIELD_IDX_PPPOE_SESS_ID */

 PFCP */

 ICE_FLOW_FIELD_IDX_PFCP_SEID */

 L2TPv3 */

 ICE_FLOW_FIELD_IDX_L2TPV3_SESS_ID */

 ESP */

 ICE_FLOW_FIELD_IDX_ESP_SPI */

 AH */

 ICE_FLOW_FIELD_IDX_AH_SPI */

 NAT_T_ESP */

 ICE_FLOW_FIELD_IDX_NAT_T_ESP_SPI */

/* Bitmaps indicating relevant packet types for a particular protocol header

 *

 * Packet types for packets with an Outer/First/Single MAC header

 Packet types for packets with an Innermost/Last MAC VLAN header */

/* Packet types for packets with an Outer/First/Single IPv4 header, does NOT

 * include IPv4 other PTYPEs

/* Packet types for packets with an Outer/First/Single IPv4 header, includes

 * IPv4 other PTYPEs

 Packet types for packets with an Innermost/Last IPv4 header */

/* Packet types for packets with an Outer/First/Single IPv6 header, does NOT

 * include IPv6 other PTYPEs

/* Packet types for packets with an Outer/First/Single IPv6 header, includes

 * IPv6 other PTYPEs

 Packet types for packets with an Innermost/Last IPv6 header */

 Packet types for packets with an Outer/First/Single IPv4 header - no L4 */

 Packet types for packets with an Outermost/First ARP header */

 Packet types for packets with an Innermost/Last IPv4 header - no L4 */

 Packet types for packets with an Outer/First/Single IPv6 header - no L4 */

 Packet types for packets with an Innermost/Last IPv6 header - no L4 */

/* UDP Packet types for non-tunneled packets or tunneled

 * packets with inner UDP.

 Packet types for packets with an Innermost/Last TCP header */

 Packet types for packets with an Innermost/Last SCTP header */

 Packet types for packets with an Outermost/First ICMP header */

 Packet types for packets with an Innermost/Last ICMP header */

 Packet types for packets with an Outermost/First GRE header */

 Packet types for packets with an Innermost/Last MAC header */

 Packet types for GTPC */

 Packet types for GTPC with TEID */

 Packet types for GTPU */

 Packet types for PPPoE */

 Packet types for packets with PFCP NODE header */

 Packet types for packets with PFCP SESSION header */

 Packet types for L2TPv3 */

 Packet types for ESP */

 Packet types for AH */

 Packet types for packets with NAT_T ESP header */

 Manage parameters and info. used during the creation of a flow profile */

 # of bytes formatted entry will require */

	/* For ACL, the es[0] will have the data of ICE_RX_MDID_PKT_FLAGS_15_0

	 * This will give us the direction flags.

 attributes can be used to add attributes to a particular PTYPE */

 mask for L4 protocols that are NOT part of IPv4/6 OTHER PTYPE groups */

/**

 * ice_flow_val_hdrs - validates packet segments for valid protocol headers

 * @segs: array of one or more packet segments that describe the flow

 * @segs_cnt: number of packet segments provided

 Multiple L3 headers */

 Multiple L4 headers */

 Sizes of fixed known protocol headers without header options */

/**

 * ice_flow_calc_seg_sz - calculates size of a packet segment based on headers

 * @params: information about the flow to be processed

 * @seg: index of packet segment whose header size is to be determined

 L2 headers */

 L3 headers */

 An L3 header is required if L4 is specified */

 L4 headers */

/**

 * ice_flow_proc_seg_hdrs - process protocol headers present in pkt segments

 * @params: information about the flow to be processed

 *

 * This function identifies the packet types associated with the protocol

 * headers being present in packet segments of the specified flow profile.

 Attributes for GTP packet with downlink */

 Attributes for GTP packet with uplink */

 Attributes for GTP packet with Extension Header */

/**

 * ice_flow_xtract_fld - Create an extraction sequence entry for the given field

 * @hw: pointer to the HW struct

 * @params: information about the flow to be processed

 * @seg: packet segment index of the field to be extracted

 * @fld: ID of field to be extracted

 * @match: bit field of all fields

 *

 * This function determines the protocol ID, offset, and size of the given

 * field. It then allocates one or more extraction sequence entries for the

 * given field, and fill the entries with protocol ID and offset information.

		/* TTL and PROT share the same extraction seq. entry.

		 * Each is considered a sibling to the other in terms of sharing

		 * the same extraction sequence entry.

		/* If the sibling field is also included, that field's

		 * mask needs to be included.

		/* TTL and PROT share the same extraction seq. entry.

		 * Each is considered a sibling to the other in terms of sharing

		 * the same extraction sequence entry.

		/* If the sibling field is also included, that field's

		 * mask needs to be included.

 GTP is accessed through UDP OF protocol */

 ICMP type and code share the same extraction seq. entry */

	/* Each extraction sequence entry is a word in size, and extracts a

	 * word-aligned offset from a protocol header.

	/* Adjust the next field-entry index after accommodating the number of

	 * entries this field consumes

 Fill in the extraction sequence entries needed for this field */

		/* Only consume an extraction sequence entry if there is no

		 * sibling field associated with this field or the sibling entry

		 * already extracts the word shared with this field.

			/* Make sure the number of extraction sequence required

			 * does not exceed the block's capability

 some blocks require a reversed field vector layout */

/**

 * ice_flow_xtract_raws - Create extract sequence entries for raw bytes

 * @hw: pointer to the HW struct

 * @params: information about the flow to be processed

 * @seg: index of packet segment whose raw fields are to be extracted

 Offsets within the segment headers are not supported */

 Storing extraction information */

		/* Determine the number of field vector entries this raw field

		 * consumes.

			/* Make sure the number of extraction sequence required

			 * does not exceed the block's capability

 some blocks require a reversed field vector layout */

/**

 * ice_flow_create_xtrct_seq - Create an extraction sequence for given segments

 * @hw: pointer to the HW struct

 * @params: information about the flow to be processed

 *

 * This function iterates through all matched fields in the given segments, and

 * creates an extraction sequence for the fields.

 Process raw matching bytes */

/**

 * ice_flow_proc_segs - process all packet segments associated with a profile

 * @hw: pointer to the HW struct

 * @params: information about the flow to be processed

/**

 * ice_flow_find_prof_conds - Find a profile matching headers and conditions

 * @hw: pointer to the HW struct

 * @blk: classification stage

 * @dir: flow direction

 * @segs: array of one or more packet segments that describe the flow

 * @segs_cnt: number of packet segments provided

 * @vsi_handle: software VSI handle to check VSI (ICE_FLOW_FIND_PROF_CHK_VSI)

 * @conds: additional conditions to be checked (ICE_FLOW_FIND_PROF_CHK_*)

 Check for profile-VSI association if specified */

			/* Protocol headers must be checked. Matched fields are

			 * checked if specified.

 A match is found if all segments are matched */

/**

 * ice_flow_find_prof_id - Look up a profile with given profile ID

 * @hw: pointer to the HW struct

 * @blk: classification stage

 * @prof_id: unique ID to identify this flow profile

/**

 * ice_dealloc_flow_entry - Deallocate flow entry memory

 * @hw: pointer to the HW struct

 * @entry: flow entry to be removed

/**

 * ice_flow_rem_entry_sync - Remove a flow entry

 * @hw: pointer to the HW struct

 * @blk: classification stage

 * @entry: flow entry to be removed

/**

 * ice_flow_add_prof_sync - Add a flow profile for packet segments and fields

 * @hw: pointer to the HW struct

 * @blk: classification stage

 * @dir: flow direction

 * @prof_id: unique ID to identify this flow profile

 * @segs: array of one or more packet segments that describe the flow

 * @segs_cnt: number of packet segments provided

 * @prof: stores the returned flow profile added

 *

 * Assumption: the caller has acquired the lock to the profile list

 initialize extraction sequence to all invalid (0xff) */

	/* Make a copy of the segments that need to be persistent in the flow

	 * profile instance

 Add a HW profile for this flow profile */

/**

 * ice_flow_rem_prof_sync - remove a flow profile

 * @hw: pointer to the hardware structure

 * @blk: classification stage

 * @prof: pointer to flow profile to remove

 *

 * Assumption: the caller has acquired the lock to the profile list

 Remove all remaining flow entries before removing the flow profile */

 Remove all hardware profiles associated with this flow profile */

/**

 * ice_flow_assoc_prof - associate a VSI with a flow profile

 * @hw: pointer to the hardware structure

 * @blk: classification stage

 * @prof: pointer to flow profile

 * @vsi_handle: software VSI handle

 *

 * Assumption: the caller has acquired the lock to the profile list

 * and the software VSI handle has been validated

/**

 * ice_flow_disassoc_prof - disassociate a VSI from a flow profile

 * @hw: pointer to the hardware structure

 * @blk: classification stage

 * @prof: pointer to flow profile

 * @vsi_handle: software VSI handle

 *

 * Assumption: the caller has acquired the lock to the profile list

 * and the software VSI handle has been validated

/**

 * ice_flow_add_prof - Add a flow profile for packet segments and matched fields

 * @hw: pointer to the HW struct

 * @blk: classification stage

 * @dir: flow direction

 * @prof_id: unique ID to identify this flow profile

 * @segs: array of one or more packet segments that describe the flow

 * @segs_cnt: number of packet segments provided

 * @prof: stores the returned flow profile added

/**

 * ice_flow_rem_prof - Remove a flow profile and all entries associated with it

 * @hw: pointer to the HW struct

 * @blk: the block for which the flow profile is to be removed

 * @prof_id: unique ID of the flow profile to be removed

 prof becomes invalid after the call */

/**

 * ice_flow_add_entry - Add a flow entry

 * @hw: pointer to the HW struct

 * @blk: classification stage

 * @prof_id: ID of the profile to add a new flow entry to

 * @entry_id: unique ID to identify this flow entry

 * @vsi_handle: software VSI handle for the flow entry

 * @prio: priority of the flow entry

 * @data: pointer to a data buffer containing flow entry's match values/masks

 * @entry_h: pointer to buffer that receives the new flow entry's handle

 No flow entry data is expected for RSS */

		/* Allocate memory for the entry being added and associate

		 * the VSI to the found flow profile

/**

 * ice_flow_rem_entry - Remove a flow entry

 * @hw: pointer to the HW struct

 * @blk: classification stage

 * @entry_h: handle to the flow entry to be removed

 Retain the pointer to the flow profile as the entry will be freed */

/**

 * ice_flow_set_fld_ext - specifies locations of field from entry's input buffer

 * @seg: packet segment the field being set belongs to

 * @fld: field to be set

 * @field_type: type of the field

 * @val_loc: if not ICE_FLOW_FLD_OFF_INVAL, location of the value to match from

 *           entry's input buffer

 * @mask_loc: if not ICE_FLOW_FLD_OFF_INVAL, location of mask value from entry's

 *            input buffer

 * @last_loc: if not ICE_FLOW_FLD_OFF_INVAL, location of last/upper value from

 *            entry's input buffer

 *

 * This helper function stores information of a field being matched, including

 * the type of the field and the locations of the value to match, the mask, and

 * the upper-bound value in the start of the input buffer for a flow entry.

 * This function should only be used for fixed-size data structures.

 *

 * This function also opportunistically determines the protocol headers to be

 * present based on the fields being set. Some fields cannot be used alone to

 * determine the protocol headers present. Sometimes, fields for particular

 * protocol headers are not matched. In those cases, the protocol headers

 * must be explicitly set.

/**

 * ice_flow_set_fld - specifies locations of field from entry's input buffer

 * @seg: packet segment the field being set belongs to

 * @fld: field to be set

 * @val_loc: if not ICE_FLOW_FLD_OFF_INVAL, location of the value to match from

 *           entry's input buffer

 * @mask_loc: if not ICE_FLOW_FLD_OFF_INVAL, location of mask value from entry's

 *            input buffer

 * @last_loc: if not ICE_FLOW_FLD_OFF_INVAL, location of last/upper value from

 *            entry's input buffer

 * @range: indicate if field being matched is to be in a range

 *

 * This function specifies the locations, in the form of byte offsets from the

 * start of the input buffer for a flow entry, from where the value to match,

 * the mask value, and upper value can be extracted. These locations are then

 * stored in the flow profile. When adding a flow entry associated with the

 * flow profile, these locations will be used to quickly extract the values and

 * create the content of a match entry. This function should only be used for

 * fixed-size data structures.

/**

 * ice_flow_add_fld_raw - sets locations of a raw field from entry's input buf

 * @seg: packet segment the field being set belongs to

 * @off: offset of the raw field from the beginning of the segment in bytes

 * @len: length of the raw pattern to be matched

 * @val_loc: location of the value to match from entry's input buffer

 * @mask_loc: location of mask value from entry's input buffer

 *

 * This function specifies the offset of the raw field to be match from the

 * beginning of the specified packet segment, and the locations, in the form of

 * byte offsets from the start of the input buffer for a flow entry, from where

 * the value to match and the mask value to be extracted. These locations are

 * then stored in the flow profile. When adding flow entries to the associated

 * flow profile, these locations can be used to quickly extract the values to

 * create the content of a match entry. This function should only be used for

 * fixed-size data structures.

 The "last" field is used to store the length of the field */

	/* Overflows of "raws" will be handled as an error condition later in

	 * the flow when this information is processed.

/**

 * ice_flow_set_rss_seg_info - setup packet segments for RSS

 * @segs: pointer to the flow field segment(s)

 * @hash_fields: fields to be hashed on for the segment(s)

 * @flow_hdr: protocol header fields within a packet segment

 *

 * Helper function to extract fields from hash bitmap and use flow

 * header value to set flow field segment for further use in flow

 * profile entry or removal.

/**

 * ice_rem_vsi_rss_list - remove VSI from RSS list

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 *

 * Remove the VSI from all RSS configurations in the list.

/**

 * ice_rem_vsi_rss_cfg - remove RSS configurations associated with VSI

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 *

 * This function will iterate through all flow profiles and disassociate

 * the VSI from that profile. If the flow profile has no VSIs it will

 * be removed.

/**

 * ice_rem_rss_list - remove RSS configuration from list

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 * @prof: pointer to flow profile

 *

 * Assumption: lock has already been acquired for RSS list

	/* Search for RSS hash fields associated to the VSI that match the

	 * hash configurations associated to the flow profile. If found

	 * remove from the RSS entry list of the VSI context and delete entry.

/**

 * ice_add_rss_list - add RSS configuration to list

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 * @prof: pointer to flow profile

 *

 * Assumption: lock has already been acquired for RSS list

/* Flow profile ID format:

 * [0:31] - Packet match fields

 * [32:62] - Protocol header

 * [63] - Encapsulation flag, 0 if non-tunneled, 1 if tunneled

/**

 * ice_add_rss_cfg_sync - add an RSS configuration

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 * @hashed_flds: hash bit fields (ICE_FLOW_HASH_*) to configure

 * @addl_hdrs: protocol header fields

 * @segs_cnt: packet segment count

 *

 * Assumption: lock has already been acquired for RSS list

 Construct the packet segment info from the hashed fields */

	/* Search for a flow profile that has matching headers, hash fields

	 * and has the input VSI associated to it. If found, no further

	 * operations required and exit.

	/* Check if a flow profile exists with the same protocol headers and

	 * associated with the input VSI. If so disassociate the VSI from

	 * this profile. The VSI will be added to a new profile created with

	 * the protocol header and new hash field configuration.

 Remove profile if it has no VSIs associated */

	/* Search for a profile that has same match fields only. If this

	 * exists then associate the VSI to this profile.

	/* Create a new flow profile with generated profile and packet

	 * segment information.

	/* If association to a new flow profile failed then this profile can

	 * be removed.

/**

 * ice_add_rss_cfg - add an RSS configuration with specified hashed fields

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 * @hashed_flds: hash bit fields (ICE_FLOW_HASH_*) to configure

 * @addl_hdrs: protocol header fields

 *

 * This function will generate a flow profile based on fields associated with

 * the input fields to hash on, the flow type and use the VSI number to add

 * a flow entry to the profile.

/**

 * ice_rem_rss_cfg_sync - remove an existing RSS configuration

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 * @hashed_flds: Packet hash types (ICE_FLOW_HASH_*) to remove

 * @addl_hdrs: Protocol header fields within a packet segment

 * @segs_cnt: packet segment count

 *

 * Assumption: lock has already been acquired for RSS list

 Construct the packet segment info from the hashed fields */

	/* Remove RSS configuration from VSI context before deleting

	 * the flow profile.

/**

 * ice_rem_rss_cfg - remove an existing RSS config with matching hashed fields

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 * @hashed_flds: Packet hash types (ICE_FLOW_HASH_*) to remove

 * @addl_hdrs: Protocol header fields within a packet segment

 *

 * This function will lookup the flow profile based on the input

 * hash field bitmap, iterate through the profile entry list of

 * that profile and find entry associated with input VSI to be

 * removed. Calls are made to underlying flow s which will APIs

 * turn build or update buffers for RSS XLT1 section.

/* Mapping of AVF hash bit fields to an L3-L4 hash combination.

 * As the ice_flow_avf_hdr_field represent individual bit shifts in a hash,

 * convert its values to their appropriate flow L3, L4 values.

/**

 * ice_add_avf_rss_cfg - add an RSS configuration for AVF driver

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 * @avf_hash: hash bit fields (ICE_AVF_FLOW_FIELD_*) to configure

 *

 * This function will take the hash bitmap provided by the AVF driver via a

 * message, convert it to ICE-compatible values, and configure RSS flow

 * profiles.

 Make sure no unsupported bits are specified */

 Always create an L3 RSS configuration for any L4 RSS configuration */

 Create the corresponding RSS configuration for each valid hash bit */

/**

 * ice_replay_rss_cfg - replay RSS configurations associated with VSI

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

/**

 * ice_get_rss_cfg - returns hashed fields for the given header types

 * @hw: pointer to the hardware structure

 * @vsi_handle: software VSI handle

 * @hdrs: protocol header type

 *

 * This function will return the match fields of the first instance of flow

 * profile having the given header types and containing input VSI

 verify if the protocol header is non zero and VSI is valid */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

/* Dummy ethernet header needed in the ice_aqc_sw_rules_elem

 * struct to configure any switch filter rules.

 * {DA (6 bytes), SA(6 bytes),

 * Ether type (2 bytes for header without VLAN tag) OR

 * VLAN tag (4 bytes for header with VLAN tag) }

 *

 * Word on Hardcoded values

 * byte 0 = 0x2: to identify it as locally administered DA MAC

 * byte 6 = 0x2: to identify it as locally administered SA MAC

 * byte 12 = 0x81 & byte 13 = 0x00:

 *	In case of VLAN filter first two bytes defines ether type (0x8100)

 *	and remaining two bytes are placeholder for programming a given VLAN ID

 *	In case of Ether type filter it is treated as header without VLAN tag

 *	and byte 12 and 13 is used to program a given Ether type instead

 ICE_PROTOCOL_LAST indicates end of list */

 ICE_MAC_OFOS 0 */

 ICE_ETYPE_OL 12 */

 ICE_IPV4_OFOS 14 */

 ICE_NVGRE 34 */

 ICE_MAC_IL 42 */

 ICE_IPV4_IL 56 */

 ICE_TCP_IL 76 */

 ICE_MAC_OFOS 0 */

 ICE_ETYPE_OL 12 */

 ICE_IPV4_OFOS 14 */

 ICE_NVGRE 34 */

 ICE_MAC_IL 42 */

 ICE_IPV4_IL 56 */

 ICE_UDP_ILOS 76 */

 ICE_MAC_OFOS 0 */

 ICE_ETYPE_OL 12 */

 ICE_IPV4_OFOS 14 */

 ICE_UDP_OF 34 */

 ICE_VXLAN 42 */

 ICE_MAC_IL 50 */

 ICE_IPV4_IL 64 */

 ICE_TCP_IL 84 */

 ICE_MAC_OFOS 0 */

 ICE_ETYPE_OL 12 */

 ICE_IPV4_OFOS 14 */

 ICE_UDP_OF 34 */

 ICE_VXLAN 42 */

 ICE_MAC_IL 50 */

 ICE_IPV4_IL 64 */

 ICE_UDP_ILOS 84 */

 offset info for MAC + IPv4 + UDP dummy packet */

 Dummy packet for MAC + IPv4 + UDP */

 ICE_MAC_OFOS 0 */

 ICE_ETYPE_OL 12 */

 ICE_IPV4_OFOS 14 */

 ICE_UDP_ILOS 34 */

 2 bytes for 4 byte alignment */

 offset info for MAC + VLAN + IPv4 + UDP dummy packet */

 C-tag (801.1Q), IPv4:UDP dummy packet */

 ICE_MAC_OFOS 0 */

 ICE_VLAN_OFOS 12 */

 ICE_ETYPE_OL 16 */

 ICE_IPV4_OFOS 18 */

 ICE_UDP_ILOS 38 */

 2 bytes for 4 byte alignment */

 offset info for MAC + IPv4 + TCP dummy packet */

 Dummy packet for MAC + IPv4 + TCP */

 ICE_MAC_OFOS 0 */

 ICE_ETYPE_OL 12 */

 ICE_IPV4_OFOS 14 */

 ICE_TCP_IL 34 */

 2 bytes for 4 byte alignment */

 offset info for MAC + VLAN (C-tag, 802.1Q) + IPv4 + TCP dummy packet */

 C-tag (801.1Q), IPv4:TCP dummy packet */

 ICE_MAC_OFOS 0 */

 ICE_VLAN_OFOS 12 */

 ICE_ETYPE_OL 16 */

 ICE_IPV4_OFOS 18 */

 ICE_TCP_IL 38 */

 2 bytes for 4 byte alignment */

 ICE_MAC_OFOS 0 */

 ICE_ETYPE_OL 12 */

 ICE_IPV6_OFOS 40 */

 Next header is TCP */

 ICE_TCP_IL 54 */

 2 bytes for 4 byte alignment */

 C-tag (802.1Q): IPv6 + TCP */

 C-tag (802.1Q), IPv6 + TCP dummy packet */

 ICE_MAC_OFOS 0 */

 ICE_VLAN_OFOS 12 */

 ICE_ETYPE_OL 16 */

 ICE_IPV6_OFOS 18 */

 Next header is TCP */

 ICE_TCP_IL 58 */

 2 bytes for 4 byte alignment */

 IPv6 + UDP */

 IPv6 + UDP dummy packet */

 ICE_MAC_OFOS 0 */

 ICE_ETYPE_OL 12 */

 ICE_IPV6_OFOS 40 */

 Next header UDP */

 ICE_UDP_ILOS 54 */

 needed for ESP packets */

 2 bytes for 4 byte alignment */

 C-tag (802.1Q): IPv6 + UDP */

 C-tag (802.1Q), IPv6 + UDP dummy packet */

 ICE_MAC_OFOS 0 */

 ICE_VLAN_OFOS 12 */

 ICE_ETYPE_OL 16 */

 ICE_IPV6_OFOS 18 */

 Next header UDP */

 ICE_UDP_ILOS 58 */

 2 bytes for 4 byte alignment */

 this is a recipe to profile association bitmap */

 this is a profile to recipe association bitmap */

/**

 * ice_init_def_sw_recp - initialize the recipe book keeping tables

 * @hw: pointer to the HW struct

 *

 * Allocate memory for the entire recipe table and initialize the structures/

 * entries corresponding to basic recipes.

/**

 * ice_aq_get_sw_cfg - get switch configuration

 * @hw: pointer to the hardware structure

 * @buf: pointer to the result buffer

 * @buf_size: length of the buffer available for response

 * @req_desc: pointer to requested descriptor

 * @num_elems: pointer to number of elements

 * @cd: pointer to command details structure or NULL

 *

 * Get switch configuration (0x0200) to be placed in buf.

 * This admin command returns information such as initial VSI/port number

 * and switch ID it belongs to.

 *

 * NOTE: *req_desc is both an input/output parameter.

 * The caller of this function first calls this function with *request_desc set

 * to 0. If the response from f/w has *req_desc set to 0, all the switch

 * configuration information has been returned; if non-zero (meaning not all

 * the information was returned), the caller should call this function again

 * with *req_desc set to the previous value returned by f/w to get the

 * next block of switch configuration information.

 *

 * *num_elems is output only parameter. This reflects the number of elements

 * in response buffer. The caller of this function to use *num_elems while

 * parsing the response buffer.

/**

 * ice_aq_add_vsi

 * @hw: pointer to the HW struct

 * @vsi_ctx: pointer to a VSI context struct

 * @cd: pointer to command details structure or NULL

 *

 * Add a VSI context to the hardware (0x0210)

/**

 * ice_aq_free_vsi

 * @hw: pointer to the HW struct

 * @vsi_ctx: pointer to a VSI context struct

 * @keep_vsi_alloc: keep VSI allocation as part of this PF's resources

 * @cd: pointer to command details structure or NULL

 *

 * Free VSI context info from hardware (0x0213)

/**

 * ice_aq_update_vsi

 * @hw: pointer to the HW struct

 * @vsi_ctx: pointer to a VSI context struct

 * @cd: pointer to command details structure or NULL

 *

 * Update VSI context in the hardware (0x0211)

/**

 * ice_is_vsi_valid - check whether the VSI is valid or not

 * @hw: pointer to the HW struct

 * @vsi_handle: VSI handle

 *

 * check whether the VSI is valid or not

/**

 * ice_get_hw_vsi_num - return the HW VSI number

 * @hw: pointer to the HW struct

 * @vsi_handle: VSI handle

 *

 * return the HW VSI number

 * Caution: call this function only if VSI is valid (ice_is_vsi_valid)

/**

 * ice_get_vsi_ctx - return the VSI context entry for a given VSI handle

 * @hw: pointer to the HW struct

 * @vsi_handle: VSI handle

 *

 * return the VSI context entry for a given VSI handle

/**

 * ice_save_vsi_ctx - save the VSI context for a given VSI handle

 * @hw: pointer to the HW struct

 * @vsi_handle: VSI handle

 * @vsi: VSI context pointer

 *

 * save the VSI context entry for a given VSI handle

/**

 * ice_clear_vsi_q_ctx - clear VSI queue contexts for all TCs

 * @hw: pointer to the HW struct

 * @vsi_handle: VSI handle

/**

 * ice_clear_vsi_ctx - clear the VSI context entry

 * @hw: pointer to the HW struct

 * @vsi_handle: VSI handle

 *

 * clear the VSI context entry

/**

 * ice_clear_all_vsi_ctx - clear all the VSI context entries

 * @hw: pointer to the HW struct

/**

 * ice_add_vsi - add VSI context to the hardware and VSI handle list

 * @hw: pointer to the HW struct

 * @vsi_handle: unique VSI handle provided by drivers

 * @vsi_ctx: pointer to a VSI context struct

 * @cd: pointer to command details structure or NULL

 *

 * Add a VSI context to the hardware also add it into the VSI handle list.

 * If this function gets called after reset for existing VSIs then update

 * with the new HW VSI number in the corresponding VSI handle list entry.

 Create a new VSI context */

 update with new HW VSI num */

/**

 * ice_free_vsi- free VSI context from hardware and VSI handle list

 * @hw: pointer to the HW struct

 * @vsi_handle: unique VSI handle

 * @vsi_ctx: pointer to a VSI context struct

 * @keep_vsi_alloc: keep VSI allocation as part of this PF's resources

 * @cd: pointer to command details structure or NULL

 *

 * Free VSI context info from hardware as well as from VSI handle list

/**

 * ice_update_vsi

 * @hw: pointer to the HW struct

 * @vsi_handle: unique VSI handle

 * @vsi_ctx: pointer to a VSI context struct

 * @cd: pointer to command details structure or NULL

 *

 * Update VSI context in the hardware

/**

 * ice_cfg_rdma_fltr - enable/disable RDMA filtering on VSI

 * @hw: pointer to HW struct

 * @vsi_handle: VSI SW index

 * @enable: boolean for enable/disable

/**

 * ice_aq_alloc_free_vsi_list

 * @hw: pointer to the HW struct

 * @vsi_list_id: VSI list ID returned or used for lookup

 * @lkup_type: switch rule filter lookup type

 * @opc: switch rules population command type - pass in the command opcode

 *

 * allocates or free a VSI list resource

/**

 * ice_aq_sw_rules - add/update/remove switch rules

 * @hw: pointer to the HW struct

 * @rule_list: pointer to switch rule population list

 * @rule_list_sz: total size of the rule list in bytes

 * @num_rules: number of switch rules in the rule_list

 * @opc: switch rules population command type - pass in the command opcode

 * @cd: pointer to command details structure or NULL

 *

 * Add(0x02a0)/Update(0x02a1)/Remove(0x02a2) switch rules commands to firmware

/**

 * ice_aq_add_recipe - add switch recipe

 * @hw: pointer to the HW struct

 * @s_recipe_list: pointer to switch rule population list

 * @num_recipes: number of switch recipes in the list

 * @cd: pointer to command details structure or NULL

 *

 * Add(0x0290)

/**

 * ice_aq_get_recipe - get switch recipe

 * @hw: pointer to the HW struct

 * @s_recipe_list: pointer to switch rule population list

 * @num_recipes: pointer to the number of recipes (input and output)

 * @recipe_root: root recipe number of recipe(s) to retrieve

 * @cd: pointer to command details structure or NULL

 *

 * Get(0x0292)

 *

 * On input, *num_recipes should equal the number of entries in s_recipe_list.

 * On output, *num_recipes will equal the number of entries returned in

 * s_recipe_list.

 *

 * The caller must supply enough space in s_recipe_list to hold all possible

 * recipes and *num_recipes must equal ICE_MAX_NUM_RECIPES.

/**

 * ice_aq_map_recipe_to_profile - Map recipe to packet profile

 * @hw: pointer to the HW struct

 * @profile_id: package profile ID to associate the recipe with

 * @r_bitmap: Recipe bitmap filled in and need to be returned as response

 * @cd: pointer to command details structure or NULL

 * Recipe to profile association (0x0291)

	/* Set the recipe ID bit in the bitmask to let the device know which

	 * profile we are associating the recipe to

/**

 * ice_aq_get_recipe_to_profile - Map recipe to packet profile

 * @hw: pointer to the HW struct

 * @profile_id: package profile ID to associate the recipe with

 * @r_bitmap: Recipe bitmap filled in and need to be returned as response

 * @cd: pointer to command details structure or NULL

 * Associate profile ID with given recipe (0x0293)

/**

 * ice_alloc_recipe - add recipe resource

 * @hw: pointer to the hardware structure

 * @rid: recipe ID returned as response to AQ call

/**

 * ice_get_recp_to_prof_map - updates recipe to profile mapping

 * @hw: pointer to hardware structure

 *

 * This function is used to populate recipe_to_profile matrix where index to

 * this array is the recipe ID and the element is the mapping of which profiles

 * is this recipe mapped to.

/**

 * ice_collect_result_idx - copy result index values

 * @buf: buffer that contains the result index

 * @recp: the recipe struct to copy data into

/**

 * ice_get_recp_frm_fw - update SW bookkeeping from FW recipe entries

 * @hw: pointer to hardware structure

 * @recps: struct that we need to populate

 * @rid: recipe ID that we are populating

 * @refresh_required: true if we should get recipe to profile mapping from FW

 *

 * This function is used to populate all the necessary entries into our

 * bookkeeping so that we have a current list of all the recipes that are

 * programmed in the firmware.

 we need a buffer big enough to accommodate all the recipes */

 non-zero status meaning recipe doesn't exist */

	/* Get recipe to profile map so that we can get the fv from lkups that

	 * we read for a recipe from FW. Since we want to minimize the number of

	 * times we make this FW call, just make one call and cache the copy

	 * until a new recipe is added. This operation is only required the

	 * first time to get the changes from FW. Then to search existing

	 * entries we don't need to update the cache again until another recipe

	 * gets added.

	/* Start populating all the entries for recps[rid] based on lkups from

	 * firmware. Note that we are only creating the root recipe in our

	 * database.

 Mark all result indices in this chain */

 get the first profile that is associated with rid */

			/* If the recipe is a chained recipe then all its

			 * child recipe's result will have a result index.

			 * To fill fv_words we should not use those result

			 * index, we only need the protocol ids and offsets.

			 * We will skip all the fv_idx which stores result

			 * index in them. We also need to skip any fv_idx which

			 * has ICE_AQ_RECIPE_LKUP_IGNORE or 0 since it isn't a

			 * valid offset value.

		/* populate rg_list with the data from the child entry of this

		 * recipe

 Propagate some data to the recipe database */

 Only do the following for root recipes entries */

 Complete initialization of the root recipe entry */

 Copy result indexes */

/* ice_init_port_info - Initialize port_info with switch configuration data

 * @pi: pointer to port_info

 * @vsi_port_num: VSI number or port number

 * @type: Type of switch element (port or VSI)

 * @swid: switch ID of the switch the element is attached to

 * @pf_vf_num: PF or VF number

 * @is_vf: true if the element is a VF, false otherwise

/* ice_get_initial_sw_cfg - Get initial port and default VSI data

 * @hw: pointer to the hardware structure

	/* Multiple calls to ice_aq_get_sw_cfg may be required

	 * to get all the switch configuration information. The need

	 * for additional calls is indicated by ice_aq_get_sw_cfg

	 * writing a non-zero value in req_desc

 FW VSI is not needed. Just continue. */

/**

 * ice_fill_sw_info - Helper function to populate lb_en and lan_en

 * @hw: pointer to the hardware structure

 * @fi: filter info structure to fill/update

 *

 * This helper function populates the lb_en and lan_en elements of the provided

 * ice_fltr_info struct using the switch's type and characteristics of the

 * switch rule being configured.

		/* Setting LB for prune actions will result in replicated

		 * packets to the internal switch that will be dropped.

		/* Set lan_en to TRUE if

		 * 1. The switch is a VEB AND

		 * 2

		 * 2.1 The lookup is a directional lookup like ethertype,

		 * promiscuous, ethertype-MAC, promiscuous-VLAN

		 * and default-port OR

		 * 2.2 The lookup is VLAN, OR

		 * 2.3 The lookup is MAC with mcast or bcast addr for MAC, OR

		 * 2.4 The lookup is MAC_VLAN with mcast or bcast addr for MAC.

		 *

		 * OR

		 *

		 * The switch is a VEPA.

		 *

		 * In all other cases, the LAN enable has to be set to false.

/**

 * ice_fill_sw_rule - Helper function to fill switch rule structure

 * @hw: pointer to the hardware structure

 * @f_info: entry containing packet forwarding information

 * @s_rule: switch rule structure to be filled in based on mac_entry

 * @opc: switch rules population command type - pass in the command opcode

 initialize the ether header with a dummy header */

 Recipe set depending on lookup type */

 Create the switch rule with the final dummy Ethernet header */

/**

 * ice_add_marker_act

 * @hw: pointer to the hardware structure

 * @m_ent: the management entry for which sw marker needs to be added

 * @sw_marker: sw marker to tag the Rx descriptor with

 * @l_id: large action resource ID

 *

 * Create a large action to hold software marker and update the switch rule

 * entry pointed by m_ent with newly created large action

	/* For software marker we need 3 large actions

	 * 1. FWD action: FWD TO VSI or VSI LIST

	 * 2. GENERIC VALUE action to hold the profile ID

	 * 3. GENERIC VALUE action to hold the software marker ID

	/* Create two back-to-back switch rules and submit them to the HW using

	 * one memory buffer:

	 *    1. Large Action

	 *    2. Look up Tx Rx

 Fill in the first switch rule i.e. large action */

	/* First action VSI forwarding or VSI list forwarding depending on how

	 * many VSIs

 Second action descriptor type */

 Third action Marker value */

 call the fill switch rule to fill the lookup Tx Rx structure */

 Update the action to point to the large action ID */

	/* Use the filter rule ID of the previously created rule with single

	 * act. Once the update happens, hardware will treat this as large

	 * action

/**

 * ice_create_vsi_list_map

 * @hw: pointer to the hardware structure

 * @vsi_handle_arr: array of VSI handles to set in the VSI mapping

 * @num_vsi: number of VSI handles in the array

 * @vsi_list_id: VSI list ID generated as part of allocate resource

 *

 * Helper function to create a new entry of VSI list ID to VSI mapping

 * using the given VSI list ID

/**

 * ice_update_vsi_list_rule

 * @hw: pointer to the hardware structure

 * @vsi_handle_arr: array of VSI handles to form a VSI list

 * @num_vsi: number of VSI handles in the array

 * @vsi_list_id: VSI list ID generated as part of allocate resource

 * @remove: Boolean value to indicate if this is a remove action

 * @opc: switch rules population command type - pass in the command opcode

 * @lkup_type: lookup type of the filter

 *

 * Call AQ command to add a new switch rule or update existing switch rule

 * using the given VSI list ID

 AQ call requires hw_vsi_id(s) */

/**

 * ice_create_vsi_list_rule - Creates and populates a VSI list rule

 * @hw: pointer to the HW struct

 * @vsi_handle_arr: array of VSI handles to form a VSI list

 * @num_vsi: number of VSI handles in the array

 * @vsi_list_id: stores the ID of the VSI list to be created

 * @lkup_type: switch rule filter's lookup type

 Update the newly created VSI list to include the specified VSIs */

/**

 * ice_create_pkt_fwd_rule

 * @hw: pointer to the hardware structure

 * @f_entry: entry containing packet forwarding information

 *

 * Create switch rule with given filter information and add an entry

 * to the corresponding filter management list to track this switch rule

 * and VSI mapping

 Initialize all the fields for the management entry */

	/* The book keeping entries will get removed when base driver

	 * calls remove filter AQ command

/**

 * ice_update_pkt_fwd_rule

 * @hw: pointer to the hardware structure

 * @f_info: filter information for switch rule

 *

 * Call AQ command to update a previously created switch rule with a

 * VSI list ID

 Update switch rule with new rule set to forward VSI list */

/**

 * ice_update_sw_rule_bridge_mode

 * @hw: pointer to the HW struct

 *

 * Updates unicast switch filter rules based on VEB/VEPA mode

 Lock to protect filter rule list */

		/* Update unicast Tx rules to reflect the selected

		 * VEB/VEPA mode

/**

 * ice_add_update_vsi_list

 * @hw: pointer to the hardware structure

 * @m_entry: pointer to current filter management list entry

 * @cur_fltr: filter information from the book keeping entry

 * @new_fltr: filter information with the new VSI to be added

 *

 * Call AQ command to add or update previously created VSI list with new VSI.

 *

 * Helper function to do book keeping associated with adding filter information

 * The algorithm to do the book keeping is described below :

 * When a VSI needs to subscribe to a given filter (MAC/VLAN/Ethtype etc.)

 *	if only one VSI has been added till now

 *		Allocate a new VSI list and add two VSIs

 *		to this list using switch rule command

 *		Update the previously created switch rule with the

 *		newly created VSI list ID

 *	if a VSI list was previously created

 *		Add the new VSI to the previously created VSI list set

 *		using the update switch rule command

		/* Only one entry existed in the mapping and it was not already

		 * a part of a VSI list. So, create a VSI list with the old and

		 * new VSIs.

 A rule already exists with the new VSI being added */

		/* Update the previous switch rule of "MAC forward to VSI" to

		 * "MAC fwd to VSI list"

		/* If this entry was large action then the large action needs

		 * to be updated to point to FWD to VSI list

 A rule already exists with the new VSI being added */

		/* Update the previously created VSI list set with

		 * the new VSI ID passed in

 update VSI list mapping info with new VSI ID */

/**

 * ice_find_rule_entry - Search a rule entry

 * @hw: pointer to the hardware structure

 * @recp_id: lookup type for which the specified rule needs to be searched

 * @f_info: rule information

 *

 * Helper function to search for a given rule entry

 * Returns pointer to entry storing the rule if found

/**

 * ice_find_vsi_list_entry - Search VSI list map with VSI count 1

 * @hw: pointer to the hardware structure

 * @recp_id: lookup type for which VSI lists needs to be searched

 * @vsi_handle: VSI handle to be found in VSI list

 * @vsi_list_id: VSI list ID found containing vsi_handle

 *

 * Helper function to search a VSI list with single entry containing given VSI

 * handle element. This can be extended further to search VSI list with more

 * than 1 vsi_count. Returns pointer to VSI list entry if found.

/**

 * ice_add_rule_internal - add rule for a given lookup type

 * @hw: pointer to the hardware structure

 * @recp_id: lookup type (recipe ID) for which rule has to be added

 * @f_entry: structure containing MAC forwarding information

 *

 * Adds or updates the rule lists for a given recipe

 Lock to protect filter rule list */

/**

 * ice_remove_vsi_list_rule

 * @hw: pointer to the hardware structure

 * @vsi_list_id: VSI list ID generated as part of allocate resource

 * @lkup_type: switch rule filter lookup type

 *

 * The VSI list should be emptied before this function is called to remove the

 * VSI list.

	/* Free the vsi_list resource that we allocated. It is assumed that the

	 * list is empty at this point.

/**

 * ice_rem_update_vsi_list

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle of the VSI to remove

 * @fm_list: filter management entry for which the VSI list management needs to

 *           be done

 A rule with the VSI being removed does not exist */

 Make sure VSI list is empty before removing it below */

 Remove the VSI list since it is no longer used */

/**

 * ice_remove_rule_internal - Remove a filter rule of a given type

 * @hw: pointer to the hardware structure

 * @recp_id: recipe ID for which the rule needs to removed

 * @f_entry: rule entry containing filter information

 Lock to protect filter rule list */

		/* a ref_cnt > 1 indicates that the vsi_list is being

		 * shared by multiple rules. Decrement the ref_cnt and

		 * remove this rule, but do not modify the list, as it

		 * is in-use by other rules.

		/* a ref_cnt of 1 indicates the vsi_list is only used

		 * by one rule. However, the original removal request is only

		 * for a single VSI. Update the vsi_list first, and only

		 * remove the rule if there are no further VSIs in this list.

 if VSI count goes to zero after updating the VSI list */

 Remove the lookup rule */

 Remove a book keeping from the list */

/**

 * ice_mac_fltr_exist - does this MAC filter exist for given VSI

 * @hw: pointer to the hardware structure

 * @mac: MAC address to be checked (for MAC filter)

 * @vsi_handle: check MAC filter for this VSI

 Lock to protect filter rule list */

/**

 * ice_vlan_fltr_exist - does this VLAN filter exist for given VSI

 * @hw: pointer to the hardware structure

 * @vlan_id: VLAN ID

 * @vsi_handle: check MAC filter for this VSI

 Lock to protect filter rule list */

 Only allowed filter action are FWD_TO_VSI/_VSI_LIST */

			/* If filter_action is FWD_TO_VSI_LIST, make sure

			 * that VSI being checked is part of VSI list

/**

 * ice_add_mac - Add a MAC address based filter rule

 * @hw: pointer to the hardware structure

 * @m_list: list of MAC addresses and forwarding information

 *

 * IMPORTANT: When the ucast_shared flag is set to false and m_list has

 * multiple unicast addresses, the function assumes that all the

 * addresses are unique in a given add_mac call. It doesn't

 * check for duplicates in this case, removing duplicates from a given

 * list should be taken care of in the caller of this function.

 Lock to protect filter rule list */

 update the src in case it is VSI num */

 Don't overwrite the unicast address */

 Exit if no suitable entries were found for adding bulk switch rule */

 Allocate switch rule buffer for the bulk update for unicast */

 Call AQ bulk switch rule update for all unicast addresses */

 Call AQ switch rule in AQ_MAX chunk */

 Fill up rule ID based on the value returned from FW */

 Create an entry to track this MAC address */

			/* The book keeping entries will get removed when

			 * base driver calls remove filter AQ command

/**

 * ice_add_vlan_internal - Add one VLAN based filter rule

 * @hw: pointer to the hardware structure

 * @f_entry: filter entry containing one VLAN information

 Lock to protect filter rule list */

 VLAN ID should only be 12 bits */

			/* All VLAN pruning rules use a VSI list. Check if

			 * there is already a VSI list containing VSI that we

			 * want to add. If found, use the same vsi_list_id for

			 * this new VLAN rule or else create a new list.

 Convert the action to forwarding to a VSI list. */

 reuse VSI list for new rule and increment ref_cnt */

		/* Update existing VSI list to add new VSI ID only if it used

		 * by one VLAN rule.

		/* If VLAN rule exists and VSI list being used by this rule is

		 * referenced by more than 1 VLAN rule. Then create a new VSI

		 * list appending previous VSI with new VSI and update existing

		 * VLAN rule to point to new VSI list ID

		/* Current implementation only supports reusing VSI list with

		 * one VSI count. We should never hit below condition

 A rule already exists with the new VSI being added */

		/* Update the previous switch rule to a new VSI list which

		 * includes current VSI that is requested

		/* before overriding VSI list map info. decrement ref_cnt of

		 * previous VSI list

 now update to newly created list */

/**

 * ice_add_vlan - Add VLAN based filter rule

 * @hw: pointer to the hardware structure

 * @v_list: list of VLAN entries and forwarding information

/**

 * ice_add_eth_mac - Add ethertype and MAC based filter rule

 * @hw: pointer to the hardware structure

 * @em_list: list of ether type MAC filter, MAC is optional

 *

 * This function requires the caller to populate the entries in

 * the filter list with the necessary fields (including flags to

 * indicate Tx or Rx rules).

/**

 * ice_remove_eth_mac - Remove an ethertype (or MAC) based filter rule

 * @hw: pointer to the hardware structure

 * @em_list: list of ethertype or ethertype MAC entries

/**

 * ice_rem_sw_rule_info

 * @hw: pointer to the hardware structure

 * @rule_head: pointer to the switch list structure that we want to delete

/**

 * ice_rem_adv_rule_info

 * @hw: pointer to the hardware structure

 * @rule_head: pointer to the switch list structure that we want to delete

/**

 * ice_cfg_dflt_vsi - change state of VSI to set/clear default

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle to set as default

 * @set: true to add the above mentioned switch rule, false to remove it

 * @direction: ICE_FLTR_RX or ICE_FLTR_TX

 *

 * add filter rule to set/unset given VSI as default VSI for the switch

 * (represented by swid)

/**

 * ice_find_ucast_rule_entry - Search for a unicast MAC filter rule entry

 * @hw: pointer to the hardware structure

 * @recp_id: lookup type for which the specified rule needs to be searched

 * @f_info: rule information

 *

 * Helper function to search for a unicast rule entry - this is to be used

 * to remove unicast MAC filter that is not shared with other VSIs on the

 * PF switch.

 *

 * Returns pointer to entry storing the rule if found

/**

 * ice_remove_mac - remove a MAC address based filter rule

 * @hw: pointer to the hardware structure

 * @m_list: list of MAC addresses and forwarding information

 *

 * This function removes either a MAC filter rule or a specific VSI from a

 * VSI list for a multicast MAC address.

 *

 * Returns ICE_ERR_DOES_NOT_EXIST if a given entry was not added by

 * ice_add_mac. Caller should be aware that this call will only work if all

 * the entries passed into m_list were added previously. It will not attempt to

 * do a partial remove of entries that were found.

 Lock to protect filter rule list */

			/* Don't remove the unicast address that belongs to

			 * another VSI on the switch, since it is not being

			 * shared...

/**

 * ice_remove_vlan - Remove VLAN based filter rule

 * @hw: pointer to the hardware structure

 * @v_list: list of VLAN entries and forwarding information

/**

 * ice_vsi_uses_fltr - Determine if given VSI uses specified filter

 * @fm_entry: filter entry to inspect

 * @vsi_handle: VSI handle to compare with filter info

/**

 * ice_add_entry_to_vsi_fltr_list - Add copy of fltr_list_entry to remove list

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle to remove filters from

 * @vsi_list_head: pointer to the list to add entry to

 * @fi: pointer to fltr_info of filter entry to copy & add

 *

 * Helper function, used when creating a list of filters to remove from

 * a specific VSI. The entry added to vsi_list_head is a COPY of the

 * original filter entry, with the exception of fltr_info.fltr_act and

 * fltr_info.fwd_id fields. These are set such that later logic can

 * extract which VSI to remove the fltr from, and pass on that information.

	/* this memory is freed up in the caller function

	 * once filters for this VSI are removed

	/* Overwrite these fields to indicate which VSI to remove filter from,

	 * so find and remove logic can extract the information from the

	 * list entries. Note that original entries will still have proper

	 * values.

/**

 * ice_add_to_vsi_fltr_list - Add VSI filters to the list

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle to remove filters from

 * @lkup_list_head: pointer to the list that has certain lookup type filters

 * @vsi_list_head: pointer to the list pertaining to VSI with vsi_handle

 *

 * Locates all filters in lkup_list_head that are used by the given VSI,

 * and adds COPIES of those entries to vsi_list_head (intended to be used

 * to remove the listed filters).

 * Note that this means all entries in vsi_list_head must be explicitly

 * deallocated by the caller when done with list.

 check to make sure VSI ID is valid and within boundary */

/**

 * ice_determine_promisc_mask

 * @fi: filter info to parse

 *

 * Helper function to determine which ICE_PROMISC_ mask corresponds

 * to given filter into.

/**

 * ice_remove_promisc - Remove promisc based filter rules

 * @hw: pointer to the hardware structure

 * @recp_id: recipe ID for which the rule needs to removed

 * @v_list: list of promisc entries

/**

 * ice_clear_vsi_promisc - clear specified promiscuous mode(s) for given VSI

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle to clear mode

 * @promisc_mask: mask of promiscuous config bits to clear

 * @vid: VLAN ID to clear VLAN promiscuous

 Lock to protect filter rule list */

 Skip if filter is not completely specified by given mask */

/**

 * ice_set_vsi_promisc - set given VSI to given promiscuous mode(s)

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle to configure

 * @promisc_mask: mask of promiscuous config bits

 * @vid: VLAN ID to set VLAN promiscuous

	/* Separate filters must be set for each direction/packet type

	 * combination, so we will loop over the mask value, store the

	 * individual type, and clear it out in the input mask as it

	 * is found.

 Check for VLAN promiscuous flag */

 Set filter DA based on packet type */

 Use the dummy ether header DA */

 Set multicast bit */

 Need to reset this to zero for all iterations */

/**

 * ice_set_vlan_vsi_promisc

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle to configure

 * @promisc_mask: mask of promiscuous config bits

 * @rm_vlan_promisc: Clear VLANs VSI promisc mode

 *

 * Configure VSI with all associated VLANs to given promiscuous mode(s)

 Lock to protect filter rule list */

/**

 * ice_remove_vsi_lkup_fltr - Remove lookup type filters for a VSI

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle to remove filters from

 * @lkup: switch rule filter lookup type

 Lock to protect filter rule list */

/**

 * ice_remove_vsi_fltr - Remove all filters for a VSI

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle to remove filters from

/**

 * ice_alloc_res_cntr - allocating resource counter

 * @hw: pointer to the hardware structure

 * @type: type of resource

 * @alloc_shared: if set it is shared else dedicated

 * @num_items: number of entries requested for FD resource type

 * @counter_id: counter index returned by AQ call

 Allocate resource */

/**

 * ice_free_res_cntr - free resource counter

 * @hw: pointer to the hardware structure

 * @type: type of resource

 * @alloc_shared: if set it is shared else dedicated

 * @num_items: number of entries to be freed for FD resource type

 * @counter_id: counter ID resource which needs to be freed

 Free resource */

/* This is mapping table entry that maps every word within a given protocol

 * structure to the real byte offset as per the specification of that

 * protocol header.

 * for example dst address is 3 words in ethertype header and corresponding

 * bytes are 0, 2, 3 in the actual packet header and src address is at 4, 6, 8

 * IMPORTANT: Every structure part of "ice_prot_hdr" union should have a

 * matching entry describing its field. This needs to be updated if new

 * structure is added to that union.

/**

 * ice_find_recp - find a recipe

 * @hw: pointer to the hardware structure

 * @lkup_exts: extension sequence to match

 *

 * Returns index of matching recipe, or ICE_MAX_NUM_RECIPES if not found.

 Walk through existing recipes to find a match */

		/* If recipe was not created for this ID, in SW bookkeeping,

		 * check if FW has an entry for this recipe. If the FW has an

		 * entry update it in our SW bookkeeping and continue with the

		 * matching.

 Skip inverse action recipes */

 if number of words we are looking for match */

			/* ar, cr, and qr are related to the recipe words, while

			 * be, de, and pe are related to the lookup words

						/* Found the "pe"th word in the

						 * given recipe

				/* After walking through all the words in the

				 * "i"th recipe if "p"th word was not found then

				 * this recipe is not what we are looking for.

				 * So break out from this loop and try the next

				 * recipe

			/* If for "i"th recipe the found was never set to false

			 * then it means we found our match

 Return the recipe ID */

/**

 * ice_prot_type_to_id - get protocol ID from protocol type

 * @type: protocol type

 * @id: pointer to variable that will receive the ID

 *

 * Returns true if found, false otherwise

/**

 * ice_fill_valid_words - count valid words

 * @rule: advanced rule with lookup information

 * @lkup_exts: byte offset extractions of the words that are valid

 *

 * calculate valid words in a lookup rule using mask value

 No more space to accommodate */

/**

 * ice_create_first_fit_recp_def - Create a recipe grouping

 * @hw: pointer to the hardware structure

 * @lkup_exts: an array of protocol header extractions

 * @rg_list: pointer to a list that stores new recipe groups

 * @recp_cnt: pointer to a variable that stores returned number of recipe groups

 *

 * Using first fit algorithm, take all the words that are still not done

 * and start grouping them in 4-word groups. Each group makes up one

 * recipe.

	/* Walk through every word in the rule to check if it is not done. If so

	 * then this word needs to be part of a new recipe.

/**

 * ice_fill_fv_word_index - fill in the field vector indices for a recipe group

 * @hw: pointer to the hardware structure

 * @fv_list: field vector with the extraction sequence information

 * @rg_list: recipe groupings with protocol-offset pairs

 *

 * Helper function to fill in the field vector indices for protocol-offset

 * pairs. These indexes are then ultimately programmed into a recipe.

 Store index of field vector */

			/* Protocol/offset could not be found, caller gave an

			 * invalid pair

/**

 * ice_find_free_recp_res_idx - find free result indexes for recipe

 * @hw: pointer to hardware structure

 * @profiles: bitmap of profiles that will be associated with the new recipe

 * @free_idx: pointer to variable to receive the free index bitmap

 *

 * The algorithm used here is:

 *	1. When creating a new recipe, create a set P which contains all

 *	   Profiles that will be associated with our new recipe

 *

 *	2. For each Profile p in set P:

 *	    a. Add all recipes associated with Profile p into set R

 *	    b. Optional : PossibleIndexes &= profile[p].possibleIndexes

 *		[initially PossibleIndexes should be 0xFFFFFFFFFFFFFFFF]

 *		i. Or just assume they all have the same possible indexes:

 *			44, 45, 46, 47

 *			i.e., PossibleIndexes = 0x0000F00000000000

 *

 *	3. For each Recipe r in set R:

 *	    a. UsedIndexes |= (bitwise or ) recipe[r].res_indexes

 *	    b. FreeIndexes = UsedIndexes ^ PossibleIndexes

 *

 *	FreeIndexes will contain the bits indicating the indexes free for use,

 *      then the code needs to update the recipe[r].used_result_idx_bits to

 *      indicate which indexes were selected for use by this recipe.

	/* For each profile we are going to associate the recipe with, add the

	 * recipes that are associated with that profile. This will give us

	 * the set of recipes that our recipe may collide with. Also, determine

	 * what possible result indexes are usable given this set of profiles.

	/* For each recipe that our new recipe may collide with, determine

	 * which indexes have been used.

 return number of free indexes */

/**

 * ice_add_sw_recipe - function to call AQ calls to create switch recipe

 * @hw: pointer to hardware structure

 * @rm: recipe management list entry

 * @profiles: bitmap of profiles that will be associated.

	/* When more than one recipe are required, another recipe is needed to

	 * chain them together. Matching a tunnel metadata ID takes up one of

	 * the match fields in the chaining recipe reducing the number of

	 * chained recipes by one.

 check number of free result indices */

	/* Allocate the recipe resources, and configure them according to the

	 * match fields from protocol headers and extracted field vectors.

		/* Clear the result index of the located recipe, as this will be

		 * updated, if needed, later in the recipe creation process.

		/* if the recipe is a non-root recipe RID should be programmed

		 * as 0 for the rules to be applied correctly.

 All recipes use look-up index 0 to match switch ID. */

		/* Setup lkup_indx 1..4 to INVALID/ignore and set the mask

		 * to be 0

			/* Checks to see if there really is a valid result index

			 * that can be used.

 fill recipe dependencies */

		/* Applicable only for ROOT_RECIPE, set the fwd_priority for

		 * the recipe which is getting created if specified

		 * by user. Usually any advanced switch filter, which results

		 * into new extraction sequence, ended up creating a new recipe

		 * of type ROOT and usually recipes are associated with profiles

		 * Switch rule referreing newly created recipe, needs to have

		 * either/or 'fwd' or 'join' priority, otherwise switch rule

		 * evaluation will not happen correctly. In other words, if

		 * switch rule to be evaluated on priority basis, then recipe

		 * needs to have priority, otherwise it will be evaluated last.

		/* Allocate the last recipe that will chain the outcomes of the

		 * other recipes together

		/* the new entry created should also be part of rg_list to

		 * make sure we have complete recipe

 All recipes use look-up index 0 to match switch ID. */

 update r_bitmap with the recp that is used for chaining */

		/* this is the recipe that chains all the other recipes so it

		 * should not have a chaining ID to indicate the same

	/* Every recipe that just got created add it to the recipe

	 * book keeping list

 find buffer index for copying some data */

		/* Copy non-result fv index values and masks to recipe. This

		 * call will also update the result recipe bitmask.

		/* for non-root recipes, also copy to the root, this allows

		 * easier matching of a complete chained recipe

/**

 * ice_create_recipe_group - creates recipe group

 * @hw: pointer to hardware structure

 * @rm: recipe management list entry

 * @lkup_exts: lookup elements

	/* Create recipes for words that are marked not done by packing them

	 * as best fit.

/**

 * ice_get_fv - get field vectors/extraction sequences for spec. lookup types

 * @hw: pointer to hardware structure

 * @lkups: lookup elements or match criteria for the advanced recipe, one

 *	   structure per protocol header

 * @lkups_cnt: number of protocols

 * @bm: bitmap of field vectors to consider

 * @fv_list: pointer to a list that holds the returned field vectors

 Find field vectors that include all specified protocol types */

/**

 * ice_tun_type_match_word - determine if tun type needs a match mask

 * @tun_type: tunnel type

 * @mask: mask to be used for the tunnel

/**

 * ice_add_special_words - Add words that are not protocols, such as metadata

 * @rinfo: other information regarding the rule e.g. priority and action info

 * @lkup_exts: lookup word structure

	/* If this is a tunneled packet, then add recipe index to match the

	 * tunnel bit in the packet metadata flags.

/* ice_get_compat_fv_bitmap - Get compatible field vector bitmap for rule

 * @hw: pointer to hardware structure

 * @rinfo: other information regarding the rule e.g. priority and action info

 * @bm: pointer to memory for returning the bitmap of field vectors

/**

 * ice_add_adv_recipe - Add an advanced recipe that is not part of the default

 * @hw: pointer to hardware structure

 * @lkups: lookup elements or match criteria for the advanced recipe, one

 *  structure per protocol header

 * @lkups_cnt: number of protocols

 * @rinfo: other information regarding the rule e.g. priority and action info

 * @rid: return the recipe ID of the recipe created

	/* Determine the number of words to be matched and if it exceeds a

	 * recipe's restrictions

	/* Get field vectors that contain fields extracted from all the protocol

	 * headers being programmed.

	/* Get bitmap of field vectors (profiles) that are compatible with the

	 * rule request; only these will be searched in the subsequent call to

	 * ice_get_fv.

	/* Create any special protocol/offset pairs, such as looking at tunnel

	 * bits by extracting metadata

	/* Group match words into recipes using preferred recipe grouping

	 * criteria.

 set the recipe priority if specified */

	/* Find offsets from the field vector. Pick the first one for all the

	 * recipes.

 get bitmap of all profiles the recipe will be associated with */

 Look for a recipe which matches our requested fv / mask list */

 Success if found a recipe that match the existing criteria */

 Recipe we need does not exist, add a recipe */

	/* Associate all the recipes created with all the profiles in the

	 * common field vector.

 Update profile to recipe bitmap array */

 Update recipe to profile bitmap array */

/**

 * ice_find_dummy_packet - find dummy packet

 *

 * @lkups: lookup elements or match criteria for the advanced recipe, one

 *	   structure per protocol header

 * @lkups_cnt: number of protocols

 * @tun_type: tunnel type

 * @pkt: dummy packet to fill according to filter match criteria

 * @pkt_len: packet length of dummy packet

 * @offsets: pointer to receive the pointer to the offsets for the packet

/**

 * ice_fill_adv_dummy_packet - fill a dummy packet with given match criteria

 *

 * @lkups: lookup elements or match criteria for the advanced recipe, one

 *	   structure per protocol header

 * @lkups_cnt: number of protocols

 * @s_rule: stores rule information from the match criteria

 * @dummy_pkt: dummy packet to fill according to filter match criteria

 * @pkt_len: packet length of dummy packet

 * @offsets: offset info for the dummy packet

	/* Start with a packet with a pre-defined/dummy content. Then, fill

	 * in the header values to be looked up or matched.

		/* find the start of this layer; it should be found since this

		 * was already checked when search for the dummy packet

 this should never happen in a correct calling sequence */

 the length should be a word multiple */

		/* We have the offset to the header start, the length, the

		 * caller's header values and mask. Use this information to

		 * copy the data into the dummy packet appropriately based on

		 * the mask. Note that we need to only write the bits as

		 * indicated by the mask to make sure we don't improperly write

		 * over any significant packet data.

/**

 * ice_fill_adv_packet_tun - fill dummy packet with udp tunnel port

 * @hw: pointer to the hardware structure

 * @tun_type: tunnel type

 * @pkt: dummy packet to fill in

 * @offsets: offset info for the dummy packet

 Nothing needs to be done for this tunnel type */

 Find the outer UDP protocol header and insert the port number */

/**

 * ice_find_adv_rule_entry - Search a rule entry

 * @hw: pointer to the hardware structure

 * @lkups: lookup elements or match criteria for the advanced recipe, one

 *	   structure per protocol header

 * @lkups_cnt: number of protocols

 * @recp_id: recipe ID for which we are finding the rule

 * @rinfo: other information regarding the rule e.g. priority and action info

 *

 * Helper function to search for a given advance rule entry

 * Returns pointer to entry storing the rule if found

/**

 * ice_adv_add_update_vsi_list

 * @hw: pointer to the hardware structure

 * @m_entry: pointer to current adv filter management list entry

 * @cur_fltr: filter information from the book keeping entry

 * @new_fltr: filter information with the new VSI to be added

 *

 * Call AQ command to add or update previously created VSI list with new VSI.

 *

 * Helper function to do book keeping associated with adding filter information

 * The algorithm to do the booking keeping is described below :

 * When a VSI needs to subscribe to a given advanced filter

 *	if only one VSI has been added till now

 *		Allocate a new VSI list and add two VSIs

 *		to this list using switch rule command

 *		Update the previously created switch rule with the

 *		newly created VSI list ID

 *	if a VSI list was previously created

 *		Add the new VSI to the previously created VSI list set

 *		using the update switch rule command

		 /* Only one entry existed in the mapping and it was not already

		  * a part of a VSI list. So, create a VSI list with the old and

		  * new VSIs.

 A rule already exists with the new VSI being added */

		/* Update the previous switch rule of "forward to VSI" to

		 * "fwd to VSI list"

 A rule already exists with the new VSI being added */

		/* Update the previously created VSI list set with

		 * the new VSI ID passed in

 update VSI list mapping info with new VSI ID */

/**

 * ice_add_adv_rule - helper function to create an advanced switch rule

 * @hw: pointer to the hardware structure

 * @lkups: information on the words that needs to be looked up. All words

 * together makes one recipe

 * @lkups_cnt: num of entries in the lkups array

 * @rinfo: other information related to the rule that needs to be programmed

 * @added_entry: this will return recipe_id, rule_id and vsi_handle. should be

 *               ignored is case of error.

 *

 * This function can program only 1 rule at a time. The lkups is used to

 * describe the all the words that forms the "lookup" portion of the recipe.

 * These words can span multiple protocols. Callers to this function need to

 * pass in a list of protocol headers with lookup information along and mask

 * that determines which words are valid from the given protocol header.

 * rinfo describes other information related to this rule such as forwarding

 * IDs, priority of this rule, etc.

 Initialize profile to result index bitmap */

 get # of words we need to match */

 make sure that we can locate a dummy packet */

		/* we have to add VSI to VSI_LIST and increment vsi_count.

		 * Also Update VSI list so that we can change forwarding rule

		 * if the rule already exists, we will check if it exists with

		 * same vsi_id, if not then add it to the VSI list if it already

		 * exists if not then create a VSI list and add the existing VSI

		 * ID and the new VSI ID to the list

		 * We will add that VSI to the list

	/* set the rule LOOKUP type based on caller specified 'Rx'

	 * instead of hardcoding it to be either LOOKUP_TX/RX

	 *

	 * for 'Rx' set the source to be the port number

	 * for 'Tx' set the source to be the source HW VSI number (determined

	 * by caller)

 Add rule entry to book keeping list */

/**

 * ice_replay_vsi_fltr - Replay filters for requested VSI

 * @hw: pointer to the hardware structure

 * @vsi_handle: driver VSI handle

 * @recp_id: Recipe ID for which rules need to be replayed

 * @list_head: list for which filters need to be replayed

 *

 * Replays the filter of recipe recp_id for a VSI represented via vsi_handle.

 * It is required to pass valid VSI handle.

 update the src in case it is VSI num */

 Clearing it so that the logic can add it back */

 update the src in case it is VSI num */

/**

 * ice_adv_rem_update_vsi_list

 * @hw: pointer to the hardware structure

 * @vsi_handle: VSI handle of the VSI to remove

 * @fm_list: filter management entry for which the VSI list management needs to

 *	     be done

 A rule with the VSI being removed does not exist */

 Make sure VSI list is empty before removing it below */

		/* Update the previous switch rule of "MAC forward to VSI" to

		 * "MAC fwd to VSI list"

 Remove the VSI list since it is no longer used */

/**

 * ice_rem_adv_rule - removes existing advanced switch rule

 * @hw: pointer to the hardware structure

 * @lkups: information on the words that needs to be looked up. All words

 *         together makes one recipe

 * @lkups_cnt: num of entries in the lkups array

 * @rinfo: Its the pointer to the rule information for the rule

 *

 * This function can be used to remove 1 rule at a time. The lkups is

 * used to describe all the words that forms the "lookup" portion of the

 * rule. These words can span multiple protocols. Callers to this function

 * need to pass in a list of protocol headers with lookup information along

 * and mask that determines which words are valid from the given protocol

 * header. rinfo describes other information related to this rule such as

 * forwarding IDs, priority of this rule, etc.

 Lock to protect filter rule list */

	/* Create any special protocol/offset pairs, such as looking at tunnel

	 * bits by extracting metadata

 If did not find a recipe that match the existing criteria */

 the rule is already removed */

/**

 * ice_rem_adv_rule_by_id - removes existing advanced switch rule by ID

 * @hw: pointer to the hardware structure

 * @remove_entry: data struct which holds rule_id, VSI handle and recipe ID

 *

 * This function is used to remove 1 rule at a time. The removal is based on

 * the remove_entry parameter. This function will remove rule for a given

 * vsi_handle with a given rule_id which is passed as parameter in remove_entry

 either list is empty or unable to find rule */

/**

 * ice_replay_vsi_all_fltr - replay all filters stored in bookkeeping lists

 * @hw: pointer to the hardware structure

 * @vsi_handle: driver VSI handle

 *

 * Replays filters for requested VSI via vsi_handle.

/**

 * ice_rm_all_sw_replay_rule_info - deletes filter replay rules

 * @hw: pointer to the HW struct

 *

 * Deletes the filter replay rules.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

 virtchnl headers (VIRTCHNL_PROTO_HDR_XXX) */

 ice headers (ICE_FLOW_SEG_HDR_XXX) */

	u32 vc_hdr;		/* virtchnl headers

				 * (VIRTCHNL_PROTO_HDR_XXX)

	u32 vc_hash_field;	/* virtchnl hash fields selector

				 * FIELD_SELECTOR((VIRTCHNL_PROTO_HDR_ETH_XXX))

	u64 ice_hash_field;	/* ice hash fields

				 * (BIT_ULL(ICE_FLOW_FIELD_IDX_XXX))

/**

 * ice_get_vf_vsi - get VF's VSI based on the stored index

 * @vf: VF used to get VSI

/**

 * ice_validate_vf_id - helper to check if VF ID is valid

 * @pf: pointer to the PF structure

 * @vf_id: the ID of the VF to check

 vf_id range is only valid for 0-255, and should always be unsigned */

/**

 * ice_check_vf_init - helper to check if VF init complete

 * @pf: pointer to the PF structure

 * @vf: the pointer to the VF to check

/**

 * ice_err_to_virt_err - translate errors for VF return code

 * @ice_err: error return code

/**

 * ice_vc_vf_broadcast - Broadcast a message to all VFs on PF

 * @pf: pointer to the PF structure

 * @v_opcode: operation code

 * @v_retval: return value

 * @msg: pointer to the msg buffer

 * @msglen: msg length

 Not all vfs are enabled so skip the ones that are not */

		/* Ignore return value on purpose - a given VF may fail, but

		 * we need to keep going and send to all of them

/**

 * ice_set_pfe_link - Set the link speed/status of the virtchnl_pf_event

 * @vf: pointer to the VF structure

 * @pfe: pointer to the virtchnl_pf_event to set link speed/status for

 * @ice_link_speed: link speed specified by ICE_AQ_LINK_SPEED_*

 * @link_up: whether or not to set the link up/down

 Speed in Mbps */

 Legacy method for virtchnl link speeds */

/**

 * ice_vf_has_no_qs_ena - check if the VF has any Rx or Tx queues enabled

 * @vf: the VF to check

 *

 * Returns true if the VF has no Rx and no Tx queues enabled and returns false

 * otherwise

/**

 * ice_is_vf_link_up - check if the VF's link is up

 * @vf: VF to check if link is up

/**

 * ice_vc_notify_vf_link_state - Inform a VF of link status

 * @vf: pointer to the VF structure

 *

 * send a link status message to a single VF

/**

 * ice_vf_invalidate_vsi - invalidate vsi_idx/vsi_num to remove VSI access

 * @vf: VF to remove access to VSI for

/**

 * ice_vf_vsi_release - invalidate the VF's VSI after freeing it

 * @vf: invalidate this VF's VSI after freeing it

/**

 * ice_vf_ctrl_invalidate_vsi - invalidate ctrl_vsi_idx to remove VSI access

 * @vf: VF that control VSI is being invalidated on

/**

 * ice_vf_ctrl_vsi_release - invalidate the VF's control VSI after freeing it

 * @vf: VF that control VSI is being released on

/**

 * ice_free_vf_res - Free a VF's resources

 * @vf: pointer to the VF info

	/* First, disable VF's configuration API to prevent OS from

	 * accessing the VF's VSI after it's freed or invalidated.

 free VF control VSI */

 free VSI and disconnect it from the parent uplink */

 clear VF MDD event information */

 Disable interrupts so that VF starts in a known state */

 reset some of the state variables keeping track of the resources */

/**

 * ice_dis_vf_mappings

 * @vf: pointer to the VF structure

/**

 * ice_sriov_free_msix_res - Reset/free any used MSIX resources

 * @pf: pointer to the PF structure

 *

 * Since no MSIX entries are taken from the pf->irq_tracker then just clear

 * the pf->sriov_base_vector.

 *

 * Returns 0 on success, and -EINVAL on error.

 give back irq_tracker resources used */

/**

 * ice_set_vf_state_qs_dis - Set VF queues state to disabled

 * @vf: pointer to the VF structure

 Clear Rx/Tx enabled queues flag */

/**

 * ice_dis_vf_qs - Disable the VF queues

 * @vf: pointer to the VF structure

/**

 * ice_free_vfs - Free all VFs

 * @pf: pointer to the PF structure

	/* Disable IOV before freeing resources. This lets any VF drivers

	 * running in the host get themselves cleaned up before we yank

	 * the carpet out from underneath their feet.

 Avoid wait time by stopping all VFs at the same time */

 disable VF qp mappings and set VF disable state */

	/* This check is for when the driver is unloaded while VFs are

	 * assigned. Setting the number of VFs to 0 through sysfs is caught

	 * before this function ever gets called.

		/* Acknowledge VFLR for all VFs. Without this, VFs will fail to

		 * work correctly when SR-IOV gets re-enabled.

 clear malicious info if the VFs are getting released */

/**

 * ice_trigger_vf_reset - Reset a VF on HW

 * @vf: pointer to the VF structure

 * @is_vflr: true if VFLR was issued, false if not

 * @is_pfr: true if the reset was triggered due to a previous PFR

 *

 * Trigger hardware to start a reset for a particular VF. Expects the caller

 * to wait the proper amount of time to allow hardware to reset the VF before

 * it cleans up and restores VF functionality.

 Inform VF that it is no longer active, as a warning */

	/* Disable VF's configuration API during reset. The flag is re-enabled

	 * when it's safe again to access VF's VSI.

	/* VF_MBX_ARQLEN and VF_MBX_ATQLEN are cleared by PFR, so the driver

	 * needs to clear them in the case of VFR/VFLR. If this is done for

	 * PFR, it can mess up VF resets because the VF driver may already

	 * have started cleanup by the time we get here.

	/* In the case of a VFLR, the HW has already reset the VF and we

	 * just need to clean up, so don't hit the VFRTRIG register.

 reset VF using VPGEN_VFRTRIG reg */

 clear the VFLR bit in GLGEN_VFLRSTAT */

 no transactions pending so stop polling */

/**

 * ice_vsi_manage_pvid - Enable or disable port VLAN for VSI

 * @vsi: the VSI to update

 * @pvid_info: VLAN ID and QoS used to set the PVID VSI context field

 * @enable: true for enable PVID false for disable

/**

 * ice_vf_get_port_info - Get the VF's port info structure

 * @vf: VF used to get the port info structure for

/**

 * ice_vf_vsi_setup - Set up a VF VSI

 * @vf: VF to setup VSI for

 *

 * Returns pointer to the successfully allocated VSI struct on success,

 * otherwise returns NULL on failure.

/**

 * ice_vf_ctrl_vsi_setup - Set up a VF control VSI

 * @vf: VF to setup control VSI for

 *

 * Returns pointer to the successfully allocated VSI struct on success,

 * otherwise returns NULL on failure.

/**

 * ice_calc_vf_first_vector_idx - Calculate MSIX vector index in the PF space

 * @pf: pointer to PF structure

 * @vf: pointer to VF that the first MSIX vector index is being calculated for

 *

 * This returns the first MSIX vector index in PF space that is used by this VF.

 * This index is used when accessing PF relative registers such as

 * GLINT_VECT2FUNC and GLINT_DYN_CTL.

 * This will always be the OICR index in the AVF driver so any functionality

 * using vf->first_vector_idx for queue configuration will have to increment by

 * 1 to avoid meddling with the OICR index.

/**

 * ice_vf_rebuild_host_tx_rate_cfg - re-apply the Tx rate limiting configuration

 * @vf: VF to re-apply the configuration for

 *

 * Called after a VF VSI has been re-added/rebuild during reset. The PF driver

 * needs to re-apply the host configured Tx rate limiting configuration.

/**

 * ice_vf_rebuild_host_vlan_cfg - add VLAN 0 filter or rebuild the Port VLAN

 * @vf: VF to add MAC filters for

 *

 * Called after a VF VSI has been re-added/rebuilt during reset. The PF driver

 * always re-adds either a VLAN 0 or port VLAN based filter after reset.

 vlan_id will either be 0 or the port VLAN number */

/**

 * ice_vf_rebuild_host_mac_cfg - add broadcast and the VF's perm_addr/LAA

 * @vf: VF to add MAC filters for

 *

 * Called after a VF VSI has been re-added/rebuilt during reset. The PF driver

 * always re-adds a broadcast filter and the VF's perm_addr/LAA after reset.

/**

 * ice_vf_set_host_trust_cfg - set trust setting based on pre-reset value

 * @vf: VF to configure trust setting for

/**

 * ice_ena_vf_msix_mappings - enable VF MSIX mappings in hardware

 * @vf: VF to enable MSIX mappings for

 *

 * Some of the registers need to be indexed/configured using hardware global

 * device values and other registers need 0-based values, which represent PF

 * based values.

 map the interrupts to its functions */

 Map mailbox interrupt to VF MSI-X vector 0 */

/**

 * ice_ena_vf_q_mappings - enable Rx/Tx queue mappings for a VF

 * @vf: VF to enable the mappings for

 * @max_txq: max Tx queues allowed on the VF's VSI

 * @max_rxq: max Rx queues allowed on the VF's VSI

 set regardless of mapping mode */

 VF Tx queues allocation */

		/* set the VF PF Tx queue range

		 * VFNUMQ value should be set to (number of queues - 1). A value

		 * of 0 means 1 queue and a value of 255 means 256 queues

 set regardless of mapping mode */

 VF Rx queues allocation */

		/* set the VF PF Rx queue range

		 * VFNUMQ value should be set to (number of queues - 1). A value

		 * of 0 means 1 queue and a value of 255 means 256 queues

/**

 * ice_ena_vf_mappings - enable VF MSIX and queue mapping

 * @vf: pointer to the VF structure

/**

 * ice_determine_res

 * @pf: pointer to the PF structure

 * @avail_res: available resources in the PF structure

 * @max_res: maximum resources that can be given per VF

 * @min_res: minimum resources that can be given per VF

 *

 * Returns non-zero value if resources (queues/vectors) are available or

 * returns zero if PF cannot accommodate for all num_alloc_vfs.

	/* start by checking if PF can assign max number of resources for

	 * all num_alloc_vfs.

	 * if yes, return number per VF

	 * If no, divide by 2 and roundup, check again

	 * repeat the loop till we reach a point where even minimum resources

	 * are not available, in that case return 0

/**

 * ice_calc_vf_reg_idx - Calculate the VF's register index in the PF space

 * @vf: VF to calculate the register index for

 * @q_vector: a q_vector associated to the VF

 always add one to account for the OICR being the first MSIX */

/**

 * ice_get_max_valid_res_idx - Get the max valid resource index

 * @res: pointer to the resource to find the max valid index for

 *

 * Start from the end of the ice_res_tracker and return right when we find the

 * first res->list entry with the ICE_RES_VALID_BIT set. This function is only

 * valid for SR-IOV because it is the only consumer that manipulates the

 * res->end and this is always called when res->end is set to res->num_entries.

/**

 * ice_sriov_set_msix_res - Set any used MSIX resources

 * @pf: pointer to PF structure

 * @num_msix_needed: number of MSIX vectors needed for all SR-IOV VFs

 *

 * This function allows SR-IOV resources to be taken from the end of the PF's

 * allowed HW MSIX vectors so that the irq_tracker will not be affected. We

 * just set the pf->sriov_base_vector and return success.

 *

 * If there are not enough resources available, return an error. This should

 * always be caught by ice_set_per_vf_res().

 *

 * Return 0 on success, and -EINVAL when there are not enough MSIX vectors

 * in the PF's space available for SR-IOV.

	/* make sure we only grab irq_tracker entries from the list end and

	 * that we have enough available MSIX vectors

/**

 * ice_set_per_vf_res - check if vectors and queues are available

 * @pf: pointer to the PF structure

 *

 * First, determine HW interrupts from common pool. If we allocate fewer VFs, we

 * get more vectors and can enable more queues per VF. Note that this does not

 * grab any vectors from the SW pool already allocated. Also note, that all

 * vector counts include one for each VF's miscellaneous interrupt vector

 * (i.e. OICR).

 *

 * Minimum VFs - 2 vectors, 1 queue pair

 * Small VFs - 5 vectors, 4 queue pairs

 * Medium VFs - 17 vectors, 16 queue pairs

 *

 * Second, determine number of queue pairs per VF by starting with a pre-defined

 * maximum each VF supports. If this is not possible, then we adjust based on

 * queue pairs available on the device.

 *

 * Lastly, set queue and MSI-X VF variables tracked by the PF so it can be used

 * by each VF during VF initialization and reset.

 determine MSI-X resources per VF */

 determine queue resources per VF */

 only allow equal Tx/Rx queue count (i.e. queue pairs) */

/**

 * ice_clear_vf_reset_trigger - enable VF to access hardware

 * @vf: VF to enabled hardware access for

/**

 * ice_vf_set_vsi_promisc - set given VF VSI to given promiscuous mode(s)

 * @vf: pointer to the VF info

 * @vsi: the VSI being configured

 * @promisc_m: mask of promiscuous config bits

 * @rm_promisc: promisc flag request from the VF to remove or add filter

 *

 * This function configures VF VSI promiscuous mode, based on the VF requests,

 * for Unicast, Multicast and VLAN

/**

 * ice_vf_pre_vsi_rebuild - tasks to be done prior to VSI rebuild

 * @vf: VF to perform pre VSI rebuild tasks

 *

 * These tasks are items that don't need to be amortized since they are most

 * likely called in a for loop with all VF(s) in the reset_all_vfs() case.

/**

 * ice_vf_rebuild_aggregator_node_cfg - rebuild aggregator node config

 * @vsi: Pointer to VSI

 *

 * This function moves VSI into corresponding scheduler aggregator node

 * based on cached value of "aggregator node info" per VSI

/**

 * ice_vf_rebuild_host_cfg - host admin configuration is persistent across reset

 * @vf: VF to rebuild host configuration on

 rebuild aggregator node config for main VF VSI */

/**

 * ice_vf_rebuild_vsi_with_release - release and setup the VF's VSI

 * @vf: VF to release and setup the VSI for

 *

 * This is only called when a single VF is being reset (i.e. VFR, VFLR, host VF

 * configuration change, etc.).

/**

 * ice_vf_rebuild_vsi - rebuild the VF's VSI

 * @vf: VF to rebuild the VSI for

 *

 * This is only called when all VF(s) are being reset (i.e. PCIe Reset on the

 * host, PFR, CORER, etc.).

	/* vsi->idx will remain the same in this case so don't update

	 * vf->lan_vsi_idx

/**

 * ice_vf_set_initialized - VF is ready for VIRTCHNL communication

 * @vf: VF to set in initialized state

 *

 * After this function the VF will be ready to receive/handle the

 * VIRTCHNL_OP_GET_VF_RESOURCES message

/**

 * ice_vf_post_vsi_rebuild - tasks to do after the VF's VSI have been rebuilt

 * @vf: VF to perform tasks on

/**

 * ice_reset_all_vfs - reset all allocated VFs in one go

 * @pf: pointer to the PF structure

 * @is_vflr: true if VFLR was issued, false if not

 *

 * First, tell the hardware to reset each VF, then do all the waiting in one

 * chunk, and finally finish restoring each VF after the wait. This is useful

 * during PF routines which need to reset all VFs, as otherwise it must perform

 * these resets in a serialized fashion.

 *

 * Returns true if any VFs were reset, and false otherwise.

 If we don't have any VFs, then there is nothing to reset */

 clear all malicious info if the VFs are getting reset */

 If VFs have been disabled, there is no need to reset */

 Begin reset on all VFs at once */

	/* HW requires some time to make sure it can flush the FIFO for a VF

	 * when it resets it. Poll the VPGEN_VFRSTAT register for each VF in

	 * sequence to make sure that it has completed. We'll keep track of

	 * the VFs using a simple iterator that increments once that VF has

	 * finished resetting.

 Check each VF in sequence */

 only delay if the check failed */

			/* If the current VF has finished resetting, move on

			 * to the next VF in sequence.

	/* Display a warning if at least one VF didn't manage to reset in

	 * time, but continue on with the operation.

 free VF resources to begin resetting the VSI state */

		/* clean VF control VSI when resetting VFs since it should be

		 * setup only when VF creates its first FDIR rule.

/**

 * ice_is_vf_disabled

 * @vf: pointer to the VF info

 *

 * Returns true if the PF or VF is disabled, false otherwise.

	/* If the PF has been disabled, there is no need resetting VF until

	 * PF is active again. Similarly, if the VF has been disabled, this

	 * means something else is resetting the VF, so we shouldn't continue.

	 * Otherwise, set disable VF state bit for actual reset, and continue.

/**

 * ice_reset_vf - Reset a particular VF

 * @vf: pointer to the VF structure

 * @is_vflr: true if VFLR was issued, false if not

 *

 * Returns true if the VF is currently in reset, resets successfully, or resets

 * are disabled and false otherwise.

 Set VF disable bit state here, before triggering reset */

	/* Call Disable LAN Tx queue AQ whether or not queues are

	 * enabled. This is needed for successful completion of VFR.

	/* poll VPGEN_VFRSTAT reg to make sure

	 * that reset is complete

		/* VF reset requires driver to first reset the VF and then

		 * poll the status register to make sure that the reset

		 * completed successfully.

 only sleep if the reset is not done */

	/* Display a warning if VF didn't manage to reset in time, but need to

	 * continue on with the operation.

	/* disable promiscuous modes in case they were enabled

	 * ignore any error if disabling process failed

	/* clean VF control VSI when resetting VF since it should be setup

	 * only when VF creates its first FDIR rule.

 if the VF has been reset allow it to come up again */

/**

 * ice_vc_notify_link_state - Inform all VFs on a PF of link status

 * @pf: pointer to the PF structure

/**

 * ice_vc_notify_reset - Send pending reset message to all VFs

 * @pf: pointer to the PF structure

 *

 * indicate a pending reset to all VFs on a given PF

/**

 * ice_vc_notify_vf_reset - Notify VF of a reset event

 * @vf: pointer to the VF structure

	/* Bail out if VF is in disabled state, neither initialized, nor active

	 * state - otherwise proceed with notifications

/**

 * ice_init_vf_vsi_res - initialize/setup VF VSI resources

 * @vf: VF to initialize/setup the VSI for

 *

 * This function creates a VSI for the VF, adds a VLAN 0 filter, and sets up the

 * VF VSI's broadcast filter and is only used during initial VF creation.

/**

 * ice_start_vfs - start VFs so they are ready to be used by SR-IOV

 * @pf: PF the VFs are associated with

/**

 * ice_set_dflt_settings_vfs - set VF defaults during initialization/creation

 * @pf: PF holding reference to all VFs for default configuration

 assign default capabilities */

		/* ctrl_vsi_idx will be set to a valid value only when VF

		 * creates its first fdir rule.

/**

 * ice_alloc_vfs - allocate num_vfs in the PF structure

 * @pf: PF to store the allocated VFs in

 * @num_vfs: number of VFs to allocate

/**

 * ice_ena_vfs - enable VFs so they are ready to be used

 * @pf: pointer to the PF structure

 * @num_vfs: number of VFs to enable

 Disable global interrupt 0 so we don't try to handle the VFLR. */

 rearm interrupts here */

/**

 * ice_pci_sriov_ena - Enable or change number of VFs

 * @pf: pointer to the PF structure

 * @num_vfs: number of VFs to allocate

 *

 * Returns 0 on success and negative on failure

/**

 * ice_check_sriov_allowed - check if SR-IOV is allowed based on various checks

 * @pf: PF to enabled SR-IOV on

/**

 * ice_sriov_configure - Enable or change number of VFs via sysfs

 * @pdev: pointer to a pci_dev structure

 * @num_vfs: number of VFs to allocate or 0 to free VFs

 *

 * This function is called when the user updates the number of VFs in sysfs. On

 * success return whatever num_vfs was set to by the caller. Return negative on

 * failure.

/**

 * ice_process_vflr_event - Free VF resources via IRQ calls

 * @pf: pointer to the PF structure

 *

 * called from the VFLR IRQ handler to

 * free up VF resources and state variables

 read GLGEN_VFLRSTAT register to find out the flr VFs */

 GLGEN_VFLRSTAT bit will be cleared in ice_reset_vf */

/**

 * ice_vc_reset_vf - Perform software reset on the VF after informing the AVF

 * @vf: pointer to the VF info

/**

 * ice_get_vf_from_pfq - get the VF who owns the PF space queue passed in

 * @pf: PF used to index all VFs

 * @pfq: queue index relative to the PF's function space

 *

 * If no VF is found who owns the pfq then return NULL, otherwise return a

 * pointer to the VF who owns the pfq

/**

 * ice_globalq_to_pfq - convert from global queue index to PF space queue index

 * @pf: PF used for conversion

 * @globalq: global queue index used to convert to PF space queue index

/**

 * ice_vf_lan_overflow_event - handle LAN overflow event for a VF

 * @pf: PF that the LAN overflow event happened on

 * @event: structure holding the event information for the LAN overflow event

 *

 * Determine if the LAN overflow event was caused by a VF queue. If it was not

 * caused by a VF, do nothing. If a VF caused this LAN overflow event trigger a

 * reset on the offending VF.

 event returns device global Rx queue number */

/**

 * ice_vc_send_msg_to_vf - Send message to VF

 * @vf: pointer to the VF info

 * @v_opcode: virtual channel opcode

 * @v_retval: virtual channel return value

 * @msg: pointer to the msg buffer

 * @msglen: msg length

 *

 * send msg to VF

 single place to detect unsuccessful return values */

 reset the invalid counter, if a valid message is received. */

/**

 * ice_vc_get_ver_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to request the API version used by the PF

 VFs running the 1.0 API expect to get 1.0 back or they will cry. */

/**

 * ice_vc_get_max_frame_size - get max frame size allowed for VF

 * @vf: VF used to determine max frame size

 *

 * Max frame size is determined based on the current port's max frame size and

 * whether a port VLAN is configured on this VF. The VF is not aware whether

 * it's in a port VLAN so the PF needs to account for this in max frame size

 * checks and sending the max frame size to the VF.

/**

 * ice_vc_get_vf_res_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to request its resources

 Tx and Rx queue are equal for VF */

 match guest capabilities */

 send the response back to the VF */

/**

 * ice_vc_reset_vf_msg

 * @vf: pointer to the VF info

 *

 * called from the VF to reset itself,

 * unlike other virtchnl messages, PF driver

 * doesn't send the response back to the VF

/**

 * ice_find_vsi_from_id

 * @pf: the PF structure to search for the VSI

 * @id: ID of the VSI it is searching for

 *

 * searches for the VSI with the given ID

/**

 * ice_vc_isvalid_vsi_id

 * @vf: pointer to the VF info

 * @vsi_id: VF relative VSI ID

 *

 * check for the valid VSI ID

/**

 * ice_vc_isvalid_q_id

 * @vf: pointer to the VF info

 * @vsi_id: VSI ID

 * @qid: VSI relative queue ID

 *

 * check for the valid queue ID

 allocated Tx and Rx queues should be always equal for VF VSI */

/**

 * ice_vc_isvalid_ring_len

 * @ring_len: length of ring

 *

 * check for the valid ring count, should be multiple of ICE_REQ_DESC_MULTIPLE

 * or zero

/**

 * ice_vc_parse_rss_cfg - parses hash fields and headers from

 * a specific virtchnl RSS cfg

 * @hw: pointer to the hardware

 * @rss_cfg: pointer to the virtchnl RSS cfg

 * @addl_hdrs: pointer to the protocol header fields (ICE_FLOW_SEG_HDR_*)

 * to configure

 * @hash_flds: pointer to the hash bit fields (ICE_FLOW_HASH_*) to configure

 *

 * Return true if all the protocol header and hash fields in the RSS cfg could

 * be parsed, else return false

 *

 * This function parses the virtchnl RSS cfg to be the intended

 * hash fields and the intended header for RSS configuration

 Find matched ice headers according to virtchnl headers. */

		/* Find matched ice hash fields according to

		 * virtchnl hash fields.

/**

 * ice_vf_adv_rss_offload_ena - determine if capabilities support advanced

 * RSS offloads

 * @caps: VF driver negotiated capabilities

 *

 * Return true if VIRTCHNL_VF_OFFLOAD_ADV_RSS_PF capability is set,

 * else return false

/**

 * ice_vc_handle_rss_cfg

 * @vf: pointer to the VF info

 * @msg: pointer to the message buffer

 * @add: add a RSS config if true, otherwise delete a RSS config

 *

 * This function adds/deletes a RSS config

 Preserve existing queueing option setting */

			/* We just ignore ICE_ERR_DOES_NOT_EXIST, because

			 * if two configurations share the same profile remove

			 * one of them actually removes both, since the

			 * profile is deleted.

/**

 * ice_vc_config_rss_key

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Configure the VF's RSS key

/**

 * ice_vc_config_rss_lut

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Configure the VF's RSS LUT

/**

 * ice_wait_on_vf_reset - poll to make sure a given VF is ready after reset

 * @vf: The VF being resseting

 *

 * The max poll time is about ~800ms, which is about the maximum time it takes

 * for a VF to be reset and/or a VF driver to be removed.

/**

 * ice_check_vf_ready_for_cfg - check if VF is ready to be configured/queried

 * @vf: VF to check if it's ready to be configured/queried

 *

 * The purpose of this function is to make sure the VF is not in reset, not

 * disabled, and initialized so it can be configured and/or queried by a host

 * administrator.

/**

 * ice_set_vf_spoofchk

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @ena: flag to enable or disable feature

 *

 * Enable or disable VF spoof checking

 only update spoofchk state and VSI context on success */

/**

 * ice_is_any_vf_in_promisc - check if any VF(s) are in promiscuous mode

 * @pf: PF structure for accessing VF(s)

 *

 * Return false if no VF(s) are in unicast and/or multicast promiscuous mode,

 * else return true

 found a VF that has promiscuous mode configured */

/**

 * ice_vc_cfg_promiscuous_mode_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to configure VF VSIs promiscuous mode

 Leave v_ret alone, lie to the VF on purpose. */

			/* only attempt to set the default forwarding VSI if

			 * it's not currently set

			/* only attempt to free the default forwarding VSI if we

			 * are the owner

/**

 * ice_vc_get_stats_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to get VSI stats

 send the response to the VF */

/**

 * ice_vc_validate_vqs_bitmaps - validate Rx/Tx queue bitmaps from VIRTCHNL

 * @vqs: virtchnl_queue_select structure containing bitmaps to validate

 *

 * Return true on successful validation, else false

/**

 * ice_vf_ena_txq_interrupt - enable Tx queue interrupt via QINT_TQCTL

 * @vsi: VSI of the VF to configure

 * @q_idx: VF queue index used to determine the queue in the PF's space

	/* MSI-X index 0 in the VF's space is always for the OICR, which means

	 * this is most likely a poll mode VF driver, so don't enable an

	 * interrupt that was never configured via VIRTCHNL_OP_CONFIG_IRQ_MAP

/**

 * ice_vf_ena_rxq_interrupt - enable Tx queue interrupt via QINT_RQCTL

 * @vsi: VSI of the VF to configure

 * @q_idx: VF queue index used to determine the queue in the PF's space

	/* MSI-X index 0 in the VF's space is always for the OICR, which means

	 * this is most likely a poll mode VF driver, so don't enable an

	 * interrupt that was never configured via VIRTCHNL_OP_CONFIG_IRQ_MAP

/**

 * ice_vc_ena_qs_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to enable all or specific queue(s)

	/* Enable only Rx rings, Tx rings were enabled by the FW when the

	 * Tx queue group list was configured and the context bits were

	 * programmed using ice_vsi_cfg_txqs

 Skip queue if enabled */

 Skip queue if enabled */

 Set flag to indicate that queues are enabled */

 send the response to the VF */

/**

 * ice_vc_dis_qs_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to disable all or specific

 * queue(s)

 Skip queue if not enabled */

 Clear enabled queues flag */

 speed up Rx queue disable by batching them if possible */

 Skip queue if not enabled */

 Clear enabled queues flag */

 Clear enabled queues flag */

 send the response to the VF */

/**

 * ice_cfg_interrupt

 * @vf: pointer to the VF info

 * @vsi: the VSI being configured

 * @vector_id: vector ID

 * @map: vector map for mapping vectors to queues

 * @q_vector: structure for interrupt vector

 * configure the IRQ to queue map

/**

 * ice_vc_cfg_irq_map_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to configure the IRQ to queue map

	/* Check to make sure number of VF vectors mapped is not greater than

	 * number of VF vectors originally allocated, and check that

	 * there is actually at least a single VF queue vector mapped

		/* vector_id is always 0-based for each VF, and can never be

		 * larger than or equal to the max allowed interrupts per VF

 No need to map VF miscellaneous or rogue vector */

		/* Subtract non queue vector from vector_id passed by VF

		 * to get actual number of VSI queue vector array index

 lookout for the invalid queue index */

 send the response to the VF */

/**

 * ice_vc_cfg_qs_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to configure the Rx/Tx queues

		/* make sure selected "q_idx" is in valid range of queues

		 * for selected "vsi"

 copy Tx queue info from VF into VSI */

 copy Rx queue info from VF into VSI */

			/* add space for the port VLAN since the VF driver is not

			 * expected to account for it in the MTU calculation

 send the response to the VF */

/**

 * ice_is_vf_trusted

 * @vf: pointer to the VF info

/**

 * ice_can_vf_change_mac

 * @vf: pointer to the VF info

 *

 * Return true if the VF is allowed to change its MAC filters, false otherwise

	/* If the VF MAC address has been set administratively (via the

	 * ndo_set_vf_mac command), then deny permission to the VF to

	 * add/delete unicast MAC addresses, unless the VF is trusted

/**

 * ice_vc_ether_addr_type - get type of virtchnl_ether_addr

 * @vc_ether_addr: used to extract the type

/**

 * ice_is_vc_addr_legacy - check if the MAC address is from an older VF

 * @vc_ether_addr: VIRTCHNL structure that contains MAC and type

/**

 * ice_is_vc_addr_primary - check if the MAC address is the VF's primary MAC

 * @vc_ether_addr: VIRTCHNL structure that contains MAC and type

 *

 * This function should only be called when the MAC address in

 * virtchnl_ether_addr is a valid unicast MAC

/**

 * ice_vfhw_mac_add - update the VF's cached hardware MAC if allowed

 * @vf: VF to update

 * @vc_ether_addr: structure from VIRTCHNL with MAC to add

	/* only allow legacy VF drivers to set the device and hardware MAC if it

	 * is zero and allow new VF drivers to set the hardware MAC if the type

	 * was correctly specified over VIRTCHNL

	/* hardware and device MACs are already set, but its possible that the

	 * VF driver sent the VIRTCHNL_OP_ADD_ETH_ADDR message before the

	 * VIRTCHNL_OP_DEL_ETH_ADDR when trying to update its MAC, so save it

	 * away for the legacy VF driver case as it will be updated in the

	 * delete flow for this case

/**

 * ice_vc_add_mac_addr - attempt to add the MAC address passed in

 * @vf: pointer to the VF info

 * @vsi: pointer to the VF's VSI

 * @vc_ether_addr: VIRTCHNL MAC address structure used to add MAC

 device MAC already added */

		/* don't return since we might need to update

		 * the primary MAC in ice_vfhw_mac_add() below

/**

 * ice_is_legacy_umac_expired - check if last added legacy unicast MAC expired

 * @last_added_umac: structure used to check expiration

/**

 * ice_update_legacy_cached_mac - update cached hardware MAC for legacy VF

 * @vf: VF to update

 * @vc_ether_addr: structure from VIRTCHNL with MAC to check

 *

 * only update cached hardware MAC for legacy VF drivers on delete

 * because we cannot guarantee order/type of MAC from the VF driver

/**

 * ice_vfhw_mac_del - update the VF's cached hardware MAC if allowed

 * @vf: VF to update

 * @vc_ether_addr: structure from VIRTCHNL with MAC to delete

	/* allow the device MAC to be repopulated in the add flow and don't

	 * clear the hardware MAC (i.e. hw_lan_addr.addr) here as that is meant

	 * to be persistent on VM reboot and across driver unload/load, which

	 * won't work if we clear the hardware MAC here

/**

 * ice_vc_del_mac_addr - attempt to delete the MAC address passed in

 * @vf: pointer to the VF info

 * @vsi: pointer to the VF's VSI

 * @vc_ether_addr: VIRTCHNL MAC address structure used to delete MAC

/**

 * ice_vc_handle_mac_addr_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 * @set: true if MAC filters are being set, false otherwise

 *

 * add guest MAC address filter

	/* If this VF is not privileged, then we can't add more than a

	 * limited number of addresses. Check to make sure that the

	 * additions do not push us over the limit.

 send the response to the VF */

/**

 * ice_vc_add_mac_addr_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * add guest MAC address filter

/**

 * ice_vc_del_mac_addr_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * remove guest MAC address filter

/**

 * ice_vc_request_qs_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * VFs get a default number of queues but can use this message to request a

 * different number. If the request is successful, PF will reset the VF and

 * return 0. If unsuccessful, PF will send message informing VF of number of

 * available queue pairs via virtchnl message response to VF.

 request is successful, then reset VF */

 send the response to the VF */

/**

 * ice_set_vf_port_vlan

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @vlan_id: VLAN ID being set

 * @qos: priority setting

 * @vlan_proto: VLAN protocol

 *

 * program VF Port VLAN ID and/or QoS

 duplicate request, so just return success */

/**

 * ice_vf_vlan_offload_ena - determine if capabilities support VLAN offloads

 * @caps: VF driver negotiated capabilities

 *

 * Return true if VIRTCHNL_VF_OFFLOAD_VLAN capability is set, else return false

/**

 * ice_vc_process_vlan_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 * @add_v: Add VLAN if true, otherwise delete VLAN

 *

 * Process virtchnl op to add or remove programmed guest VLAN ID

		/* There is no need to let VF know about being not trusted,

		 * so we can just return success message here

				/* There is no need to let VF know about being

				 * not trusted, so we can just return success

				 * message here as well.

			/* we add VLAN 0 by default for each VF so we can enable

			 * Tx VLAN anti-spoof without triggering MDD events so

			 * we don't need to add it again here

 Enable VLAN pruning when non-zero VLAN is added */

 Enable Ucast/Mcast VLAN promiscuous mode */

		/* In case of non_trusted VF, number of VLAN elements passed

		 * to PF for removal might be greater than number of VLANs

		 * filter programmed for that VF - So, use actual number of

		 * VLANS added earlier with add VLAN opcode. In order to avoid

		 * removing VLAN that doesn't exist, which result to sending

		 * erroneous failed message back to the VF

			/* we add VLAN 0 by default for each VF so we can enable

			 * Tx VLAN anti-spoof without triggering MDD events so

			 * we don't want a VIRTCHNL request to remove it

			/* Make sure ice_vsi_kill_vlan is successful before

			 * updating VLAN information

 Disable VLAN pruning when only VLAN 0 is left */

 Disable Unicast/Multicast VLAN promiscuous mode */

 send the response to the VF */

/**

 * ice_vc_add_vlan_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Add and program guest VLAN ID

/**

 * ice_vc_remove_vlan_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * remove programmed guest VLAN ID

/**

 * ice_vc_ena_vlan_stripping

 * @vf: pointer to the VF info

 *

 * Enable VLAN header stripping for a given VF

/**

 * ice_vc_dis_vlan_stripping

 * @vf: pointer to the VF info

 *

 * Disable VLAN header stripping for a given VF

/**

 * ice_vf_init_vlan_stripping - enable/disable VLAN stripping on initialization

 * @vf: VF to enable/disable VLAN stripping for on initialization

 *

 * If the VIRTCHNL_VF_OFFLOAD_VLAN flag is set enable VLAN stripping, else if

 * the flag is cleared then we want to disable stripping. For example, the flag

 * will be cleared when port VLANs are configured by the administrator before

 * passing the VF to the guest or if the AVF driver doesn't support VLAN

 * offloads.

 don't modify stripping if port VLAN is configured */

/**

 * ice_vc_repr_add_mac

 * @vf: pointer to VF

 * @msg: virtchannel message

 *

 * When port representors are created, we do not add MAC rule

 * to firmware, we store it so that PF could report same

 * MAC as VF.

/**

 * ice_vc_repr_del_mac - response with success for deleting MAC

 * @vf: pointer to VF

 * @msg: virtchannel message

 *

 * Respond with success to not break normal VF flow.

 * For legacy VF driver try to update cached MAC address.

/**

 * ice_vc_process_vf_msg - Process request from VF

 * @pf: pointer to the PF structure

 * @event: pointer to the AQ event

 *

 * called from the common asq/arq handler to

 * process request from VF

 if de-init is underway, don't process messages from VF */

 Check if VF is disabled. */

 Perform basic checks on the msg */

	/* VF is being configured in another context that triggers a VFR, so no

	 * need to process this message

		/* Helper function cares less about error return values here

		 * as it is busy with pending work.

/**

 * ice_get_vf_cfg

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @ivi: VF configuration structure

 *

 * return VF configuration

 VF configuration for VLAN and applicable QoS */

/**

 * ice_unicast_mac_exists - check if the unicast MAC exists on the PF's switch

 * @pf: PF used to reference the switch's rules

 * @umac: unicast MAC to compare against existing switch rules

 *

 * Return true on the first/any match, else return false

 protect MAC filter list access */

/**

 * ice_set_vf_mac

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @mac: MAC address

 *

 * program VF MAC address

 nothing left to do, unicast MAC already set */

	/* VF is notified of its new MAC via the PF's response to the

	 * VIRTCHNL_OP_GET_VF_RESOURCES message after the VF has been reset

 VF will send VIRTCHNL_OP_ADD_ETH_ADDR message with its MAC */

 PF will add MAC rule for the VF */

/**

 * ice_set_vf_trust

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @trusted: Boolean value to enable/disable trusted VF

 *

 * Enable or disable a given VF as trusted

 Check if already trusted */

/**

 * ice_set_vf_link_state

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @link_state: required link state

 *

 * Set VF's link state, irrespective of physical link state status

/**

 * ice_calc_all_vfs_min_tx_rate - calculate cumulative min Tx rate on all VFs

 * @pf: PF associated with VFs

/**

 * ice_min_tx_rate_oversubscribed - check if min Tx rate causes oversubscription

 * @vf: VF trying to configure min_tx_rate

 * @min_tx_rate: min Tx rate in Mbps

 *

 * Check if the min_tx_rate being passed in will cause oversubscription of total

 * min_tx_rate based on the current link speed and all other VFs configured

 * min_tx_rate

 *

 * Return true if the passed min_tx_rate would cause oversubscription, else

 * return false

 this VF's previous rate is being overwritten */

/**

 * ice_set_vf_bw - set min/max VF bandwidth

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @min_tx_rate: Minimum Tx rate in Mbps

 * @max_tx_rate: Maximum Tx rate in Mbps

	/* when max_tx_rate is zero that means no max Tx rate limiting, so only

	 * check if max_tx_rate is non-zero

/**

 * ice_get_vf_stats - populate some stats for the VF

 * @netdev: the netdev of the PF

 * @vf_id: the host OS identifier (0-255)

 * @vf_stats: pointer to the OS memory to be initialized

/**

 * ice_print_vf_rx_mdd_event - print VF Rx malicious driver detect event

 * @vf: pointer to the VF structure

/**

 * ice_print_vfs_mdd_events - print VFs malicious driver detect event

 * @pf: pointer to the PF structure

 *

 * Called from ice_handle_mdd_event to rate limit and print VFs MDD events.

 check that there are pending MDD events to print */

 VF MDD event logs are rate limited to one second intervals */

 only print Rx MDD event message if there are new events */

 only print Tx MDD event message if there are new events */

/**

 * ice_restore_all_vfs_msi_state - restore VF MSI state after PF FLR

 * @pdev: pointer to a pci_dev structure

 *

 * Called when recovering from a PF FLR to restore interrupt capability to

 * the VFs.

/**

 * ice_is_malicious_vf - helper function to detect a malicious VF

 * @pf: ptr to struct ice_pf

 * @event: pointer to the AQ event

 * @num_msg_proc: the number of messages processed so far

 * @num_msg_pending: the number of messages peinding in admin queue

 Check if VF is disabled. */

 check to see if we have a malicious VF */

		/* if the VF is malicious and we haven't let the user

		 * know about it, then let them know now

	/* if there was an error in detection or the VF is not malicious then

	 * return false

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2019-2021, Intel Corporation. */

/**

 * ice_tc_count_lkups - determine lookup count for switch filter

 * @flags: TC-flower flags

 * @headers: Pointer to TC flower filter header structure

 * @fltr: Pointer to outer TC filter structure

 *

 * Determine lookup count based on TC flower input for switch filter.

 currently inner etype filter isn't supported */

 are MAC fields specified? */

 is VLAN specified? */

 are IPv[4|6] fields specified? */

 is L4 (TCP/UDP/any other L4 protocol fields) specified? */

/**

 * ice_tc_fill_rules - fill filter rules based on TC fltr

 * @hw: pointer to HW structure

 * @flags: tc flower field flags

 * @tc_fltr: pointer to TC flower filter

 * @list: list of advance rule elements

 * @rule_info: pointer to information about rule

 * @l4_proto: pointer to information such as L4 proto type

 *

 * Fill ice_adv_lkup_elem list based on TC flower flags and

 * TC flower headers. This list should be used to add

 * advance filter in hardware.

 copy VLAN info */

 copy L3 (IPv[4|6]: src, dest) address */

 copy L4 (src, dest) port */

/**

 * ice_tc_tun_get_type - get the tunnel type

 * @tunnel_dev: ptr to tunnel device

 *

 * This function detects appropriate tunnel_type if specified device is

 * tunnel device such as VXLAN/Geneve

 egress traffic is always redirect to uplink */

	/* For now, making priority to be highest, and it also becomes

	 * the priority for recipe which will get created as a result of

	 * new extraction sequence based on input set.

	 * Priority '7' is max val for switch recipe, higher the number

	 * results into order of switch rule evaluation.

 specify the cookie as filter_rule_id */

	/* store the output params, which are needed later for removing

	 * advanced switch filter

/**

 * ice_add_tc_flower_adv_fltr - add appropriate filter rules

 * @vsi: Pointer to VSI

 * @tc_fltr: Pointer to TC flower filter structure

 *

 * based on filter parameters using Advance recipes supported

 * by OS package.

 get the channel (aka ADQ VSI) */

 specify the cookie as filter_rule_id */

	/* store the output params, which are needed later for removing

	 * advanced switch filter

		/* For PF ADQ, VSI type is set as ICE_VSI_CHNL, and

		 * for PF ADQ filter, it is not yet set in tc_fltr,

		 * hence store the dest_vsi ptr in tc_fltr

		/* keep track of advanced switch filter for

		 * destination VSI (channel VSI)

 in this case, dest_id is VSI handle (sw handle) */

 keeps track of channel filters for PF VSI */

/**

 * ice_tc_set_ipv4 - Parse IPv4 addresses from TC flower filter

 * @match: Pointer to flow match structure

 * @fltr: Pointer to filter structure

 * @headers: inner or outer header fields

 * @is_encap: set true for tunnel IPv4 address

/**

 * ice_tc_set_ipv6 - Parse IPv6 addresses from TC flower filter

 * @match: Pointer to flow match structure

 * @fltr: Pointer to filter structure

 * @headers: inner or outer header fields

 * @is_encap: set true for tunnel IPv6 address

	/* src and dest IPV6 address should not be LOOPBACK

	 * (0:0:0:0:0:0:0:1), which can be represented as ::1

 if src/dest IPv6 address is *,* error */

/**

 * ice_tc_set_port - Parse ports from TC flower filter

 * @match: Flow match structure

 * @fltr: Pointer to filter structure

 * @headers: inner or outer header fields

 * @is_encap: set true for tunnel port

/**

 * ice_parse_cls_flower - Parse TC flower filters provided by kernel

 * @vsi: Pointer to the VSI

 * @filter_dev: Pointer to device on which filter is being added

 * @f: Pointer to struct flow_cls_offload

 * @fltr: Pointer to filter structure

		/* header pointers should point to the inner headers, outer

		 * header were already set by ice_parse_tunnel_attr

/**

 * ice_add_switch_fltr - Add TC flower filters

 * @vsi: Pointer to VSI

 * @fltr: Pointer to struct ice_tc_flower_fltr

 *

 * Add filter in HW switch block

/**

 * ice_handle_tclass_action - Support directing to a traffic class

 * @vsi: Pointer to VSI

 * @cls_flower: Pointer to TC flower offload structure

 * @fltr: Pointer to TC flower filter structure

 *

 * Support directing traffic to a traffic class

 Redirect to a TC class or Queue Group */

	/* For ADQ, filter must include dest MAC address, otherwise unwanted

	 * packets with unrelated MAC address get delivered to ADQ VSIs as long

	 * as remaining filter criteria is satisfied such as dest IP address

	 * and dest/src L4 port. Following code is trying to handle:

	 * 1. For non-tunnel, if user specify MAC addresses, use them (means

	 * this code won't do anything

	 * 2. For non-tunnel, if user didn't specify MAC address, add implicit

	 * dest MAC to be lower netdev's active unicast MAC address

	/* validate specified dest MAC address, make sure either it belongs to

	 * lower netdev or any of MACVLAN. MACVLANs MAC address are added as

	 * unicast MAC filter destined to main VSI.

	/* Make sure VLAN is already added to main VSI, before allowing ADQ to

	 * add a VLAN based filter such as MAC + VLAN + L4 port.

/**

 * ice_parse_tc_flower_actions - Parse the actions for a TC filter

 * @vsi: Pointer to VSI

 * @cls_flower: Pointer to TC flower offload structure

 * @fltr: Pointer to TC flower filter structure

 *

 * Parse the actions for a TC filter

 Allow only one rule per filter */

 Drop action */

/**

 * ice_del_tc_fltr - deletes a filter from HW table

 * @vsi: Pointer to VSI

 * @fltr: Pointer to struct ice_tc_flower_fltr

 *

 * This function deletes a filter from HW table and manages book-keeping

	/* update advanced switch filter count for destination

	 * VSI if filter destination was VSI

 keeps track of channel filters for PF VSI */

/**

 * ice_add_tc_fltr - adds a TC flower filter

 * @netdev: Pointer to netdev

 * @vsi: Pointer to VSI

 * @f: Pointer to flower offload structure

 * @__fltr: Pointer to struct ice_tc_flower_fltr

 *

 * This function parses TC-flower input fields, parses action,

 * and adds a filter.

 by default, set output to be INVALID */

 return the newly created filter */

/**

 * ice_find_tc_flower_fltr - Find the TC flower filter in the list

 * @pf: Pointer to PF

 * @cookie: filter specific cookie

/**

 * ice_add_cls_flower - add TC flower filters

 * @netdev: Pointer to filter device

 * @vsi: Pointer to VSI

 * @cls_flower: Pointer to flower offload structure

		/* Based on TC indirect notifications from kernel, all ice

		 * devices get an instance of rule from higher level device.

		 * Avoid triggering explicit error in this case.

 avoid duplicate entries, if exists - return error */

 prep and add TC-flower filter in HW */

 add filter into an ordered list */

/**

 * ice_del_cls_flower - delete TC flower filters

 * @vsi: Pointer to VSI

 * @cls_flower: Pointer to struct flow_cls_offload

 find filter */

 delete filter from HW */

 delete filter from an ordered list */

 free the filter node */

/**

 * ice_replay_tc_fltrs - replay TC filters

 * @pf: pointer to PF struct

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

/**

 * ice_set_mac_type - Sets MAC type

 * @hw: pointer to the HW structure

 *

 * This function sets the MAC type of the adapter based on the

 * vendor ID and device ID stored in the HW structure.

/**

 * ice_is_e810

 * @hw: pointer to the hardware structure

 *

 * returns true if the device is E810 based, false if not.

/**

 * ice_is_e810t

 * @hw: pointer to the hardware structure

 *

 * returns true if the device is E810T based, false if not.

/**

 * ice_clear_pf_cfg - Clear PF configuration

 * @hw: pointer to the hardware structure

 *

 * Clears any existing PF configuration (VSIs, VSI lists, switch rules, port

 * configuration, flow director filters, etc.).

/**

 * ice_aq_manage_mac_read - manage MAC address read command

 * @hw: pointer to the HW struct

 * @buf: a virtual buffer to hold the manage MAC read response

 * @buf_size: Size of the virtual buffer

 * @cd: pointer to command details structure or NULL

 *

 * This function is used to return per PF station MAC address (0x0107).

 * NOTE: Upon successful completion of this command, MAC address information

 * is returned in user specified buffer. Please interpret user specified

 * buffer as "manage_mac_read" response.

 * Response such as various MAC addresses are stored in HW struct (port.mac)

 * ice_discover_dev_caps is expected to be called before this function is

 * called.

 A single port can report up to two (LAN and WoL) addresses */

/**

 * ice_aq_get_phy_caps - returns PHY capabilities

 * @pi: port information structure

 * @qual_mods: report qualified modules

 * @report_mode: report mode capabilities

 * @pcaps: structure for PHY capabilities to be filled

 * @cd: pointer to command details structure or NULL

 *

 * Returns the various PHY capabilities supported on the Port (0x0600)

/**

 * ice_aq_get_link_topo_handle - get link topology node return status

 * @pi: port information structure

 * @node_type: requested node type

 * @cd: pointer to command details structure or NULL

 *

 * Get link topology node return status for specified node type (0x06E0)

 *

 * Node type cage can be used to determine if cage is present. If AQC

 * returns error (ENOENT), then no cage present. If no cage present, then

 * connection type is backplane or BASE-T.

 set node type */

/**

 * ice_is_media_cage_present

 * @pi: port information structure

 *

 * Returns true if media cage is present, else false. If no cage, then

 * media type is backplane or BASE-T.

	/* Node type cage can be used to determine if cage is present. If AQC

	 * returns error (ENOENT), then no cage present. If no cage present then

	 * connection type is backplane or BASE-T.

/**

 * ice_get_media_type - Gets media type

 * @pi: port information structure

 If more than one media type is selected, report unknown */

		/* 1G SGMII is a special case where some DA cable PHYs

		 * may show this as an option when it really shouldn't

		 * be since SGMII is meant to be between a MAC and a PHY

		 * in a backplane. Try to detect this case and handle it

/**

 * ice_aq_get_link_info

 * @pi: port information structure

 * @ena_lse: enable/disable LinkStatusEvent reporting

 * @link: pointer to link status structure - optional

 * @cd: pointer to command details structure or NULL

 *

 * Get Link Status (0x607). Returns the link status of the adapter.

 save off old link status information */

 update current link status information */

 update fc info */

 save link status information */

 flag cleared so calling functions don't call AQ again */

/**

 * ice_fill_tx_timer_and_fc_thresh

 * @hw: pointer to the HW struct

 * @cmd: pointer to MAC cfg structure

 *

 * Add Tx timer and FC refresh threshold info to Set MAC Config AQ command

 * descriptor

	/* We read back the transmit timer and FC threshold value of

	 * LFC. Thus, we will use index =

	 * PRTMAC_HSEC_CTL_TX_PAUSE_QUANTA_MAX_INDEX.

	 *

	 * Also, because we are operating on transmit timer and FC

	 * threshold of LFC, we don't turn on any bit in tx_tmr_priority

 Retrieve the transmit timer */

 Retrieve the FC threshold */

/**

 * ice_aq_set_mac_cfg

 * @hw: pointer to the HW struct

 * @max_frame_size: Maximum Frame Size to be supported

 * @cd: pointer to command details structure or NULL

 *

 * Set MAC configuration (0x0603)

/**

 * ice_init_fltr_mgmt_struct - initializes filter management list and locks

 * @hw: pointer to the HW struct

/**

 * ice_cleanup_fltr_mgmt_struct - cleanup filter management list and locks

 * @hw: pointer to the HW struct

/**

 * ice_get_fw_log_cfg - get FW logging configuration

 * @hw: pointer to the HW struct

 Save FW logging information into the HW structure */

/**

 * ice_cfg_fw_log - configure FW logging

 * @hw: pointer to the HW struct

 * @enable: enable certain FW logging events if true, disable all if false

 *

 * This function enables/disables the FW logging via Rx CQ events and a UART

 * port based on predetermined configurations. FW logging via the Rx CQ can be

 * enabled/disabled for individual PF's. However, FW logging via the UART can

 * only be enabled/disabled for all PFs on the same device.

 *

 * To enable overall FW logging, the "cq_en" and "uart_en" enable bits in

 * hw->fw_log need to be set accordingly, e.g. based on user-provided input,

 * before initializing the device.

 *

 * When re/configuring FW logging, callers need to update the "cfg" elements of

 * the hw->fw_log.evnts array with the desired logging event configurations for

 * modules of interest. When disabling FW logging completely, the callers can

 * just pass false in the "enable" parameter. On completion, the function will

 * update the "cur" element of the hw->fw_log.evnts array with the resulting

 * logging event configurations of the modules that are being re/configured. FW

 * logging modules that are not part of a reconfiguration operation retain their

 * previous states.

 *

 * Before resetting the device, it is recommended that the driver disables FW

 * logging before shutting down the control queue. When disabling FW logging

 * ("enable" = false), the latest configurations of FW logging events stored in

 * hw->fw_log.evnts[] are not overridden to allow them to be reconfigured after

 * a device reset.

 *

 * When enabling FW logging to emit log messages via the Rx CQ during the

 * device's initialization phase, a mechanism alternative to interrupt handlers

 * needs to be used to extract FW log messages from the Rx CQ periodically and

 * to prevent the Rx CQ from being full and stalling other types of control

 * messages from FW to SW. Interrupts are typically disabled during the device's

 * initialization phase.

 Disable FW logging only when the control queue is still responsive */

 Get current FW log settings */

 Indicate which controls are valid */

		/* Fill in an array of entries with FW logging modules and

		 * logging events being reconfigured.

 Keep track of enabled event types */

		/* Only enable FW logging if at least one module is specified.

		 * If FW logging is currently enabled but all modules are not

		 * enabled to emit log messages, disable FW logging altogether.

 Leave if there is effectively no change */

		/* Update the current configuration to reflect events enabled.

		 * hw->fw_log.cq_en and hw->fw_log.uart_en indicate if the FW

		 * logging mode is enabled for the device. They do not reflect

		 * actual modules being enabled to emit log messages. So, their

		 * values remain unchanged even when all modules are disabled.

				/* When disabling all FW logging events as part

				 * of device's de-initialization, the original

				 * configurations are retained, and can be used

				 * to reconfigure FW logging later if the device

				 * is re-initialized.

/**

 * ice_output_fw_log

 * @hw: pointer to the HW struct

 * @desc: pointer to the AQ message descriptor

 * @buf: pointer to the buffer accompanying the AQ message

 *

 * Formats a FW Log message and outputs it via the standard driver logs.

/**

 * ice_get_itr_intrl_gran

 * @hw: pointer to the HW struct

 *

 * Determines the ITR/INTRL granularities based on the maximum aggregate

 * bandwidth according to the device's configuration during power-on.

/**

 * ice_init_hw - main hardware initialization routine

 * @hw: pointer to the hardware structure

 Set MAC type based on DeviceID */

 Enable FW logging. Not fatal if this fails. */

 Set bit to enable Flow Director filters */

 set the back pointer to HW */

 Initialize port_info struct with switch configuration data */

 Query the allocated resources for Tx scheduler */

 Initialize port_info struct with scheduler data */

 Initialize port_info struct with PHY capabilities */

 Initialize port_info struct with link information */

 need a valid SW entry point to build a Tx tree */

 Initialize max burst size */

 Get MAC information */

 A single port can report up to two (LAN and WoL) addresses */

 enable jumbo frame support at MAC level */

 Obtain counter base index which would be used by flow director */

/**

 * ice_deinit_hw - unroll initialization operations done by ice_init_hw

 * @hw: pointer to the hardware structure

 *

 * This should be called only during nominal operation, not as a result of

 * ice_init_hw() failing since ice_init_hw() will take care of unrolling

 * applicable initializations if it fails for any reason.

 Attempt to disable FW logging before shutting down control queues */

 Clear VSI contexts if not already cleared */

/**

 * ice_check_reset - Check to see if a global reset is complete

 * @hw: pointer to the hardware structure

	/* Poll for Device Active state in case a recent CORER, GLOBR,

	 * or EMPR has occurred. The grst delay value is in 100ms units.

	 * Add 1sec for outstanding AQ commands that can take a long time.

 Device is Active; check Global Reset processes are done */

/**

 * ice_pf_reset - Reset the PF

 * @hw: pointer to the hardware structure

 *

 * If a global reset has been triggered, this function checks

 * for its completion and then issues the PF reset

	/* If at function entry a global reset was already in progress, i.e.

	 * state is not 'device active' or any of the reset done bits are not

	 * set in GLNVM_ULD, there is no need for a PF Reset; poll until the

	 * global reset is done.

 poll on global reset currently in progress until done */

 Reset the PF */

	/* Wait for the PFR to complete. The wait time is the global config lock

	 * timeout plus the PFR timeout which will account for a possible reset

	 * that is occurring during a download package operation.

/**

 * ice_reset - Perform different types of reset

 * @hw: pointer to the hardware structure

 * @req: reset request

 *

 * This function triggers a reset as specified by the req parameter.

 *

 * Note:

 * If anything other than a PF reset is triggered, PXE mode is restored.

 * This has to be cleared using ice_clear_pxe_mode again, once the AQ

 * interface has been restored in the rebuild flow.

 wait for the FW to be ready */

/**

 * ice_copy_rxq_ctx_to_hw

 * @hw: pointer to the hardware structure

 * @ice_rxq_ctx: pointer to the rxq context

 * @rxq_index: the index of the Rx queue

 *

 * Copies rxq context from dense structure to HW register space

 Copy each dword separately to HW */

 LAN Rx Queue Context */

 Field		Width	LSB */

/**

 * ice_write_rxq_ctx

 * @hw: pointer to the hardware structure

 * @rlan_ctx: pointer to the rxq context

 * @rxq_index: the index of the Rx queue

 *

 * Converts rxq context from sparse to dense structure and then writes

 * it to HW register space and enables the hardware to prefetch descriptors

 * instead of only fetching them on demand

 LAN Tx Queue Context */

 Field			Width	LSB */

 Sideband Queue command wrappers */

/**

 * ice_sbq_send_cmd - send Sideband Queue command to Sideband Queue

 * @hw: pointer to the HW struct

 * @desc: descriptor describing the command

 * @buf: buffer to use for indirect commands (NULL for direct commands)

 * @buf_size: size of buffer for indirect commands (0 for direct commands)

 * @cd: pointer to command details structure

/**

 * ice_sbq_rw_reg - Fill Sideband Queue command

 * @hw: pointer to the HW struct

 * @in: message info to be filled in descriptor

		/* data read comes back in completion, so shorten the struct by

		 * sizeof(msg.data)

 FW Admin Queue command wrappers */

/* Software lock/mutex that is meant to be held while the Global Config Lock

 * in firmware is acquired by the software to prevent most (but not all) types

 * of AQ commands from being sent to FW

/**

 * ice_should_retry_sq_send_cmd

 * @opcode: AQ opcode

 *

 * Decide if we should retry the send command routine for the ATQ, depending

 * on the opcode.

/**

 * ice_sq_send_cmd_retry - send command to Control Queue (ATQ)

 * @hw: pointer to the HW struct

 * @cq: pointer to the specific Control queue

 * @desc: prefilled descriptor describing the command

 * @buf: buffer to use for indirect commands (or NULL for direct commands)

 * @buf_size: size of buffer for indirect commands (or 0 for direct commands)

 * @cd: pointer to command details structure

 *

 * Retry sending the FW Admin Queue command, multiple times, to the FW Admin

 * Queue if the EBUSY AQ error is returned.

/**

 * ice_aq_send_cmd - send FW Admin Queue command to FW Admin Queue

 * @hw: pointer to the HW struct

 * @desc: descriptor describing the command

 * @buf: buffer to use for indirect commands (NULL for direct commands)

 * @buf_size: size of buffer for indirect commands (0 for direct commands)

 * @cd: pointer to command details structure

 *

 * Helper function to send FW Admin Queue commands to the FW Admin Queue.

	/* When a package download is in process (i.e. when the firmware's

	 * Global Configuration Lock resource is held), only the Download

	 * Package, Get Version, Get Package Info List and Release Resource

	 * (with resource ID set to Global Config Lock) AdminQ commands are

	 * allowed; all others must block until the package download completes

	 * and the Global Config Lock is released.  See also

	 * ice_acquire_global_cfg_lock().

/**

 * ice_aq_get_fw_ver

 * @hw: pointer to the HW struct

 * @cd: pointer to command details structure or NULL

 *

 * Get the firmware version (0x0001) from the admin queue commands

/**

 * ice_aq_send_driver_ver

 * @hw: pointer to the HW struct

 * @dv: driver's major, minor version

 * @cd: pointer to command details structure or NULL

 *

 * Send the driver version (0x0002) to the firmware

/**

 * ice_aq_q_shutdown

 * @hw: pointer to the HW struct

 * @unloading: is the driver unloading itself

 *

 * Tell the Firmware that we're shutting down the AdminQ and whether

 * or not the driver is unloading as well (0x0003).

/**

 * ice_aq_req_res

 * @hw: pointer to the HW struct

 * @res: resource ID

 * @access: access type

 * @sdp_number: resource number

 * @timeout: the maximum time in ms that the driver may hold the resource

 * @cd: pointer to command details structure or NULL

 *

 * Requests common resource using the admin queue commands (0x0008).

 * When attempting to acquire the Global Config Lock, the driver can

 * learn of three states:

 *  1) ICE_SUCCESS -        acquired lock, and can perform download package

 *  2) ICE_ERR_AQ_ERROR -   did not get lock, driver should fail to load

 *  3) ICE_ERR_AQ_NO_WORK - did not get lock, but another driver has

 *                          successfully downloaded the package; the driver does

 *                          not have to download the package and can continue

 *                          loading

 *

 * Note that if the caller is in an acquire lock, perform action, release lock

 * phase of operation, it is possible that the FW may detect a timeout and issue

 * a CORER. In this case, the driver will receive a CORER interrupt and will

 * have to determine its cause. The calling thread that is handling this flow

 * will likely get an error propagated back to it indicating the Download

 * Package, Update Package or the Release Resource AQ commands timed out.

	/* The completion specifies the maximum time in ms that the driver

	 * may hold the resource in the Timeout field.

	/* Global config lock response utilizes an additional status field.

	 *

	 * If the Global config lock resource is held by some other driver, the

	 * command completes with ICE_AQ_RES_GLBL_IN_PROG in the status field

	 * and the timeout field indicates the maximum time the current owner

	 * of the resource has to free it.

 invalid FW response, force a timeout immediately */

	/* If the resource is held by some other driver, the command completes

	 * with a busy return value and the timeout field indicates the maximum

	 * time the current owner of the resource has to free it.

/**

 * ice_aq_release_res

 * @hw: pointer to the HW struct

 * @res: resource ID

 * @sdp_number: resource number

 * @cd: pointer to command details structure or NULL

 *

 * release common resource using the admin queue commands (0x0009)

/**

 * ice_acquire_res

 * @hw: pointer to the HW structure

 * @res: resource ID

 * @access: access type (read or write)

 * @timeout: timeout in milliseconds

 *

 * This function will attempt to acquire the ownership of a resource.

	/* A return code of ICE_ERR_AQ_NO_WORK means that another driver has

	 * previously acquired the resource and performed any necessary updates;

	 * in this case the caller does not obtain the resource and has no

	 * further work to do.

 If necessary, poll until the current lock owner timeouts */

 lock free, but no work to do */

 lock acquired */

/**

 * ice_release_res

 * @hw: pointer to the HW structure

 * @res: resource ID

 *

 * This function will release a resource using the proper Admin Command.

	/* there are some rare cases when trying to release the resource

	 * results in an admin queue timeout, so handle them correctly

/**

 * ice_aq_alloc_free_res - command to allocate/free resources

 * @hw: pointer to the HW struct

 * @num_entries: number of resource entries in buffer

 * @buf: Indirect buffer to hold data parameters and response

 * @buf_size: size of buffer for indirect commands

 * @opc: pass in the command opcode

 * @cd: pointer to command details structure or NULL

 *

 * Helper function to allocate/free resources using the admin queue commands

/**

 * ice_alloc_hw_res - allocate resource

 * @hw: pointer to the HW struct

 * @type: type of resource

 * @num: number of resources to allocate

 * @btm: allocate from bottom

 * @res: pointer to array that will receive the resources

 Prepare buffer to allocate resource. */

/**

 * ice_free_hw_res - free allocated HW resource

 * @hw: pointer to the HW struct

 * @type: type of resource to free

 * @num: number of resources

 * @res: pointer to array that contains the resources to free

 Prepare buffer to free resource. */

/**

 * ice_get_num_per_func - determine number of resources per PF

 * @hw: pointer to the HW structure

 * @max: value to be evenly split between each PF

 *

 * Determine the number of valid functions by going through the bitmap returned

 * from parsing capabilities and use this to calculate the number of resources

 * per PF based on the max value passed in.

/**

 * ice_parse_common_caps - parse common device/function capabilities

 * @hw: pointer to the HW struct

 * @caps: pointer to common capabilities structure

 * @elem: the capability element to parse

 * @prefix: message prefix for tracing capabilities

 *

 * Given a capability element, extract relevant details into the common

 * capability structure.

 *

 * Returns: true if the capability matches one of the common capability ids,

 * false otherwise.

 Not one of the recognized common capabilities */

/**

 * ice_recalc_port_limited_caps - Recalculate port limited capabilities

 * @hw: pointer to the HW structure

 * @caps: pointer to capabilities structure to fix

 *

 * Re-calculate the capabilities that are dependent on the number of physical

 * ports; i.e. some features are not supported or function differently on

 * devices with more than 4 ports.

	/* This assumes device capabilities are always scanned before function

	 * capabilities during the initialization flow.

 Max 4 TCs per port */

		/* print message only when processing device capabilities

		 * during initialization.

/**

 * ice_parse_vf_func_caps - Parse ICE_AQC_CAPS_VF function caps

 * @hw: pointer to the HW struct

 * @func_p: pointer to function capabilities structure

 * @cap: pointer to the capability element to parse

 *

 * Extract function capabilities for ICE_AQC_CAPS_VF.

/**

 * ice_parse_vsi_func_caps - Parse ICE_AQC_CAPS_VSI function caps

 * @hw: pointer to the HW struct

 * @func_p: pointer to function capabilities structure

 * @cap: pointer to the capability element to parse

 *

 * Extract function capabilities for ICE_AQC_CAPS_VSI.

/**

 * ice_parse_1588_func_caps - Parse ICE_AQC_CAPS_1588 function caps

 * @hw: pointer to the HW struct

 * @func_p: pointer to function capabilities structure

 * @cap: pointer to the capability element to parse

 *

 * Extract function capabilities for ICE_AQC_CAPS_1588.

/**

 * ice_parse_fdir_func_caps - Parse ICE_AQC_CAPS_FD function caps

 * @hw: pointer to the HW struct

 * @func_p: pointer to function capabilities structure

 *

 * Extract function capabilities for ICE_AQC_CAPS_FD.

/**

 * ice_parse_func_caps - Parse function capabilities

 * @hw: pointer to the HW struct

 * @func_p: pointer to function capabilities structure

 * @buf: buffer containing the function capability records

 * @cap_count: the number of capabilities

 *

 * Helper function to parse function (0x000A) capabilities list. For

 * capabilities shared between device and function, this relies on

 * ice_parse_common_caps.

 *

 * Loop through the list of provided capabilities and extract the relevant

 * data into the function capabilities structured.

 Don't list common capabilities as unknown */

/**

 * ice_parse_valid_functions_cap - Parse ICE_AQC_CAPS_VALID_FUNCTIONS caps

 * @hw: pointer to the HW struct

 * @dev_p: pointer to device capabilities structure

 * @cap: capability element to parse

 *

 * Parse ICE_AQC_CAPS_VALID_FUNCTIONS for device capabilities.

/**

 * ice_parse_vf_dev_caps - Parse ICE_AQC_CAPS_VF device caps

 * @hw: pointer to the HW struct

 * @dev_p: pointer to device capabilities structure

 * @cap: capability element to parse

 *

 * Parse ICE_AQC_CAPS_VF for device capabilities.

/**

 * ice_parse_vsi_dev_caps - Parse ICE_AQC_CAPS_VSI device caps

 * @hw: pointer to the HW struct

 * @dev_p: pointer to device capabilities structure

 * @cap: capability element to parse

 *

 * Parse ICE_AQC_CAPS_VSI for device capabilities.

/**

 * ice_parse_1588_dev_caps - Parse ICE_AQC_CAPS_1588 device caps

 * @hw: pointer to the HW struct

 * @dev_p: pointer to device capabilities structure

 * @cap: capability element to parse

 *

 * Parse ICE_AQC_CAPS_1588 for device capabilities.

/**

 * ice_parse_fdir_dev_caps - Parse ICE_AQC_CAPS_FD device caps

 * @hw: pointer to the HW struct

 * @dev_p: pointer to device capabilities structure

 * @cap: capability element to parse

 *

 * Parse ICE_AQC_CAPS_FD for device capabilities.

/**

 * ice_parse_dev_caps - Parse device capabilities

 * @hw: pointer to the HW struct

 * @dev_p: pointer to device capabilities structure

 * @buf: buffer containing the device capability records

 * @cap_count: the number of capabilities

 *

 * Helper device to parse device (0x000B) capabilities list. For

 * capabilities shared between device and function, this relies on

 * ice_parse_common_caps.

 *

 * Loop through the list of provided capabilities and extract the relevant

 * data into the device capabilities structured.

 Don't list common capabilities as unknown */

/**

 * ice_aq_list_caps - query function/device capabilities

 * @hw: pointer to the HW struct

 * @buf: a buffer to hold the capabilities

 * @buf_size: size of the buffer

 * @cap_count: if not NULL, set to the number of capabilities reported

 * @opc: capabilities type to discover, device or function

 * @cd: pointer to command details structure or NULL

 *

 * Get the function (0x000A) or device (0x000B) capabilities description from

 * firmware and store it in the buffer.

 *

 * If the cap_count pointer is not NULL, then it is set to the number of

 * capabilities firmware will report. Note that if the buffer size is too

 * small, it is possible the command will return ICE_AQ_ERR_ENOMEM. The

 * cap_count will still be updated in this case. It is recommended that the

 * buffer size be set to ICE_AQ_MAX_BUF_LEN (the largest possible buffer that

 * firmware could return) to avoid this.

/**

 * ice_discover_dev_caps - Read and extract device capabilities

 * @hw: pointer to the hardware structure

 * @dev_caps: pointer to device capabilities structure

 *

 * Read the device capabilities and extract them into the dev_caps structure

 * for later use.

	/* Although the driver doesn't know the number of capabilities the

	 * device will return, we can simply send a 4KB buffer, the maximum

	 * possible size that firmware can return.

/**

 * ice_discover_func_caps - Read and extract function capabilities

 * @hw: pointer to the hardware structure

 * @func_caps: pointer to function capabilities structure

 *

 * Read the function capabilities and extract them into the func_caps structure

 * for later use.

	/* Although the driver doesn't know the number of capabilities the

	 * device will return, we can simply send a 4KB buffer, the maximum

	 * possible size that firmware can return.

/**

 * ice_set_safe_mode_caps - Override dev/func capabilities when in safe mode

 * @hw: pointer to the hardware structure

 cache some func_caps values that should be restored after memset */

 unset func capabilities */

 restore cached values */

 one Tx and one Rx queue in safe mode */

 two MSIX vectors, one for traffic and one for misc causes */

 cache some dev_caps values that should be restored after memset */

 unset dev capabilities */

 restore cached values */

 one Tx and one Rx queue per function in safe mode */

 two MSIX vectors per function */

/**

 * ice_get_caps - get info about the HW

 * @hw: pointer to the hardware structure

/**

 * ice_aq_manage_mac_write - manage MAC address write command

 * @hw: pointer to the HW struct

 * @mac_addr: MAC address to be written as LAA/LAA+WoL/Port address

 * @flags: flags to control write behavior

 * @cd: pointer to command details structure or NULL

 *

 * This function is used to write MAC address to the NVM (0x0108).

/**

 * ice_aq_clear_pxe_mode

 * @hw: pointer to the HW struct

 *

 * Tell the firmware that the driver is taking over from PXE (0x0110).

/**

 * ice_clear_pxe_mode - clear pxe operations mode

 * @hw: pointer to the HW struct

 *

 * Make sure all PXE mode settings are cleared, including things

 * like descriptor fetch/write-back mode.

/**

 * ice_get_link_speed_based_on_phy_type - returns link speed

 * @phy_type_low: lower part of phy_type

 * @phy_type_high: higher part of phy_type

 *

 * This helper function will convert an entry in PHY type structure

 * [phy_type_low, phy_type_high] to its corresponding link speed.

 * Note: In the structure of [phy_type_low, phy_type_high], there should

 * be one bit set, as this function will convert one PHY type to its

 * speed.

 * If no bit gets set, ICE_LINK_SPEED_UNKNOWN will be returned

 * If more than one bit gets set, ICE_LINK_SPEED_UNKNOWN will be returned

/**

 * ice_update_phy_type

 * @phy_type_low: pointer to the lower part of phy_type

 * @phy_type_high: pointer to the higher part of phy_type

 * @link_speeds_bitmap: targeted link speeds bitmap

 *

 * Note: For the link_speeds_bitmap structure, you can check it at

 * [ice_aqc_get_link_status->link_speed]. Caller can pass in

 * link_speeds_bitmap include multiple speeds.

 *

 * Each entry in this [phy_type_low, phy_type_high] structure will

 * present a certain link speed. This helper function will turn on bits

 * in [phy_type_low, phy_type_high] structure based on the value of

 * link_speeds_bitmap input parameter.

 We first check with low part of phy_type */

 We then check with high part of phy_type */

/**

 * ice_aq_set_phy_cfg

 * @hw: pointer to the HW struct

 * @pi: port info structure of the interested logical port

 * @cfg: structure with PHY configuration data to be set

 * @cd: pointer to command details structure or NULL

 *

 * Set the various PHY configuration parameters supported on the Port.

 * One or more of the Set PHY config parameters may be ignored in an MFP

 * mode as the PF may not have the privilege to set some of the PHY Config

 * parameters. This status will be indicated by the command response (0x0601).

 Ensure that only valid bits of cfg->caps can be turned on. */

/**

 * ice_update_link_info - update status of the HW network link

 * @pi: port info structure of the interested logical port

/**

 * ice_cache_phy_user_req

 * @pi: port information structure

 * @cache_data: PHY logging data

 * @cache_mode: PHY logging mode

 *

 * Log the user request on (FC, FEC, SPEED) for later use.

/**

 * ice_caps_to_fc_mode

 * @caps: PHY capabilities

 *

 * Convert PHY FC capabilities to ice FC mode

/**

 * ice_caps_to_fec_mode

 * @caps: PHY capabilities

 * @fec_options: Link FEC options

 *

 * Convert PHY FEC capabilities to ice FEC mode

/**

 * ice_cfg_phy_fc - Configure PHY FC data based on FC mode

 * @pi: port information structure

 * @cfg: PHY configuration data to set FC mode

 * @req_mode: FC mode to configure

 clear the old pause settings */

 set the new capabilities */

 Cache user FC request */

/**

 * ice_set_fc

 * @pi: port information structure

 * @aq_failures: pointer to status code, specific to ice_set_fc routine

 * @ena_auto_link_update: enable automatic link update

 *

 * Set the requested flow control mode.

 Get the current PHY config */

 Configure the set PHY data */

 If the capabilities have changed, then set the new config */

 Auto restart link so settings take effect */

		/* Update the link info

		 * It sometimes takes a really long time for link to

		 * come back from the atomic reset. Thus, we wait a

		 * little bit.

/**

 * ice_phy_caps_equals_cfg

 * @phy_caps: PHY capabilities

 * @phy_cfg: PHY configuration

 *

 * Helper function to determine if PHY capabilities matches PHY

 * configuration

	/* These bits are not common between capabilities and configuration.

	 * Do not use them to determine equality.

/**

 * ice_copy_phy_caps_to_cfg - Copy PHY ability data to configuration data

 * @pi: port information structure

 * @caps: PHY ability structure to copy date from

 * @cfg: PHY configuration structure to copy data to

 *

 * Helper function to copy AQC PHY get ability data to PHY set configuration

 * data structure

/**

 * ice_cfg_phy_fec - Configure PHY FEC data based on FEC mode

 * @pi: port information structure

 * @cfg: PHY configuration data to set FEC mode

 * @fec: FEC mode to configure

		/* Clear RS bits, and AND BASE-R ability

		 * bits and OR request bits.

		/* Clear BASE-R bits, and AND RS ability

		 * bits and OR request bits.

 Clear all FEC option bits. */

 AND auto FEC bit, and all caps bits. */

/**

 * ice_get_link_status - get status of the HW network link

 * @pi: port information structure

 * @link_up: pointer to bool (true/false = linkup/linkdown)

 *

 * Variable link_up is true if link is up, false if link is down.

 * The variable link_up is invalid if status is non zero. As a

 * result of this call, link status reporting becomes enabled

/**

 * ice_aq_set_link_restart_an

 * @pi: pointer to the port information structure

 * @ena_link: if true: enable link, if false: disable link

 * @cd: pointer to command details structure or NULL

 *

 * Sets up the link and restarts the Auto-Negotiation over the link.

/**

 * ice_aq_set_event_mask

 * @hw: pointer to the HW struct

 * @port_num: port number of the physical function

 * @mask: event mask to be set

 * @cd: pointer to command details structure or NULL

 *

 * Set event mask (0x0613)

/**

 * ice_aq_set_mac_loopback

 * @hw: pointer to the HW struct

 * @ena_lpbk: Enable or Disable loopback

 * @cd: pointer to command details structure or NULL

 *

 * Enable/disable loopback on a given port

/**

 * ice_aq_set_port_id_led

 * @pi: pointer to the port information

 * @is_orig_mode: is this LED set to original mode (by the net-list)

 * @cd: pointer to command details structure or NULL

 *

 * Set LED value for the given port (0x06e9)

/**

 * ice_aq_sff_eeprom

 * @hw: pointer to the HW struct

 * @lport: bits [7:0] = logical port, bit [8] = logical port valid

 * @bus_addr: I2C bus address of the eeprom (typically 0xA0, 0=topo default)

 * @mem_addr: I2C offset. lower 8 bits for address, 8 upper bits zero padding.

 * @page: QSFP page

 * @set_page: set or ignore the page

 * @data: pointer to data buffer to be read/written to the I2C device.

 * @length: 1-16 for read, 1 for write.

 * @write: 0 read, 1 for write.

 * @cd: pointer to command details structure or NULL

 *

 * Read/Write SFF EEPROM (0x06EE)

/**

 * __ice_aq_get_set_rss_lut

 * @hw: pointer to the hardware structure

 * @params: RSS LUT parameters

 * @set: set true to set the table, false to get the table

 *

 * Internal function to get (0x0B05) or set (0x0B03) RSS look up table

 LUT size is only valid for Global and PF table types */

/**

 * ice_aq_get_rss_lut

 * @hw: pointer to the hardware structure

 * @get_params: RSS LUT parameters used to specify which RSS LUT to get

 *

 * get the RSS lookup table, PF or VSI type

/**

 * ice_aq_set_rss_lut

 * @hw: pointer to the hardware structure

 * @set_params: RSS LUT parameters used to specify how to set the RSS LUT

 *

 * set the RSS lookup table, PF or VSI type

/**

 * __ice_aq_get_set_rss_key

 * @hw: pointer to the HW struct

 * @vsi_id: VSI FW index

 * @key: pointer to key info struct

 * @set: set true to set the key, false to get the key

 *

 * get (0x0B04) or set (0x0B02) the RSS key per VSI

/**

 * ice_aq_get_rss_key

 * @hw: pointer to the HW struct

 * @vsi_handle: software VSI handle

 * @key: pointer to key info struct

 *

 * get the RSS key per VSI

/**

 * ice_aq_set_rss_key

 * @hw: pointer to the HW struct

 * @vsi_handle: software VSI handle

 * @keys: pointer to key info struct

 *

 * set the RSS key per VSI

/**

 * ice_aq_add_lan_txq

 * @hw: pointer to the hardware structure

 * @num_qgrps: Number of added queue groups

 * @qg_list: list of queue groups to be added

 * @buf_size: size of buffer for indirect command

 * @cd: pointer to command details structure or NULL

 *

 * Add Tx LAN queue (0x0C30)

 *

 * NOTE:

 * Prior to calling add Tx LAN queue:

 * Initialize the following as part of the Tx queue context:

 * Completion queue ID if the queue uses Completion queue, Quanta profile,

 * Cache profile and Packet shaper profile.

 *

 * After add Tx LAN queue AQ command is completed:

 * Interrupts should be associated with specific queues,

 * Association of Tx queue to Doorbell queue is not part of Add LAN Tx queue

 * flow.

/**

 * ice_aq_dis_lan_txq

 * @hw: pointer to the hardware structure

 * @num_qgrps: number of groups in the list

 * @qg_list: the list of groups to disable

 * @buf_size: the total size of the qg_list buffer in bytes

 * @rst_src: if called due to reset, specifies the reset source

 * @vmvf_num: the relative VM or VF number that is undergoing the reset

 * @cd: pointer to command details structure or NULL

 *

 * Disable LAN Tx queue (0x0C31)

 qg_list can be NULL only in VM/VF reset flow */

 In this case, FW expects vmvf_num to be absolute VF ID */

 flush pipe on time out */

 If no queue group info, we are in a reset flow. Issue the AQ */

	/* set RD bit to indicate that command buffer is provided by the driver

	 * and it needs to be read by the firmware

 If the num of queues is even, add 2 bytes of padding */

/**

 * ice_aq_add_rdma_qsets

 * @hw: pointer to the hardware structure

 * @num_qset_grps: Number of RDMA Qset groups

 * @qset_list: list of Qset groups to be added

 * @buf_size: size of buffer for indirect command

 * @cd: pointer to command details structure or NULL

 *

 * Add Tx RDMA Qsets (0x0C33)

 End of FW Admin Queue command wrappers */

/**

 * ice_write_byte - write a byte to a packed context structure

 * @src_ctx:  the context structure to read from

 * @dest_ctx: the context to be written to

 * @ce_info:  a description of the struct to be filled

 copy from the next struct field */

 prepare the bits and mask */

 shift to correct alignment */

 get the current bits from the target bit string */

 get the bits not changing */

 add in the new bits */

 put it all back */

/**

 * ice_write_word - write a word to a packed context structure

 * @src_ctx:  the context structure to read from

 * @dest_ctx: the context to be written to

 * @ce_info:  a description of the struct to be filled

 copy from the next struct field */

 prepare the bits and mask */

	/* don't swizzle the bits until after the mask because the mask bits

	 * will be in a different bit position on big endian machines

 shift to correct alignment */

 get the current bits from the target bit string */

 get the bits not changing */

 add in the new bits */

 put it all back */

/**

 * ice_write_dword - write a dword to a packed context structure

 * @src_ctx:  the context structure to read from

 * @dest_ctx: the context to be written to

 * @ce_info:  a description of the struct to be filled

 copy from the next struct field */

 prepare the bits and mask */

	/* if the field width is exactly 32 on an x86 machine, then the shift

	 * operation will not work because the SHL instructions count is masked

	 * to 5 bits so the shift will do nothing

	/* don't swizzle the bits until after the mask because the mask bits

	 * will be in a different bit position on big endian machines

 shift to correct alignment */

 get the current bits from the target bit string */

 get the bits not changing */

 add in the new bits */

 put it all back */

/**

 * ice_write_qword - write a qword to a packed context structure

 * @src_ctx:  the context structure to read from

 * @dest_ctx: the context to be written to

 * @ce_info:  a description of the struct to be filled

 copy from the next struct field */

 prepare the bits and mask */

	/* if the field width is exactly 64 on an x86 machine, then the shift

	 * operation will not work because the SHL instructions count is masked

	 * to 6 bits so the shift will do nothing

	/* don't swizzle the bits until after the mask because the mask bits

	 * will be in a different bit position on big endian machines

 shift to correct alignment */

 get the current bits from the target bit string */

 get the bits not changing */

 add in the new bits */

 put it all back */

/**

 * ice_set_ctx - set context bits in packed structure

 * @hw: pointer to the hardware structure

 * @src_ctx:  pointer to a generic non-packed context structure

 * @dest_ctx: pointer to memory for the packed structure

 * @ce_info:  a description of the structure to be transformed

		/* We have to deal with each element of the FW response

		 * using the correct size so that we are correct regardless

		 * of the endianness of the machine.

/**

 * ice_get_lan_q_ctx - get the LAN queue context for the given VSI and TC

 * @hw: pointer to the HW struct

 * @vsi_handle: software VSI handle

 * @tc: TC number

 * @q_handle: software queue handle

/**

 * ice_ena_vsi_txq

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc: TC number

 * @q_handle: software queue handle

 * @num_qgrps: Number of added queue groups

 * @buf: list of queue groups to be added

 * @buf_size: size of buffer for indirect command

 * @cd: pointer to command details structure or NULL

 *

 * This function adds one LAN queue

 find a parent node */

	/* Mark that the values in the "generic" section as valid. The default

	 * value in the "generic" section is zero. This means that :

	 * - Scheduling mode is Bytes Per Second (BPS), indicated by Bit 0.

	 * - 0 priority among siblings, indicated by Bit 1-3.

	 * - WFQ, indicated by Bit 4.

	 * - 0 Adjustment value is used in PSM credit update flow, indicated by

	 * Bit 5-6.

	 * - Bit 7 is reserved.

	 * Without setting the generic section as valid in valid_sections, the

	 * Admin queue command will fail with error code ICE_AQ_RC_EINVAL.

 add the LAN queue */

 add a leaf node into scheduler tree queue layer */

/**

 * ice_dis_vsi_txq

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc: TC number

 * @num_queues: number of queues

 * @q_handles: pointer to software queue handle array

 * @q_ids: pointer to the q_id array

 * @q_teids: pointer to queue node teids

 * @rst_src: if called due to reset, specifies the reset source

 * @vmvf_num: the relative VM or VF number that is undergoing the reset

 * @cd: pointer to command details structure or NULL

 *

 * This function removes queues and their corresponding nodes in SW DB

		/* if queue is disabled already yet the disable queue command

		 * has to be sent to complete the VF reset, then call

		 * ice_aq_dis_lan_txq without any queue information

/**

 * ice_cfg_vsi_qs - configure the new/existing VSI queues

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc_bitmap: TC bitmap

 * @maxqs: max queues array per TC

 * @owner: LAN or RDMA

 *

 * This function adds/updates the VSI queues per TC.

 configuration is possible only if TC node is present */

/**

 * ice_cfg_vsi_lan - configure VSI LAN queues

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc_bitmap: TC bitmap

 * @max_lanqs: max LAN queues array per TC

 *

 * This function adds/updates the VSI LAN queues per TC.

/**

 * ice_cfg_vsi_rdma - configure the VSI RDMA queues

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc_bitmap: TC bitmap

 * @max_rdmaqs: max RDMA queues array per TC

 *

 * This function adds/updates the VSI RDMA queues per TC.

/**

 * ice_ena_vsi_rdma_qset

 * @pi: port information structure

 * @vsi_handle: software VSI handle

 * @tc: TC number

 * @rdma_qset: pointer to RDMA Qset

 * @num_qsets: number of RDMA Qsets

 * @qset_teid: pointer to Qset node TEIDs

 *

 * This function adds RDMA Qset

/**

 * ice_dis_vsi_rdma_qset - free RDMA resources

 * @pi: port_info struct

 * @count: number of RDMA Qsets to free

 * @qset_teid: TEID of Qset node

 * @q_id: list of queue IDs being disabled

/**

 * ice_replay_pre_init - replay pre initialization

 * @hw: pointer to the HW struct

 *

 * Initializes required config data for VSI, FD, ACL, and RSS before replay.

 Delete old entries from replay filter list head if there is any */

	/* In start of replay, move entries into replay_rules list, it

	 * will allow adding rules entries back to filt_rules list,

	 * which is operational list.

/**

 * ice_replay_vsi - replay VSI configuration

 * @hw: pointer to the HW struct

 * @vsi_handle: driver VSI handle

 *

 * Restore all VSI configuration after reset. It is required to call this

 * function with main VSI first.

 Replay pre-initialization if there is any */

 Replay per VSI all RSS configurations */

 Replay per VSI all filters */

/**

 * ice_replay_post - post replay configuration cleanup

 * @hw: pointer to the HW struct

 *

 * Post replay cleanup.

 Delete old entries from replay filter list head */

/**

 * ice_stat_update40 - read 40 bit stat from the chip and update stat values

 * @hw: ptr to the hardware info

 * @reg: offset of 64 bit HW register to read from

 * @prev_stat_loaded: bool to specify if previous stats are loaded

 * @prev_stat: ptr to previous loaded stat value

 * @cur_stat: ptr to current stat value

	/* device stats are not reset at PFR, they likely will not be zeroed

	 * when the driver starts. Thus, save the value from the first read

	 * without adding to the statistic value so that we report stats which

	 * count up from zero.

	/* Calculate the difference between the new and old values, and then

	 * add it to the software stat value.

 to manage the potential roll-over */

 Update the previously stored value to prepare for next read */

/**

 * ice_stat_update32 - read 32 bit stat from the chip and update stat values

 * @hw: ptr to the hardware info

 * @reg: offset of HW register to read from

 * @prev_stat_loaded: bool to specify if previous stats are loaded

 * @prev_stat: ptr to previous loaded stat value

 * @cur_stat: ptr to current stat value

	/* device stats are not reset at PFR, they likely will not be zeroed

	 * when the driver starts. Thus, save the value from the first read

	 * without adding to the statistic value so that we report stats which

	 * count up from zero.

	/* Calculate the difference between the new and old values, and then

	 * add it to the software stat value.

 to manage the potential roll-over */

 Update the previously stored value to prepare for next read */

/**

 * ice_sched_query_elem - query element information from HW

 * @hw: pointer to the HW struct

 * @node_teid: node TEID to be queried

 * @buf: buffer to element information

 *

 * This function queries HW element information

/**

 * ice_aq_set_driver_param - Set driver parameter to share via firmware

 * @hw: pointer to the HW struct

 * @idx: parameter index to set

 * @value: the value to set the parameter to

 * @cd: pointer to command details structure or NULL

 *

 * Set the value of one of the software defined parameters. All PFs connected

 * to this device can read the value using ice_aq_get_driver_param.

 *

 * Note that firmware provides no synchronization or locking, and will not

 * save the parameter value during a device reset. It is expected that

 * a single PF will write the parameter value, while all other PFs will only

 * read it.

/**

 * ice_aq_get_driver_param - Get driver parameter shared via firmware

 * @hw: pointer to the HW struct

 * @idx: parameter index to set

 * @value: storage to return the shared parameter

 * @cd: pointer to command details structure or NULL

 *

 * Get the value of one of the software defined parameters.

 *

 * Note that firmware provides no synchronization or locking. It is expected

 * that only a single PF will write a given parameter.

/**

 * ice_aq_set_gpio

 * @hw: pointer to the hw struct

 * @gpio_ctrl_handle: GPIO controller node handle

 * @pin_idx: IO Number of the GPIO that needs to be set

 * @value: SW provide IO value to set in the LSB

 * @cd: pointer to command details structure or NULL

 *

 * Sends 0x06EC AQ command to set the GPIO pin state that's part of the topology

/**

 * ice_aq_get_gpio

 * @hw: pointer to the hw struct

 * @gpio_ctrl_handle: GPIO controller node handle

 * @pin_idx: IO Number of the GPIO that needs to be set

 * @value: IO value read

 * @cd: pointer to command details structure or NULL

 *

 * Sends 0x06ED AQ command to get the value of a GPIO signal which is part of

 * the topology

/**

 * ice_fw_supports_link_override

 * @hw: pointer to the hardware structure

 *

 * Checks if the firmware supports link override

/**

 * ice_get_link_default_override

 * @ldo: pointer to the link default override struct

 * @pi: pointer to the port info struct

 *

 * Gets the link default override for a port

 Each port has its own config; calculate for our port */

 link options first */

 link PHY config */

 PHY types low */

 shift 16 bits at a time to fill 64 bits */

 PHY types high */

 shift 16 bits at a time to fill 64 bits */

/**

 * ice_is_phy_caps_an_enabled - check if PHY capabilities autoneg is enabled

 * @caps: get PHY capability data

/**

 * ice_aq_set_lldp_mib - Set the LLDP MIB

 * @hw: pointer to the HW struct

 * @mib_type: Local, Remote or both Local and Remote MIBs

 * @buf: pointer to the caller-supplied buffer to store the MIB block

 * @buf_size: size of the buffer (in bytes)

 * @cd: pointer to command details structure or NULL

 *

 * Set the LLDP MIB. (0x0A08)

/**

 * ice_fw_supports_lldp_fltr_ctrl - check NVM version supports lldp_fltr_ctrl

 * @hw: pointer to HW struct

/**

 * ice_lldp_fltr_add_remove - add or remove a LLDP Rx switch filter

 * @hw: pointer to HW struct

 * @vsi_num: absolute HW index for VSI

 * @add: boolean for if adding or removing a filter

/**

 * ice_fw_supports_report_dflt_cfg

 * @hw: pointer to the hardware structure

 *

 * Checks if the firmware supports report default configuration

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019, Intel Corporation. */

/**

 * ice_qp_reset_stats - Resets all stats for rings of given index

 * @vsi: VSI that contains rings of interest

 * @q_idx: ring index in array

/**

 * ice_qp_clean_rings - Cleans all the rings of a given index

 * @vsi: VSI that contains rings of interest

 * @q_idx: ring index in array

/**

 * ice_qvec_toggle_napi - Enables/disables NAPI for a given q_vector

 * @vsi: VSI that has netdev

 * @q_vector: q_vector that has NAPI context

 * @enable: true for enable, false for disable

/**

 * ice_qvec_dis_irq - Mask off queue interrupt generation on given ring

 * @vsi: the VSI that contains queue vector being un-configured

 * @rx_ring: Rx ring that will have its IRQ disabled

 * @q_vector: queue vector

	/* QINT_TQCTL is being cleared in ice_vsi_stop_tx_ring, so handle

	 * here only QINT_RQCTL

/**

 * ice_qvec_cfg_msix - Enable IRQ for given queue vector

 * @vsi: the VSI that contains queue vector

 * @q_vector: queue vector

/**

 * ice_qvec_ena_irq - Enable IRQ for given queue vector

 * @vsi: the VSI that contains queue vector

 * @q_vector: queue vector

/**

 * ice_qp_dis - Disables a queue pair

 * @vsi: VSI of interest

 * @q_idx: ring index in array

 *

 * Returns 0 on success, negative on failure.

/**

 * ice_qp_ena - Enables a queue pair

 * @vsi: VSI of interest

 * @q_idx: ring index in array

 *

 * Returns 0 on success, negative on failure.

/**

 * ice_xsk_pool_disable - disable a buffer pool region

 * @vsi: Current VSI

 * @qid: queue ID

 *

 * Returns 0 on success, negative on failure

/**

 * ice_xsk_pool_enable - enable a buffer pool region

 * @vsi: Current VSI

 * @pool: pointer to a requested buffer pool region

 * @qid: queue ID

 *

 * Returns 0 on success, negative on failure

/**

 * ice_xsk_pool_setup - enable/disable a buffer pool region depending on its state

 * @vsi: Current VSI

 * @pool: buffer pool to enable/associate to a ring, NULL to disable

 * @qid: queue ID

 *

 * Returns 0 on success, negative on failure

/**

 * ice_alloc_rx_bufs_zc - allocate a number of Rx buffers

 * @rx_ring: Rx ring

 * @count: The number of buffers to allocate

 *

 * This function allocates a number of Rx buffers from the fill ring

 * or the internal recycle mechanism and places them on the Rx ring.

 *

 * Returns true if all allocations were successful, false if any fail.

 clear the status bits for the next_to_use descriptor */

/**

 * ice_bump_ntc - Bump the next_to_clean counter of an Rx ring

 * @rx_ring: Rx ring

/**

 * ice_construct_skb_zc - Create an sk_buff from zero-copy buffer

 * @rx_ring: Rx ring

 * @xdp_arr: Pointer to the SW ring of xdp_buff pointers

 *

 * This function allocates a new skb from a zero-copy Rx buffer.

 *

 * Returns the skb on success, NULL on failure.

/**

 * ice_run_xdp_zc - Executes an XDP program in zero-copy path

 * @rx_ring: Rx ring

 * @xdp: xdp_buff used as input to the XDP program

 * @xdp_prog: XDP program to run

 * @xdp_ring: ring to be used for XDP_TX action

 *

 * Returns any of ICE_XDP_{PASS, CONSUMED, TX, REDIR}

/**

 * ice_clean_rx_irq_zc - consumes packets from the hardware ring

 * @rx_ring: AF_XDP Rx ring

 * @budget: NAPI budget

 *

 * Returns number of processed packets on success, remaining budget on failure.

	/* ZC patch is enabled only when XDP program is set,

	 * so here it can not be NULL

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we have

		 * verified the descriptor has been written back.

 XDP_PASS path */

/**

 * ice_xmit_zc - Completes AF_XDP entries, and cleans XDP entries

 * @xdp_ring: XDP Tx ring

 * @budget: max number of frames to xmit

 *

 * Returns true if cleanup/transmission is done.

/**

 * ice_clean_xdp_tx_buf - Free and unmap XDP Tx buffer

 * @xdp_ring: XDP Tx ring

 * @tx_buf: Tx buffer to clean

/**

 * ice_clean_tx_irq_zc - Completes AF_XDP entries, and cleans XDP entries

 * @xdp_ring: XDP Tx ring

 * @budget: NAPI budget

 *

 * Returns true if cleanup/tranmission is done.

/**

 * ice_xsk_wakeup - Implements ndo_xsk_wakeup

 * @netdev: net_device

 * @queue_id: queue to wake up

 * @flags: ignored in our case, since we have Rx and Tx in the same NAPI

 *

 * Returns negative on error, zero otherwise.

	/* The idea here is that if NAPI is running, mark a miss, so

	 * it will run again. If not, trigger an interrupt and

	 * schedule the NAPI from interrupt context. If NAPI would be

	 * scheduled here, the interrupt affinity would not be

	 * honored.

/**

 * ice_xsk_any_rx_ring_ena - Checks if Rx rings have AF_XDP buff pool attached

 * @vsi: VSI to be checked

 *

 * Returns true if any of the Rx rings has an AF_XDP buff pool attached

/**

 * ice_xsk_clean_rx_ring - clean buffer pool queues connected to a given Rx ring

 * @rx_ring: ring to be cleaned

/**

 * ice_xsk_clean_xdp_ring - Clean the XDP Tx ring and its buffer pool queues

 * @xdp_ring: XDP_Tx ring

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

 ethtool support for ice */

/* These PF_STATs might look like duplicates of some NETDEV_STATs,

 * but they aren't. This device is capable of supporting multiple

 * VSIs/netdevs on a single PF. The NETDEV_STATs are for individual

 * netdevs whereas the PF_STATs are for the physical function that's

 * hosting these netdevs.

 *

 * The PF_STATs are appended to the netdev stats only when ethtool -S

 * is queried on the base PF netdev.

 bit position in pf->flags */

	/* Display NVM version (from which the firmware version can be

	 * determined) which contains more pertinent information.

 !CONFIG_DYNAMIC_DEBUG */

 !CONFIG_DYNAMIC_DEBUG */

/**

 * ice_active_vfs - check if there are any active VFs

 * @pf: board private structure

 *

 * Returns true if an active VF is found, otherwise returns false

/**

 * ice_link_test - perform a link test on a given net_device

 * @netdev: network interface device structure

 *

 * This function performs one of the self-tests required by ethtool.

 * Returns 0 on success, non-zero on failure.

/**

 * ice_eeprom_test - perform an EEPROM test on a given net_device

 * @netdev: network interface device structure

 *

 * This function performs one of the self-tests required by ethtool.

 * Returns 0 on success, non-zero on failure.

/**

 * ice_reg_pattern_test

 * @hw: pointer to the HW struct

 * @reg: reg to be tested

 * @mask: bits to be touched

/**

 * ice_reg_test - perform a register test on a given net_device

 * @netdev: network interface device structure

 *

 * This function performs one of the self-tests required by ethtool.

 * Returns 0 on success, non-zero on failure.

 bail on failure (non-zero return) */

/**

 * ice_lbtest_prepare_rings - configure Tx/Rx test rings

 * @vsi: pointer to the VSI structure

 *

 * Function configures rings of a VSI for loopback test without

 * enabling interrupts or informing the kernel about new queues.

 *

 * Returns 0 on success, negative on failure.

/**

 * ice_lbtest_disable_rings - disable Tx/Rx test rings after loopback test

 * @vsi: pointer to the VSI structure

 *

 * Function stops and frees VSI rings after a loopback test.

 * Returns 0 on success, negative on failure.

/**

 * ice_lbtest_create_frame - create test packet

 * @pf: pointer to the PF structure

 * @ret_data: allocated frame buffer

 * @size: size of the packet data

 *

 * Function allocates a frame with a test pattern on specific offsets.

 * Returns 0 on success, non-zero on failure.

	/* Since the ethernet test frame should always be at least

	 * 64 bytes long, fill some octets in the payload with test data.

/**

 * ice_lbtest_check_frame - verify received loopback frame

 * @frame: pointer to the raw packet data

 *

 * Function verifies received test frame with a pattern.

 * Returns true if frame matches the pattern, false otherwise.

 Validate bytes of a frame under offsets chosen earlier */

/**

 * ice_diag_send - send test frames to the test ring

 * @tx_ring: pointer to the transmit ring

 * @data: pointer to the raw packet data

 * @size: size of the packet to send

 *

 * Function sends loopback packets on a test Tx ring.

 These flags are required for a descriptor to be pushed out */

	/* Force memory write to complete before letting h/w know

	 * there are new descriptors to fetch.

 Wait until the packets get transmitted to the receive queue. */

/**

 * ice_lbtest_receive_frames - receive and verify test frames

 * @rx_ring: pointer to the receive ring

 *

 * Function receives loopback packets and verify their correctness.

 * Returns number of received valid frames.

/**

 * ice_loopback_test - perform a loopback test on a given net_device

 * @netdev: network interface device structure

 *

 * This function performs one of the self-tests required by ethtool.

 * Returns 0 on success, non-zero on failure.

 Enable MAC loopback in firmware */

 Test VSI needs to receive broadcast packets */

 Disable MAC loopback after the test is completed. */

/**

 * ice_intr_test - perform an interrupt test on a given net_device

 * @netdev: network interface device structure

 *

 * This function performs one of the self-tests required by ethtool.

 * Returns 0 on success, non-zero on failure.

/**

 * ice_self_test - handler function for performing a self-test by ethtool

 * @netdev: network interface device structure

 * @eth_test: ethtool_test structure

 * @data: required by ethtool.self_test

 *

 * This function is called after invoking 'ethtool -t devname' command where

 * devname is the name of the network device on which ethtool should operate.

 * It performs a set of self-tests to check if a device works properly.

 If the device is online then take it offline */

 indicate we're in test mode */

 Online tests */

 Offline only tests, not run in online; pass by default */

/**

 * ice_set_fec_cfg - Set link FEC options

 * @netdev: network interface device structure

 * @req_fec: FEC mode to configure

 Changing the FEC parameters is not supported if not the PF VSI */

 Proceed only if requesting different FEC mode */

	/* Copy the current user PHY configuration. The current user PHY

	 * configuration is initialized during probe from PHY capabilities

	 * software mode, and updated on set PHY configuration.

 Save requested FEC config */

/**

 * ice_set_fecparam - Set FEC link options

 * @netdev: network interface device structure

 * @fecparam: Ethtool structure to retrieve FEC parameters

/**

 * ice_get_fecparam - Get link FEC options

 * @netdev: network interface device structure

 * @fecparam: Ethtool structure to retrieve FEC parameters

 Set FEC mode based on negotiated link info */

 Set supported/configured FEC modes based on PHY capability */

/**

 * ice_nway_reset - restart autonegotiation

 * @netdev: network interface device structure

 If VSI state is up, then restart autoneg with link up */

/**

 * ice_get_priv_flags - report device private flags

 * @netdev: network interface device structure

 *

 * The get string set count and the string set should be matched for each

 * flag returned.  Add new strings for each flag to the ice_gstrings_priv_flags

 * array.

 *

 * Returns a u32 bitmap of flags.

/**

 * ice_set_priv_flags - set private flags

 * @netdev: network interface device structure

 * @flags: bit flags to be set

	/* Do not allow change to link-down-on-close when Total Port Shutdown

	 * is enabled.

 Disable FW LLDP engine */

			/* If unregistering for LLDP events fails, this is

			 * not an error state, as there shouldn't be any

			 * events to respond to.

			/* The AQ call to stop the FW LLDP agent will generate

			 * an error if the agent is already stopped.

			/* Use case for having the FW LLDP agent stopped

			 * will likely not need DCB, so failure to init is

			 * not a concern of ethtool

			/* Remove rule to direct LLDP packets to default VSI.

			 * The FW LLDP engine will now be consuming them.

			/* AQ command to start FW LLDP agent will return an

			 * error if the agent is already started

			/* AQ command to start FW DCBX agent will fail if

			 * the agent is already started

			/* Failure to configure MIB change or init DCB is not

			 * relevant to ethtool.  Print notification that

			 * registration/init failed but do not return error

			 * state to ethtool

 Register for MIB change events */

 down and up VSI so that changes of Rx cfg are reflected. */

	/* don't allow modification of this flag when a single VF is in

	 * promiscuous mode because it's not supported

 toggle bit back to previous state */

		/* The number (and order) of strings reported *must* remain

		 * constant for a given netdevice. This function must not

		 * report a different number based on run time parameters

		 * (such as the number of queues in use, or the setting of

		 * a private ethtool flag). This is due to the nature of the

		 * ethtool stats API.

		 *

		 * Userspace programs such as ethtool must make 3 separate

		 * ioctl requests, one for size, one for the strings, and

		 * finally one for the stats. Since these cross into

		 * userspace, changes to the number or size could result in

		 * undefined memory access or incorrect string<->value

		 * correlations for statistics.

		 *

		 * Even if it appears to be safe, changes to the size or

		 * order of strings will suffer from race conditions and are

		 * not safe.

 populate per queue stats */

/**

 * ice_mask_min_supported_speeds

 * @phy_types_high: PHY type high

 * @phy_types_low: PHY type low to apply minimum supported speeds mask

 *

 * Apply minimum supported speeds mask to PHY type low. These are the speeds

 * for ethtool supported link mode.

 if QSFP connection with 100G speed, minimum supported speed is 25G */

/**

 * ice_phy_type_to_ethtool - convert the phy_types to ethtool link modes

 * @netdev: network interface device structure

 * @ks: ethtool link ksettings struct to fill out

	/* Check if lenient mode is supported and enabled, or in strict mode.

	 *

	 * In lenient mode the Supported link modes are the PHY types without

	 * media. The Advertising link mode is either 1. the user requested

	 * speed, 2. the override PHY mask, or 3. the PHY types with media.

	 *

	 * In strict mode Supported link mode are the PHY type with media,

	 * and Advertising link modes are the media PHY type or the speed

	 * requested by user.

		/* determine advertised modes based on link override only

		 * if it's supported and if the FW doesn't abstract the

		 * driver from having to account for link overrides

			/* If override enabled and PHY mask set, then

			 * Advertising link mode is the intersection of the PHY

			 * types without media and the override PHY mask.

 strict mode */

	/* If Advertising link mode PHY type is not using override PHY type,

	 * then use PHY type with media.

/**

 * ice_get_settings_link_up - Get Link settings for when link is up

 * @ks: ethtool ksettings to fill in

 * @netdev: network interface device structure

 Get supported and advertised settings from PHY ability with media */

 Set flow control negotiated Rx/Tx pause */

/**

 * ice_get_settings_link_down - Get the Link settings when link is down

 * @ks: ethtool ksettings to fill in

 * @netdev: network interface device structure

 *

 * Reports link settings that can be determined when link is down

	/* link is down and the driver needs to fall back on

	 * supported PHY types to figure out what info to display

 With no link, speed and duplex are unknown */

/**

 * ice_get_link_ksettings - Get Link Speed and Duplex settings

 * @netdev: network interface device structure

 * @ks: ethtool ksettings

 *

 * Reports speed/duplex settings based on media_type

 set speed and duplex */

 set autoneg settings */

 set media type settings */

 flow control is symmetric and always supported */

 Set the advertised flow control based on the PHY capability */

 Set advertised FEC modes based on PHY capability */

 Set supported FEC modes based on PHY capability */

 Set supported and advertised autoneg */

/**

 * ice_ksettings_find_adv_link_speed - Find advertising link speed

 * @ks: ethtool ksettings

/**

 * ice_setup_autoneg

 * @p: port info

 * @ks: ethtool_link_ksettings

 * @config: configuration that will be sent down to FW

 * @autoneg_enabled: autonegotiation is enabled or not

 * @autoneg_changed: will there a change in autonegotiation

 * @netdev: network interface device structure

 *

 * Setup PHY autonegotiation feature

 Check autoneg */

 If autoneg was not already enabled */

 If autoneg is not supported, return error */

 Autoneg is allowed to change */

 If autoneg is currently enabled */

			/* If autoneg is supported 10GBASE_T is the only PHY

			 * that can disable it, so otherwise return error

 Autoneg is allowed to change */

/**

 * ice_set_link_ksettings - Set Speed and Duplex

 * @netdev: network interface device structure

 * @ks: ethtool ksettings

 *

 * Set speed/duplex per media_types advertised/forced

 Get the PHY capabilities based on media */

 save autoneg out of ksettings */

 Get link modes supported by hardware.*/

	/* and check against modes requested by user.

	 * Return an error if unsupported mode was set.

 get our own copy of the bits to check against */

 set autoneg back to what it currently is */

 we don't compare the speed */

	/* If copy_ks.base and safe_ks.base are not the same now, then they are

	 * trying to set something that we do not support.

	/* Copy the current user PHY configuration. The current user PHY

	 * configuration is initialized during probe from PHY capabilities

	 * software mode, and updated on set PHY configuration.

 Check autoneg */

 Call to get the current link speed */

	/* If speed didn't get set, set it to what it currently is.

	 * This is needed because if advertise is 0 (as it is when autoneg

	 * is disabled) then speed won't get set.

 Convert the advertise link speeds to their corresponded PHY_TYPE */

 save the requested speeds */

 set link and auto negotiation so changes take effect */

 check if there is a PHY type for the requested advertised speed */

	/* intersect requested advertised speed PHY types with media PHY types

	 * for set PHY configuration

		/* If there is no intersection and lenient mode is enabled, then

		 * intersect the requested advertised speed with NVM media type

		 * PHY types.

 If link is up put link down */

		/* Tell the OS link is going down, the link will go

		 * back up when fw says it is ready asynchronously

 make the aq call */

 Save speed request */

/**

 * ice_parse_hdrs - parses headers from RSS hash input

 * @nfc: ethtool rxnfc command

 *

 * This function parses the rxnfc command and returns intended

 * header types for RSS configuration

/**

 * ice_parse_hash_flds - parses hash fields from RSS hash input

 * @nfc: ethtool rxnfc command

 *

 * This function parses the rxnfc command and returns intended

 * hash fields for RSS configuration

/**

 * ice_set_rss_hash_opt - Enable/Disable flow types for RSS hash

 * @vsi: the VSI being configured

 * @nfc: ethtool rxnfc command

 *

 * Returns Success if the flow input set is supported.

/**

 * ice_get_rss_hash_opt - Retrieve hash fields for a given flow-type

 * @vsi: the VSI being configured

 * @nfc: ethtool rxnfc command

/**

 * ice_set_rxnfc - command to set Rx flow rules.

 * @netdev: network interface device structure

 * @cmd: ethtool rxnfc command

 *

 * Returns 0 for success and negative values for errors

/**

 * ice_get_rxnfc - command to get Rx flow classification rules

 * @netdev: network interface device structure

 * @cmd: ethtool rxnfc command

 * @rule_locs: buffer to rturn Rx flow classification rules

 *

 * Returns Success if the command is supported.

 report total rule count */

 Rx mini and jumbo rings are not supported */

 if nothing to do return success */

	/* If there is a AF_XDP UMEM attached to any of Rx rings,

	 * disallow changing the number of descriptors -- regardless

	 * if the netdev is running or not.

 set for the next time the netdev is started */

 alloc updated Tx resources */

 clone ring and setup updated count */

 alloc updated XDP resources */

 clone ring and setup updated count */

 alloc updated Rx resources */

 clone ring and setup updated count */

		/* this is to allow wr32 to have something to write to

		 * during early allocation of Rx buffers

 allocate Rx buffers */

	/* Bring interface down, copy in the new ring info, then restore the

	 * interface. if VSI is up, bring it down and then back up

 copy the real tail offset */

				/* this is to fake out the allocation routine

				 * into thinking it has to realloc everything

				 * but the recycling logic will let us re-use

				 * the buffers allocated above

 error cleanup if the Rx allocations failed after getting Tx */

/**

 * ice_get_pauseparam - Get Flow Control status

 * @netdev: network interface device structure

 * @pause: ethernet pause (flow control) parameters

 *

 * Get requested flow control status from PHY capability.

 * If autoneg is true, then ethtool will send the ETHTOOL_GSET ioctl which

 * is handled by ice_get_link_ksettings. ice_get_link_ksettings will report

 * the negotiated Rx/Tx pause via lp_advertising.

 Initialize pause params */

 Get current PHY config */

 PFC enabled so report LFC as off */

/**

 * ice_set_pauseparam - Set Flow Control parameter

 * @netdev: network interface device structure

 * @pause: return Tx/Rx flow control status

	/* Changing the port's flow control is not supported if this isn't the

	 * PF VSI

	/* Get pause param reports configured and negotiated flow control pause

	 * when ETHTOOL_GLINKSETTINGS is defined. Since ETHTOOL_GLINKSETTINGS is

	 * defined get pause param pause->autoneg reports SW configured setting,

	 * so compare pause->autoneg with SW configured to prevent the user from

	 * using set pause param to chance autoneg.

 Get current PHY config */

 If we have link and don't have autoneg */

 Send message that it might not necessarily work*/

 Set the FC mode and only restart AN if link is up */

/**

 * ice_get_rxfh_key_size - get the RSS hash key size

 * @netdev: network interface device structure

 *

 * Returns the table size.

/**

 * ice_get_rxfh_indir_size - get the Rx flow hash indirection table size

 * @netdev: network interface device structure

 *

 * Returns the table size.

/**

 * ice_get_rxfh - get the Rx flow hash indirection table

 * @netdev: network interface device structure

 * @indir: indirection table

 * @key: hash key

 * @hfunc: hash function

 *

 * Reads the indirection table directly from the hardware.

 RSS not supported return error here */

/**

 * ice_set_rxfh - set the Rx flow hash indirection table

 * @netdev: network interface device structure

 * @indir: indirection table

 * @key: hash key

 * @hfunc: hash function

 *

 * Returns -EINVAL if the table specifies an invalid queue ID, otherwise

 * returns 0 after programming the table.

 RSS not supported return error here */

 Each 32 bits pointed by 'indir' is stored with a lut entry */

 only report timestamping if PTP is enabled */

/**

 * ice_get_max_txq - return the maximum number of Tx queues for in a PF

 * @pf: PF structure

/**

 * ice_get_max_rxq - return the maximum number of Rx queues for in a PF

 * @pf: PF structure

/**

 * ice_get_combined_cnt - return the current number of combined channels

 * @vsi: PF VSI pointer

 *

 * Go through all queue vectors and count ones that have both Rx and Tx ring

 * attached

/**

 * ice_get_channels - get the current and max supported channels

 * @dev: network interface device structure

 * @ch: ethtool channel data structure

 report maximum channels */

 report current channels */

 report other queues */

/**

 * ice_get_valid_rss_size - return valid number of RSS queues

 * @hw: pointer to the HW structure

 * @new_size: requested RSS queues

/**

 * ice_vsi_set_dflt_rss_lut - set default RSS LUT with requested RSS size

 * @vsi: VSI to reconfigure RSS LUT on

 * @req_rss_size: requested range of queue numbers for hashing

 *

 * Set the VSI's RSS parameters, configure the RSS LUT based on these.

 set RSS LUT parameters */

 create/set RSS LUT */

/**

 * ice_set_channels - set the number channels

 * @dev: network interface device structure

 * @ch: ethtool channel data structure

 do not support changing channels in Safe Mode */

 do not support changing other_count */

	/* these checks are for cases where user didn't specify a particular

	 * value on cmd line but we get non-zero value anyway via

	 * get_channels(); look at ethtool.c in ethtool repository (the user

	 * space part), particularly, do_schannels() routine

 Update rss_size due to change in Rx queues */

/**

 * ice_get_wol - get current Wake on LAN configuration

 * @netdev: network interface device structure

 * @wol: Ethtool structure to retrieve WoL settings

 Get WoL settings based on the HW capability */

/**

 * ice_set_wol - set Wake on LAN on supported device

 * @netdev: network interface device structure

 * @wol: Ethtool structure to set WoL

 only magic packet is supported */

 Set WoL only if there is a new value */

/**

 * ice_get_rc_coalesce - get ITR values for specific ring container

 * @ec: ethtool structure to fill with driver's coalesce settings

 * @rc: ring container that the ITR values will come from

 *

 * Query the device for ice_ring_container specific ITR values. This is

 * done per ice_ring_container because each q_vector can have 1 or more rings

 * and all of said ring(s) will have the same ITR values.

 *

 * Returns 0 on success, negative otherwise.

/**

 * ice_get_q_coalesce - get a queue's ITR/INTRL (coalesce) settings

 * @vsi: VSI associated to the queue for getting ITR/INTRL (coalesce) settings

 * @ec: coalesce settings to program the device with

 * @q_num: update ITR/INTRL (coalesce) settings for this queue number/index

 *

 * Return 0 on success, and negative under the following conditions:

 * 1. Getting Tx or Rx ITR/INTRL (coalesce) settings failed.

 * 2. The q_num passed in is not a valid number/index for Tx and Rx rings.

/**

 * __ice_get_coalesce - get ITR/INTRL values for the device

 * @netdev: pointer to the netdev associated with this query

 * @ec: ethtool structure to fill with driver's coalesce settings

 * @q_num: queue number to get the coalesce settings for

 *

 * If the caller passes in a negative q_num then we return coalesce settings

 * based on queue number 0, else use the actual q_num passed in.

/**

 * ice_set_rc_coalesce - set ITR values for specific ring container

 * @ec: ethtool structure from user to update ITR settings

 * @rc: ring container that the ITR values will come from

 * @vsi: VSI associated to the ring container

 *

 * Set specific ITR values. This is done per ice_ring_container because each

 * q_vector can have 1 or more rings and all of said ring(s) will have the same

 * ITR values.

 *

 * Returns 0 on success, negative otherwise.

 store user facing value how it was set */

 write the change to the register */

		/* force writes to take effect immediately, the flush shouldn't

		 * be done in the functions above because the intent is for

		 * them to do lazy writes.

/**

 * ice_set_q_coalesce - set a queue's ITR/INTRL (coalesce) settings

 * @vsi: VSI associated to the queue that need updating

 * @ec: coalesce settings to program the device with

 * @q_num: update ITR/INTRL (coalesce) settings for this queue number/index

 *

 * Return 0 on success, and negative under the following conditions:

 * 1. Setting Tx or Rx ITR/INTRL (coalesce) settings failed.

 * 2. The q_num passed in is not a valid number/index for Tx and Rx rings.

/**

 * ice_print_if_odd_usecs - print message if user tries to set odd [tx|rx]-usecs

 * @netdev: netdev used for print

 * @itr_setting: previous user setting

 * @use_adaptive_coalesce: if adaptive coalesce is enabled or being enabled

 * @coalesce_usecs: requested value of [tx|rx]-usecs

 * @c_type_str: either "rx" or "tx" to match user set field of [tx|rx]-usecs

/**

 * __ice_set_coalesce - set ITR/INTRL values for the device

 * @netdev: pointer to the netdev associated with this query

 * @ec: ethtool structure to fill with driver's coalesce settings

 * @q_num: queue number to get the coalesce settings for

 *

 * If the caller passes in a negative q_num then we set the coalesce settings

 * for all Tx/Rx queues, else use the actual q_num passed in.

			/* In some cases if DCB is configured the num_[rx|tx]q

			 * can be less than vsi->num_q_vectors. This check

			 * accounts for that so we don't report a false failure

 for port representors only ETH_SS_STATS is supported */

/**

 * ice_get_module_info - get SFF module type and revision information

 * @netdev: network interface device structure

 * @modinfo: module EEPROM size and layout information structure

 Check revision compliance */

 Module is SFF-8636 compliant */

/**

 * ice_get_module_eeprom - fill buffer with SFF EEPROM contents

 * @netdev: network interface device structure

 * @ee: EEPROM dump request structure

 * @data: buffer to be filled with EEPROM contents

 Check if we need to access the other memory page */

 Compute memory page number and offset. */

		/* Bit 2 of EEPROM address 0x02 declares upper

		 * pages are disabled on QSFP modules.

		 * SFP modules only ever use page 0.

			/* If i2c bus is busy due to slow page change or

			 * link management access, call can fail. This is normal.

			 * So we retry this a few times.

 Make sure we have enough room for the new block */

/**

 * ice_set_ethtool_safe_mode_ops - setup safe mode ethtool ops

 * @netdev: network interface device structure

/**

 * ice_set_ethtool_repr_ops - setup VF's port representor ethtool ops

 * @netdev: network interface device structure

/**

 * ice_set_ethtool_ops - setup netdev ethtool ops

 * @netdev: network interface device structure

 *

 * setup netdev ethtool ops with ice specific ops

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2019-2021, Intel Corporation. */

/**

 * ice_eswitch_setup_env - configure switchdev HW filters

 * @pf: pointer to PF struct

 *

 * This function adds HW filters configuration specific for switchdev

 * mode.

/**

 * ice_eswitch_remap_rings_to_vectors - reconfigure rings of switchdev ctrl VSI

 * @pf: pointer to PF struct

 *

 * In switchdev number of allocated Tx/Rx rings is equal.

 *

 * This function fills q_vectors structures associated with representor and

 * move each ring pairs to port representor netdevs. Each port representor

 * will have dedicated 1 Tx/Rx ring pair, so number of rings pair is equal to

 * number of VFs.

		/* In switchdev mode, from OS stack perspective, there is only

		 * one queue for given netdev, so it needs to be indexed as 0.

/**

 * ice_eswitch_setup_reprs - configure port reprs to run in switchdev mode

 * @pf: pointer to PF struct

/**

 * ice_eswitch_release_reprs - clear PR VSIs configuration

 * @pf: poiner to PF struct

 * @ctrl_vsi: pointer to switchdev control VSI

/**

 * ice_eswitch_update_repr - reconfigure VF port representor

 * @vsi: VF VSI for which port representor is configured

/**

 * ice_eswitch_port_start_xmit - callback for packets transmit

 * @skb: send buffer

 * @netdev: network interface device structure

 *

 * Returns NETDEV_TX_OK if sent, else an error code

/**

 * ice_eswitch_set_target_vsi - set switchdev context in Tx context descriptor

 * @skb: pointer to send buffer

 * @off: pointer to offload struct

/**

 * ice_eswitch_release_env - clear switchdev HW filters

 * @pf: pointer to PF struct

 *

 * This function removes HW filters configuration specific for switchdev

 * mode and restores default legacy mode settings.

/**

 * ice_eswitch_vsi_setup - configure switchdev control VSI

 * @pf: pointer to PF structure

 * @pi: pointer to port_info structure

/**

 * ice_eswitch_napi_del - remove NAPI handle for all port representors

 * @pf: pointer to PF structure

/**

 * ice_eswitch_napi_enable - enable NAPI for all port representors

 * @pf: pointer to PF structure

/**

 * ice_eswitch_napi_disable - disable NAPI for all port representors

 * @pf: pointer to PF structure

/**

 * ice_eswitch_set_rxdid - configure rxdid on all Rx queues from VSI

 * @vsi: VSI to setup rxdid on

 * @rxdid: flex descriptor id

/**

 * ice_eswitch_enable_switchdev - configure eswitch in switchdev mode

 * @pf: pointer to PF structure

/**

 * ice_eswitch_disable_switchdev - disable switchdev resources

 * @pf: pointer to PF structure

/**

 * ice_eswitch_mode_set - set new eswitch mode

 * @devlink: pointer to devlink structure

 * @mode: eswitch mode to switch to

 * @extack: pointer to extack structure

/**

 * ice_eswitch_get_target_netdev - return port representor netdev

 * @rx_ring: pointer to Rx ring

 * @rx_desc: pointer to Rx descriptor

 *

 * When working in switchdev mode context (when control VSI is used), this

 * function returns netdev of appropriate port representor. For non-switchdev

 * context, regular netdev associated with Rx ring is returned.

/**

 * ice_eswitch_mode_get - get current eswitch mode

 * @devlink: pointer to devlink structure

 * @mode: output parameter for current eswitch mode

/**

 * ice_is_eswitch_mode_switchdev - check if eswitch mode is set to switchdev

 * @pf: pointer to PF structure

 *

 * Returns true if eswitch mode is set to DEVLINK_ESWITCH_MODE_SWITCHDEV,

 * false otherwise.

/**

 * ice_eswitch_release - cleanup eswitch

 * @pf: pointer to PF structure

/**

 * ice_eswitch_configure - configure eswitch

 * @pf: pointer to PF structure

/**

 * ice_eswitch_start_all_tx_queues - start Tx queues of all port representors

 * @pf: pointer to PF structure

/**

 * ice_eswitch_stop_all_tx_queues - stop Tx queues of all port representors

 * @pf: pointer to PF structure

/**

 * ice_eswitch_rebuild - rebuild eswitch

 * @pf: pointer to PF structure

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2008 Intel Corporation. */

 Local prototypes */

/******************************************************************************

 * Raises the EEPROM's clock input.

 *

 * hw - Struct containing variables accessed by shared code

 * eecd_reg - EECD's current value

	/* Raise the clock input to the EEPROM (by setting the SK bit), and then

	 *  wait 50 microseconds.

/******************************************************************************

 * Lowers the EEPROM's clock input.

 *

 * hw - Struct containing variables accessed by shared code

 * eecd_reg - EECD's current value

	/* Lower the clock input to the EEPROM (by clearing the SK bit), and then

	 * wait 50 microseconds.

/******************************************************************************

 * Shift data bits out to the EEPROM.

 *

 * hw - Struct containing variables accessed by shared code

 * data - data to send to the EEPROM

 * count - number of bits to shift out

	/* We need to shift "count" bits out to the EEPROM. So, value in the

	 * "data" parameter will be shifted out to the EEPROM one bit at a time.

	 * In order to do this, "data" must be broken down into bits.

		/* A "1" is shifted out to the EEPROM by setting bit "DI" to a "1",

		 * and then raising and then lowering the clock (the SK bit controls

		 * the clock input to the EEPROM).  A "0" is shifted out to the EEPROM

		 * by setting "DI" to "0" and then raising and then lowering the clock.

 We leave the "DI" bit set to "0" when we leave this routine. */

/******************************************************************************

 * Shift data bits in from the EEPROM

 *

 * hw - Struct containing variables accessed by shared code

	/* In order to read a register from the EEPROM, we need to shift 16 bits

	 * in from the EEPROM. Bits are "shifted in" by raising the clock input to

	 * the EEPROM (setting the SK bit), and then reading the value of the "DO"

	 * bit.  During this "shifting in" process the "DI" bit should always be

	 * clear..

/******************************************************************************

 * Prepares EEPROM for access

 *

 * hw - Struct containing variables accessed by shared code

 *

 * Lowers EEPROM clock. Clears input pin. Sets the chip select pin. This

 * function should be called before issuing a command to the EEPROM.

  Clear SK and DI  */

  Set CS  */

/******************************************************************************

 * Returns EEPROM to a "standby" state

 *

 * hw - Struct containing variables accessed by shared code

  Deselect EEPROM  */

  Clock high  */

  Select EEPROM  */

  Clock low  */

/******************************************************************************

 * Raises then lowers the EEPROM's clock pin

 *

 * hw - Struct containing variables accessed by shared code

  Rising edge of clock  */

  Falling edge of clock  */

/******************************************************************************

 * Terminates a command by lowering the EEPROM's chip select pin

 *

 * hw - Struct containing variables accessed by shared code

/******************************************************************************

 * Waits for the EEPROM to finish the current command.

 *

 * hw - Struct containing variables accessed by shared code

 *

 * The command is done when the EEPROM's data out pin goes high.

 *

 * Returns:

 *      true: EEPROM data pin is high before timeout.

 *      false:  Time expired.

	/* Toggle the CS line.  This in effect tells to EEPROM to actually execute

	 * the command in question.

	/* Now read DO repeatedly until is high (equal to '1').  The EEPROM will

	 * signal that the command has been completed by raising the DO signal.

	 * If DO does not go high in 10 milliseconds, then error out.

/******************************************************************************

 * Verifies that the EEPROM has a valid checksum

 *

 * hw - Struct containing variables accessed by shared code

 *

 * Reads the first 64 16 bit words of the EEPROM and sums the values read.

 * If the sum of the 64 16 bit words is 0xBABA, the EEPROM's checksum is

 * valid.

 *

 * Returns:

 *  true: Checksum is valid

 *  false: Checksum is not valid.

/******************************************************************************

 * Calculates the EEPROM checksum and writes it to the EEPROM

 *

 * hw - Struct containing variables accessed by shared code

 *

 * Sums the first 63 16 bit words of the EEPROM. Subtracts the sum from 0xBABA.

 * Writes the difference to word offset 63 of the EEPROM.

/******************************************************************************

 * Writes a 16 bit word to a given offset in the EEPROM.

 *

 * hw - Struct containing variables accessed by shared code

 * reg - offset within the EEPROM to be written to

 * data - 16 bit word to be written to the EEPROM

 *

 * If ixgb_update_eeprom_checksum is not called after this function, the

 * EEPROM will most likely contain an invalid checksum.

 *

 Prepare the EEPROM for writing */

	/*  Send the 9-bit EWEN (write enable) command to the EEPROM (5-bit opcode

	 *  plus 4-bit dummy).  This puts the EEPROM into write/erase mode.

  Prepare the EEPROM  */

  Send the Write command (3-bit opcode + 6-bit addr)  */

  Send the data  */

  Recover from write  */

	/* Send the 9-bit EWDS (write disable) command to the EEPROM (5-bit

	 * opcode plus 4-bit dummy).  This takes the EEPROM out of write/erase

	 * mode.

  Done with writing  */

 clear the init_ctrl_reg_1 to signify that the cache is invalidated */

/******************************************************************************

 * Reads a 16 bit word from the EEPROM.

 *

 * hw - Struct containing variables accessed by shared code

 * offset - offset of 16 bit word in the EEPROM to read

 *

 * Returns:

 *  The 16-bit value read from the eeprom

  Prepare the EEPROM for reading  */

  Send the READ command (opcode + addr)  */

	/*

	 * We have a 64 word EEPROM, there are 6 address bits

  Read the data  */

  End this read operation  */

/******************************************************************************

 * Reads eeprom and stores data in shared structure.

 * Validates eeprom checksum and eeprom signature.

 *

 * hw - Struct containing variables accessed by shared code

 *

 * Returns:

 *      true: if eeprom read is successful

 *      false: otherwise.

		/* clear the init_ctrl_reg_1 to signify that the cache is

/******************************************************************************

 * Local function to check if the eeprom signature is good

 * If the eeprom signature is good, calls ixgb)get_eeprom_data.

 *

 * hw - Struct containing variables accessed by shared code

 *

 * Returns:

 *      true: eeprom signature was good and the eeprom read was successful

 *      false: otherwise.

/******************************************************************************

 * return a word from the eeprom

 *

 * hw - Struct containing variables accessed by shared code

 * index - Offset of eeprom word

 *

 * Returns:

 *          Word at indexed offset in eeprom, if valid, 0 otherwise.

/******************************************************************************

 * return the mac address from EEPROM

 *

 * hw       - Struct containing variables accessed by shared code

 * mac_addr - Ethernet Address if EEPROM contents are valid, 0 otherwise

 *

 * Returns: None.

/******************************************************************************

 * return the Printed Board Assembly number from EEPROM

 *

 * hw - Struct containing variables accessed by shared code

 *

 * Returns:

 *          PBA number if EEPROM contents are valid, 0 otherwise

/******************************************************************************

 * return the Device Id from EEPROM

 *

 * hw - Struct containing variables accessed by shared code

 *

 * Returns:

 *          Device Id if EEPROM contents are valid, 0 otherwise

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2008 Intel Corporation. */

/* ixgb_hw.c

 * Shared functions for accessing and configuring the adapter

  Local function prototypes */

 All pins are Output=1 */

 Initial value 1101   */

 Workaround for 82597EX reset errata */

 Delay a few ms just to allow the reset to complete */

 Make sure the self-clearing global reset bit did self clear */

 Enable interrupt from XFP and SerDes */

/******************************************************************************

 * Reset the transmit and receive units; mask and clear all interrupts.

 *

 * hw - Struct containing variables accessed by shared code

	/* If we are stopped or resetting exit gracefully and wait to be

	 * started again before accessing the hardware.

	/* Set the Adapter Stopped flag so other driver functions stop

	 * touching the Hardware.

 Clear interrupt mask to stop board from generating interrupts */

	/* Disable the Transmit and Receive units.  Then delay to allow

	 * any pending transactions to complete before we hit the MAC with

	 * the global reset.

	/* Issue a global reset to the MAC.  This will reset the chip's

	 * transmit, receive, DMA, and link units.  It will not effect

	 * the current PCI configuration.  The global reset bit is self-

	 * clearing, and should clear within a microsecond.

 Clear interrupt mask to stop board from generating interrupts */

 Clear any pending interrupt events. */

/******************************************************************************

 * Identifies the vendor of the optics module on the adapter.  The SR adapters

 * support two different types of XPAK optics, so it is necessary to determine

 * which optics are present before applying any optics-specific workarounds.

 *

 * hw - Struct containing variables accessed by shared code.

 *

 * Returns: the vendor of the XPAK optics module.

	/* Read the first few bytes of the vendor string from the XPAK NVR

	 * registers.  These are standard XENPAK/XPAK registers, so all XPAK

 Determine the actual vendor */

/******************************************************************************

 * Determine the physical layer module on the adapter.

 *

 * hw - Struct containing variables accessed by shared code.  The device_id

 *      field must be (correctly) populated before calling this routine.

 *

 * Returns: the phy type of the adapter.

 Infer the transceiver/phy type from the device id */

		/* The SR adapters carry two different types of XPAK optics

		 * modules; read the vendor identifier to determine the exact

 update phy type for sun specific board */

/******************************************************************************

 * Performs basic configuration of the adapter.

 *

 * hw - Struct containing variables accessed by shared code

 *

 * Resets the controller.

 * Reads and validates the EEPROM.

 * Initializes the receive address registers.

 * Initializes the multicast table.

 * Clears all on-chip counters.

 * Calls routine to setup flow control settings.

 * Leaves the transmit and receive units disabled and uninitialized.

 *

 * Returns:

 *      true if successful,

 *      false if unrecoverable problems were encountered.

	/* Issue a global reset to the MAC.  This will reset the chip's

	 * transmit, receive, DMA, and link units.  It will not effect

	 * the current PCI configuration.  The global reset bit is self-

	 * clearing, and should clear within a microsecond.

 Workaround for 82597EX reset errata */

 Delay a few ms just to allow the reset to complete */

 Use the device id to determine the type of phy/transceiver. */

	/* Setup the receive addresses.

	 * Receive Address Registers (RARs 0 - 15).

	/*

	 * Check that a valid MAC address has been set.

	 * If it is not valid, we fail hardware init.

 tell the routines in this file they can access hardware again */

 Fill in the bus_info structure */

 Zero out the Multicast HASH table */

 Zero out the VLAN Filter Table Array */

 Zero all of the hardware counters */

 Call a subroutine to setup flow control. */

 82597EX errata: Call check-for-link in case lane deskew is locked */

/******************************************************************************

 * Initializes receive address filters.

 *

 * hw - Struct containing variables accessed by shared code

 *

 * Places the MAC address in receive address register 0 and clears the rest

 * of the receive address registers. Clears the multicast table. Assumes

 * the receiver is in reset when the routine is called.

	/*

	 * If the current mac address is valid, assume it is a software override

	 * to the permanent address.

	 * Otherwise, use the permanent address from the eeprom.

 Get the MAC address from the eeprom for later reference */

 Setup the receive address. */

 Zero out the other 15 receive addresses. */

 Write high reg first to disable the AV bit first */

/******************************************************************************

 * Updates the MAC's list of multicast addresses.

 *

 * hw - Struct containing variables accessed by shared code

 * mc_addr_list - the list of new multicast addresses

 * mc_addr_count - number of addresses

 * pad - number of bytes between addresses in the list

 *

 * The given list replaces any existing list. Clears the last 15 receive

 * address registers and the multicast table. Uses receive address registers

 * for the first 15 multicast addresses, and hashes the rest into the

 * multicast table.

 RAR[0] is used for our MAC address */

 Set the new number of MC addresses that we are being requested to use. */

 Clear RAR[1-15] */

 Clear the MTA */

 Add the new addresses */

		/* Place this multicast address in the RAR if there is room, *

		 * else put it in the MTA

/******************************************************************************

 * Hashes an address to determine its location in the multicast table

 *

 * hw - Struct containing variables accessed by shared code

 * mc_addr - the multicast address to hash

 *

 * Returns:

 *      The hash value

	/* The portion of the address that is used for the hash table is

	 * determined by the mc_filter_type setting.

		/* [0] [1] [2] [3] [4] [5]

		 * 01  AA  00  12  34  56

 [47:36] i.e. 0x563 for above example address */

 [46:35] i.e. 0xAC6 for above example address */

 [45:34] i.e. 0x5D8 for above example address */

 [43:32] i.e. 0x634 for above example address */

 Invalid mc_filter_type, what should we do? */

/******************************************************************************

 * Sets the bit in the multicast table corresponding to the hash value.

 *

 * hw - Struct containing variables accessed by shared code

 * hash_value - Multicast address hash value

	/* The MTA is a register array of 128 32-bit registers.

	 * It is treated like an array of 4096 bits.  We want to set

	 * bit BitArray[hash_value]. So we figure out what register

	 * the bit is in, read it, OR in the new bit, then write

	 * back the new value.  The register is determined by the

	 * upper 7 bits of the hash value and the bit within that

	 * register are determined by the lower 5 bits of the value.

/******************************************************************************

 * Puts an ethernet address into a receive address register.

 *

 * hw - Struct containing variables accessed by shared code

 * addr - Address to put into receive address register

 * index - Receive address register to write

	/* HW expects these in little endian so we reverse the byte order

	 * from network order (big endian) to little endian

/******************************************************************************

 * Writes a value to the specified offset in the VLAN filter table.

 *

 * hw - Struct containing variables accessed by shared code

 * offset - Offset in VLAN filer table to write

 * value - Value to write into VLAN filter table

/******************************************************************************

 * Clears the VLAN filer table

 *

 * hw - Struct containing variables accessed by shared code

/******************************************************************************

 * Configures the flow control settings based on SW configuration.

 *

 * hw - Struct containing variables accessed by shared code

 by default, assume no pause time */

 Get the current control reg 0 settings */

 Clear the Receive Pause Enable and Transmit Pause Enable bits */

	/* The possible values of the "flow_control" parameter are:

	 *      0:  Flow control is completely disabled

	 *      1:  Rx flow control is enabled (we can receive pause frames

	 *          but not send pause frames).

	 *      2:  Tx flow control is enabled (we can send pause frames

	 *          but we do not support receiving pause frames).

	 *      3:  Both Rx and TX flow control (symmetric) are enabled.

	 *  other:  Invalid.

 0 */

 Set CMDC bit to disable Rx Flow control */

 1 */

		/* RX Flow control is enabled, and TX Flow control is

		 * disabled.

 2 */

		/* TX Flow control is enabled, and RX Flow control is

		 * disabled, by a software over-ride.

 3 */

		/* Flow control (both RX and TX) is enabled by a software

		 * over-ride.

 We should never get here.  The value should be 0-3. */

 Write the new settings */

	/* Set the flow control receive threshold registers.  Normally,

	 * these registers will be set to a default threshold that may be

	 * adjusted later by the driver's runtime code.  However, if the

	 * ability to transmit pause frames in not enabled, then these

	 * registers will be set to 0.

	   /* We need to set up the Receive Threshold high and low water

	    * marks as well as (optionally) enabling the transmission of XON

/******************************************************************************

 * Reads a word from a device over the Management Data Interface (MDI) bus.

 * This interface is used to manage Physical layer devices.

 *

 * hw          - Struct containing variables accessed by hw code

 * reg_address - Offset of device register being read.

 * phy_address - Address of device on MDI.

 *

 * Returns:  Data word (16 bits) from MDI device.

 *

 * The 82597EX has support for several MDI access methods.  This routine

 * uses the new protocol MDI Single Command and Address Operation.

 * This requires that first an address cycle command is sent, followed by a

 * read command.

 Setup and write the address cycle command */

    /**************************************************************

    ** Check every 10 usec to see if the address cycle completed

    ** The COMMAND bit will clear when the operation is complete.

    ** This may take as long as 64 usecs (we'll wait 100 usecs max)

    ** from the CPU Write to the Ready bit assertion.

 Address cycle complete, setup and write the read command */

    /**************************************************************

    ** Check every 10 usec to see if the read command completed

    ** The COMMAND bit will clear when the operation is complete.

    ** The read may take as long as 64 usecs (we'll wait 100 usecs max)

    ** from the CPU Write to the Ready bit assertion.

	/* Operation is complete, get the data from the MDIO Read/Write Data

	 * register and return.

/******************************************************************************

 * Writes a word to a device over the Management Data Interface (MDI) bus.

 * This interface is used to manage Physical layer devices.

 *

 * hw          - Struct containing variables accessed by hw code

 * reg_address - Offset of device register being read.

 * phy_address - Address of device on MDI.

 * device_type - Also known as the Device ID or DID.

 * data        - 16-bit value to be written

 *

 * Returns:  void.

 *

 * The 82597EX has support for several MDI access methods.  This routine

 * uses the new protocol MDI Single Command and Address Operation.

 * This requires that first an address cycle command is sent, followed by a

 * write command.

 Put the data in the MDIO Read/Write Data register */

 Setup and write the address cycle command */

	/**************************************************************

	** Check every 10 usec to see if the address cycle completed

	** The COMMAND bit will clear when the operation is complete.

	** This may take as long as 64 usecs (we'll wait 100 usecs max)

	** from the CPU Write to the Ready bit assertion.

 Address cycle complete, setup and write the write command */

	/**************************************************************

	** Check every 10 usec to see if the read command completed

	** The COMMAND bit will clear when the operation is complete.

	** The write may take as long as 64 usecs (we'll wait 100 usecs max)

	** from the CPU Write to the Ready bit assertion.

 Operation is complete, return. */

/******************************************************************************

 * Checks to see if the link status of the hardware has changed.

 *

 * hw - Struct containing variables accessed by hw code

 *

 * Called by any function that needs to check the link status of the adapter.

		/*

		 * 82597EX errata.  Since the lane deskew problem may prevent

		 * link, reset the link before reporting link down.

  Anything else for 10 Gig?? */

/******************************************************************************

 * Check for a bad link condition that may have occurred.

 * The indication is that the RFC / LFC registers may be incrementing

 * continually.  A full adapter reset is required to recover.

 *

 * hw - Struct containing variables accessed by hw code

 *

 * Called by any function that needs to check the link status of the adapter.

/******************************************************************************

 * Clears all hardware statistics counters.

 *

 * hw - Struct containing variables accessed by shared code

 if we are stopped or resetting exit gracefully */

/******************************************************************************

 * Turns on the software controllable LED

 *

 * hw - Struct containing variables accessed by shared code

 To turn on the LED, clear software-definable pin 0 (SDP0). */

/******************************************************************************

 * Turns off the software controllable LED

 *

 * hw - Struct containing variables accessed by shared code

 To turn off the LED, set software-definable pin 0 (SDP0). */

/******************************************************************************

 * Gets the current PCI bus type, speed, and width of the hardware

 *

 * hw - Struct containing variables accessed by shared code

/******************************************************************************

 * Tests a MAC address to ensure it is a valid Individual Address

 *

 * mac_addr - pointer to MAC address.

 *

 Make sure it is not a multicast address */

 Not a broadcast address */

 Reject the zero address */

/******************************************************************************

 * Resets the 10GbE link.  Waits the settle time and returns the state of

 * the link.

 *

 * hw - Struct containing variables accessed by shared code

 Reset the link */

 Wait for link-up and lane re-alignment */

/******************************************************************************

 * Resets the 10GbE optics module.

 *

 * hw - Struct containing variables accessed by shared code

/******************************************************************************

 * Resets the 10GbE optics module for Sun variant NIC.

 *

 * hw - Struct containing variables accessed by shared code

 SerDes needs extra delay */

 Broadcom 7408L configuration */

 Reference clock config */

  we must read the registers twice */

 SerDes needs extra delay */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2008 Intel Corporation. */

 ethtool support for ixgb */

	{ "rx_length_errors", IXGB_NETDEV_STAT(stats.rx_length_errors) },	*/

 be optimistic about our link, since we were up before */

	/* the 1 (one) below indicates an attempt at versioning, if the

	 * interface in ethtool or the driver changes, this 1 should be

 General Registers */

   0 */

   1 */

   2 */

   3 */

   4 */

 Interrupt */

   5 */

   6 */

   7 */

   8 */

 Receive */

   9 */

  10 */

  11 */

  12 */

  13 */

  14 */

  15 */

  16 */

  17 */

  18 */

  19 */

  20 */

 there are 16 RAR entries in hardware, we only use 3 */

21,...,51 */

22,...,52 */

 Transmit */

  53 */

  54 */

  55 */

  56 */

  57 */

  58 */

  59 */

  60 */

  61 */

  62 */

 Physical */

  63 */

  64 */

  65 */

  66 */

  67 */

  68 */

  69 */

  70 */

  71 */

  72 */

  73 */

  74 */

  75 */

 Statistics */

  76 */

  77 */

  78 */

  79 */

  80 */

  81 */

  82 */

  83 */

  84 */

  85 */

  86 */

  87 */

  88 */

  89 */

  90 */

  91 */

  92 */

  93 */

  94 */

  95 */

  96 */

  97 */

  98 */

  99 */

 100 */

 101 */

 102 */

 103 */

 104 */

 105 */

 106 */

 107 */

 108 */

 109 */

 110 */

 111 */

 112 */

 113 */

 114 */

 115 */

 116 */

 117 */

 118 */

 119 */

 120 */

 121 */

 122 */

 123 */

 124 */

 125 */

 126 */

 127 */

 128 */

 129 */

 130 */

 131 */

 132 */

 133 */

 134 */

 135 */

 return size in bytes */

 note the eeprom was good because the driver loaded */

 need read/modify/write of first changed EEPROM word */

 only the second byte of the word is being modified */

 need read/modify/write of last changed EEPROM word */

 only the first byte of the word is being modified */

 Update the checksum over the first part of the EEPROM if needed */

 Try to get new resources before deleting old */

		/* save the new, restore the old in order to free it,

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2008 Intel Corporation. */

/* ixgb_pci_tbl - PCI Device ID Table

 *

 * Wildcard entries (PCI_ANY_ID) should come last

 * Last entry must be all 0s

 *

 * { Vendor ID, Device ID, SubVendor ID, SubDevice ID,

 *   Class, Class Mask, private data (not used) }

 required last entry */

 Local Function Prototypes */

/**

 * ixgb_init_module - Driver Registration Routine

 *

 * ixgb_init_module is the first routine called when the driver is

 * loaded. All it does is register with the PCI subsystem.

/**

 * ixgb_exit_module - Driver Exit Cleanup Routine

 *

 * ixgb_exit_module is called just before the driver is removed

 * from memory.

/**

 * ixgb_irq_disable - Mask off interrupt generation on the NIC

 * @adapter: board private structure

/**

 * ixgb_irq_enable - Enable default interrupt generation settings

 * @adapter: board private structure

 hardware has been reset, we need to reload some things */

 disable interrupts and get the hardware into a known state */

 only enable MSI if bus is in PCI-X mode */

 proceed to try to request regular interrupt */

 prevent the interrupt handler from restarting watchdog */

 waiting for NAPI to complete can re-enable interrupts */

 restore frame size information */

	/*

	 * Tx VLAN insertion does not work per HW design when Rx stripping is

	 * disabled.

/**

 * ixgb_probe - Device Initialization Routine

 * @pdev: PCI device information struct

 * @ent: entry in ixgb_pci_tbl

 *

 * Returns 0 on success, negative on failure

 *

 * ixgb_probe initializes an adapter identified by a pci_dev structure.

 * The OS initialization, configuring of the adapter private structure,

 * and a hardware reset occur.

 setup the private structure */

 MTU range: 68 - 16114 */

 make sure the EEPROM is good */

 carrier off reporting is important to ethtool even BEFORE open */

 reset the hardware with the new settings */

/**

 * ixgb_remove - Device Removal Routine

 * @pdev: PCI device information struct

 *

 * ixgb_remove is called by the PCI subsystem to alert the driver

 * that it should release a PCI device.  The could be caused by a

 * Hot-Plug event, or because the driver is going to be removed from

 * memory.

/**

 * ixgb_sw_init - Initialize general software structures (struct ixgb_adapter)

 * @adapter: board private structure to initialize

 *

 * ixgb_sw_init initializes the Adapter private data structure.

 * Fields are initialized based on PCI device information and

 * OS network device settings (MTU size).

 PCI config space info */

 + 8 for errata */

 should never have loaded on this device */

 enable flow control to be programmed */

/**

 * ixgb_open - Called when a network interface is made active

 * @netdev: network interface device structure

 *

 * Returns 0 on success, negative value on failure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP).  At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the watchdog timer is started,

 * and the stack is notified that the interface is ready.

 allocate transmit descriptors */

 allocate receive descriptors */

/**

 * ixgb_close - Disables a network interface

 * @netdev: network interface device structure

 *

 * Returns 0, this is not allowed to fail

 *

 * The close entry point is called when an interface is de-activated

 * by the OS.  The hardware is still under the drivers control, but

 * needs to be disabled.  A global MAC reset is issued to stop the

 * hardware, and all transmit and receive resources are freed.

/**

 * ixgb_setup_tx_resources - allocate Tx resources (Descriptors)

 * @adapter: board private structure

 *

 * Return 0 on success, negative on failure

 round up to nearest 4K */

/**

 * ixgb_configure_tx - Configure 82597 Transmit Unit after Reset.

 * @adapter: board private structure

 *

 * Configure the Tx unit of the MAC after a reset.

	/* Setup the Base and Length of the Tx Descriptor Ring

	 * tx_ring.dma can be either a 32 or 64 bit value

 Setup the HW Tx Head and Tail descriptor pointers */

	/* don't set up txdctl, it induces performance problems if configured

 Set the Tx Interrupt Delay register */

 Program the Transmit Control Register */

 Setup Transmit Descriptor Settings for this adapter */

/**

 * ixgb_setup_rx_resources - allocate Rx resources (Descriptors)

 * @adapter: board private structure

 *

 * Returns 0 on success, negative on failure

 Round up to nearest 4K */

/**

 * ixgb_setup_rctl - configure the receive control register

 * @adapter: Board private structure

/**

 * ixgb_configure_rx - Configure 82597 Receive Unit after Reset.

 * @adapter: board private structure

 *

 * Configure the Rx unit of the MAC after a reset.

 make sure receives are disabled while setting up the descriptors */

 set the Receive Delay Timer Register */

 Setup the Base and Length of the Rx Descriptor Ring */

 Setup the HW Rx Head and Tail Descriptor Pointers */

	/* due to the hardware errata with RXDCTL, we are unable to use any of

	 * the performance enhancing features of it without causing other

	 * subtle bugs, some of the bugs could include receive length

	 * corruption at high data rates (WTHRESH > 0) and/or receive

 Enable Receive Checksum Offload for TCP and UDP */

 Enable Receives */

/**

 * ixgb_free_tx_resources - Free Tx Resources

 * @adapter: board private structure

 *

 * Free all transmit software resources

	/* these fields must always be initialized in tx

	 * buffer_info->length = 0;

/**

 * ixgb_clean_tx_ring - Free Tx Buffers

 * @adapter: board private structure

 Free all the Tx ring sk_buffs */

 Zero out the descriptor ring */

/**

 * ixgb_free_rx_resources - Free Rx Resources

 * @adapter: board private structure

 *

 * Free all receive software resources

/**

 * ixgb_clean_rx_ring - Free Rx Buffers

 * @adapter: board private structure

 Free all the Rx ring sk_buffs */

 Zero out the descriptor ring */

/**

 * ixgb_set_mac - Change the Ethernet Address of the NIC

 * @netdev: network interface device structure

 * @p: pointer to an address structure

 *

 * Returns 0 on success, negative on failure

/**

 * ixgb_set_multi - Multicast and Promiscuous mode set

 * @netdev: network interface device structure

 *

 * The set_multi entry point is called whenever the multicast address

 * list or the network interface flags are updated.  This routine is

 * responsible for configuring the hardware for proper multicast,

 * promiscuous mode, and all-multi behavior.

 Check for Promiscuous and All Multicast modes */

 disable VLAN filtering */

 enable VLAN filtering */

/**

 * ixgb_watchdog - Timer Call-back

 * @t: pointer to timer_list containing our private info pointer

 force the reset path */

			/* We've lost link, so the controller stops DMA,

			 * but we've got queued Tx work that's never going

			 * to get done, so reset controller to flush Tx.

 return immediately since reset is imminent */

 Force detection of hung controller every watchdog period */

 generate an interrupt to force clean up of any stragglers */

 Reset the timer */

 zero out any previously existing data in one instruction */

		/* Workaround for premature desc write-backs

			/* Workaround for premature desc write-backs

	/* Force memory writes to complete before letting h/w

	 * know there are new descriptors to fetch.  (Only

	 * applicable for weak-ordered memory model archs,

	/* Herbert's original patch had:

	 *  smp_mb__after_netif_stop_queue();

	/* We need to check again in a case another CPU has just

 A reprieve! */

 Tx Descriptors needed, worst case */

 skb->date */ + \

 for context */ \

 one more needed for sentinel TSO workaround */

 Make sure there is space in the ring for the next send. */

/**

 * ixgb_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: queue hanging (unused)

 Do the reset outside of interrupt context */

/**

 * ixgb_change_mtu - Change the Maximum Transfer Unit

 * @netdev: network interface device structure

 * @new_mtu: new value for maximum frame size

 *

 * Returns 0 on success, negative on failure

 + 8 for errata */

/**

 * ixgb_update_stats - Update the board statistics counters.

 * @adapter: board private structure

 Prevent stats update while adapter is being reset */

 fix up multicast stats by removing broadcasts */

 Fill out the OS statistics structure */

	/* ignore RLEC as it reports errors for padded (<64bytes) frames

 adapter->stats.rnbc + */ adapter->stats.crcerrs +

+ adapter->stats.rlec */  +

	/* see above

	 * netdev->stats.rx_length_errors = adapter->stats.rlec;

/**

 * ixgb_intr - Interrupt Handler

 * @irq: interrupt number

 * @data: pointer to a network interface device structure

 Not our interrupt */

		/* Disable interrupts and register for poll. The flush

		  of the posted write is intentionally left out.

/**

 * ixgb_clean - NAPI Rx polling callback

 * @napi: napi struct pointer

 * @budget: max number of receives to clean

 If budget not fully consumed, exit the polling mode */

/**

 * ixgb_clean_tx_irq - Reclaim resources after transmit completes

 * @adapter: board private structure

 read buffer_info after eop_desc */

		/* Make sure that anybody stopping the queue after this

		/* detect a transmit hang in hardware, this serializes the

 detected Tx unit hang */

/**

 * ixgb_rx_checksum - Receive Checksum Offload for 82597.

 * @adapter: board private structure

 * @rx_desc: receive descriptor

 * @skb: socket buffer with received data

	/* Ignore Checksum bit is set OR

	 * TCP Checksum has not been calculated

 At this point we know the hardware did the TCP checksum */

 now look at the TCP checksum error bit */

 let the stack verify checksum errors */

 TCP checksum is good */

/*

 * this should improve performance for small packets with large amounts

 * of reassembly being done in the stack

 save the skb in buffer_info as good */

/**

 * ixgb_clean_rx_irq - Send received data up the network stack,

 * @adapter: board private structure

 * @work_done: output pointer to amount of packets cleaned

 * @work_to_do: how much work we can complete

 read descriptor and rx_buffer_info after status DD */

 All receives must fit into a single buffer */

 Good Receive */

 Receive Checksum Offload */

 clean up descriptor, might be written over by hw */

 return some buffers to hardware, one at a time is too slow */

 use prefetched values */

/**

 * ixgb_alloc_rx_buffers - Replace used receive buffers

 * @adapter: address of board private structure

 * @cleaned_count: how many buffers to allocate

 leave three descriptors unused */

 recycle! its good for you */

 Better luck next round */

		/* guarantee DD bit not set now before h/w gets descriptor

		 * this is the rest of the workaround for h/w double

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs, such

 enable VLAN tag insert/strip */

 disable VLAN tag insert/strip */

 add VID to filter table */

 remove VID from filter table */

/**

 * ixgb_io_error_detected - called when PCI error is detected

 * @pdev:    pointer to pci device with error

 * @state:   pci channel state after error

 *

 * This callback is called by the PCI subsystem whenever

 * a PCI bus error is detected.

 Request a slot reset. */

/**

 * ixgb_io_slot_reset - called after the pci bus has been reset.

 * @pdev: pointer to pci device with error

 *

 * This callback is called after the PCI bus has been reset.

 * Basically, this tries to restart the card from scratch.

 * This is a shortened version of the device probe/discovery code,

 * it resembles the first-half of the ixgb_probe() routine.

 Perform card reset only on one instance of the card */

 Make sure the EEPROM is good */

/**

 * ixgb_io_resume - called when its OK to resume normal operations

 * @pdev: pointer to pci device with error

 *

 * The error recovery driver tells us that its OK to resume

 * normal operation. Implementation resembles the second-half

 * of the ixgb_probe() routine.

 ixgb_main.c */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2008 Intel Corporation. */

/* This is the only thing that needs to be changed to adjust the

 * maximum number of ports that the driver can manage.

/* All parameters are treated the same, as an integer array of values.

 * This macro just reduces the need to repeat the same declaration code

 * over and over (plus this helps to avoid typo bugs).

/* Transmit Descriptor Count

 *

 * Valid Range: 64-4096

 *

 * Default Value: 256

/* Receive Descriptor Count

 *

 * Valid Range: 64-4096

 *

 * Default Value: 1024

/* User Specified Flow Control Override

 *

 * Valid Range: 0-3

 *  - 0 - No Flow Control

 *  - 1 - Rx only, respond to PAUSE frames but do not generate them

 *  - 2 - Tx only, generate PAUSE frames but ignore them on receive

 *  - 3 - Full Flow Control Support

 *

 * Default Value: 2 - Tx only (silicon bug avoidance)

/* XsumRX - Receive Checksum Offload Enable/Disable

 *

 * Valid Range: 0, 1

 *  - 0 - disables all checksum offload

 *  - 1 - enables receive IP/TCP/UDP checksum offload

 *        on 82597 based NICs

 *

 * Default Value: 1

/* Transmit Interrupt Delay in units of 0.8192 microseconds

 *

 * Valid Range: 0-65535

 *

 * Default Value: 32

/* Receive Interrupt Delay in units of 0.8192 microseconds

 *

 * Valid Range: 0-65535

 *

 * Default Value: 72

/* Receive Flow control high threshold (when we send a pause frame)

 * (FCRTH)

 *

 * Valid Range: 1,536 - 262,136 (0x600 - 0x3FFF8, 8 byte granularity)

 *

 * Default Value: 196,608 (0x30000)

/* Receive Flow control low threshold (when we send a resume frame)

 * (FCRTL)

 *

 * Valid Range: 64 - 262,136 (0x40 - 0x3FFF8, 8 byte granularity)

 *              must be less than high threshold by at least 8 bytes

 *

 * Default Value:  163,840 (0x28000)

/* Flow control request timeout (how long to pause the link partner's tx)

 * (PAP 15:0)

 *

 * Valid Range: 1 - 65535

 *

 * Default Value:  65535 (0xffff) (we'll send an xon if we recover)

/* Interrupt Delay Enable

 *

 * Valid Range: 0, 1

 *

 *  - 0 - disables transmit interrupt delay

 *  - 1 - enables transmmit interrupt delay

 *

 * Default Value: 1

 this may be too long */

 range_option info */

 list_option info */

/**

 * ixgb_check_options - Range Checking for Command Line Parameters

 * @adapter: board private structure

 *

 * This routine checks all command line parameters for valid user

 * input.  If an invalid value is given, or if no user specified

 * value exists, a default value is used.  The final value is stored

 * in a variable in the adapter structure.

 Transmit Descriptor Count */

 Receive Descriptor Count */

 Receive Checksum Offload Enable */

 Flow Control */

 Receive Flow Control High Threshold */

 Receive Flow Control Low Threshold */

 Flow Control Pause Time Request*/

 high low and spacing check for rx flow control thresholds */

 high must be greater than low */

 set defaults */

 Receive Interrupt Delay */

 Transmit Interrupt Delay */

 Transmit Interrupt Delay Enable */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 Base table for registers values that change by MAC */

/**

 *  ixgbe_device_supports_autoneg_fc - Check if phy supports autoneg flow

 *  control

 *  @hw: pointer to hardware structure

 *

 *  There are several phys that do not support autoneg flow control. This

 *  function check the device id to see if the associated phy supports

 *  autoneg flow control.

 flow control autoneg black list */

 if link is down, assume supported */

 only some copper devices support flow control autoneg */

/**

 *  ixgbe_setup_fc_generic - Set up flow control

 *  @hw: pointer to hardware structure

 *

 *  Called at init time to set up flow control.

	/*

	 * Validate the requested mode.  Strict IEEE mode does not allow

	 * ixgbe_fc_rx_pause because it will cause us to fail at UNH.

	/*

	 * 10gig parts do not have a word in the EEPROM to determine the

	 * default flow control setting, so we explicitly set it to full.

	/*

	 * Set up the 1G and 10G flow control advertisement registers so the

	 * HW will be able to do fc autoneg once the cable is plugged in.  If

	 * we link at 10G, the 1G advertisement is harmless and vice versa.

 some MAC's need RMW protection on AUTOC */

 only backplane uses autoc */

	/*

	 * The possible values of fc.requested_mode are:

	 * 0: Flow control is completely disabled

	 * 1: Rx flow control is enabled (we can receive pause frames,

	 *    but not send pause frames).

	 * 2: Tx flow control is enabled (we can send pause frames but

	 *    we do not support receiving pause frames).

	 * 3: Both Rx and Tx flow control (symmetric) are enabled.

	 * other: Invalid.

 Flow control completely disabled by software override. */

		/*

		 * Tx Flow control is enabled, and Rx Flow control is

		 * disabled by software override.

		/*

		 * Rx Flow control is enabled and Tx Flow control is

		 * disabled by software override. Since there really

		 * isn't a way to advertise that we are capable of RX

		 * Pause ONLY, we will advertise that we support both

		 * symmetric and asymmetric Rx PAUSE, as such we fall

		 * through to the fc_full statement.  Later, we will

		 * disable the adapter's ability to send PAUSE frames.

 Flow control (both Rx and Tx) is enabled by SW override. */

		/*

		 * Enable auto-negotiation between the MAC & PHY;

		 * the MAC will advertise clause 37 flow control.

 Disable AN timeout */

	/*

	 * AUTOC restart handles negotiation of 1G and 10G on backplane

	 * and copper. There is no need to set the PCS1GCTL register.

	 *

		/* Need the SW/FW semaphore around AUTOC writes if 82599 and

		 * LESM is on, likewise reset_pipeline requries the lock as

		 * it also writes AUTOC.

/**

 *  ixgbe_start_hw_generic - Prepare hardware for Tx/Rx

 *  @hw: pointer to hardware structure

 *

 *  Starts the hardware by filling the bus info structure and media type, clears

 *  all on chip counters, initializes receive address registers, multicast

 *  table, VLAN filter table, calls routine to set up link and flow control

 *  settings, and leaves transmit and receive units disabled and uninitialized

 Set the media type */

 Identify the PHY */

 Clear the VLAN filter table */

 Clear statistics registers */

 Set No Snoop Disable */

 Setup flow control if method for doing so */

 Cashe bit indicating need for crosstalk fix */

 Clear adapter stopped flag */

/**

 *  ixgbe_start_hw_gen2 - Init sequence for common device family

 *  @hw: pointer to hw structure

 *

 * Performs the init sequence common to the second generation

 * of 10 GbE devices.

 * Devices in the second generation:

 *     82599

 *     X540

 Clear the rate limiters */

/**

 *  ixgbe_init_hw_generic - Generic hardware initialization

 *  @hw: pointer to hardware structure

 *

 *  Initialize the hardware by resetting the hardware, filling the bus info

 *  structure and media type, clears all on chip counters, initializes receive

 *  address registers, multicast table, VLAN filter table, calls routine to set

 *  up link and flow control settings, and leaves transmit and receive units

 *  disabled and uninitialized

 Reset the hardware */

 Start the HW */

 Initialize the LED link active for LED blink support */

/**

 *  ixgbe_clear_hw_cntrs_generic - Generic clear hardware counters

 *  @hw: pointer to hardware structure

 *

 *  Clears all hardware statistics counters by reading them from the hardware

 *  Statistics counters are clear on read.

/**

 *  ixgbe_read_pba_string_generic - Reads part number string from EEPROM

 *  @hw: pointer to hardware structure

 *  @pba_num: stores the part number string from the EEPROM

 *  @pba_num_size: part number string buffer length

 *

 *  Reads the part number string from the EEPROM.

	/*

	 * if data is not ptr guard the PBA must be in legacy format which

	 * means pba_ptr is actually our second data word for the PBA number

	 * and we can decode it into an ascii string

 we will need 11 characters to store the PBA */

 extract hex string from data and pba_ptr */

 put a null character on the end of our string */

 switch all the data but the '-' to hex char */

 check if pba_num buffer is big enough */

 trim pba length from start of string */

/**

 *  ixgbe_get_mac_addr_generic - Generic get MAC address

 *  @hw: pointer to hardware structure

 *  @mac_addr: Adapter MAC address

 *

 *  Reads the adapter's MAC address from first Receive Address Register (RAR0)

 *  A reset of the adapter must be performed prior to calling this function

 *  in order for the MAC address to have been loaded from the EEPROM into RAR0

/**

 *  ixgbe_get_bus_info_generic - Generic set PCI bus info

 *  @hw: pointer to hardware structure

 *

 *  Sets the PCI bus info (speed, width, type) within the ixgbe_hw structure

 Get the negotiated link width and speed from PCI config space */

/**

 *  ixgbe_set_lan_id_multi_port_pcie - Set LAN id for PCIe multiple port devices

 *  @hw: pointer to the HW structure

 *

 *  Determines the LAN function id by reading memory-mapped registers

 *  and swaps the port value if requested.

 check for a port swap */

 Get MAC instance from EEPROM for configuring CS4227 */

/**

 *  ixgbe_stop_adapter_generic - Generic stop Tx/Rx units

 *  @hw: pointer to hardware structure

 *

 *  Sets the adapter_stopped flag within ixgbe_hw struct. Clears interrupts,

 *  disables transmit and receive units. The adapter_stopped flag is used by

 *  the shared code and drivers to determine if the adapter is in a stopped

 *  state and should not touch the hardware.

	/*

	 * Set the adapter_stopped flag so other driver functions stop touching

	 * the hardware

 Disable the receive unit */

 Clear interrupt mask to stop interrupts from being generated */

 Clear any pending interrupts, flush previous writes */

 Disable the transmit unit.  Each queue must be disabled. */

 Disable the receive unit by stopping each queue */

 flush all queues disables */

	/*

	 * Prevent the PCI-E bus from from hanging by disabling PCI-E master

	 * access and verify no pending requests

/**

 *  ixgbe_init_led_link_act_generic - Store the LED index link/activity.

 *  @hw: pointer to hardware structure

 *

 *  Store the index for the link active LED. This will be used to support

 *  blinking the LED.

 Get LED link active from the LEDCTL register */

	/* If LEDCTL register does not have the LED link active set, then use

	 * known MAC defaults.

/**

 *  ixgbe_led_on_generic - Turns on the software controllable LEDs.

 *  @hw: pointer to hardware structure

 *  @index: led number to turn on

 To turn on the LED, set mode to ON. */

/**

 *  ixgbe_led_off_generic - Turns off the software controllable LEDs.

 *  @hw: pointer to hardware structure

 *  @index: led number to turn off

 To turn off the LED, set mode to OFF. */

/**

 *  ixgbe_init_eeprom_params_generic - Initialize EEPROM params

 *  @hw: pointer to hardware structure

 *

 *  Initializes the EEPROM parameters ixgbe_eeprom_info within the

 *  ixgbe_hw struct in order to set up EEPROM access.

		/* Set default semaphore delay to 10ms which is a well

 Clear EEPROM page size, it will be initialized as needed */

		/*

		 * Check for EEPROM present first.

		 * If not present leave as none

			/*

			 * SPI EEPROM is assumed here.  This code would need to

			 * change if a future EEPROM is not SPI.

/**

 *  ixgbe_write_eeprom_buffer_bit_bang_generic - Write EEPROM using bit-bang

 *  @hw: pointer to hardware structure

 *  @offset: offset within the EEPROM to write

 *  @words: number of words

 *  @data: 16 bit word(s) to write to EEPROM

 *

 *  Reads 16 bit word(s) from EEPROM through bit-bang method

	/*

	 * The EEPROM page size cannot be queried from the chip. We do lazy

	 * initialization. It is worth to do that when we write large buffer.

	/*

	 * We cannot hold synchronization semaphores for too long

	 * to avoid other entity starvation. However it is more efficient

	 * to read in bursts than synchronizing access for each word.

/**

 *  ixgbe_write_eeprom_buffer_bit_bang - Writes 16 bit word(s) to EEPROM

 *  @hw: pointer to hardware structure

 *  @offset: offset within the EEPROM to be written to

 *  @words: number of word(s)

 *  @data: 16 bit word(s) to be written to the EEPROM

 *

 *  If ixgbe_eeprom_update_checksum is not called after this function, the

 *  EEPROM will most likely contain an invalid checksum.

 Prepare the EEPROM for writing  */

 Send the WRITE ENABLE command (8 bit opcode) */

		/* Some SPI eeproms use the 8th address bit embedded

		 * in the opcode

 Send the Write command (8-bit opcode + addr) */

 Send the data in burst via SPI */

 do not wrap around page */

 Done with writing - release the EEPROM */

/**

 *  ixgbe_write_eeprom_generic - Writes 16 bit value to EEPROM

 *  @hw: pointer to hardware structure

 *  @offset: offset within the EEPROM to be written to

 *  @data: 16 bit word to be written to the EEPROM

 *

 *  If ixgbe_eeprom_update_checksum is not called after this function, the

 *  EEPROM will most likely contain an invalid checksum.

/**

 *  ixgbe_read_eeprom_buffer_bit_bang_generic - Read EEPROM using bit-bang

 *  @hw: pointer to hardware structure

 *  @offset: offset within the EEPROM to be read

 *  @words: number of word(s)

 *  @data: read 16 bit words(s) from EEPROM

 *

 *  Reads 16 bit word(s) from EEPROM through bit-bang method

	/*

	 * We cannot hold synchronization semaphores for too long

	 * to avoid other entity starvation. However it is more efficient

	 * to read in bursts than synchronizing access for each word.

/**

 *  ixgbe_read_eeprom_buffer_bit_bang - Read EEPROM using bit-bang

 *  @hw: pointer to hardware structure

 *  @offset: offset within the EEPROM to be read

 *  @words: number of word(s)

 *  @data: read 16 bit word(s) from EEPROM

 *

 *  Reads 16 bit word(s) from EEPROM through bit-bang method

 Prepare the EEPROM for reading  */

		/* Some SPI eeproms use the 8th address bit embedded

		 * in the opcode

 Send the READ command (opcode + addr) */

 Read the data. */

 End this read operation */

/**

 *  ixgbe_read_eeprom_bit_bang_generic - Read EEPROM word using bit-bang

 *  @hw: pointer to hardware structure

 *  @offset: offset within the EEPROM to be read

 *  @data: read 16 bit value from EEPROM

 *

 *  Reads 16 bit value from EEPROM through bit-bang method

/**

 *  ixgbe_read_eerd_buffer_generic - Read EEPROM word(s) using EERD

 *  @hw: pointer to hardware structure

 *  @offset: offset of word in the EEPROM to read

 *  @words: number of word(s)

 *  @data: 16 bit word(s) from the EEPROM

 *

 *  Reads a 16 bit word(s) from the EEPROM using the EERD register.

/**

 *  ixgbe_detect_eeprom_page_size_generic - Detect EEPROM page size

 *  @hw: pointer to hardware structure

 *  @offset: offset within the EEPROM to be used as a scratch pad

 *

 *  Discover EEPROM page size by writing marching data at given offset.

 *  This function is called only when we are writing a new large buffer

 *  at given offset so the data would be overwritten anyway.

	/*

	 * When writing in burst more than the actual page size

	 * EEPROM address wraps around current page.

/**

 *  ixgbe_read_eerd_generic - Read EEPROM word using EERD

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to read

 *  @data: word read from the EEPROM

 *

 *  Reads a 16 bit word from the EEPROM using the EERD register.

/**

 *  ixgbe_write_eewr_buffer_generic - Write EEPROM word(s) using EEWR

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to write

 *  @words: number of words

 *  @data: word(s) write to the EEPROM

 *

 *  Write a 16 bit word(s) to the EEPROM using the EEWR register.

/**

 *  ixgbe_write_eewr_generic - Write EEPROM word using EEWR

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to write

 *  @data: word write to the EEPROM

 *

 *  Write a 16 bit word to the EEPROM using the EEWR register.

/**

 *  ixgbe_poll_eerd_eewr_done - Poll EERD read or EEWR write status

 *  @hw: pointer to hardware structure

 *  @ee_reg: EEPROM flag for polling

 *

 *  Polls the status bit (bit 1) of the EERD or EEWR to determine when the

 *  read or write is done respectively.

/**

 *  ixgbe_acquire_eeprom - Acquire EEPROM using bit-bang

 *  @hw: pointer to hardware structure

 *

 *  Prepares EEPROM for access using bit-bang method. This function should

 *  be called before issuing a command to the EEPROM.

 Request EEPROM Access */

 Release if grant not acquired */

 Setup EEPROM for Read/Write */

 Clear CS and SK */

/**

 *  ixgbe_get_eeprom_semaphore - Get hardware semaphore

 *  @hw: pointer to hardware structure

 *

 *  Sets the hardware semaphores so EEPROM access can occur for bit-bang method

 Get SMBI software semaphore between device drivers first */

		/*

		 * If the SMBI bit is 0 when we read it, then the bit will be

		 * set and we have the semaphore

		/* this release is particularly important because our attempts

		 * above to get the semaphore may have succeeded, and if there

		 * was a timeout, we should unconditionally clear the semaphore

		 * bits to free the driver to make progress

		/* one last try

		 * If the SMBI bit is 0 when we read it, then the bit will be

		 * set and we have the semaphore

 Now get the semaphore between SW/FW through the SWESMBI bit */

 Set the SW EEPROM semaphore bit to request access */

		/* If we set the bit successfully then we got the

		 * semaphore.

	/* Release semaphores and return error if SW EEPROM semaphore

	 * was not granted because we don't have access to the EEPROM

/**

 *  ixgbe_release_eeprom_semaphore - Release hardware semaphore

 *  @hw: pointer to hardware structure

 *

 *  This function clears hardware semaphore bits.

 Release both semaphores by writing 0 to the bits SWESMBI and SMBI */

/**

 *  ixgbe_ready_eeprom - Polls for EEPROM ready

 *  @hw: pointer to hardware structure

	/*

	 * Read "Status Register" repeatedly until the LSB is cleared.  The

	 * EEPROM will signal that the command has been completed by clearing

	 * bit 0 of the internal status register.  If it's not cleared within

	 * 5 milliseconds, then error out.

	/*

	 * On some parts, SPI write time could vary from 0-20mSec on 3.3V

	 * devices (and only 0-5mSec on 5V devices)

/**

 *  ixgbe_standby_eeprom - Returns EEPROM to a "standby" state

 *  @hw: pointer to hardware structure

 Toggle CS to flush commands */

/**

 *  ixgbe_shift_out_eeprom_bits - Shift data bits out to the EEPROM.

 *  @hw: pointer to hardware structure

 *  @data: data to send to the EEPROM

 *  @count: number of bits to shift out

	/*

	 * Mask is used to shift "count" bits of "data" out to the EEPROM

	 * one bit at a time.  Determine the starting bit based on count

		/*

		 * A "1" is shifted out to the EEPROM by setting bit "DI" to a

		 * "1", and then raising and then lowering the clock (the SK

		 * bit controls the clock input to the EEPROM).  A "0" is

		 * shifted out to the EEPROM by setting "DI" to "0" and then

		 * raising and then lowering the clock.

		/*

		 * Shift mask to signify next bit of data to shift in to the

		 * EEPROM

 We leave the "DI" bit set to "0" when we leave this routine. */

/**

 *  ixgbe_shift_in_eeprom_bits - Shift data bits in from the EEPROM

 *  @hw: pointer to hardware structure

 *  @count: number of bits to shift

	/*

	 * In order to read a register from the EEPROM, we need to shift

	 * 'count' bits in from the EEPROM. Bits are "shifted in" by raising

	 * the clock input to the EEPROM (setting the SK bit), and then reading

	 * the value of the "DO" bit.  During this "shifting in" process the

	 * "DI" bit should always be clear.

/**

 *  ixgbe_raise_eeprom_clk - Raises the EEPROM's clock input.

 *  @hw: pointer to hardware structure

 *  @eec: EEC register's current value

	/*

	 * Raise the clock input to the EEPROM

	 * (setting the SK bit), then delay

/**

 *  ixgbe_lower_eeprom_clk - Lowers the EEPROM's clock input.

 *  @hw: pointer to hardware structure

 *  @eec: EEC's current value

	/*

	 * Lower the clock input to the EEPROM (clearing the SK bit), then

	 * delay

/**

 *  ixgbe_release_eeprom - Release EEPROM, release semaphores

 *  @hw: pointer to hardware structure

 Pull CS high */

 Lower SCK */

 Stop requesting EEPROM access */

	/*

	 * Delay before attempt to obtain semaphore again to allow FW

	 * access. semaphore_delay is in ms we need us for usleep_range

/**

 *  ixgbe_calc_eeprom_checksum_generic - Calculates and returns the checksum

 *  @hw: pointer to hardware structure

 Include 0x0-0x3F in the checksum */

 Include all data from pointers except for the fw pointer */

 If the pointer seems invalid */

/**

 *  ixgbe_validate_eeprom_checksum_generic - Validate EEPROM checksum

 *  @hw: pointer to hardware structure

 *  @checksum_val: calculated checksum

 *

 *  Performs checksum calculation and validates the EEPROM checksum.  If the

 *  caller does not need checksum_val, the value can be NULL.

	/*

	 * Read the first word from the EEPROM. If this times out or fails, do

	 * not continue or we could be in for a very long wait while every

	 * EEPROM read fails

	/* Verify read checksum from EEPROM is the same as

	 * calculated checksum

 If the user cares, return the calculated checksum */

/**

 *  ixgbe_update_eeprom_checksum_generic - Updates the EEPROM checksum

 *  @hw: pointer to hardware structure

	/*

	 * Read the first word from the EEPROM. If this times out or fails, do

	 * not continue or we could be in for a very long wait while every

	 * EEPROM read fails

/**

 *  ixgbe_set_rar_generic - Set Rx address register

 *  @hw: pointer to hardware structure

 *  @index: Receive address register to write

 *  @addr: Address to put into receive address register

 *  @vmdq: VMDq "set" or "pool" index

 *  @enable_addr: set flag that address is active

 *

 *  Puts an ethernet address into a receive address register.

 Make sure we are using a valid rar index range */

 setup VMDq pool selection before this RAR gets enabled */

	/*

	 * HW expects these in little endian so we reverse the byte

	 * order from network order (big endian) to little endian

	/*

	 * Some parts put the VMDq setting in the extra RAH bits,

	 * so save everything except the lower 16 bits that hold part

	 * of the address and the address valid bit.

	/* Record lower 32 bits of MAC address and then make

	 * sure that write is flushed to hardware before writing

	 * the upper 16 bits and setting the valid bit.

/**

 *  ixgbe_clear_rar_generic - Remove Rx address register

 *  @hw: pointer to hardware structure

 *  @index: Receive address register to write

 *

 *  Clears an ethernet address from a receive address register.

 Make sure we are using a valid rar index range */

	/*

	 * Some parts put the VMDq setting in the extra RAH bits,

	 * so save everything except the lower 16 bits that hold part

	 * of the address and the address valid bit.

	/* Clear the address valid bit and upper 16 bits of the address

	 * before clearing the lower bits. This way we aren't updating

	 * a live filter.

 clear VMDq pool/queue selection for this RAR */

/**

 *  ixgbe_init_rx_addrs_generic - Initializes receive address filters.

 *  @hw: pointer to hardware structure

 *

 *  Places the MAC address in receive address register 0 and clears the rest

 *  of the receive address registers. Clears the multicast table. Assumes

 *  the receiver is in reset when the routine is called.

	/*

	 * If the current mac address is valid, assume it is a software override

	 * to the permanent address.

	 * Otherwise, use the permanent address from the eeprom.

 Get the MAC address from the RAR0 for later reference */

 Setup the receive address. */

  clear VMDq pool/queue selection for RAR 0 */

 Zero out the other receive addresses. */

 Clear the MTA */

/**

 *  ixgbe_mta_vector - Determines bit-vector in multicast table to set

 *  @hw: pointer to hardware structure

 *  @mc_addr: the multicast address

 *

 *  Extracts the 12 bits, from a multicast address, to determine which

 *  bit-vector to set in the multicast table. The hardware uses 12 bits, from

 *  incoming rx multicast addresses, to determine the bit-vector to check in

 *  the MTA. Which of the 4 combination, of 12-bits, the hardware uses is set

 *  by the MO field of the MCSTCTRL. The MO field is set during initialization

 *  to mc_filter_type.

 use bits [47:36] of the address */

 use bits [46:35] of the address */

 use bits [45:34] of the address */

 use bits [43:32] of the address */

 Invalid mc_filter_type */

 vector can only be 12-bits or boundary will be exceeded */

/**

 *  ixgbe_set_mta - Set bit-vector in multicast table

 *  @hw: pointer to hardware structure

 *  @mc_addr: Multicast address

 *

 *  Sets the bit-vector in the multicast table.

	/*

	 * The MTA is a register array of 128 32-bit registers. It is treated

	 * like an array of 4096 bits.  We want to set bit

	 * BitArray[vector_value]. So we figure out what register the bit is

	 * in, read it, OR in the new bit, then write back the new value.  The

	 * register is determined by the upper 7 bits of the vector value and

	 * the bit within that register are determined by the lower 5 bits of

	 * the value.

/**

 *  ixgbe_update_mc_addr_list_generic - Updates MAC list of multicast addresses

 *  @hw: pointer to hardware structure

 *  @netdev: pointer to net device structure

 *

 *  The given list replaces any existing list. Clears the MC addrs from receive

 *  address registers and the multicast table. Uses unused receive address

 *  registers for the first multicast addresses, and hashes the rest into the

 *  multicast table.

	/*

	 * Set the new number of MC addresses that we are being requested to

	 * use.

 Clear mta_shadow */

 Update mta shadow */

 Enable mta */

/**

 *  ixgbe_enable_mc_generic - Enable multicast address in RAR

 *  @hw: pointer to hardware structure

 *

 *  Enables multicast address in RAR and the use of the multicast hash table.

/**

 *  ixgbe_disable_mc_generic - Disable multicast address in RAR

 *  @hw: pointer to hardware structure

 *

 *  Disables multicast address in RAR and the use of the multicast hash table.

/**

 *  ixgbe_fc_enable_generic - Enable flow control

 *  @hw: pointer to hardware structure

 *

 *  Enable flow control according to the current settings.

 Validate the water mark configuration. */

 Low water mark of zero causes XOFF floods */

 Negotiate the fc mode to use */

 Disable any previous flow control settings */

	/*

	 * The possible values of fc.current_mode are:

	 * 0: Flow control is completely disabled

	 * 1: Rx flow control is enabled (we can receive pause frames,

	 *    but not send pause frames).

	 * 2: Tx flow control is enabled (we can send pause frames but

	 *    we do not support receiving pause frames).

	 * 3: Both Rx and Tx flow control (symmetric) are enabled.

	 * other: Invalid.

		/*

		 * Flow control is disabled by software override or autoneg.

		 * The code below will actually disable it in the HW.

		/*

		 * Rx Flow control is enabled and Tx Flow control is

		 * disabled by software override. Since there really

		 * isn't a way to advertise that we are capable of RX

		 * Pause ONLY, we will advertise that we support both

		 * symmetric and asymmetric Rx PAUSE.  Later, we will

		 * disable the adapter's ability to send PAUSE frames.

		/*

		 * Tx Flow control is enabled, and Rx Flow control is

		 * disabled by software override.

 Flow control (both Rx and Tx) is enabled by SW override. */

 Set 802.3x based flow control settings. */

 Set up and enable Rx high/low water mark thresholds, enable XON. */

			/*

			 * In order to prevent Tx hangs when the internal Tx

			 * switch is enabled we must set the high water mark

			 * to the Rx packet buffer size - 24KB.  This allows

			 * the Tx switch to function even under heavy Rx

			 * workloads.

 Configure pause time (2 TCs per register) */

/**

 *  ixgbe_negotiate_fc - Negotiate flow control

 *  @hw: pointer to hardware structure

 *  @adv_reg: flow control advertised settings

 *  @lp_reg: link partner's flow control settings

 *  @adv_sym: symmetric pause bit in advertisement

 *  @adv_asm: asymmetric pause bit in advertisement

 *  @lp_sym: symmetric pause bit in link partner advertisement

 *  @lp_asm: asymmetric pause bit in link partner advertisement

 *

 *  Find the intersection between advertised settings and link partner's

 *  advertised settings

		/*

		 * Now we need to check if the user selected Rx ONLY

		 * of pause frames.  In this case, we had to advertise

		 * FULL flow control because we could not advertise RX

		 * ONLY. Hence, we must now check to see if we need to

		 * turn OFF the TRANSMISSION of PAUSE frames.

/**

 *  ixgbe_fc_autoneg_fiber - Enable flow control on 1 gig fiber

 *  @hw: pointer to hardware structure

 *

 *  Enable flow control according on 1 gig fiber.

	/*

	 * On multispeed fiber at 1g, bail out if

	 * - link is up but AN did not complete, or if

	 * - link is up and AN completed but timed out

/**

 *  ixgbe_fc_autoneg_backplane - Enable flow control IEEE clause 37

 *  @hw: pointer to hardware structure

 *

 *  Enable flow control according to IEEE clause 37.

	/*

	 * On backplane, bail out if

	 * - backplane autoneg was not completed, or if

	 * - we are 82599 and link partner is not AN enabled

	/*

	 * Read the 10g AN autoc and LP ability registers and resolve

	 * local flow control settings accordingly

/**

 *  ixgbe_fc_autoneg_copper - Enable flow control IEEE clause 37

 *  @hw: pointer to hardware structure

 *

 *  Enable flow control according to IEEE clause 37.

/**

 *  ixgbe_fc_autoneg - Configure flow control

 *  @hw: pointer to hardware structure

 *

 *  Compares our advertised flow control capabilities to those advertised by

 *  our link partner, and determines the proper flow control mode to use.

	/*

	 * AN should have completed when the cable was plugged in.

	 * Look for reasons to bail out.  Bail out if:

	 * - FC autoneg is disabled, or if

	 * - link is not up.

	 *

	 * Since we're being called from an LSC, link is already known to be up.

	 * So use link_up_wait_to_complete=false.

 Autoneg flow control on fiber adapters */

 Autoneg flow control on backplane adapters */

 Autoneg flow control on copper adapters */

/**

 * ixgbe_pcie_timeout_poll - Return number of times to poll for completion

 * @hw: pointer to hardware structure

 *

 * System-wide timeout range is encoded in PCIe Device Control2 register.

 *

 *  Add 10% to specified maximum and return the number of times to poll for

 *  completion timeout, in units of 100 microsec.  Never return less than

 *  800 = 80 millisec.

 130 millisec */

 520 millisec */

 2 sec */

 8 sec */

 34 sec */

 100 microsecs */

 2 millisecs */

 32 millisec */

 32 millisec default */

 80 millisec minimum */

 add 10% to spec maximum */

/**

 *  ixgbe_disable_pcie_master - Disable PCI-express master access

 *  @hw: pointer to hardware structure

 *

 *  Disables PCI-Express master access and verifies there are no pending

 *  requests. IXGBE_ERR_MASTER_REQUESTS_PENDING is returned if master disable

 *  bit hasn't caused the master requests to be disabled, else 0

 *  is returned signifying master requests disabled.

 Always set this bit to ensure any future transactions are blocked */

 Poll for bit to read as set */

 Exit if master requests are blocked */

 Poll for master request bit to clear */

	/*

	 * Two consecutive resets are required via CTRL.RST per datasheet

	 * 5.2.5.3.2 Master Disable.  We set a flag to inform the reset routine

	 * of this need.  The first reset prevents new master requests from

	 * being issued by our device.  We then must wait 1usec or more for any

	 * remaining completions from the PCIe bus to trickle in, and then reset

	 * again to clear out any effects they may have had on our device.

	/*

	 * Before proceeding, make sure that the PCIe block does not have

	 * transactions pending.

/**

 *  ixgbe_acquire_swfw_sync - Acquire SWFW semaphore

 *  @hw: pointer to hardware structure

 *  @mask: Mask to specify which semaphore to acquire

 *

 *  Acquires the SWFW semaphore through the GSSR register for the specified

 *  function (CSR, PHY0, PHY1, EEPROM, Flash)

		/*

		 * SW NVM semaphore bit is used for access to all

		 * SW_FW_SYNC bits (not just NVM)

 Resource is currently in use by FW or SW */

 If time expired clear the bits holding the lock and retry */

/**

 *  ixgbe_release_swfw_sync - Release SWFW semaphore

 *  @hw: pointer to hardware structure

 *  @mask: Mask to specify which semaphore to release

 *

 *  Releases the SWFW semaphore through the GSSR register for the specified

 *  function (CSR, PHY0, PHY1, EEPROM, Flash)

/**

 * prot_autoc_read_generic - Hides MAC differences needed for AUTOC read

 * @hw: pointer to hardware structure

 * @reg_val: Value we read from AUTOC

 * @locked: bool to indicate whether the SW/FW lock should be taken.  Never

 *	    true in this the generic case.

 *

 * The default case requires no protection so just to the register read.

/**

 * prot_autoc_write_generic - Hides MAC differences needed for AUTOC write

 * @hw: pointer to hardware structure

 * @reg_val: value to write to AUTOC

 * @locked: bool to indicate whether the SW/FW lock was already taken by

 *	    previous read.

/**

 *  ixgbe_disable_rx_buff_generic - Stops the receive data path

 *  @hw: pointer to hardware structure

 *

 *  Stops the receive data path and waits for the HW to internally

 *  empty the Rx security block.

 Use interrupt-safe sleep just in case */

 For informational purposes only */

/**

 *  ixgbe_enable_rx_buff_generic - Enables the receive data path

 *  @hw: pointer to hardware structure

 *

 *  Enables the receive data path

/**

 *  ixgbe_enable_rx_dma_generic - Enable the Rx DMA unit

 *  @hw: pointer to hardware structure

 *  @regval: register value to write to RXCTRL

 *

 *  Enables the Rx DMA unit

/**

 *  ixgbe_blink_led_start_generic - Blink LED based on index.

 *  @hw: pointer to hardware structure

 *  @index: led number to blink

	/*

	 * Link must be up to auto-blink the LEDs;

	 * Force it if link is down.

/**

 *  ixgbe_blink_led_stop_generic - Stop blinking LED based on index.

 *  @hw: pointer to hardware structure

 *  @index: led number to stop blinking

/**

 *  ixgbe_get_san_mac_addr_offset - Get SAN MAC address offset from the EEPROM

 *  @hw: pointer to hardware structure

 *  @san_mac_offset: SAN MAC address offset

 *

 *  This function will read the EEPROM location for the SAN MAC address

 *  pointer, and returns the value at that location.  This is used in both

 *  get and set mac_addr routines.

	/*

	 * First read the EEPROM pointer to see if the MAC addresses are

	 * available.

/**

 *  ixgbe_get_san_mac_addr_generic - SAN MAC address retrieval from the EEPROM

 *  @hw: pointer to hardware structure

 *  @san_mac_addr: SAN MAC address

 *

 *  Reads the SAN MAC address from the EEPROM, if it's available.  This is

 *  per-port, so set_lan_id() must be called before reading the addresses.

 *  set_lan_id() is called by identify_sfp(), but this cannot be relied

 *  upon for non-SFP connections, so we must call it here.

	/*

	 * First read the EEPROM pointer to see if the MAC addresses are

	 * available.  If they're not, no point in calling set_lan_id() here.

 make sure we know which port we need to program */

 apply the port offset to the address offset */

	/* No addresses available in this EEPROM.  It's not necessarily an

	 * error though, so just wipe the local address and return.

/**

 *  ixgbe_get_pcie_msix_count_generic - Gets MSI-X vector count

 *  @hw: pointer to hardware structure

 *

 *  Read PCIe configuration space, and get the MSI-X vector count from

 *  the capabilities table.

 MSI-X count is zero-based in HW */

/**

 *  ixgbe_clear_vmdq_generic - Disassociate a VMDq pool index from a rx address

 *  @hw: pointer to hardware struct

 *  @rar: receive address register index to disassociate

 *  @vmdq: VMDq pool index to remove from the rar

 Make sure we are using a valid rar index range */

 was that the last pool using this rar? */

/**

 *  ixgbe_set_vmdq_generic - Associate a VMDq pool index with a rx address

 *  @hw: pointer to hardware struct

 *  @rar: receive address register index to associate with a VMDq index

 *  @vmdq: VMDq pool index

 Make sure we are using a valid rar index range */

/**

 *  ixgbe_set_vmdq_san_mac_generic - Associate VMDq pool index with a rx address

 *  @hw: pointer to hardware struct

 *  @vmdq: VMDq pool index

 *

 *  This function should only be involved in the IOV mode.

 *  In IOV mode, Default pool is next pool after the number of

 *  VFs advertized and not 0.

 *  MPSAR table needs to be updated for SAN_MAC RAR [hw->mac.san_mac_rar_index]

/**

 *  ixgbe_init_uta_tables_generic - Initialize the Unicast Table Array

 *  @hw: pointer to hardware structure

/**

 *  ixgbe_find_vlvf_slot - find the vlanid or the first empty slot

 *  @hw: pointer to hardware structure

 *  @vlan: VLAN id to write to VLAN filter

 *  @vlvf_bypass: true to find vlanid only, false returns first empty slot if

 *		  vlanid not found

 *

 *  return the VLVF index where this VLAN id should be placed

 *

 short cut the special case */

	/* if vlvf_bypass is set we don't want to use an empty slot, we

	 * will simply bypass the VLVF if there are no entries present in the

	 * VLVF that contain our VLAN

 add VLAN enable bit for comparison */

	/* Search for the vlan id in the VLVF entries. Save off the first empty

	 * slot found along the way.

	 *

	 * pre-decrement loop covering (IXGBE_VLVF_ENTRIES - 1) .. 1

	/* If we are here then we didn't find the VLAN.  Return first empty

	 * slot we found during our search, else error.

/**

 *  ixgbe_set_vfta_generic - Set VLAN filter table

 *  @hw: pointer to hardware structure

 *  @vlan: VLAN id to write to VLAN filter

 *  @vind: VMDq output index that maps queue to VLAN id in VFVFB

 *  @vlan_on: boolean flag to turn on/off VLAN in VFVF

 *  @vlvf_bypass: boolean flag indicating updating default pool is okay

 *

 *  Turn on/off specified VLAN in the VLAN filter table.

	/*

	 * this is a 2 part operation - first the VFTA, then the

	 * VLVF and VLVFB if VT Mode is set

	 * We don't write the VFTA until we know the VLVF part succeeded.

	/* Part 1

	 * The VFTA is a bitstring made up of 128 32-bit registers

	 * that enable the particular VLAN id, much like the MTA:

	 *    bits[11-5]: which register

	 *    bits[4-0]:  which bit in the register

	/* vfta_delta represents the difference between the current value

	 * of vfta and the value we want in the register.  Since the diff

	 * is an XOR mask we can just update vfta using an XOR.

	/* Part 2

	 * If VT Mode is set

	 *   Either vlan_on

	 *     make sure the vlan is in VLVF

	 *     set the vind bit in the matching VLVFB

	 *   Or !vlan_on

	 *     clear the pool bit and possibly the vind

 set the pool bit */

 clear the pool bit */

		/* Clear VFTA first, then disable VLVF.  Otherwise

		 * we run the risk of stray packets leaking into

		 * the PF via the default pool

 disable VLVF and clear remaining bit from pool */

	/* If there are still bits set in the VLVFB registers

	 * for the VLAN ID indicated we need to see if the

	 * caller is requesting that we clear the VFTA entry bit.

	 * If the caller has requested that we clear the VFTA

	 * entry bit but there are still pools/VFs using this VLAN

	 * ID entry then ignore the request.  We're not worried

	 * about the case where we're turning the VFTA VLAN ID

	 * entry bit on, only when requested to turn it off as

	 * there may be multiple pools and/or VFs using the

	 * VLAN ID entry.  In that case we cannot clear the

	 * VFTA bit until all pools/VFs using that VLAN ID have also

	 * been cleared.  This will be indicated by "bits" being

	 * zero.

 record pool change and enable VLAN ID if not already enabled */

 Update VFTA now that we are ready for traffic */

/**

 *  ixgbe_clear_vfta_generic - Clear VLAN filter table

 *  @hw: pointer to hardware structure

 *

 *  Clears the VLAN filer table, and the VMDq index associated with the filter

/**

 *  ixgbe_need_crosstalk_fix - Determine if we need to do cross talk fix

 *  @hw: pointer to hardware structure

 *

 *  Contains the logic to identify if we need to verify link for the

 *  crosstalk fix

 Does FW say we need the fix */

 Only consider SFP+ PHYs i.e. media type fiber */

/**

 *  ixgbe_check_mac_link_generic - Determine link and speed status

 *  @hw: pointer to hardware structure

 *  @speed: pointer to link speed

 *  @link_up: true when link is up

 *  @link_up_wait_to_complete: bool used to wait for link up or not

 *

 *  Reads the links register to determine if link is up and the current speed

	/* If Crosstalk fix enabled do the sanity check of making sure

	 * the SFP+ cage is full.

 sanity check - No SFP+ devices here */

 clear the old state */

/**

 *  ixgbe_get_wwn_prefix_generic - Get alternative WWNN/WWPN prefix from

 *  the EEPROM

 *  @hw: pointer to hardware structure

 *  @wwnn_prefix: the alternative WWNN prefix

 *  @wwpn_prefix: the alternative WWPN prefix

 *

 *  This function will read the EEPROM from the alternative SAN MAC address

 *  block to check the support for the alternative WWNN/WWPN prefix support.

 clear output first */

 check if alternative SAN MAC is supported */

 check capability in alternative san mac address block */

 get the corresponding prefix for WWNN/WWPN */

/**

 *  ixgbe_set_mac_anti_spoofing - Enable/Disable MAC anti-spoofing

 *  @hw: pointer to hardware structure

 *  @enable: enable or disable switch for MAC anti-spoofing

 *  @vf: Virtual Function pool - VF Pool to set for MAC anti-spoofing

 *

/**

 *  ixgbe_set_vlan_anti_spoofing - Enable/Disable VLAN anti-spoofing

 *  @hw: pointer to hardware structure

 *  @enable: enable or disable switch for VLAN anti-spoofing

 *  @vf: Virtual Function pool - VF Pool to set for VLAN anti-spoofing

 *

/**

 *  ixgbe_get_device_caps_generic - Get additional device capabilities

 *  @hw: pointer to hardware structure

 *  @device_caps: the EEPROM word with the extra device capabilities

 *

 *  This function will read the EEPROM location for the device capabilities,

 *  and return the word through device_caps.

/**

 * ixgbe_set_rxpba_generic - Initialize RX packet buffer

 * @hw: pointer to hardware structure

 * @num_pb: number of packet buffers to allocate

 * @headroom: reserve n KB of headroom

 * @strategy: packet buffer allocation strategy

 Reserve headroom */

	/* Divide remaining packet buffer space amongst the number

	 * of packet buffers requested using supplied strategy.

		/* pba_80_48 strategy weight first half of packet buffer with

		 * 5/8 of the packet buffer space.

 configure remaining packet buffers */

 Divide the remaining Rx packet buffer evenly among the TCs */

	/*

	 * Setup Tx packet buffer and threshold equally for all TCs

	 * TXPBTHRESH register is set in K so divide by 1024 and subtract

	 * 10 since the largest packet we support is just over 9K.

 Clear unused TCs, if any, to zero buffer size*/

/**

 *  ixgbe_calculate_checksum - Calculate checksum for buffer

 *  @buffer: pointer to EEPROM

 *  @length: size of EEPROM to calculate a checksum for

 *

 *  Calculates the checksum for some buffer on a specified length.  The

 *  checksum calculated is returned.

/**

 *  ixgbe_hic_unlocked - Issue command to manageability block unlocked

 *  @hw: pointer to the HW structure

 *  @buffer: command to write and where the return status will be placed

 *  @length: length of buffer, must be multiple of 4 bytes

 *  @timeout: time in ms to wait for command completion

 *

 *  Communicates with the manageability block. On success return 0

 *  else returns semaphore error when encountering an error acquiring

 *  semaphore or IXGBE_ERR_HOST_INTERFACE_COMMAND when command fails.

 *

 *  This function assumes that the IXGBE_GSSR_SW_MNG_SM semaphore is held

 *  by the caller.

 Set bit 9 of FWSTS clearing FW reset indication */

 Check that the host interface is enabled. */

 Calculate length in DWORDs. We must be DWORD aligned */

	/* The device driver writes the relevant command block

	 * into the ram area.

 Setting this bit tells the ARC that a new command is pending. */

 Check command successful completion. */

/**

 *  ixgbe_host_interface_command - Issue command to manageability block

 *  @hw: pointer to the HW structure

 *  @buffer: contains the command to write and where the return status will

 *           be placed

 *  @length: length of buffer, must be multiple of 4 bytes

 *  @timeout: time in ms to wait for command completion

 *  @return_data: read and return data from the buffer (true) or not (false)

 *  Needed because FW structures are big endian and decoding of

 *  these fields can be 8 bit or 16 bit based on command. Decoding

 *  is not easily understood without making a table of commands.

 *  So we will leave this up to the caller to read back the data

 *  in these cases.

 *

 *  Communicates with the manageability block.  On success return 0

 *  else return IXGBE_ERR_HOST_INTERFACE_COMMAND.

 Take management host interface semaphore */

 Calculate length in DWORDs */

 first pull in the header so we know the buffer length */

 If there is any thing in data position pull it in */

 Calculate length in DWORDs, add 3 for odd lengths */

 Pull in the rest of the buffer (bi is where we left off) */

/**

 *  ixgbe_set_fw_drv_ver_generic - Sends driver version to firmware

 *  @hw: pointer to the HW structure

 *  @maj: driver version major number

 *  @min: driver version minor number

 *  @build: driver version build number

 *  @sub: driver version sub build number

 *  @len: length of driver_ver string

 *  @driver_ver: driver string

 *

 *  Sends driver version number to firmware through the manageability

 *  block.  On success return 0

 *  else returns IXGBE_ERR_SWFW_SYNC when encountering an error acquiring

 *  semaphore or IXGBE_ERR_HOST_INTERFACE_COMMAND when command fails.

/**

 * ixgbe_clear_tx_pending - Clear pending TX work from the PCIe fifo

 * @hw: pointer to the hardware structure

 *

 * The 82599 and x540 MACs can experience issues if TX work is still pending

 * when a reset occurs.  This function prevents this by flushing the PCIe

 * buffers on the system.

	/*

	 * If double reset is not requested then all transactions should

	 * already be clear and as such there is no work to do

	/*

	 * Set loopback enable to prevent any transmits from being sent

	 * should the link come up.  This assumes that the RXCTRL.RXEN bit

	 * has already been cleared.

 wait for a last completion before clearing buffers */

	/* Before proceeding, make sure that the PCIe block does not have

	 * transactions pending.

 initiate cleaning flow for buffers in the PCIe transaction layer */

 Flush all writes and allow 20usec for all transactions to clear */

 restore previous register values */

/**

 *  ixgbe_get_ets_data - Extracts the ETS bit data

 *  @hw: pointer to hardware structure

 *  @ets_cfg: extected ETS data

 *  @ets_offset: offset of ETS data

 *

 *  Returns error code.

/**

 *  ixgbe_get_thermal_sensor_data_generic - Gathers thermal sensor data

 *  @hw: pointer to hardware structure

 *

 *  Returns the thermal sensor data structure

 Only support thermal sensors attached to physical port 0 */

/**

 * ixgbe_init_thermal_sensor_thresh_generic - Inits thermal sensor thresholds

 * @hw: pointer to hardware structure

 *

 * Inits the thermal sensor thresholds according to the NVM map

 * and save off the threshold and location values into mac.thermal_sensor_data

 Only support thermal sensors attached to physical port 0 */

/**

 *  ixgbe_get_orom_version - Return option ROM from EEPROM

 *

 *  @hw: pointer to hardware structure

 *  @nvm_ver: pointer to output structure

 *

 *  if valid option ROM version, nvm_ver->or_valid set to true

 *  else nvm_ver->or_valid is false.

 Option Rom may or may not be present.  Start with pointer */

 make sure offset is valid */

 option rom exists and is valid */

/**

 *  ixgbe_get_oem_prod_version - Etrack ID from EEPROM

 *  @hw: pointer to hardware structure

 *  @nvm_ver: pointer to output structure

 *

 *  if valid OEM product version, nvm_ver->oem_valid set to true

 *  else nvm_ver->oem_valid is false.

 Return is offset to OEM Product Version block is invalid */

 Read product version block */

 Return if OEM product version block is invalid */

 Return if version is invalid */

/**

 *  ixgbe_get_etk_id - Return Etrack ID from EEPROM

 *

 *  @hw: pointer to hardware structure

 *  @nvm_ver: pointer to output structure

 *

 *  word read errors will return 0xFFFF

	/* The word order for the version format is determined by high order

	 * word bit 15.

/** ixgbe_mng_present - returns true when management capability is present

 * @hw: pointer to hardware structure

/**

 *  ixgbe_setup_mac_link_multispeed_fiber - Set MAC link speed

 *  @hw: pointer to hardware structure

 *  @speed: new link speed

 *  @autoneg_wait_to_complete: true when waiting for completion is needed

 *

 *  Set the link speed in the MAC and/or PHY register and restarts link.

 Mask off requested but non-supported speeds */

	/* Try each speed one by one, highest priority first.  We do this in

	 * software because 10Gb fiber doesn't support speed autonegotiation.

 Set the module link speed */

 QSFP module automatically detects MAC link speed */

 Allow module to change analog characteristics (1G->10G) */

 Flap the Tx laser if it has not already been done */

		/* Wait for the controller to acquire link.  Per IEEE 802.3ap,

		 * Section 73.10.2, we may have to wait up to 500ms if KR is

		 * attempted.  82599 uses the same timing for 10g SFI.

 Wait for the link partner to also set speed */

 If we have link, just jump out */

 Set the module link speed */

 QSFP module automatically detects link speed */

 Allow module to change analog characteristics (10G->1G) */

 Flap the Tx laser if it has not already been done */

 Wait for the link partner to also set speed */

 If we have link, just jump out */

	/* We didn't get link.  Configure back to the highest speed we tried,

	 * (if there was more than one).  We call ourselves back with just the

	 * single highest speed that the user requested.

 Set autoneg_advertised value based on input link speed */

/**

 *  ixgbe_set_soft_rate_select_speed - Set module link speed

 *  @hw: pointer to hardware structure

 *  @speed: link speed to set

 *

 *  Set module link speed via the soft rate select.

 one bit mask same as setting on */

 Set RS0 */

 Set RS1 */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 Start with X540 invariants, since so simular */

 Start with X540 invariants, since so similar */

 Start with X540 invariants, since so simular */

 Start with X540 invariants, since so similar */

/** ixgbe_setup_mux_ctl - Setup ESDP register for I2C mux control

 *  @hw: pointer to hardware structure

/**

 * ixgbe_read_cs4227 - Read CS4227 register

 * @hw: pointer to hardware structure

 * @reg: register number to write

 * @value: pointer to receive value read

 *

 * Returns status code

/**

 * ixgbe_write_cs4227 - Write CS4227 register

 * @hw: pointer to hardware structure

 * @reg: register number to write

 * @value: value to write to register

 *

 * Returns status code

/**

 * ixgbe_read_pe - Read register from port expander

 * @hw: pointer to hardware structure

 * @reg: register number to read

 * @value: pointer to receive read value

 *

 * Returns status code

/**

 * ixgbe_write_pe - Write register to port expander

 * @hw: pointer to hardware structure

 * @reg: register number to write

 * @value: value to write

 *

 * Returns status code

/**

 * ixgbe_reset_cs4227 - Reset CS4227 using port expander

 * @hw: pointer to hardware structure

 *

 * This function assumes that the caller has acquired the proper semaphore.

 * Returns error code

 Trigger hard reset. */

 Wait for the reset to complete. */

/**

 * ixgbe_check_cs4227 - Check CS4227 and reset as needed

 * @hw: pointer to hardware structure

 Get status of reset flow. */

 Reset is pending. Wait and check again. */

 If still pending, assume other instance failed. */

 Reset the CS4227. */

	/* Reset takes so long, temporarily release semaphore in case the

	 * other driver instance is waiting for the reset indication.

 Record completion for next time. */

/** ixgbe_identify_phy_x550em - Get PHY type based on device id

 *  @hw: pointer to hardware structure

 *

 *  Returns error code

 set up for CS4227 usage */

/**

 * ixgbe_read_i2c_combined_generic - Perform I2C read combined operation

 * @hw: pointer to the hardware structure

 * @addr: I2C bus address to read from

 * @reg: I2C device register to read from

 * @val: pointer to location to receive read value

 *

 * Returns an error code on error.

/**

 * ixgbe_read_i2c_combined_generic_unlocked - Do I2C read combined operation

 * @hw: pointer to the hardware structure

 * @addr: I2C bus address to read from

 * @reg: I2C device register to read from

 * @val: pointer to location to receive read value

 *

 * Returns an error code on error.

/**

 * ixgbe_write_i2c_combined_generic - Perform I2C write combined operation

 * @hw: pointer to the hardware structure

 * @addr: I2C bus address to write to

 * @reg: I2C device register to write to

 * @val: value to write

 *

 * Returns an error code on error.

/**

 * ixgbe_write_i2c_combined_generic_unlocked - Do I2C write combined operation

 * @hw: pointer to the hardware structure

 * @addr: I2C bus address to write to

 * @reg: I2C device register to write to

 * @val: value to write

 *

 * Returns an error code on error.

/**

 * ixgbe_fw_phy_activity - Perform an activity on a PHY

 * @hw: pointer to hardware structure

 * @activity: activity to perform

 * @data: Pointer to 4 32-bit words of data

/**

 * ixgbe_get_phy_id_fw - Get the phy ID via firmware command

 * @hw: pointer to hardware structure

 *

 * Returns error code

/**

 * ixgbe_identify_phy_fw - Get PHY type based on firmware command

 * @hw: pointer to hardware structure

 *

 * Returns error code

/**

 * ixgbe_shutdown_fw_phy - Shutdown a firmware-controlled PHY

 * @hw: pointer to hardware structure

 *

 * Returns error code

/**

 * ixgbe_setup_fw_link - Setup firmware-controlled PHYs

 * @hw: pointer to hardware structure

/**

 * ixgbe_fc_autoneg_fw - Set up flow control for FW-controlled PHYs

 * @hw: pointer to hardware structure

 *

 * Called at init time to set up flow control.

/** ixgbe_init_eeprom_params_X550 - Initialize EEPROM params

 *  @hw: pointer to hardware structure

 *

 *  Initializes the EEPROM parameters ixgbe_eeprom_info within the

 *  ixgbe_hw struct in order to set up EEPROM access.

/**

 * ixgbe_iosf_wait - Wait for IOSF command completion

 * @hw: pointer to hardware structure

 * @ctrl: pointer to location to receive final IOSF control value

 *

 * Return: failing status on timeout

 *

 * Note: ctrl can be NULL if the IOSF control register value is not needed

	/* Check every 10 usec to see if the address cycle completed.

	 * The SB IOSF BUSY bit will clear when the operation is

	 * complete.

/** ixgbe_read_iosf_sb_reg_x550 - Writes a value to specified register of the

 *  IOSF device

 *  @hw: pointer to hardware structure

 *  @reg_addr: 32 bit PHY register to write

 *  @device_type: 3 bit device type

 *  @phy_data: Pointer to read data from the register

 Write IOSF control register */

/**

 * ixgbe_get_phy_token - Get the token for shared PHY access

 * @hw: Pointer to hardware structure

/**

 * ixgbe_put_phy_token - Put the token for shared PHY access

 * @hw: Pointer to hardware structure

/**

 *  ixgbe_write_iosf_sb_reg_x550a - Write to IOSF PHY register

 *  @hw: pointer to hardware structure

 *  @reg_addr: 32 bit PHY register to write

 *  @device_type: 3 bit device type

 *  @data: Data to write to the register

/**

 *  ixgbe_read_iosf_sb_reg_x550a - Read from IOSF PHY register

 *  @hw: pointer to hardware structure

 *  @reg_addr: 32 bit PHY register to write

 *  @device_type: 3 bit device type

 *  @data: Pointer to read data from the register

 Extract the register value from the response. */

/** ixgbe_read_ee_hostif_buffer_X550- Read EEPROM word(s) using hostif

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to read

 *  @words: number of words

 *  @data: word(s) read from the EEPROM

 *

 *  Reads a 16 bit word(s) from the EEPROM using the hostif.

 Take semaphore for the entire operation. */

 convert offset from words to bytes */

/** ixgbe_checksum_ptr_x550 - Checksum one pointer region

 *  @hw: pointer to hardware structure

 *  @ptr: pointer offset in eeprom

 *  @size: size of section pointed by ptr, if 0 first word will be used as size

 *  @csum: address of checksum to update

 *

 *  Returns error status for any failure

 Read a chunk at the pointer location */

 Skip pointer section if length is invalid. */

 Read a chunk at the pointer location */

/** ixgbe_calc_checksum_X550 - Calculates and returns the checksum

 *  @hw: pointer to hardware structure

 *  @buffer: pointer to buffer containing calculated checksum

 *  @buffer_size: size of buffer

 *

 *  Returns a negative error code on error, or the 16-bit checksum

 Read pointer area */

	/* For X550 hardware include 0x0-0x41 in the checksum, skip the

	 * checksum word itself

	/* Include all data from pointers 0x3, 0x6-0xE.  This excludes the

	 * FW, PHY module, and PCIe Expansion/Option ROM pointers.

 Skip pointer section if the pointer is invalid. */

/** ixgbe_calc_eeprom_checksum_X550 - Calculates and returns the checksum

 *  @hw: pointer to hardware structure

 *

 *  Returns a negative error code on error, or the 16-bit checksum

/** ixgbe_read_ee_hostif_X550 - Read EEPROM word using a host interface command

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to read

 *  @data: word read from the EEPROM

 *

 *   Reads a 16 bit word from the EEPROM using the hostif.

 convert offset from words to bytes */

 one word */

/** ixgbe_validate_eeprom_checksum_X550 - Validate EEPROM checksum

 *  @hw: pointer to hardware structure

 *  @checksum_val: calculated checksum

 *

 *  Performs checksum calculation and validates the EEPROM checksum.  If the

 *  caller does not need checksum_val, the value can be NULL.

	/* Read the first word from the EEPROM. If this times out or fails, do

	 * not continue or we could be in for a very long wait while every

	 * EEPROM read fails

	/* Verify read checksum from EEPROM is the same as

	 * calculated checksum

 If the user cares, return the calculated checksum */

/** ixgbe_write_ee_hostif_X550 - Write EEPROM word using hostif

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to write

 *  @data: word write to the EEPROM

 *

 *  Write a 16 bit word to the EEPROM using the hostif.

 one word */

/** ixgbe_write_ee_hostif_X550 - Write EEPROM word using hostif

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to write

 *  @data: word write to the EEPROM

 *

 *  Write a 16 bit word to the EEPROM using the hostif.

/** ixgbe_update_flash_X550 - Instruct HW to copy EEPROM to Flash device

 *  @hw: pointer to hardware structure

 *

 *  Issue a shadow RAM dump to FW to copy EEPROM from shadow RAM to the flash.

/**

 * ixgbe_get_bus_info_X550em - Set PCI bus info

 * @hw: pointer to hardware structure

 *

 * Sets bus link width and speed to unknown because X550em is

 * not a PCI device.

/**

 * ixgbe_fw_recovery_mode_X550 - Check FW NVM recovery mode

 * @hw: pointer t hardware structure

 *

 * Returns true if in FW NVM recovery mode.

/** ixgbe_disable_rx_x550 - Disable RX unit

 *

 *  Enables the Rx DMA unit for x550

 If we fail - disable RX using register write */

/** ixgbe_update_eeprom_checksum_X550 - Updates the EEPROM checksum and flash

 *  @hw: pointer to hardware structure

 *

 *  After writing EEPROM to shadow RAM using EEWR register, software calculates

 *  checksum and updates the EEPROM and instructs the hardware to update

 *  the flash.

	/* Read the first word from the EEPROM. If this times out or fails, do

	 * not continue or we could be in for a very long wait while every

	 * EEPROM read fails

/** ixgbe_write_ee_hostif_buffer_X550 - Write EEPROM word(s) using hostif

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to write

 *  @words: number of words

 *  @data: word(s) write to the EEPROM

 *

 *

 *  Write a 16 bit word(s) to the EEPROM using the hostif.

 Take semaphore for the entire operation. */

/** ixgbe_write_iosf_sb_reg_x550 - Writes a value to specified register of the

 *  IOSF device

 *

 *  @hw: pointer to hardware structure

 *  @reg_addr: 32 bit PHY register to write

 *  @device_type: 3 bit device type

 *  @data: Data to write to the register

 Write IOSF control register */

 Write IOSF data register */

/**

 *  ixgbe_setup_ixfi_x550em_x - MAC specific iXFI configuration

 *  @hw: pointer to hardware structure

 *

 *  iXfI configuration needed for ixgbe_mac_X550EM_x devices.

 Disable training protocol FSM. */

 Disable Flex from training TXFFE. */

 Enable override for coefficients. */

/**

 *  ixgbe_restart_an_internal_phy_x550em - restart autonegotiation for the

 *  internal PHY

 *  @hw: pointer to hardware structure

 Restart auto-negotiation. */

 Indicate to FW that AN restart has been asserted */

/** ixgbe_setup_ixfi_x550em - Configure the KR PHY for iXFI mode.

 *  @hw: pointer to hardware structure

 *  @speed: the link speed to force

 *

 *  Configures the integrated KR PHY to use iXFI mode. Used to connect an

 *  internal and external PHY at a specific speed, without autonegotiation.

 iXFI is only supported with X552 */

 Disable AN and force speed to 10G Serial. */

 Select forced link speed for internal PHY. */

 Other link speeds are not supported by internal KR PHY. */

 Additional configuration needed for x550em_x */

 Toggle port SW reset by AN reset. */

/**

 *  ixgbe_supported_sfp_modules_X550em - Check if SFP module type is supported

 *  @hw: pointer to hardware structure

 *  @linear: true if SFP module is linear

/**

 * ixgbe_setup_mac_link_sfp_x550em - Configure the KR PHY for SFP.

 * @hw: pointer to hardware structure

 * @speed: the link speed to force

 * @autoneg_wait_to_complete: unused

 *

 * Configures the extern PHY and the integrated KR PHY for SFP support.

 Check if SFP module is supported and linear */

	/* If no SFP module present, then return success. Return success since

	 * there is no reason to configure CS4227 and SFP not present error is

	 * not accepted in the setup MAC link flow.

 Configure internal PHY for KR/KX. */

 Configure CS4227 LINE side to proper mode. */

/**

 * ixgbe_setup_sfi_x550a - Configure the internal PHY for native SFI mode

 * @hw: pointer to hardware structure

 * @speed: the link speed to force

 *

 * Configures the integrated PHY for native SFI mode. Used to connect the

 * internal PHY directly to an SFP cage, without autonegotiation.

 Disable all AN and force speed to 10G Serial. */

 Select forced link speed for internal PHY. */

 Other link speeds are not supported by internal PHY. */

 Toggle port SW reset by AN reset. */

/**

 * ixgbe_setup_mac_link_sfp_n - Setup internal PHY for native SFP

 * @hw: pointer to hardware structure

 * @speed: link speed

 * @autoneg_wait_to_complete: unused

 *

 * Configure the the integrated PHY for native SFP support.

 Check if SFP module is supported and linear */

	/* If no SFP module present, then return success. Return success since

	 * SFP not present error is not excepted in the setup MAC link flow.

 Configure internal PHY for native SFI based on module type */

 Setup SFI internal link. */

/**

 * ixgbe_setup_mac_link_sfp_x550a - Setup internal PHY for SFP

 * @hw: pointer to hardware structure

 * @speed: link speed

 * @autoneg_wait_to_complete: unused

 *

 * Configure the the integrated PHY for SFP support.

 Check if SFP module is supported and linear */

	/* If no SFP module present, then return success. Return success since

	 * SFP not present error is not excepted in the setup MAC link flow.

 Configure internal PHY for KR/KX. */

 Get external PHY SKU id */

	/* When configuring quad port CS4223, the MAC instance is part

	 * of the slice offset.

 Configure CS4227/CS4223 LINE side to proper mode. */

 Flush previous write with a read */

/**

 * ixgbe_setup_mac_link_t_X550em - Sets the auto advertised link speed

 * @hw: pointer to hardware structure

 * @speed: new link speed

 * @autoneg_wait: true when waiting for completion is needed

 *

 * Setup internal/external PHY link speed based on link speed, then set

 * external PHY auto advertised link speed.

 *

 * Returns error status for any failure

	/* Setup internal/external PHY link speed to iXFI (10G), unless

	 * only 1G is auto advertised then setup KX link.

	/* If X552 and internal link mode is XFI, then setup XFI internal link.

/** ixgbe_check_link_t_X550em - Determine link and speed status

  * @hw: pointer to hardware structure

  * @speed: pointer to link speed

  * @link_up: true when link is up

  * @link_up_wait_to_complete: bool used to wait for link up or not

  *

  * Check that both the MAC and X557 external PHY have link.

 If check link fails or MAC link is not up, then return */

	/* MAC link is up, so check external PHY link.

	 * Link status is latching low, and can only be used to detect link

	 * drop, and not the current status of the link without performing

	 * back-to-back reads.

 If external PHY link is not up, then indicate link not up */

/**

 * ixgbe_setup_sgmii - Set up link for sgmii

 * @hw: pointer to hardware structure

 * @speed: unused

 * @autoneg_wait_to_complete: unused

/**

 * ixgbe_setup_sgmii_fw - Set up link for sgmii with firmware-controlled PHYs

 * @hw: pointer to hardware structure

 * @speed: the link speed to force

 * @autoneg_wait: true when waiting for completion is needed

/**

 * ixgbe_fc_autoneg_sgmii_x550em_a - Enable flow control IEEE clause 37

 * @hw: pointer to hardware structure

 *

 * Enable flow control according to IEEE clause 37.

	/* AN should have completed when the cable was plugged in.

	 * Look for reasons to bail out.  Bail out if:

	 * - FC autoneg is disabled, or if

	 * - link is not up.

 Check if auto-negotiation has completed */

 Negotiate the flow control */

/** ixgbe_init_mac_link_ops_X550em_a - Init mac link function pointers

 *  @hw: pointer to hardware structure

/** ixgbe_init_mac_link_ops_X550em - init mac link function pointers

 *  @hw: pointer to hardware structure

		/* CS4227 does not support autoneg, so disable the laser control

		 * functions for SFP+ fiber

 Additional modification for X550em_a devices */

/** ixgbe_setup_sfp_modules_X550em - Setup SFP module

 * @hw: pointer to hardware structure

 Check if SFP module is supported */

/** ixgbe_get_link_capabilities_x550em - Determines link capabilities

 * @hw: pointer to hardware structure

 * @speed: pointer to link speed

 * @autoneg: true when autoneg or autotry is enabled

 SFP */

 CS4227 SFP must not enable auto-negotiation */

 Link capabilities are based on SFP */

 check different backplane modes */

/**

 * ixgbe_get_lasi_ext_t_x550em - Determime external Base T PHY interrupt cause

 * @hw: pointer to hardware structure

 * @lsc: pointer to boolean flag which indicates whether external Base T

 *	 PHY interrupt is lsc

 *

 * Determime if external Base T PHY interrupt cause is high temperature

 * failure alarm or link status change.

 *

 * Return IXGBE_ERR_OVERTEMP if interrupt is high temperature

 * failure alarm, else return PHY access status.

 Vendor alarm triggered */

 Vendor Auto-Neg alarm triggered or Global alarm 1 triggered */

 Global alarm triggered */

 If high temperature failure, then return over temp error and exit */

 power down the PHY in case the PHY FW didn't already */

  device fault alarm triggered */

 if device fault was due to high temp alarm handle and exit */

 power down the PHY in case the PHY FW didn't */

 Vendor alarm 2 triggered */

 link connect/disconnect event occurred */

 Indicate LSC */

/**

 * ixgbe_enable_lasi_ext_t_x550em - Enable external Base T PHY interrupts

 * @hw: pointer to hardware structure

 *

 * Enable link status change and temperature failure alarm for the external

 * Base T PHY

 *

 * Returns PHY access status

 Clear interrupt flags */

 Enable link status change alarm */

	/* Enable the LASI interrupts on X552 devices to receive notifications

	 * of the link configurations of the external PHY and correspondingly

	 * support the configuration of the internal iXFI link, since iXFI does

	 * not support auto-negotiation. This is not required for X553 devices

	 * having KR support, which performs auto-negotiations and which is used

	 * as the internal link to the external PHY. Hence adding a check here

	 * to avoid enabling LASI interrupts for X553 devices.

 Enable high temperature failure and global fault alarms */

 Enable vendor Auto-Neg alarm and Global Interrupt Mask 1 alarm */

 Enable chip-wide vendor alarm */

/**

 * ixgbe_handle_lasi_ext_t_x550em - Handle external Base T PHY interrupt

 * @hw: pointer to hardware structure

 *

 * Handle external Base T PHY interrupt. If high temperature

 * failure alarm then return error, else if link status change

 * then setup internal/external PHY link

 *

 * Return IXGBE_ERR_OVERTEMP if interrupt is high temperature

 * failure alarm, else return PHY access status.

/**

 * ixgbe_setup_kr_speed_x550em - Configure the KR PHY for link speed.

 * @hw: pointer to hardware structure

 * @speed: link speed

 *

 * Configures the integrated KR PHY.

 Advertise 10G support. */

 Advertise 1G support. */

 Set lane mode  to KR auto negotiation */

/**

 * ixgbe_setup_kr_x550em - Configure the KR PHY

 * @hw: pointer to hardware structure

 leave link alone for 2.5G */

/** ixgbe_ext_phy_t_x550em_get_link - Get ext phy link status

 *  @hw: address of hardware structure

 *  @link_up: address of boolean to indicate link status

 *

 *  Returns error code if unable to get link status.

 read this twice back to back to indicate current status */

/** ixgbe_setup_internal_phy_t_x550em - Configure KR PHY to X557 link

 *  @hw: point to hardware structure

 *

 *  Configures the link between the integrated KR PHY and the external X557 PHY

 *  The driver will call this function when it gets a link status change

 *  interrupt from the X557 PHY. This function configures the link speed

 *  between the PHYs to match the link speed of the BASE-T link.

 *

 * A return of a non-zero value indicates an error, and the base driver should

 * not report link up.

 If link is not up, then there is no setup necessary so return  */

 If link is not still up, then no setup is necessary so return */

 clear everything but the speed and duplex bits */

 Internal PHY does not support anything else */

/** ixgbe_reset_phy_t_X550em - Performs X557 PHY reset and enables LASI

 *  @hw: pointer to hardware structure

 Configure Link Status Alarm and Temperature Threshold interrupts */

/**

 *  ixgbe_led_on_t_x550em - Turns on the software controllable LEDs.

 *  @hw: pointer to hardware structure

 *  @led_idx: led number to turn on

 To turn on the LED, set mode to ON. */

/**

 *  ixgbe_led_off_t_x550em - Turns off the software controllable LEDs.

 *  @hw: pointer to hardware structure

 *  @led_idx: led number to turn off

 To turn on the LED, set mode to ON. */

/**

 *  ixgbe_set_fw_drv_ver_x550 - Sends driver version to firmware

 *  @hw: pointer to the HW structure

 *  @maj: driver version major number

 *  @min: driver version minor number

 *  @build: driver version build number

 *  @sub: driver version sub build number

 *  @len: length of driver_ver string

 *  @driver_ver: driver string

 *

 *  Sends driver version number to firmware through the manageability

 *  block.  On success return 0

 *  else returns IXGBE_ERR_SWFW_SYNC when encountering an error acquiring

 *  semaphore or IXGBE_ERR_HOST_INTERFACE_COMMAND when command fails.

/** ixgbe_get_lcd_x550em - Determine lowest common denominator

 *  @hw: pointer to hardware structure

 *  @lcd_speed: pointer to lowest common link speed

 *

 *  Determine lowest common link speed with link partner.

 If link partner advertised 1G, return 1G */

 If 10G disabled for LPLU via NVM D10GMP, then return no valid LCD */

 Link partner not capable of lower speeds, return 10G */

/**

 * ixgbe_setup_fc_x550em - Set up flow control

 * @hw: pointer to hardware structure

 Validate the requested mode */

	/* 10gig parts do not have a word in the EEPROM to determine the

	 * default flow control setting, so we explicitly set it to full.

 Determine PAUSE and ASM_DIR bits. */

		/* Rx Flow control is enabled and Tx Flow control is

		 * disabled by software override. Since there really

		 * isn't a way to advertise that we are capable of RX

		 * Pause ONLY, we will advertise that we support both

		 * symmetric and asymmetric Rx PAUSE, as such we fall

		 * through to the fc_full statement.  Later, we will

		 * disable the adapter's ability to send PAUSE frames.

 This device does not fully support AN. */

/**

 *  ixgbe_fc_autoneg_backplane_x550em_a - Enable flow control IEEE clause 37

 *  @hw: pointer to hardware structure

	/* AN should have completed when the cable was plugged in.

	 * Look for reasons to bail out.  Bail out if:

	 * - FC autoneg is disabled, or if

	 * - link is not up.

 Check at auto-negotiation has completed */

	/* Read the 10g AN autoc and LP ability registers and resolve

	 * local flow control settings accordingly

/**

 *  ixgbe_fc_autoneg_fiber_x550em_a - passthrough FC settings

 *  @hw: pointer to hardware structure

/** ixgbe_enter_lplu_x550em - Transition to low power states

 *  @hw: pointer to hardware structure

 *

 *  Configures Low Power Link Up on transition to low power states

 *  (from D0 to non-D0). Link is required to enter LPLU so avoid resetting

 *  the X557 PHY immediately prior to entering LPLU.

 If blocked by MNG FW, then don't restart AN */

	/* If link is down, LPLU disabled in NVM, WoL disabled, or

	 * manageability disabled, then force link down by entering

	 * low power mode.

 Determine LCD */

 If no valid LCD link speed, then force link down and exit. */

 If no link now, speed is invalid so take link down */

 clear everything but the speed bits */

 If current speed is already LCD, then exit. */

 Clear AN completed indication */

 Setup link at least common link speed */

 restore autoneg from before setting lplu speed */

/**

 * ixgbe_reset_phy_fw - Reset firmware-controlled PHYs

 * @hw: pointer to hardware structure

/**

 * ixgbe_check_overtemp_fw - Check firmware-controlled PHYs for overtemp

 * @hw: pointer to hardware structure

/**

 * ixgbe_read_mng_if_sel_x550em - Read NW_MNG_IF_SEL register

 * @hw: pointer to hardware structure

 *

 * Read NW_MNG_IF_SEL register and save field values.

	/* Save NW management interface connected on board. This is used

	 * to determine internal PHY mode.

	/* If X552 (X550EM_a) and MDIO is connected to external PHY, then set

	 * PHY address. This register field was has only been used for X552.

/** ixgbe_init_phy_ops_X550em - PHY/SFP specific init

 *  @hw: pointer to hardware structure

 *

 *  Initialize any function pointers that were not able to be

 *  set during init_shared_code because the PHY/SFP type was

 *  not known.  Perform the SFP init if necessary.

 Identify the PHY or SFP module */

 Setup function pointers based on detected hardware */

 Set functions pointers based on phy type */

 link is managed by HW */

		/* Save NW management interface connected on board. This is used

		 * to determine internal PHY mode

		/* If internal link mode is XFI, then setup iXFI internal link,

		 * else setup KR now.

 setup SW LPLU only for first revision */

/** ixgbe_get_media_type_X550em - Get media type

 *  @hw: pointer to hardware structure

 *

 *  Returns the media type (fiber, copper, backplane)

 *

 Detect if there is a copper PHY attached. */

/** ixgbe_init_ext_t_x550em - Start (unstall) the external Base T PHY.

 ** @hw: pointer to hardware structure

	/* If PHY FW reset completed bit is set then this is the first

	 * SW instance after a power on so the PHY FW must be un-stalled.

/**

 * ixgbe_set_mdio_speed - Set MDIO clock speed

 * @hw: pointer to hardware structure

 Config MDIO clock speed before the first MDIO PHY access */

 Select fast MDIO clock speed for these devices */

/**  ixgbe_reset_hw_X550em - Perform hardware reset

 **  @hw: pointer to hardware structure

 **

 **  Resets the hardware by resetting the transmit and receive units, masks

 **  and clears all interrupts, perform a PHY reset, and perform a link (MAC)

 **  reset.

 Call adapter stop to disable Tx/Rx and clear interrupts */

 flush pending Tx transactions */

 PHY ops must be identified and initialized prior to reset */

 start the external PHY */

 Setup SFP module if there is one present. */

 Reset PHY */

	/* Issue global reset to the MAC.  Needs to be SW reset if link is up.

	 * If link reset is used when link is up, it might reset the PHY when

	 * mng is using it.  If link is down or the flag to force full link

	 * reset is set, then perform link reset.

 Poll for reset bit to self-clear meaning reset is complete */

	/* Double resets are required for recovery from certain error

	 * clear the multicast table.  Also reset num_rar_entries to 128,

	 * since we modify this value when programming the SAN MAC address.

 Store the permanent mac address */

	/* Store MAC address from RAR0, clear receive address registers, and

	 * clear the multicast table.  Also reset num_rar_entries to 128,

	 * since we modify this value when programming the SAN MAC address.

/** ixgbe_set_ethertype_anti_spoofing_X550 - Enable/Disable Ethertype

 *	anti-spoofing

 *  @hw:  pointer to hardware structure

 *  @enable: enable or disable switch for Ethertype anti-spoofing

 *  @vf: Virtual Function pool - VF Pool to set for Ethertype anti-spoofing

/** ixgbe_set_source_address_pruning_X550 - Enable/Disbale src address pruning

 *  @hw: pointer to hardware structure

 *  @enable: enable or disable source address pruning

 *  @pool: Rx pool to set source address pruning for

 max rx pool is 63 */

/**

 *  ixgbe_setup_fc_backplane_x550em_a - Set up flow control

 *  @hw: pointer to hardware structure

 *

 *  Called at init time to set up flow control.

 Validate the requested mode */

	/* Set up the 1G and 10G flow control advertisement registers so the

	 * HW will be able to do FC autoneg once the cable is plugged in.  If

	 * we link at 10G, the 1G advertisement is harmless and vice versa.

	/* The possible values of fc.requested_mode are:

	 * 0: Flow control is completely disabled

	 * 1: Rx flow control is enabled (we can receive pause frames,

	 *    but not send pause frames).

	 * 2: Tx flow control is enabled (we can send pause frames but

	 *    we do not support receiving pause frames).

	 * 3: Both Rx and Tx flow control (symmetric) are enabled.

	 * other: Invalid.

 Flow control completely disabled by software override. */

		/* Tx Flow control is enabled, and Rx Flow control is

		 * disabled by software override.

		/* Rx Flow control is enabled and Tx Flow control is

		 * disabled by software override. Since there really

		 * isn't a way to advertise that we are capable of RX

		 * Pause ONLY, we will advertise that we support both

		 * symmetric and asymmetric Rx PAUSE, as such we fall

		 * through to the fc_full statement.  Later, we will

		 * disable the adapter's ability to send PAUSE frames.

 Flow control (both Rx and Tx) is enabled by SW override. */

 Restart auto-negotiation. */

/**

 * ixgbe_set_mux - Set mux for port 1 access with CS4227

 * @hw: pointer to hardware structure

 * @state: set mux if 1, clear if 0

/**

 * ixgbe_acquire_swfw_sync_X550em - Acquire SWFW semaphore

 * @hw: pointer to hardware structure

 * @mask: Mask to specify which semaphore to acquire

 *

 * Acquires the SWFW semaphore and sets the I2C MUX

/**

 * ixgbe_release_swfw_sync_X550em - Release SWFW semaphore

 * @hw: pointer to hardware structure

 * @mask: Mask to specify which semaphore to release

 *

 * Releases the SWFW semaphore and sets the I2C MUX

/**

 * ixgbe_acquire_swfw_sync_x550em_a - Acquire SWFW semaphore

 * @hw: pointer to hardware structure

 * @mask: Mask to specify which semaphore to acquire

 *

 * Acquires the SWFW semaphore and get the shared PHY token as needed

/**

 * ixgbe_release_swfw_sync_x550em_a - Release SWFW semaphore

 * @hw: pointer to hardware structure

 * @mask: Mask to specify which semaphore to release

 *

 * Release the SWFW semaphore and puts the shared PHY token as needed

/**

 * ixgbe_read_phy_reg_x550a - Reads specified PHY register

 * @hw: pointer to hardware structure

 * @reg_addr: 32 bit address of PHY register to read

 * @device_type: 5 bit device type

 * @phy_data: Pointer to read data from PHY register

 *

 * Reads a value from a specified PHY register using the SWFW lock and PHY

 * Token. The PHY Token is needed since the MDIO is shared between to MAC

 * instances.

/**

 * ixgbe_write_phy_reg_x550a - Writes specified PHY register

 * @hw: pointer to hardware structure

 * @reg_addr: 32 bit PHY register to write

 * @device_type: 5 bit device type

 * @phy_data: Data to write to the PHY register

 *

 * Writes a value to specified PHY register using the SWFW lock and PHY Token.

 * The PHY Token is needed since the MDIO is shared between to MAC instances.

 defined later */

 defined later */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 *  ixgbe_read_mbx - Reads a message from the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @mbx_id: id of mailbox to read

 *

 *  returns SUCCESS if it successfully read message from buffer

 limit read to size of mailbox */

/**

 *  ixgbe_write_mbx - Write a message to the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully copied message into the buffer

/**

 *  ixgbe_check_for_msg - checks to see if someone sent us mail

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to check

 *

 *  returns SUCCESS if the Status bit was found or else ERR_MBX

/**

 *  ixgbe_check_for_ack - checks to see if someone sent us ACK

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to check

 *

 *  returns SUCCESS if the Status bit was found or else ERR_MBX

/**

 *  ixgbe_check_for_rst - checks to see if other side has reset

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to check

 *

 *  returns SUCCESS if the Status bit was found or else ERR_MBX

/**

 *  ixgbe_poll_for_msg - Wait for message notification

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully received a message notification

/**

 *  ixgbe_poll_for_ack - Wait for message acknowledgement

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully received a message acknowledgement

/**

 *  ixgbe_read_posted_mbx - Wait for message notification and receive message

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully received a message notification and

 *  copied it into the receive buffer.

 if ack received read message */

/**

 *  ixgbe_write_posted_mbx - Write a message to the mailbox, wait for ack

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully copied message into the buffer and

 *  received an ack to that message within delay * timeout period

 exit if either we can't write or there isn't a defined timeout */

 send msg */

 if msg sent wait until we receive an ack */

/**

 *  ixgbe_check_for_msg_pf - checks to see if the VF has sent mail

 *  @hw: pointer to the HW structure

 *  @vf_number: the VF index

 *

 *  returns SUCCESS if the VF has set the Status bit or else ERR_MBX

/**

 *  ixgbe_check_for_ack_pf - checks to see if the VF has ACKed

 *  @hw: pointer to the HW structure

 *  @vf_number: the VF index

 *

 *  returns SUCCESS if the VF has set the Status bit or else ERR_MBX

/**

 *  ixgbe_check_for_rst_pf - checks to see if the VF has reset

 *  @hw: pointer to the HW structure

 *  @vf_number: the VF index

 *

 *  returns SUCCESS if the VF has set the Status bit or else ERR_MBX

/**

 *  ixgbe_obtain_mbx_lock_pf - obtain mailbox lock

 *  @hw: pointer to the HW structure

 *  @vf_number: the VF index

 *

 *  return SUCCESS if we obtained the mailbox lock

 Take ownership of the buffer */

 reserve mailbox for vf use */

/**

 *  ixgbe_write_mbx_pf - Places a message in the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @vf_number: the VF index

 *

 *  returns SUCCESS if it successfully copied message into the buffer

 lock the mailbox to prevent pf/vf race condition */

 flush msg and acks as we are overwriting the message buffer */

 copy the caller specified message to the mailbox memory buffer */

 Interrupt VF to tell it a message has been sent and release buffer*/

 update stats */

/**

 *  ixgbe_read_mbx_pf - Read a message from the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @vf_number: the VF index

 *

 *  This function copies a message from the mailbox buffer to the caller's

 *  memory buffer.  The presumption is that the caller knows that there was

 *  a message due to a VF request so no polling for message is needed.

 lock the mailbox to prevent pf/vf race condition */

 copy the message to the mailbox memory buffer */

 Acknowledge the message and release buffer */

 update stats */

/**

 *  ixgbe_init_mbx_params_pf - set initial values for pf mailbox

 *  @hw: pointer to the HW structure

 *

 *  Initializes the hw->mbx struct to correct values for pf mailbox

 CONFIG_PCI_IOV */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 * ixgbe_fcoe_clear_ddp - clear the given ddp context

 * @ddp: ptr to the ixgbe_fcoe_ddp

 *

 * Returns : none

 *

/**

 * ixgbe_fcoe_ddp_put - free the ddp context for a given xid

 * @netdev: the corresponding net_device

 * @xid: the xid that corresponding ddp will be freed

 *

 * This is the implementation of net_device_ops.ndo_fcoe_ddp_done

 * and it is expected to be called by ULD, i.e., FCP layer of libfc

 * to release the corresponding ddp context when the I/O is done.

 *

 * Returns : data length already ddp-ed in bytes

 if no error then skip ddp context invalidation */

 X550 does not require DDP FCoE lock */

 program FCBUFF */

 program FCDMARW */

 read FCBUFF to check context invalidated */

 other hardware requires DDP FCoE lock */

 guaranteed to be invalidated after 100us */

/**

 * ixgbe_fcoe_ddp_setup - called to set up ddp context

 * @netdev: the corresponding net_device

 * @xid: the exchange id requesting ddp

 * @sgl: the scatter-gather list for this request

 * @sgc: the number of scatter-gather items

 * @target_mode: 1 to setup target mode, 0 to setup initiator mode

 *

 * Returns : 1 for success and 0 for no ddp

 no DDP if we are already down or resetting */

 setup dma from scsi command sgl */

 alloc the udl from per cpu ddp pool */

 max number of buffers allowed in one DDP context */

 get the offset of length of current buffer */

			/*

			 * all but the 1st buffer (j == 0)

			 * must be aligned on bufflen

			/*

			 * all but the last buffer

			 * ((i == (dmacount - 1)) && (thislen == len))

			 * must end at bufflen

 only the first buffer may have none-zero offset */

 only the last buffer may have non-full bufflen */

	/*

	 * lastsize can not be buffer len.

	 * If it is then adding another buffer with lastsize = 1.

 Set WRCONTX bit to allow DDP for target */

 program DMA context */

	/* turn on last frame indication for target mode as FCP_RSPtarget is

 X550 does not require DDP lock */

 program filter context */

 DDP lock for indirect DDP context access */

 program filter context */

/**

 * ixgbe_fcoe_ddp_get - called to set up ddp context in initiator mode

 * @netdev: the corresponding net_device

 * @xid: the exchange id requesting ddp

 * @sgl: the scatter-gather list for this request

 * @sgc: the number of scatter-gather items

 *

 * This is the implementation of net_device_ops.ndo_fcoe_ddp_setup

 * and is expected to be called from ULD, e.g., FCP layer of libfc

 * to set up ddp for the corresponding xid of the given sglist for

 * the corresponding I/O.

 *

 * Returns : 1 for success and 0 for no ddp

/**

 * ixgbe_fcoe_ddp_target - called to set up ddp context in target mode

 * @netdev: the corresponding net_device

 * @xid: the exchange id requesting ddp

 * @sgl: the scatter-gather list for this request

 * @sgc: the number of scatter-gather items

 *

 * This is the implementation of net_device_ops.ndo_fcoe_ddp_target

 * and is expected to be called from ULD, e.g., FCP layer of libfc

 * to set up ddp for the corresponding xid of the given sglist for

 * the corresponding I/O. The DDP in target mode is a write I/O request

 * from the initiator.

 *

 * Returns : 1 for success and 0 for no ddp

/**

 * ixgbe_fcoe_ddp - check ddp status and mark it done

 * @adapter: ixgbe adapter

 * @rx_desc: advanced rx descriptor

 * @skb: the skb holding the received data

 *

 * This checks ddp status.

 *

 * Returns : < 0 indicates an error or not a FCiE ddp, 0 indicates

 * not passing the skb to ULD, > 0 indicates is the length of data

 * being ddped.

 X550 has different DDP Max limit */

 return 0 to bypass going to ULD for DDPed data */

 update length of DDPed data */

 unmap the sg list when FCPRSP is received */

 if DDP length is present pass it through to ULD */

 update length of DDPed data */

 no match will return as an error */

	/* In target mode, check the last data frame of the sequence.

	 * For DDP in target mode, data is already DDPed but the header

	 * indication of the last data frame ould allow is to tell if we

	 * got all the data and the ULP can send FCP_RSP back, as this is

	 * not a full fcoe frame, we fill the trailer here so it won't be

	 * dropped by the ULP stack.

/**

 * ixgbe_fso - ixgbe FCoE Sequence Offload (FSO)

 * @tx_ring: tx desc ring

 * @first: first tx_buffer structure containing skb, tx_flags, and protocol

 * @hdr_len: hdr_len to be returned

 *

 * This sets up large send offload for FCoE

 *

 * Returns : 0 indicates success, < 0 for error

 resets the header to point fcoe/fc */

 sets up SOF and ORIS */

 the first byte of the last dword is EOF */

 sets up EOF and ORIE */

 lso needs ORIE */

 sets up PARINC indicating data offset */

 include trailer in headlen as it is replicated per frame */

 hdr_len includes fc_hdr if FCoE LSO is enabled */

 update gso_segs and bytecount */

 Hardware expects L4T to be RSV for FCoE TSO */

 set flag indicating FCOE to ixgbe_tx_map call */

 mss_l4len_id: use 0 for FSO as TSO, no need for L4LEN */

 vlan_macip_lens: HEADLEN, MACLEN, VLAN tag */

 write context desc */

/**

 * ixgbe_configure_fcoe - configures registers for fcoe at start

 * @adapter: ptr to ixgbe adapter

 *

 * This sets up FCoE related registers

 *

 * Returns : none

 Minimal functionality for FCoE requires at least CRC offloads */

 Enable L2 EtherType filter for FCoE, needed for FCoE CRC and DDP */

 leave registers un-configured if FCoE is disabled */

 Use one or more Rx queues for FCoE by redirection table */

 Enable L2 EtherType filter for FIP */

 Send FIP frames to the first FCoE queue */

 Configure FCoE Rx control */

/**

 * ixgbe_free_fcoe_ddp_resources - release all fcoe ddp context resources

 * @adapter : ixgbe adapter

 *

 * Cleans up outstanding ddp context resources

 *

 * Returns : none

 do nothing if no DDP pools were allocated */

 X550 has different DDP Max limit */

/**

 * ixgbe_setup_fcoe_ddp_resources - setup all fcoe ddp context resources

 * @adapter: ixgbe adapter

 *

 * Sets up ddp context resouces

 *

 * Returns : 0 indicates success or -EINVAL on failure

 do nothing if no DDP pools were allocated */

 Extra buffer to be shared by all DDPs for HW work around */

 allocate pci pool for each cpu */

 X550 has different DDP Max limit */

/**

 * ixgbe_fcoe_enable - turn on FCoE offload feature

 * @netdev: the corresponding netdev

 *

 * Turns on FCoE offload feature in 82599.

 *

 * Returns : 0 indicates success or -EINVAL on failure

 Allocate per CPU memory to track DDP pools */

 enable FCoE and notify stack */

 release existing queues and reallocate them */

/**

 * ixgbe_fcoe_disable - turn off FCoE offload feature

 * @netdev: the corresponding netdev

 *

 * Turns off FCoE offload feature in 82599.

 *

 * Returns : 0 indicates success or -EINVAL on failure

 Free per CPU memory to track DDP pools */

 disable FCoE and notify stack */

 release existing queues and reallocate them */

/**

 * ixgbe_fcoe_get_wwn - get world wide name for the node or the port

 * @netdev : ixgbe adapter

 * @wwn : the world wide name

 * @type: the type of world wide name

 *

 * Returns the node or port world wide name if both the prefix and the san

 * mac address are valid, then the wwn is formed based on the NAA-2 for

 * IEEE Extended name identifier (ref. to T10 FC-LS Spec., Sec. 15.3).

 *

 * Returns : 0 on success

/**

 * ixgbe_fcoe_get_hbainfo - get FCoE HBA information

 * @netdev : ixgbe adapter

 * @info : HBA information

 *

 * Returns ixgbe HBA information

 *

 * Returns : 0 on success

 Don't return information on unsupported devices */

 Manufacturer */

 Serial Number */

 Get the PCI-e Device Serial Number Capability */

 Hardware Version */

 Driver Name/Version */

 Firmware Version */

 Model */

 Model Description */

/**

 * ixgbe_fcoe_get_tc - get the current TC that fcoe is mapped to

 * @adapter: pointer to the device adapter structure

 *

 * Return : TC that FCoE is mapped to

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 ethtool support for ixgbe */

 IXGBE_FCOE */

/* ixgbe allocates num_tx_queues and num_rx_queues symmetrically so

 * we set the num_rx_queues to evaluate to num_tx_queues. This is

 * used because we do not have a good way to get the max number of

 * rx queues with CONFIG_RPS disabled.

 set the supported link speeds */

 set the advertised speeds */

 Determine the remaining settings based on the PHY type. */

 SFP+ devices, further checking needed */

 Indicate pause support */

		/*

		 * this function does not support duplex forcing, but can

		 * limit the advertising of the adapter to the specified speed

 only allow one speed at a time if no autoneg */

 this sets the link speed and restarts auto-neg */

 in this case we currently only support 10Gb/FULL */

 82598 does no support link flow control with DCB enabled */

 some devices do not support autoneg of link flow control */

 if the thing changed then we'll update and use new autoneg */

 General Registers */

 NVM Register */

 Interrupt */

	/* don't read EICR because it can clear interrupt causes, instead

 Flow Control */

 Receive DMA */

 Receive */

 Transmit */

 Wake Up */

 DCB */

 same as FCCFG  */

 same as RTTPCS */

 same as RTTPT2C */

 same as RTTPT2S */

 Statistics */

 MAC */

 Diagnostic */

 82599 X540 specific registers  */

 82599 X540 specific DCB registers  */

 same as RTTQCNRM */

 same as RTTQCNRR */

 X540 specific DCB registers  */

 Security config registers */

 Device's eeprom is always little-endian, word addressable */

		/*

		 * need read/modify/write of first changed EEPROM word

		 * only the second byte of the word is being modified

		/*

		 * need read/modify/write of last changed EEPROM word

		 * only the first byte of the word is being modified

 Device's eeprom is always little-endian, word addressable */

 Update the checksum */

 nothing to do */

 allocate temporary buffer to store rings in */

	/*

	 * Setup new Tx resources and free the old Tx resources in that order.

	 * We can then assign the new resources to the rings via a memcpy.

	 * The advantage to this approach is that we are guaranteed to still

	 * have resources even in the case of an allocation failure.

 Repeat the process for the Rx rings if needed */

 Clear copied XDP RX-queue info */

 BUG_ON(p - data != IXGBE_STATS_LEN * ETH_GSTRING_LEN); */

 ethtool register test data */

/* In the hardware, registers are laid out either singly, in arrays

 * spaced 0x40 bytes apart, or in contiguous tables.  We assume

 * most tests take place on arrays or single registers (handled

 * as a single-element array) and special-case the tables.

 * Table tests are always pattern tests.

 *

 * We also make provision for some required setup steps by specifying

 * registers to be written without any read-back testing.

 default 82599 register test */

 default 82598 register test */

 Enable all four RX queues before testing. */

 RDH is read-only for 82598, only test RDT. */

	/*

	 * Because the status register is such a special case,

	 * we handle it separately from the rest of the register

	 * tests.  Some bits are read-only, some toggle, and some

	 * are writeable on newer MACs.

 restore previous status */

	/*

	 * Perform the remainder of the register test, looping through

	 * the test table until we either fail or reach the null entry.

 Hook up test interrupt handler just for this test */

 NOTE: we don't test MSI-X interrupts here, yet */

 Disable all the interrupts */

 Test each interrupt */

 Interrupt to test */

			/*

			 * Disable the interrupts to be reported in

			 * the cause register and then force the same

			 * interrupt and see if one gets posted.  If

			 * an interrupt was posted to the bus, the

			 * test failed.

		/*

		 * Enable the interrupt to be reported in the cause

		 * register and then force the same interrupt and see

		 * if one gets posted.  If an interrupt was not posted

		 * to the bus, the test failed.

			/*

			 * Disable the other interrupts to be reported in

			 * the cause register and then force the other

			 * interrupts and see if any get posted.  If

			 * an interrupt was posted to the bus, the

			 * test failed.

 Disable all the interrupts */

 Unhook test interrupt handler */

	/* Shut down the DMA engines now so they can be reinitialized later,

	 * since the test rings and normally used rings should overlap on

	 * queue 0 we can just use the standard disable Rx/Tx calls and they

	 * will take care of disabling the test rings for us.

 first Rx */

 now Tx */

 Setup Tx descriptor ring and Tx buffers */

 Setup Rx Descriptor ring and Rx buffers */

 Setup MAC loopback */

 X540 and X550 needs to set the MACC.FLU bit to force link up */

 Disable Atlas Tx lanes; re-enabled in reset path */

 initialize next to clean and descriptor values */

 if DD is not set transmit has not completed */

 unmap buffer on Tx side */

 Free all the Tx ring sk_buffs */

 unmap skb header data */

 increment Tx next to clean counter */

 check Rx buffer */

 sync Rx buffer for CPU read */

 verify contents of skb */

 sync Rx buffer for device write */

 increment Rx next to clean counter */

 fetch next descriptor */

 re-map buffers to ring, store next to clean values */

 DCB can modify the frames on Tx */

 allocate test skb */

 place data into test skb */

	/*

	 * Calculate the loop count based on the largest descriptor ring

	 * The idea is to wrap the largest ring a number of times using 64

	 * send/receive pairs during each loop

 reset count of good packets */

 place 64 packets on the transmit queue*/

 allow 200 milliseconds for packets to go from Tx to Rx */

 free the original skb */

 Offline tests */

		/* Link test performed before hardware reset so autoneg doesn't

		 * interfere with test result

 indicate we're in test mode */

		/* If SRIOV or VMDq is enabled then skip MAC

 clear testing bit and return adapter to previous state */

 Online tests */

 Offline tests aren't run; pass by default */

 WOL not supported for all devices */

 Restore LED settings */

 only valid if in constant ITR mode */

 if in mixed tx/rx queues per vector mode, report only rx settings */

 only valid if in constant ITR mode */

/*

 * this function must be called before setting the new value of

 * rx_itr_setting

 nothing to do if LRO or RSC are not enabled */

 check the feature flag value and enable RSC if necessary */

 if interrupt rate is too high then disable RSC */

 reject Tx specific changes in case of mixed RxTx vectors */

 mixed Rx/Tx */

 detect ITR changes that require update of TXDCTL.WTHRESH */

 check the old value and enable RSC if necessary */

 tx only */

 rx only or mixed */

	/*

	 * do reset here at the end to make sure EITR==0 case is handled

	 * correctly w.r.t stopping tx, and changing TXDCTL.WTHRESH settings

	 * also locks in RSC enable/disable which requires reset

 report total rule count */

 fill out the flow spec entry */

 set flow type field */

 record action */

 report total rule count */

 Report default options for RSS on ixgbe */

 hash found, or no matching entry */

 if there is an old rule occupying our place remove it */

	/*

	 * If no input this was a delete, err should be 0 if a rule was

	 * successfully found and removed from the list else -EINVAL

 initialize node and set software index */

 add filter to the list */

 update counts */

	/* ring_cookie is a masked into a set of queues and ixgbe pools or

	 * we use the drop index.

 Map the ring onto the absolute queue index */

 Don't allow indexes to exist outside of available space */

 set SW index */

 record flow type */

 Copy input into formatted structures */

 determine if we need to drop or route the packet */

 save mask and program input mask into HW */

 apply mask and compute/store hash */

 program filters to filter memory */

	/*

	 * RSS does not support anything other than hashing

	 * to queues on src and dst IPs and ports

 if we changed something we need to update flags */

 Perform hash on these packet types */

 Fill out the redirection table */

Allow at least 2 queues w/ SR-IOV.*/

 Verify user input. */

 Fill out the rss hash key */

 we always support timestamping disabled */

 We only support one q_vector without MSI-X */

 Limit value based on the queue mask */

 For DCB report channels per traffic class */

 8 TC w/ 4 queues per TC */

 8 TC w/ 8 queues per TC */

 4 TC w/ 16 queues per TC */

 support up to 64 queues with ATR */

 support up to 16 queues with RSS */

 report maximum channels */

 report info for other vector */

 record RSS queues */

 nothing else to report if RSS is disabled */

 we do not support ATR queueing if SR-IOV is enabled */

 same thing goes for being DCB enabled */

 if ATR is disabled we can exit */

 report flow director queues as maximum channels */

 verify they are not requesting separate vectors */

 verify other_count has not changed */

 verify the number of channels does not exceed hardware limits */

 update feature limits from largest to smallest supported values */

 cap RSS limit */

 cap FCoE limit at 8 */

 use setup TC to update any traffic class queue mapping */

 Check whether we support SFF-8472 or not */

 addressing mode is not supported */

 We have a SFP, but it does not support SFF-8472 */

 We have a SFP which supports a revision of SFF-8472. */

 I2C reads can take long time */

 reset link */

 reset interface to repopulate queues */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/* ixgbe_pci_tbl - PCI Device ID Table

 *

 * Wildcard entries (PCI_ANY_ID) should come last

 * Last entry must be all 0s

 *

 * { Vendor ID, Device ID, SubVendor ID, SubDevice ID,

 *   Class, Class Mask, private data (not used) }

 required last entry */

 CONFIG_PCI_IOV */

	/* Get the negotiated link width and speed from PCI config space of the

	 * parent, as this device is behind a switch

 assume caller will handle error case */

/**

 * ixgbe_pcie_from_parent - Determine whether PCIe info should come from parent

 * @hw: hw specific details

 *

 * This function is used by probe to determine whether a device's PCI-Express

 * bandwidth details should be gathered from the parent bus instead of from the

 * device. Used to ensure that various locations all have the correct device ID

 * checks.

	/* Some devices are not connected over PCIe and thus do not negotiate

	 * speed. These devices do not have valid bus info, and thus any report

	 * we generate may not be correct.

 determine whether to use the parent device */

	/* Register read of 0xFFFFFFF can indicate the adapter has been removed,

	 * so perform several status register reads to determine if the adapter

	 * has been removed.

/**

 * ixgbe_read_reg - Read from device register

 * @hw: hw specific details

 * @reg: offset of register to read

 *

 * Returns : value read or IXGBE_FAILED_READ_REG if removed

 *

 * This function is used to read device registers. It checks for device

 * removal by confirming any read that returns all ones by checking the

 * status register value for all ones. This function avoids reading from

 * the hardware if a removal was previously detected in which case it

 * returns IXGBE_FAILED_READ_REG (all ones).

 CONFIG_PCI_IOV */

 flush memory to make sure state is correct before next watchdog */

 General Registers */

 Interrupt Registers */

 RX Registers */

 TX Registers */

 List Terminator */

/*

 * ixgbe_regdump - register printout routine

/*

 * ixgbe_dump - Print registers, tx-rings and rx-rings

 Print netdevice Info */

 Print Registers */

 Print TX Ring Summary */

 Print TX Rings */

	/* Transmit Descriptor Formats

	 *

	 * 82598 Advanced Transmit Descriptor

	 *   +--------------------------------------------------------------+

	 * 0 |         Buffer Address [63:0]                                |

	 *   +--------------------------------------------------------------+

	 * 8 |  PAYLEN  | POPTS  | IDX | STA | DCMD  |DTYP |  RSV |  DTALEN |

	 *   +--------------------------------------------------------------+

	 *   63       46 45    40 39 36 35 32 31   24 23 20 19              0

	 *

	 * 82598 Advanced Transmit Descriptor (Write-Back Format)

	 *   +--------------------------------------------------------------+

	 * 0 |                          RSV [63:0]                          |

	 *   +--------------------------------------------------------------+

	 * 8 |            RSV           |  STA  |          NXTSEQ           |

	 *   +--------------------------------------------------------------+

	 *   63                       36 35   32 31                         0

	 *

	 * 82599+ Advanced Transmit Descriptor

	 *   +--------------------------------------------------------------+

	 * 0 |         Buffer Address [63:0]                                |

	 *   +--------------------------------------------------------------+

	 * 8 |PAYLEN  |POPTS|CC|IDX  |STA  |DCMD  |DTYP |MAC  |RSV  |DTALEN |

	 *   +--------------------------------------------------------------+

	 *   63     46 45 40 39 38 36 35 32 31  24 23 20 19 18 17 16 15     0

	 *

	 * 82599+ Advanced Transmit Descriptor (Write-Back Format)

	 *   +--------------------------------------------------------------+

	 * 0 |                          RSV [63:0]                          |

	 *   +--------------------------------------------------------------+

	 * 8 |            RSV           |  STA  |           RSV             |

	 *   +--------------------------------------------------------------+

	 *   63                       36 35   32 31                         0

 Print RX Rings Summary */

 Print RX Rings */

	/* Receive Descriptor Formats

	 *

	 * 82598 Advanced Receive Descriptor (Read) Format

	 *    63                                           1        0

	 *    +-----------------------------------------------------+

	 *  0 |       Packet Buffer Address [63:1]           |A0/NSE|

	 *    +----------------------------------------------+------+

	 *  8 |       Header Buffer Address [63:1]           |  DD  |

	 *    +-----------------------------------------------------+

	 *

	 *

	 * 82598 Advanced Receive Descriptor (Write-Back) Format

	 *

	 *   63       48 47    32 31  30      21 20 16 15   4 3     0

	 *   +------------------------------------------------------+

	 * 0 |       RSS Hash /  |SPH| HDR_LEN  | RSV |Packet|  RSS |

	 *   | Packet   | IP     |   |          |     | Type | Type |

	 *   | Checksum | Ident  |   |          |     |      |      |

	 *   +------------------------------------------------------+

	 * 8 | VLAN Tag | Length | Extended Error | Extended Status |

	 *   +------------------------------------------------------+

	 *   63       48 47    32 31            20 19               0

	 *

	 * 82599+ Advanced Receive Descriptor (Read) Format

	 *    63                                           1        0

	 *    +-----------------------------------------------------+

	 *  0 |       Packet Buffer Address [63:1]           |A0/NSE|

	 *    +----------------------------------------------+------+

	 *  8 |       Header Buffer Address [63:1]           |  DD  |

	 *    +-----------------------------------------------------+

	 *

	 *

	 * 82599+ Advanced Receive Descriptor (Write-Back) Format

	 *

	 *   63       48 47    32 31  30      21 20 17 16   4 3     0

	 *   +------------------------------------------------------+

	 * 0 |RSS / Frag Checksum|SPH| HDR_LEN  |RSC- |Packet|  RSS |

	 *   |/ RTT / PCoE_PARAM |   |          | CNT | Type | Type |

	 *   |/ Flow Dir Flt ID  |   |          |     |      |      |

	 *   +------------------------------------------------------+

	 * 8 | VLAN Tag | Length |Extended Error| Xtnd Status/NEXTP |

	 *   +------------------------------------------------------+

	 *   63       48 47    32 31          20 19                 0

 Descriptor Done */

 Let firmware take over control of h/w */

 Let firmware know the driver has taken over */

/**

 * ixgbe_set_ivar - set the IVAR registers, mapping interrupt causes to vectors

 * @adapter: pointer to adapter struct

 * @direction: 0 for Rx, 1 for Tx, -1 for other causes

 * @queue: queue to map the corresponding interrupt to

 * @msix_vector: the vector to map to the corresponding queue

 *

 other causes */

 tx or rx causes */

 refill credits (no tx hang) if we received xoff */

 update stats for each tc, only valid with PFC enabled */

 Get the TC for given UP */

 disarm tx queues that have received xoff frames */

	/*

	 * Check for a hung queue, but be thorough. This verifies

	 * that a transmit has been completed since the previous

	 * check AND there is at least one packet pending. The

	 * ARMED bit is set to indicate a potential hang. The

	 * bit is cleared if a pause frame is received to remove

	 * false hang detection due to PFC or 802.3x frames. By

	 * requiring this to fail twice we avoid races with

	 * pfc clearing the ARMED bit and conditions where we

	 * run the check_tx_hang logic with a transmit completion

	 * pending but without time to complete it yet.

 make sure it is true for two checks in a row */

 update completed stats and continue */

 reset the countdown */

/**

 * ixgbe_tx_timeout_reset - initiate reset due to Tx timeout

 * @adapter: driver private struct

 Do the reset outside of interrupt context */

/**

 * ixgbe_tx_maxrate - callback to set the maximum per-queue bitrate

 * @netdev: network interface device structure

 * @queue_index: Tx queue to set

 * @maxrate: desired maximum transmit bitrate

 Calculate the rate factor values to set */

 clear everything but the rate factor */

 enable the rate scheduler */

/**

 * ixgbe_clean_tx_irq - Reclaim resources after transmit completes

 * @q_vector: structure containing interrupt and ring information

 * @tx_ring: tx ring to clean

 * @napi_budget: Used to determine if we are in netpoll

 if next_to_watch is not set then there is no work pending */

 prevent any other reads prior to eop_desc */

 if DD is not set pending work has not been completed */

 clear next_to_watch to prevent false hangs */

 update the statistics for this packet */

 free the skb */

 unmap skb header data */

 clear tx_buffer data */

 unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 issue prefetch for next Tx descriptor */

 update budget accounting */

 schedule immediate reset if we believe we hung */

 schedule immediate reset if we believe we hung */

 the adapter is about to reset, no point in enabling stuff */

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

 for unknown hardware do not write register */

	/*

	 * We can enable relaxed ordering for reads, but not writes when

	 * DCA is enabled.  This is due to a known issue in some chipsets

	 * which will cause the DCA tag to be cleared.

	/*

	 * We can enable relaxed ordering for reads, but not writes when

	 * DCA is enabled.  This is due to a known issue in some chipsets

	 * which will cause the DCA tag to be cleared.

 always use CB2 mode, difference is masked in the CB driver */

 if we're already enabled, don't do it again */

 DCA is disabled. */

 CONFIG_IXGBE_DCA */

/**

 * ixgbe_rx_is_fcoe - check the rx desc for incoming pkt type

 * @ring: structure containing ring specific data

 * @rx_desc: advanced rx descriptor

 *

 * Returns : true if it is FCoE pkt

 IXGBE_FCOE */

/**

 * ixgbe_rx_checksum - indicate in skb if hw indicated a good cksum

 * @ring: structure containing ring specific data

 * @rx_desc: current Rx descriptor being processed

 * @skb: skb currently being received and modified

 Rx csum disabled */

 check for VXLAN and Geneve packets */

 if IP and error */

		/*

		 * 82599 errata, UDP frames with a 0 checksum can be marked as

		 * checksum errors.

 It must be a TCP or UDP packet with a valid checksum */

 If we checked the outer header let the stack know */

 since we are recycling buffers we should seldom need to alloc */

 alloc new page for storage */

 map page for use */

	/*

	 * if mapping failed free memory back to system since

	 * there isn't much point in holding memory we can't use

/**

 * ixgbe_alloc_rx_buffers - Replace used receive buffers

 * @rx_ring: ring to place buffers on

 * @cleaned_count: number of buffers to replace

 nothing to do */

 sync the buffer for use by the device */

		/*

		 * Refresh the desc even if buffer_addrs didn't change

		 * because each write-back erases this info.

 clear the length for the next_to_use descriptor */

 update next to alloc since we have filled the ring */

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

 set gso_size to avoid messing up TCP MSS */

 if append_cnt is 0 then frame is not RSC */

 gso_size is computed using append_cnt so always clear it last */

/**

 * ixgbe_process_skb_fields - Populate skb header fields from Rx descriptor

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @rx_desc: pointer to the EOP Rx descriptor

 * @skb: pointer to current skb being populated

 *

 * This function checks the ring, descriptor, and packet information in

 * order to populate the hash, checksum, VLAN, timestamp, protocol, and

 * other fields within the skb.

 record Rx queue, or update MACVLAN statistics */

/**

 * ixgbe_is_non_eop - process handling of non-EOP buffers

 * @rx_ring: Rx ring being processed

 * @rx_desc: Rx descriptor for current buffer

 * @skb: Current socket buffer containing buffer in progress

 *

 * This function updates next to clean.  If the buffer is an EOP buffer

 * this function exits returning false, otherwise it will place the

 * sk_buff in the next buffer to be chained and return true indicating

 * that this is in fact a non-EOP buffer.

 fetch, update, and store next to clean */

 update RSC append count if present */

 update ntc based on RSC value */

 if we are the last buffer then there is nothing else to do */

 place skb in next buffer to be received */

/**

 * ixgbe_pull_tail - ixgbe specific version of skb_pull_tail

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @skb: pointer to current skb being adjusted

 *

 * This function is an ixgbe specific version of __pskb_pull_tail.  The

 * main difference between this version and the original function is that

 * this function can make several assumptions about the state of things

 * that allow for significant optimizations versus the standard function.

 * As a result we can do things like drop a frag and maintain an accurate

 * truesize for the skb.

	/*

	 * it is valid to use page_address instead of kmap since we are

	 * working with pages allocated out of the lomem pool per

	 * alloc_page(GFP_ATOMIC)

	/*

	 * we need the header to contain the greater of either ETH_HLEN or

	 * 60 bytes if the skb->len is less than 60 for skb_pad.

 align pull length to size of long to optimize memcpy performance */

 update all of the pointers */

/**

 * ixgbe_dma_sync_frag - perform DMA sync for first frag of SKB

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @skb: pointer to current skb being updated

 *

 * This function provides a basic DMA sync up for the first fragment of an

 * skb.  The reason for doing this is that the first fragment cannot be

 * unmapped until we have reached the end of packet descriptor for a buffer

 * chain.

 If the page was released, just unmap it. */

/**

 * ixgbe_cleanup_headers - Correct corrupted or empty headers

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @rx_desc: pointer to the EOP Rx descriptor

 * @skb: pointer to current skb being fixed

 *

 * Check if the skb is valid in the XDP case it will be an error pointer.

 * Return true in this case to abort processing and advance to next

 * descriptor.

 *

 * Check for corrupted packet headers caused by senders on the local L2

 * embedded NIC switch not setting up their Tx Descriptors right.  These

 * should be very rare.

 *

 * Also address the case where we are pulling data in on pages only

 * and as such no data is present in the skb header.

 *

 * In addition if skb is not at least 60 bytes we need to pad it so that

 * it is large enough to qualify as a valid Ethernet frame.

 *

 * Returns true if an error was encountered and skb was freed.

 XDP packets use error pointer so abort at this point */

	/* Verify netdev is present, and that packet does not have any

	 * errors that would be unacceptable to the netdev.

 place header in linear portion of buffer */

 do not attempt to pad FCoE Frames as this will disrupt DDP */

 if eth_skb_pad returns an error the skb was freed */

/**

 * ixgbe_reuse_rx_page - page flip buffer and store it back on the ring

 * @rx_ring: rx descriptor ring to store buffers on

 * @old_buff: donor buffer to have page reused

 *

 * Synchronizes page for reuse by the adapter

 update, and store next to alloc */

	/* Transfer page from old buffer to new buffer.

	 * Move each member individually to avoid possible store

	 * forwarding stalls and unnecessary copy of skb.

 avoid re-using remote and pfmemalloc pages */

 if we are only owner of page we can reuse it */

	/* The last offset is a bit aggressive in that we assume the

	 * worst case of FCoE being enabled and using a 3K buffer.

	 * However this should have minimal impact as the 1K extra is

	 * still less than one buffer in size.

	/* If we have drained the page fragment pool we need to update

	 * the pagecnt_bias and page count so that we fully restock the

	 * number of references the driver holds.

/**

 * ixgbe_add_rx_frag - Add contents of Rx buffer to sk_buff

 * @rx_ring: rx descriptor ring to transact packets on

 * @rx_buffer: buffer containing page to add

 * @skb: sk_buff to place the data into

 * @size: size of data in rx_buffer

 *

 * This function will add the data contained in rx_buffer->page to the skb.

 * This is done either through a direct copy if the data in the buffer is

 * less than the skb header size, otherwise it will just attach the page as

 * a frag to the skb.

 *

 * The function will then update the page offset if necessary and return

 * true if the buffer can be reused by the adapter.

	/* Delay unmapping of the first packet. It carries the header

	 * information, HW may still access the header after the writeback.

	 * Only unmap it when EOP is reached

 we are reusing so sync this buffer for CPU use */

 hand second half of page back to the ring */

 the page has been released from the ring */

 we are not reusing the buffer so unmap it */

 clear contents of rx_buffer */

 prefetch first cache line of first page */

	/* Note, we get here by enabling legacy-rx via:

	 *

	 *    ethtool --set-priv-flags <dev> legacy-rx on

	 *

	 * In this mode, we currently get 0 extra XDP headroom as

	 * opposed to having legacy-rx off, where we process XDP

	 * packets going to stack via ixgbe_build_skb(). The latter

	 * provides us currently with 192 bytes of headroom.

	 *

	 * For ixgbe_construct_skb() mode it means that the

	 * xdp->data_meta will always point to xdp->data, since

	 * the helper cannot expand the head. Should this ever

	 * change in future for legacy-rx mode on, then lets also

	 * add xdp->data_meta handling here.

 allocate a skb to store the frags */

	/* Prefetch first cache line of first page. If xdp->data_meta

	 * is unused, this points extactly as xdp->data, otherwise we

	 * likely have a consumer accessing first few bytes of meta

	 * data, and then actual data.

 build an skb to around the page buffer */

 update pointers within the skb to store the data */

 record DMA address if this is the start of a chain of buffers */

 update buffer offset */

 xdp_frame write */

 handle aborts by dropping packet */

 Must be power-of-2 */

/**

 * ixgbe_clean_rx_irq - Clean completed descriptors from Rx ring - bounce buf

 * @q_vector: structure containing interrupt and ring information

 * @rx_ring: rx descriptor ring to transact packets on

 * @budget: Total limit on number of packets to process

 *

 * This function provides a "bounce buffer" approach to Rx interrupt

 * processing.  The advantage to this is that on systems that have

 * expensive overhead for IOMMU access this provides a means of avoiding

 * it by maintaining the mapping of the page to the syste.

 *

 * Returns amount of work completed

 IXGBE_FCOE */

 Frame size depend on rx_ring setup when PAGE_SIZE=4K */

 return some buffers to hardware, one at a time is too slow */

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we know the

		 * descriptor has been written back

 retrieve a buffer from the ring */

 At larger PAGE_SIZE, frame_sz depend on len size */

 exit if we failed to retrieve a buffer */

 place incomplete frames back on ring for completion */

 verify the packet layout is correct */

 probably a little skewed due to removing CRC */

 populate checksum, timestamp, VLAN, and protocol */

 if ddp, not passing to ULD unless for FCP_RSP or error */

 include DDPed FCoE data */

 IXGBE_FCOE */

 update budget accounting */

/**

 * ixgbe_configure_msix - Configure MSI-X hardware

 * @adapter: board private structure

 *

 * ixgbe_configure_msix sets up the hardware to properly generate MSI-X

 * interrupts.

 Populate MSIX to EITR Select */

	/*

	 * Populate the IVAR table and set the ITR values to the

	 * corresponding register.

 set up to autoclear timer, and the vectors */

/**

 * ixgbe_update_itr - update the dynamic ITR value based on statistics

 * @q_vector: structure containing interrupt and ring information

 * @ring_container: structure containing ring performance data

 *

 *      Stores a new ITR value based on packets and byte

 *      counts during the last interrupt.  The advantage of per interrupt

 *      computation is faster updates and more accurate ITR for the current

 *      traffic pattern.  Constants in this function were computed

 *      based on theoretical maximum wire speed and thresholds were set based

 *      on testing data as well as attempting to minimize response time

 *      while increasing bulk throughput.

	/* If we don't have any rings just leave ourselves set for maximum

	 * possible latency so we take ourselves out of the equation.

	/* If we didn't update within up to 1 - 2 jiffies we can assume

	 * that either packets are coming in so slow there hasn't been

	 * any work, or that there is so much work that NAPI is dealing

	 * with interrupt moderation and we don't need to do anything.

	/* We have no packets to actually measure against. This means

	 * either one of the other queues on this vector is active or

	 * we are a Tx queue doing TSO with too high of an interrupt rate.

	 *

	 * When this occurs just tick up our delay by the minimum value

	 * and hope that this extra delay will prevent us from being called

	 * without any work on our queue.

	/* If packets are less than 4 or bytes are less than 9000 assume

	 * insufficient data to use bulk rate limiting approach. We are

	 * likely latency driven.

	/* Between 4 and 48 we can assume that our current interrupt delay

	 * is only slightly too low. As such we should increase it by a small

	 * fixed amount.

	/* Between 48 and 96 is our "goldilocks" zone where we are working

	 * out "just right". Just report that our current ITR is good for us.

	/* If packet count is 96 or greater we are likely looking at a slight

	 * overrun of the delay we want. Try halving our delay to see if that

	 * will cut the number of packets in half per interrupt.

	/* The paths below assume we are dealing with a bulk ITR since number

	 * of packets is 256 or greater. We are just going to have to compute

	 * a value and try to bring the count under control, though for smaller

	 * packet sizes there isn't much we can do as NAPI polling will likely

	 * be kicking in sooner rather than later.

	/* If packet counts are 256 or greater we can assume we have a gross

	 * overestimation of what the rate should be. Instead of trying to fine

	 * tune it just use the formula below to try and dial in an exact value

	 * give the current packet size of the frame.

	/* The following is a crude approximation of:

	 *  wmem_default / (size + overhead) = desired_pkts_per_int

	 *  rate / bits_per_byte / (size + ethernet overhead) = pkt_rate

	 *  (desired_pkt_rate / pkt_rate) * usecs_per_sec = ITR value

	 *

	 * Assuming wmem_default is 212992 and overhead is 640 bytes per

	 * packet, (256 skb, 64 headroom, 320 shared info), we can reduce the

	 * formula down to

	 *

	 *  (170 * (size + 24)) / (size + 640) = ITR

	 *

	 * We first do some math on the packet size and then finally bitshift

	 * by 8 after rounding up. We also have to account for PCIe link speed

	 * difference as ITR scales based on this.

 Start at 50k ints/sec */

 50K ints/sec to 16K ints/sec */

 16K ints/sec to 9.2K ints/sec */

 9.2K ints/sec to 8K ints/sec */

 plateau at a limit of 8K ints/sec */

	/* If we are in low latency mode half our delay which doubles the rate

	 * to somewhere between 100K to 16K ints/sec

	/* Resultant value is 256 times larger than it needs to be. This

	 * gives us room to adjust the value as needed to either increase

	 * or decrease the value based on link speeds of 10G, 2.5G, 1G, etc.

	 *

	 * Use addition as we have already recorded the new latency flag

	 * for the ITR value.

 write back value */

 next update should occur within next jiffy */

/**

 * ixgbe_write_eitr - write EITR register in hardware specific way

 * @q_vector: structure containing interrupt and ring information

 *

 * This function is made to be called by ethtool and by the driver

 * when it needs to update EITR registers at runtime.  Hardware

 * specific quirks/differences are taken care of here.

 must write high and low 16 bits to reset counter */

		/*

		 * set the WDIS bit to not clear the timer bits and cause an

		 * immediate assertion of the interrupt

 use the smallest value of new ITR delay calculations */

 Clear latency flag if set, shift into correct position */

 save the algorithm value here */

/**

 * ixgbe_check_overtemp_subtask - check for over temperature

 * @adapter: pointer to adapter

		/*

		 * Since the warning interrupt is for both ports

		 * we don't have to check if:

		 *  - This interrupt wasn't for our port.

		 *  - We may have missed the interrupt so always have to

		 *    check if we  got a LSC

 Check if this is not due to overtemp */

 write to clear the interrupt */

		/*

		 * Need to check link state so complete overtemp check

		 * on service task

 Later MAC's use different SDP */

 Clear the interrupt */

 Clear the interrupt */

 skip the flush */

/**

 * ixgbe_irq_enable - Enable default interrupt generation settings

 * @adapter: board private structure

 * @queues: enable irqs for queues

 * @flush: flush register write

 don't reenable LSC while waiting for link */

	/*

	 * Workaround for Silicon errata.  Use clear-by-write instead

	 * of clear-by-read.  Reading with EICS will return the

	 * interrupt causes without clearing, which later be done

	 * with the write to EICR.

	/* The lower 16bits of the EICR register are for the queue interrupts

	 * which should be masked here in order to not accidentally clear them if

	 * the bits are high when ixgbe_msix_other is called. There is a race

	 * condition otherwise which results in possible performance loss

	 * especially if the ixgbe_msix_other interrupt is triggering

	 * consistently (as it would when PPS is turned on for the X540 device)

 Handle Flow Director Full threshold interrupt */

 no more flow director interrupts until after init */

 re-enable the original interrupt state, no lsc, no queues */

 EIAM disabled interrupts (on this vector) for us */

/**

 * ixgbe_poll - NAPI Rx polling callback

 * @napi: structure for representing this polling device

 * @budget: how many packets driver is allowed to clean

 *

 * This function is used for legacy and MSI, NAPI mode

 Exit if we are called by netpoll */

	/* attempt to distribute budget to each queue fairly, but don't allow

 If all work not completed, return budget and keep polling */

 all work done, exit the polling mode */

/**

 * ixgbe_request_msix_irqs - Initialize MSI-X interrupts

 * @adapter: board private structure

 *

 * ixgbe_request_msix_irqs allocates MSI-X vectors and requests

 * interrupts from the kernel.

 skip this unused q_vector */

 If Flow Director is enabled, set interrupt affinity */

 assign the mask for this irq */

/**

 * ixgbe_intr - legacy mode Interrupt Handler

 * @irq: interrupt number

 * @data: pointer to a network interface device structure

	/*

	 * Workaround for silicon errata #26 on 82598.  Mask the interrupt

	 * before the read of EICR.

	/* for NAPI, using EIAM to auto-mask tx/rx interrupt bits on read

		/*

		 * shared interrupt alert!

		 * make sure interrupts are enabled because the read will

		 * have disabled interrupts due to EIAM

		 * finish the workaround of silicon errata on 82598.  Unmask

		 * the interrupt that we masked before the EICR read.

 Not our interrupt */

 would disable interrupts here but EIAM disabled it */

	/*

	 * re-enable link(maybe) and non-queue interrupts, no flush.

	 * ixgbe_poll will re-enable the queue interrupts

/**

 * ixgbe_request_irq - initialize interrupts

 * @adapter: board private structure

 *

 * Attempts to configure interrupts using the best available

 * capabilities of the hardware and kernel.

 free only the irqs that were actually requested */

 clear the affinity_mask in the IRQ descriptor */

/**

 * ixgbe_irq_disable - Mask off interrupt generation on the NIC

 * @adapter: board private structure

/**

 * ixgbe_configure_msi_and_legacy - Initialize PIN (INTA...) and MSI interrupts

 * @adapter: board private structure

 *

/**

 * ixgbe_configure_tx_ring - Configure 8259x Tx ring after Reset

 * @adapter: board private structure

 * @ring: structure containing ring specific data

 *

 * Configure the Tx descriptor ring after a reset.

 disable queue to avoid issues while updating state */

	/*

	 * set WTHRESH to encourage burst writeback, it should not be set

	 * higher than 1 when:

	 * - ITR is 0 as it could cause false TX hangs

	 * - ITR is set to > 100k int/sec and BQL is enabled

	 *

	 * In order to avoid issues WTHRESH + PTHRESH should always be equal

	 * to or less than the number of on chip descriptors, which is

	 * currently 40.

 WTHRESH = 1 */

 WTHRESH = 8 */

	/*

	 * Setting PTHRESH to 32 both improves performance

	 * and avoids a TX hang with DFP enabled

 HTHRESH = 1 */

 PTHRESH = 32 */

 reinitialize flowdirector state */

 initialize XPS */

 reinitialize tx_buffer_info */

 enable queue */

 TXDCTL.EN will return 0 on 82598 if link is down, so skip it */

 poll to verify queue is enabled */

 disable the arbiter while setting MTQC */

 set transmit pool layout */

 Enable Security TX Buffer IFG for multiple pb */

 re-enable the arbiter */

/**

 * ixgbe_configure_tx - Configure 8259x Transmit Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Tx unit of the MAC after a reset.

 DMATXCTL.EN must be before Tx queues are enabled */

 Setup the HW Tx Head and Tail descriptor pointers */

	/*

	 * We should set the drop enable bit if:

	 *  SR-IOV is enabled

	 *   or

	 *  Number of Rx queues > 1 and flow control is disabled

	 *

	 *  This allows us to avoid head of line blocking for security

	 *  and performance reasons.

		/*

		 * if VMDq is not active we must program one srrctl register

		 * per RSS queue since we have enabled RDRXCTL.MVMEN

 configure header buffer length, needed for RSC */

 configure the packet buffer length */

		/* If the MAC support setting RXDCTL.RLPML, the

		 * SRRCTL[n].BSIZEPKT is set to PAGE_SIZE and

		 * RXDCTL.RLPML is set to the actual UMEM buffer

		 * size. If not, then we are stuck with a 1k buffer

		 * size resolution. In this case frames larger than

		 * the UMEM buffer size viewed in a 1k resolution will

		 * be dropped.

 configure descriptor type */

/**

 * ixgbe_rss_indir_tbl_entries - Return RSS indirection table entries

 * @adapter: device handle

 *

 *  - 82598/82599/X540:     128

 *  - X550(non-SRIOV mode): 512

 *  - X550(SRIOV mode):     64

/**

 * ixgbe_store_key - Write the RSS key to HW

 * @adapter: device handle

 *

 * Write the RSS key stored in adapter.rss_key to HW.

/**

 * ixgbe_init_rss_key - Initialize adapter RSS key

 * @adapter: device handle

 *

 * Allocates and initializes the RSS key if it is not allocated.

/**

 * ixgbe_store_reta - Write the RETA table to HW

 * @adapter: device handle

 *

 * Write the RSS redirection table stored in adapter.rss_indir_tbl[] to HW.

	/* Fill out the redirection table as follows:

	 *  - 82598:      8 bit wide entries containing pair of 4 bit RSS

	 *    indices.

	 *  - 82599/X540: 8 bit wide entries containing 4 bit RSS index

	 *  - X550:       8 bit wide entries containing 6 bit RSS index

 Write redirection table to HW */

/**

 * ixgbe_store_vfreta - Write the RETA table to HW (x550 devices in SRIOV mode)

 * @adapter: device handle

 *

 * Write the RSS redirection table stored in adapter.rss_indir_tbl[] to HW.

 Write redirection table to HW */

	/* Program table for at least 4 queues w/ SR-IOV so that VFs can

	 * make full use of any rings they may have.  We will use the

	 * PSRTYPE register to control how many rings we use within the PF.

 Fill out hash function seeds */

 Fill out redirection table */

 Fill out hash function seeds */

 Fill out the redirection table */

 Disable indicating checksum in descriptor, enables RSS hash */

 8 TCs */

 4 TCs */

			/* Enable L3/L4 for Tx Switched packets only for X550,

			 * older devices do not support this feature

 Perform hash on these packet types */

 Enable VF RSS mode */

 Setup RSS through the VF registers */

/**

 * ixgbe_configure_rscctl - enable RSC for the indicated ring

 * @adapter: address of board private structure

 * @ring: structure containing ring specific data

	/*

	 * we must limit the number of descriptors so that the

	 * total size of max desc * buf_len is not greater

	 * than 65536

 RXDCTL.EN will return 0 on 82598 if link is down, so skip it */

 disable queue to avoid use of these values while updating state */

 write value back with RXDCTL.ENABLE bit cleared */

 Force flushing of IXGBE_RDLEN to prevent MDD */

		/*

		 * enable cache line friendly hardware writes:

		 * PTHRESH=32 descriptors (half the internal cache),

		 * this also removes ugly rx_no_buffer_count increment

		 * HTHRESH=4 descriptors (to minimize latency on fetch)

		 * WTHRESH=8 burst writeback up to two cache lines

 RXDCTL.RLPML does not work on 82599 */

		/* Limit the maximum frame size so we don't overrun the skb.

		 * This can happen in SRIOV mode when the MTU of the VF is

		 * higher than the MTU of the PF.

 initialize rx_buffer_info */

 initialize Rx descriptor 0 */

 enable receive descriptor ring */

 PSRTYPE must be initialized in non 82598 adapters */

	/* accept untagged packets until a vlan tag is

	 * specifically set for the VMDQ queue/pool

 Enable only the PF's pool for Tx/Rx */

 Map PF MAC address in RAR Entry 0 to first pool following VFs */

 clear VLAN promisc flag so VFTA will be updated if necessary */

	/*

	 * Set up VF register offsets for selected VT Mode,

	 * i.e. 32 or 64 VFs for SR-IOV

 configure spoof checking */

 Enable/Disable RSS query feature  */

 adjust max frame to be able to do baby jumbo for FCoE */

 IXGBE_FCOE */

 adjust max frame to be at least the size of a standard frame */

 set jumbo enable since MHADD.MFS is keeping size locked at max_frame */

	/*

	 * Setup the HW Rx Head and Tail Descriptor Pointers and

	 * the Base and Length of the Rx Descriptor Ring

		/*

		 * For VMDq support of different descriptor types or

		 * buffer sizes through the use of multiple SRRCTL

		 * registers, RDRXCTL.MVMEN must be set to 1

		 *

		 * also, the manual doesn't mention it clearly but DCA hints

		 * will only use queue 0's tags unless this bit is set.  Side

		 * effects of setting this bit are only that SRRCTL must be

		 * fully programmed [0..15]

 Disable RSC for ACK packets */

 hardware requires some bits to be set by default */

 We should do nothing since we don't know this hardware */

/**

 * ixgbe_configure_rx - Configure 8259x Receive Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Rx unit of the MAC after a reset.

 disable receives while setting up the descriptors */

 RSC Setup */

 disable NFS filtering */

 Program registers for the distribution of queues */

 set_rx_buffer_len must be called before ring initialization */

	/*

	 * Setup the HW Rx Head and Tail Descriptor Pointers and

	 * the Base and Length of the Rx Descriptor Ring

 disable drop enable for 82598 parts */

 enable all receives */

 add VID to filter table */

 short cut the special case */

 Search for the vlan id in the VLVF entries */

	/* See if any other pools are set for this VLAN filter

	 * entry other than the PF.

 Disable the filter so this falls into the default pool. */

 remove VID from filter table */

/**

 * ixgbe_vlan_strip_disable - helper to disable hw vlan stripping

 * @adapter: driver data

/**

 * ixgbe_vlan_strip_enable - helper to enable hw vlan stripping

 * @adapter: driver data

 For VMDq and SR-IOV we must leave VLAN filtering enabled */

 Nothing to do for 82598 */

 We are already in VLAN promisc, nothing to do */

 Set flag so we don't redo unnecessary work */

 Add PF to all active pools */

 Set all bits in the VLAN filter table array */

 pull VLAN ID from VLVF */

 only concern outselves with a certain range */

 record VLAN ID in VFTA */

 if PF is part of this then continue */

 remove PF from the pool */

 extract values from active_vlans and write back to VFTA */

 Set VLAN filtering to enabled */

 We are not in VLAN promisc, nothing to do */

 Set flag so we don't redo unnecessary work */

/**

 * ixgbe_write_mc_addr_list - write multicast addresses to MTA

 * @netdev: network interface device structure

 *

 * Writes multicast address list to the MTA hash table.

 * Returns: -ENOMEM on failure

 *                0 on no addresses written

 *                X on writing X addresses to MTA

 do not count default RAR as available */

 only count unused and addresses that belong to us */

 this function destroys the first RAR entry */

 search table for addr, if found clear IN_USE flag and sync */

 we can only delete an entry if it is in use */

 we only care about entries that belong to the given pool */

 we only care about a specific MAC address */

/**

 * ixgbe_set_rx_mode - Unicast, Multicast and Promiscuous mode set

 * @netdev: network interface device structure

 *

 * The set_rx_method entry point is called whenever the unicast/multicast

 * address list or the network interface flags are updated.  This routine is

 * responsible for configuring the hardware for proper unicast, multicast and

 * promiscuous mode.

 Check for Promiscuous and All Multicast modes */

 set all bits that we expect to always be set */

 disable store-bad-packets */

 discard pause frames when FC enabled */

 clear the bits we are changing the status of */

	/*

	 * Write addresses to available RAR registers, if there is not

	 * sufficient space to store all the addresses then enable

	 * unicast promiscuous mode

	/* Write addresses to the MTA, if the attempt fails

	 * then we should just turn on promiscuous mode so

	 * that we can at least receive multicast traffic

 This is useful for sniffing bad packets. */

		/* UPE and MPE will be handled by normal PROMISC logic

 Receive bad packets */

 RX All Bcast Pkts */

 RX All MAC Ctrl Pkts */

 NOTE:  VLAN filtering is disabled by setting PROMISC */

/**

 * ixgbe_configure_dcb - Configure DCB hardware

 * @adapter: ixgbe adapter struct

 *

 * This is called by the driver on open to configure the DCB hardware.

 * This is also called by the gennetlink interface when reconfiguring

 * the DCB state.

 reconfigure the hardware */

 Enable RSS Hash per TC */

 write msb to all 8 TCs in one write */

 Additional bittime to account for IXGBE framing */

/**

 * ixgbe_hpbthresh - calculate high water mark for flow control

 *

 * @adapter: board private structure to calculate for

 * @pb: packet buffer to calculate

 Calculate max LAN frame size */

 FCoE traffic class uses FCOE jumbo frames */

 Calculate delay value for device */

 Loopback switch introduces additional latency */

 Delay value is calculated in bit times convert to KB */

	/* It is possible that the packet buffer is not large enough

	 * to provide required headroom. In this case throw an error

	 * to user and a do the best we can.

/**

 * ixgbe_lpbthresh - calculate low water mark for for flow control

 *

 * @adapter: board private structure to calculate for

 * @pb: packet buffer to calculate

 Calculate max LAN frame size */

 FCoE traffic class uses FCOE jumbo frames */

 Calculate delay value for device */

 Delay value is calculated in bit times convert to KB */

/*

 * ixgbe_pbthresh_setup - calculate and setup high low water marks

 Low water marks must not be larger than high water marks */

 Map the ring onto the absolute queue index */

/**

 * ixgbe_clean_rx_ring - Free Rx Buffers per Queue

 * @rx_ring: ring to free buffers from

 Free all the Rx ring sk_buffs */

		/* Invalidate cache lines that may have been written to by

		 * device so that we avoid corrupting memory.

 free resources associated with mapping */

 record configuration for macvlan interface in vdev */

	/* Guarantee all rings are updated before we update the

	 * MAC address filter.

	/* ixgbe_add_mac_filter will return an index if it succeeds, so we

	 * need to only treat it as an error value if it is negative.

 if we cannot add the MAC rule then disable the offload */

 unbind the queues and drop the subordinate channel config */

	/*

	 * We must restore virtualization before VLANs or else

	 * the VLVF registers will not be populated

 configure DCA */

 CONFIG_IXGBE_DCA */

 configure FCoE L2 filters, redirection table, and Rx control */

 IXGBE_FCOE */

/**

 * ixgbe_sfp_link_config - set up SFP+ link

 * @adapter: pointer to private adapter struct

	/*

	 * We are assuming the worst case scenario here, and that

	 * is that an SFP was inserted/removed after the reset

	 * but before SFP detection was enabled.  As such the best

	 * solution is to just start searching as soon as we start

/**

 * ixgbe_non_sfp_link_config - set up non-SFP+ link

 * @hw: pointer to private hardware struct

 *

 * Returns 0 on success, negative on failure

		/*

		 * use EIAM to auto-mask when MSI-X interrupt is asserted

		 * this saves a register write for every interrupt

		/* legacy interrupts, use EIAM to auto-mask when reading EICR,

 XXX: to interrupt immediately for EICS writes, enable this */

 gpie |= IXGBE_GPIE_EIMEN; */

 Enable Thermal over heat sensor interrupt */

 Enable fan failure interrupt */

 enable the optics for 82599 SFP+ fiber */

 clear any pending interrupts, may auto mask */

	/*

	 * If this adapter has a fan, check to see if we had a failure

	 * before we enabled the interrupt.

	/* bring the link up in the watchdog, this could race with our first

 Set PF Reset Done bit so PF/VF Mail Ops can work */

 put off any impending NetWatchDogTimeout */

	/*

	 * If SR-IOV enabled then wait a bit before bringing the adapter

	 * back up to give the VFs time to respond to the reset.  The

	 * two second wait is based upon the watchdog timer cycle in

	 * the VF driver.

 hardware has been reset, we need to reload some things */

		/* For now we cap the upper limit on delay to 2 seconds

		 * as we end up going up to 34 seconds of delay in worst

		 * case timeout value.

 2.0 s */

 520 ms */

 130 ms */

 32 ms */

 2 ms */

 100 us */

 32 ms */

	/* We shouldn't need to hit this path, but just in case default as

	 * though completion timeout is not supported and support 32ms.

 disable receives */

 disable all enabled Rx queues */

 write value back with RXDCTL.ENABLE bit cleared */

 RXDCTL.EN may not change on 82598 if link is down, so skip it */

	/* Determine our minimum delay interval. We will increase this value

	 * with each subsequent test. This way if the device returns quickly

	 * we should spend as little time as possible waiting, however as

	 * the time increases we will wait for larger periods of time.

	 *

	 * The trick here is that we increase the interval using the

	 * following pattern: 1x 3x 5x 7x 9x 11x 13x 15x 17x 19x. The result

	 * of that wait is that it totals up to 100x whatever interval we

	 * choose. Since our minimum wait is 100us we can just divide the

	 * total timeout by 100 to get our minimum delay interval.

		/* OR together the reading of all the active RXDCTL registers,

		 * and then test the result. We need the disable to complete

		 * before we start freeing the memory and invalidating the

		 * DMA mappings.

 disable all enabled Tx queues */

 disable all enabled XDP Tx queues */

	/* If the link is not up there shouldn't be much in the way of

	 * pending transactions. Those that are left will be flushed out

	 * when the reset logic goes through the flush sequence to clean out

	 * the pending Tx transactions.

	/* Determine our minimum delay interval. We will increase this value

	 * with each subsequent test. This way if the device returns quickly

	 * we should spend as little time as possible waiting, however as

	 * the time increases we will wait for larger periods of time.

	 *

	 * The trick here is that we increase the interval using the

	 * following pattern: 1x 3x 5x 7x 9x 11x 13x 15x 17x 19x. The result

	 * of that wait is that it totals up to 100x whatever interval we

	 * choose. Since our minimum wait is 100us we can just divide the

	 * total timeout by 100 to get our minimum delay interval.

		/* OR together the reading of all the active TXDCTL registers,

		 * and then test the result. We need the disable to complete

		 * before we start freeing the memory and invalidating the

		 * DMA mappings.

 Disable the Tx DMA engine on 82599 and later MAC */

 lock SFP init bit to prevent race conditions with the watchdog */

 clear all SFP and link config related flags while holding SFP_INIT */

 We are running on a pre-production device, log a warning */

 flush entries out of MAC table */

 do not flush user set addresses */

 update SAN MAC vmdq pool selection */

/**

 * ixgbe_clean_tx_ring - Free Tx Buffers

 * @tx_ring: ring to be cleaned

 Free all the Tx ring sk_buffs */

 unmap skb header data */

 check for eop_desc to determine the end of the packet */

 unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 reset BQL for queue */

 reset next_to_use and next_to_clean */

/**

 * ixgbe_clean_all_rx_rings - Free Rx Buffers for all queues

 * @adapter: board private structure

/**

 * ixgbe_clean_all_tx_rings - Free Tx Buffers for all queues

 * @adapter: board private structure

 signal that we are down to the interrupt handler */

 do nothing if already down */

 Shut off incoming Tx traffic */

 call carrier off first to avoid false dev_watchdog timeouts */

 Disable Rx */

 synchronize_rcu() needed for pending XDP buffers to drain */

 Clear EITR Select mapping */

 Mark all the VFs as inactive */

 ping all the active vfs to let them know we are going down */

 Disable all VFTE/VFRE TX/RX */

 disable transmits in the hardware now that interrupts are off */

 power down the optics for 82599 SFP+ fiber */

/**

 * ixgbe_set_eee_capable - helper function to determine EEE support on X550

 * @adapter: board private structure

/**

 * ixgbe_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: queue number that timed out

 Do the reset outside of interrupt context */

 Configure DCB traffic classes */

 Initialize default user to priority mapping, UPx->TC0 */

/**

 * ixgbe_sw_init - Initialize general software structures (struct ixgbe_adapter)

 * @adapter: board private structure to initialize

 * @ii: pointer to ixgbe_info for device

 *

 * ixgbe_sw_init initializes the Adapter private data structure.

 * Fields are initialized based on PCI device information and

 * OS network device settings (MTU size).

 PCI config space info */

 get_invariants needs the device IDs */

 Set common capability flags and settings */

 Default traffic class to use for FCoE */

 CONFIG_IXGBE_DCB */

 IXGBE_FCOE */

 initialize static ixgbe jump table entries */

 Set MAC specific capability flags and exceptions */

 IXGBE_DCB */

 IXGBE_FCOE */

 IXGBE_DCB */

 IXGBE_FCOE */

 FCoE support exists, always init the FCoE lock */

 n-tuple support exists, always init our spinlock */

 default flow control settings */

 init for ethtool output */

 assign number of SR-IOV VFs */

 CONFIG_PCI_IOV */

 enable itr by default in dynamic mode */

 set default ring sizes */

 set default work limits */

 initialize eeprom parameters */

 PF holds first pool slot */

/**

 * ixgbe_setup_tx_resources - allocate Tx resources (Descriptors)

 * @tx_ring:    tx descriptor ring (for a specific queue) to setup

 *

 * Return 0 on success, negative on failure

 round up to nearest 4K */

/**

 * ixgbe_setup_all_tx_resources - allocate all queues Tx resources

 * @adapter: board private structure

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

 rewind the index freeing the rings as we go */

/**

 * ixgbe_setup_rx_resources - allocate Rx resources (Descriptors)

 * @adapter: pointer to ixgbe_adapter

 * @rx_ring:    rx descriptor ring (for a specific queue) to setup

 *

 * Returns 0 on success, negative on failure

 Round up to nearest 4K */

 XDP RX-queue info */

/**

 * ixgbe_setup_all_rx_resources - allocate all queues Rx resources

 * @adapter: board private structure

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

 rewind the index freeing the rings as we go */

/**

 * ixgbe_free_tx_resources - Free Tx Resources per Queue

 * @tx_ring: Tx descriptor ring for a specific queue

 *

 * Free all transmit software resources

 if not set, then don't free */

/**

 * ixgbe_free_all_tx_resources - Free Tx Resources for All Queues

 * @adapter: board private structure

 *

 * Free all transmit software resources

/**

 * ixgbe_free_rx_resources - Free Rx Resources

 * @rx_ring: ring to clean the resources from

 *

 * Free all receive software resources

 if not set, then don't free */

/**

 * ixgbe_free_all_rx_resources - Free Rx Resources for All Queues

 * @adapter: board private structure

 *

 * Free all receive software resources

/**

 * ixgbe_change_mtu - Change the Maximum Transfer Unit

 * @netdev: network interface device structure

 * @new_mtu: new value for maximum frame size

 *

 * Returns 0 on success, negative on failure

	/*

	 * For 82599EB we cannot allow legacy VFs to enable their receive

	 * paths when MTU greater than 1500 is configured.  So display a

	 * warning that legacy VFs will be disabled.

 must set new MTU before calling down or up */

/**

 * ixgbe_open - Called when a network interface is made active

 * @netdev: network interface device structure

 *

 * Returns 0 on success, negative value on failure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP).  At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the watchdog timer is started,

 * and the stack is notified that the interface is ready.

 disallow open during test */

 allocate transmit descriptors */

 allocate receive descriptors */

 Notify the stack of the actual queue counts. */

/**

 * ixgbe_close - Disables a network interface

 * @netdev: network interface device structure

 *

 * Returns 0, this is not allowed to fail

 *

 * The close entry point is called when an interface is de-activated

 * by the OS.  The hardware is still under the drivers control, but

 * needs to be disabled.  A global MAC reset is issued to stop the

 * hardware, and all transmit and receive resources are freed.

 enable the optics for 82599 SFP+ fiber as we can WoL */

 enable the reception of multicast packets */

/**

 * ixgbe_update_stats - Update the board statistics counters.

 * @adapter: board private structure

 gather some stats to the adapter struct that are per queue */

 8 register reads */

 for packet buffers not used, the register should read 0 */

16 register reads */

 to clear */

 to clear */

 work around hardware counting issue */

 82598 hardware only has a 32 bit counter in the high register */

 OS2BMC stats are X540 and later */

 to clear */

 to clear */

 to clear */

 Add up per cpu counters for total ddp aloc fail */

 IXGBE_FCOE */

	/*

	 * 82598 errata - tx of flow control packets is included in tx counters

 Fill out the OS statistics structure */

 Rx Errors */

/**

 * ixgbe_fdir_reinit_subtask - worker thread to reinit FDIR filter table

 * @adapter: pointer to the device adapter structure

 if interface is down do nothing */

 do nothing if we are not using signature filters */

 re-enable flow director interrupts */

/**

 * ixgbe_check_hang_subtask - check for hung queues and dropped interrupts

 * @adapter: pointer to the device adapter structure

 *

 * This function serves two purposes.  First it strobes the interrupt lines

 * in order to make certain interrupts are occurring.  Secondly it sets the

 * bits needed to check for TX hangs.  As a result we should immediately

 * determine if a hang has occurred.

 If we're down, removing or resetting, just bail */

 Force detection of hung controller */

		/*

		 * for legacy and MSI interrupts don't set any bits

		 * that are enabled for EIAM, because this operation

		 * would set *both* EIMS and EICS for any bit in EIAM

 get one bit for every active tx/rx interrupt vector */

 Cause software interrupt to ensure rings are cleaned */

/**

 * ixgbe_watchdog_update_link - update the link status

 * @adapter: pointer to the device adapter structure

 always assume link is up, if no check link function */

/**

 * ixgbe_watchdog_link_is_up - update netif_carrier status and

 *                             print link up message

 * @adapter: pointer to the device adapter structure

 only continue if link was previously down */

 enable transmits */

 update the default user priority for VFs */

 ping all the active vfs to let them know link has changed */

/**

 * ixgbe_watchdog_link_is_down - update netif_carrier status and

 *                               print link down message

 * @adapter: pointer to the adapter structure

 only continue if link was up previously */

 poll for SFP+ cable when link is down */

 ping all the active vfs to let them know link has changed */

 resetting the PF is only needed for MAC before X550 */

/**

 * ixgbe_watchdog_flush_tx - flush queues on link down

 * @adapter: pointer to the device adapter structure

			/* We've lost link, so the controller stops DMA,

			 * but we've got queued Tx work that's never going

			 * to get done, so reset controller to flush Tx.

			 * (Do the reset outside of interrupt context).

 If incrementing then no need for the check below */

	/* Check to see if a bad DMA write target from an errant or

	 * malicious VF has caused a PCIe error.  If so then we can

	 * issue a VFLR to the offending VF(s) and then resume without

	 * requesting a full slot reset.

 check status reg for all VFs owned by this PF */

 Do not perform spoof check for 82598 or if not in IOV mode */

	/*

	 * ssvpc register is cleared on read, if zero then no

	 * spoofed packets in the last interval.

 CONFIG_PCI_IOV */

/**

 * ixgbe_watchdog_subtask - check and bring link up

 * @adapter: pointer to the device adapter structure

 if interface is down, removing or resetting, do nothing */

/**

 * ixgbe_sfp_detection_subtask - poll for SFP+ cable

 * @adapter: the ixgbe adapter structure

 not searching for SFP so there is nothing to do here */

 If not yet time to poll for SFP */

 someone else is in init, wait until next service event */

		/* If no cable is present, then we need to reset

 exit on error */

 exit if reset not needed */

	/*

	 * A module may be identified correctly, but the EEPROM may not have

	 * support for that module.  setup_sfp() will fail in that case, so

	 * we should not allow that module to load.

/**

 * ixgbe_sfp_link_config_subtask - set up link SFP after module install

 * @adapter: the ixgbe adapter structure

 someone else is in init, wait until next service event */

 advertise highest capable link speed */

/**

 * ixgbe_service_timer - Timer Call-back

 * @t: pointer to timer_list structure

 poll faster when waiting for link */

 Reset the timer */

 If we're already down, removing or resetting, just bail */

/**

 * ixgbe_check_fw_error - Check firmware for errors

 * @adapter: the adapter private structure

 *

 * Check firmware errors in register FWSM

 read fwsm.ext_err_ind register and log errors */

/**

 * ixgbe_service_task - manages and runs subtasks

 * @work: pointer to work_struct containing our data

 ADV DTYP TUCMD MKRLOC/ISCSIHEDLEN */

 initialize outer IP header fields */

		/* IP header will have to cancel out any data that

		 * is not a part of the outer IP header, so set to

		 * a reverse csum if needed, else init check to 0.

 determine offset of inner transport header */

 remove payload length from inner checksum */

 compute length of segmentation header */

 compute length of segmentation header */

 update gso size and bytecount with header size */

 mss_l4len_id: use 0 as index for TSO */

 vlan_macip_lens: HEADLEN, MACLEN, VLAN tag */

 validate that this is actually an SCTP request */

 update TX checksum flag */

 vlan_macip_lens: MACLEN, VLAN tag */

 set type for advanced descriptor with frame checksum insertion */

 set HW vlan bit if vlan is present */

 set segmentation enable bits for TSO/FSO */

 set timestamp bit if present */

 insert frame checksum */

 enable L4 checksum for TSO and TX checksum offload */

 enable IPv4 checksum for TSO */

 enable IPsec */

	/*

	 * Check Context must be set if Tx switch is enabled, which it

	 * always is for case where virtual functions are running

	/* Herbert's original patch had:

	 *  smp_mb__after_netif_stop_queue();

	 * but since that doesn't exist yet, just open code it.

	/* We need to check again in a case another CPU has just

	 * made room available.

 A reprieve! - use start_queue because it doesn't call schedule */

 record length, and DMA address */

 write last descriptor with RS and EOP bits */

 set the timestamp */

	/*

	 * Force memory writes to complete before letting h/w know there

	 * are new descriptors to fetch.  (Only applicable for weak-ordered

	 * memory model archs, such as IA-64).

	 *

	 * We also need this memory barrier to make certain all of the

	 * status bits have been updated before next_to_watch is written.

 set next_to_watch value indicating a packet is present */

 clear dma mappings for failed tx_buffer_info map */

 if ring doesn't have a interrupt vector, cannot perform ATR */

 do nothing if sampling is disabled */

 currently only IPv4/IPv6 with TCP is supported */

 snag network header to get L4 type and address */

 verify the port is recognized as VXLAN */

	/* Make sure we have at least [minimum IPv4 header + TCP]

	 * or [IPv6 header] bytes

 Currently only IPv4/IPv6 with TCP is supported */

 access ihl as u8 to avoid unaligned access on ia64 */

 skip this packet since the socket is closing */

 sample on all syn packets or once every atr sample count */

 reset sample count */

	/*

	 * src and dst are inverted, think how the receiver sees them

	 *

	 * The input is broken into two sections, a non-compressed section

	 * containing vm_pool, vlan_id, and flow_type.  The rest of the data

	 * is XORed together and stored in the compressed dword.

	/*

	 * since src port and flex bytes occupy the same word XOR them together

	 * and write the value to source port portion of compressed dword

 This assumes the Rx queue and Tx queue are bound to the same CPU */

	/*

	 * only execute the code below if protocol is FCoE

	 * or FIP and we have FCoE enabled on the adapter

 record the location of the first descriptor for this packet */

 put descriptor type bits */

 Avoid any potential race with xdp_xmit and cleanup */

 set next_to_watch value indicating a packet is present */

	/*

	 * need: 1 descriptor per page * PAGE_SIZE/IXGBE_MAX_DATA_PER_TXD,

	 *       + 1 desc for skb_headlen/IXGBE_MAX_DATA_PER_TXD,

	 *       + 2 desc gap to keep tail from touching head,

	 *       + 1 desc for context descriptor,

	 * otherwise try next time

 record the location of the first descriptor for this packet */

 if we have a HW VLAN tag being added default to the HW one */

 else if it is a SW VLAN check the next protocol and store the tag */

 schedule check for Tx timestamp */

	/*

	 * Use the l2switch_enable flag - would be false if the DMA

	 * Tx switch had been disabled.

 DCB maps skb priorities 0-7 onto 3 bit PCP of VLAN tag. */

 record initial flags and protocol */

 setup tx offload for FCoE */

 IXGBE_FCOE */

 add the ATR filter if ATR is on */

 IXGBE_FCOE */

	/*

	 * The minimum packet size for olinfo paylen is 17 so pad the skb

	 * in order to meet this minimum size requirement.

/**

 * ixgbe_set_mac - Change the Ethernet Address of the NIC

 * @netdev: network interface device structure

 * @p: pointer to an address structure

 *

 * Returns 0 on success, negative on failure

/**

 * ixgbe_add_sanmac_netdev - Add the SAN MAC address to the corresponding

 * netdev->dev_addrs

 * @dev: network interface device structure

 *

 * Returns non-zero on failure

 update SAN MAC vmdq pool selection */

/**

 * ixgbe_del_sanmac_netdev - Removes the SAN MAC address to the corresponding

 * netdev->dev_addrs

 * @dev: network interface device structure

 *

 * Returns non-zero on failure

 following stats updated by ixgbe_watchdog_task() */

/**

 * ixgbe_validate_rtr - verify 802.1Qp to Rx packet buffer mapping is valid.

 * @adapter: pointer to ixgbe_adapter

 * @tc: number of traffic classes currently enabled

 *

 * Configure a valid 802.1Qp to Rx packet buffer mapping ie confirm

 * 802.1Q priority maps to a packet buffer that exists.

	/* 82598 have a static priority to TC mapping that can not

	 * be changed so no validation is needed.

 If up2tc is out of bounds default to zero */

/**

 * ixgbe_set_prio_tc_map - Configure netdev prio tc map

 * @adapter: Pointer to adapter struct

 *

 * Populate the netdev user priority to tc map

 CONFIG_IXGBE_DCB */

 we only care about macvlans... */

 that have hardware offload enabled... */

 If we can relocate to a different bit do so */

 if we cannot find a free pool then disable the offload */

 unbind the queues and drop the subordinate channel config */

 flush any stale bits out of the fwd bitmask */

 walk through upper devices reassigning pools */

/**

 * ixgbe_setup_tc - configure net_device for multiple traffic classes

 *

 * @dev: net device to configure

 * @tc: number of traffic classes to enable

 Hardware supports up to 8 traffic classes */

	/* Hardware has to reinitialize queues and interrupts to

	 * match packet buffer alignment. Unfortunately, the

	 * hardware is not flexible enough to do this dynamically.

 CONFIG_IXGBE_DCB */

 Clear this filter in the link data it is associated with */

 Check if the filter being deleted is a link */

			/* Delete filters in the hardware in the child hash

			 * table associated with this link

 Remove resources for this link */

	/* This ixgbe devices do not support hash tables at the moment

	 * so abort when given hash tables.

 redirect to a SRIOV VF */

 redirect to a offloaded macvlan netdev */

 Drop action */

 Redirect to a VF or a offloaded macvlan */

 CONFIG_NET_CLS_ACT */

	/* At the moment cls_u32 jumps to network layer and skips past

	 * L2 headers. The canonical method to match L2 frames is to use

	 * negative values. However this is error prone at best but really

	 * just broken because there is no way to "know" what sort of hdr

	 * is in front of the network layer. Fix cls_u32 to support L2

	 * headers when needed.

	/* cls u32 is a graph starting at root node 0x800. The driver tracks

	 * links and also the fields used to advance the parser across each

	 * link (e.g. nexthdr/eat parameters from 'tc'). This way we can map

	 * the u32 graph onto the hardware parse graph denoted in ixgbe_model.h

	 * To add support for new nodes update ixgbe_model.h parse structures

	 * this function _should_ be generic try not to hardcode values here.

	/* At this point we know the field_ptr is valid and need to either

	 * build cls_u32 link or attach filter. Because adding a link to

	 * a handle that does not exist is invalid and the same for adding

	 * rules to handles that don't exist.

		/* Multiple filters as links to the same hash table are not

		 * supported. To add a new filter with the same next header

		 * but different match/jump conditions, create a new hash table

		 * and link to it.

		/* Lookup in all child hash tables if this location is already

		 * filled with a filter

 If Rx checksum is disabled, then RSC/LRO should also be disabled */

 Turn off LRO if not RSC capable */

 go back to full RSS if we're not running SR-IOV */

 Make sure RSC matches LRO, reset if change */

	/*

	 * Check if Flow Director n-tuple support or hw_tc support was

	 * enabled or disabled.  If the state changed, we need to reset.

 turn off ATR, enable perfect filters and reset */

 turn off perfect filters, enable ATR and reset */

 We cannot enable ATR if SR-IOV is enabled */

 We cannot enable ATR if we have 2 or more tcs */

 We cannot enable ATR if RSS is disabled */

 A sample rate of 0 indicates ATR disabled */

 do nothing not supported */

 otherwise supported and set the flag */

 guarantee we can provide a unique filter for the unicast address */

/**

 * ixgbe_configure_bridge_mode - set various bridge modes

 * @adapter: the private structure

 * @mode: requested bridge mode

 *

 * Configure some settings require for various bridge modes.

 disable Tx loopback, rely on switch hairpin mode */

		/* must enable Rx switching replication to allow multicast

		 * packet reception on all VFs, and to enable source address

		 * pruning.

		/* enable Rx source address pruning. Note, this requires

		 * replication to be enabled or else it does nothing.

 enable Tx loopback for internal VF/PF communication */

		/* disable Rx switching replication unless we have SR-IOV

		 * virtual functions

		/* disable Rx source address pruning, since we don't expect to

		 * be receiving external loopback of our transmitted frames.

	/* The hardware supported by ixgbe only filters on the destination MAC

	 * address. In order to avoid issues we only support offloading modes

	 * where the hardware can actually provide the functionality.

	/* We need to lock down the macvlan to be a single queue device so that

	 * we can reuse the tc_to_txq field in the macvlan netdev to represent

	 * the queue mapping to our netdev.

		/* Hardware has a limited number of available pools. Each VF,

		 * and the PF require a pool. Check to ensure we don't

		 * attempt to use more then the available number of pools.

 Enable VMDq flag so device will be set in VM mode */

		/* Try to reserve as many queues per pool as possible,

		 * we start with the configurations that support 4 queues

		 * per pools, followed by 2, and then by just 1 per pool.

 Force reinit of ring allocation with VMDQ enabled */

 delete unicast filter associated with offloaded interface */

	/* Allow remaining Rx packets to get flushed out of the

	 * Rx FIFO before we drop the netdev for the ring.

		/* Make sure we aren't processing any packets and clear

		 * netdev to shut down the ring.

 unbind the queues and drop the subordinate channel config */

 Make certain the headers can be described by a context descriptor */

	/* We can only support IPV4 TSO in tunnels if we can mangle the

	 * inner IP ID field, so strip TSO if MANGLEID is not supported.

	 * IPsec offoad sets skb->encapsulation but still can handle

	 * the TSO, so it's the exception.

 verify ixgbe ring attributes are sufficient for XDP */

	/* if the number of cpus is much larger than the maximum of queues,

	 * we should stop it and then return with ENOMEM like before.

 If transitioning XDP modes reconfigure rings */

 Wait until ndo_xsk_wakeup completes. */

	/* Kick start the NAPI context if there is an AF_XDP socket open

	 * on that queue id. This so that receiving will start.

	/* Force memory writes to complete before letting h/w know there

	 * are new descriptors to fetch.

	/* During program transitions its possible adapter->xdp_prog is assigned

	 * but ring has not been configured yet. In this case simply abort xmit.

 IXGBE_FCOE */

 delay mechanism from ixgbe_disable_tx */

 write value back with RXDCTL.ENABLE bit cleared */

 RXDCTL.EN may not change on 82598 if link is down, so skip it */

 delay mechanism from ixgbe_disable_rx */

/**

 * ixgbe_txrx_ring_disable - Disable Rx/Tx/XDP Tx rings

 * @adapter: adapter structure

 * @ring: ring index

 *

 * This function disables a certain Rx/Tx/XDP Tx ring. The function

 * assumes that the netdev is running.

 Rx/Tx/XDP Tx share the same napi context. */

/**

 * ixgbe_txrx_ring_enable - Enable Rx/Tx/XDP Tx rings

 * @adapter: adapter structure

 * @ring: ring index

 *

 * This function enables a certain Rx/Tx/XDP Tx ring. The function

 * assumes that the netdev is running.

 Rx/Tx/XDP Tx share the same napi context. */

/**

 * ixgbe_enumerate_functions - Get the number of ports this device has

 * @adapter: adapter structure

 *

 * This function enumerates the phsyical functions co-located on a single slot,

 * in order to determine how many ports a device has. This is most useful in

 * determining the required GT/s of PCIe bandwidth necessary for optimal

 * performance.

	/* Some cards can not use the generic count PCIe functions method,

	 * because they are behind a parent switch, so we hardcode these with

	 * the correct number of functions.

 don't count virtual functions */

		/* When the devices on the bus don't all match our device ID,

		 * we can't reliably determine the correct number of

		 * functions. This can occur if a function has been direct

		 * attached to a virtual machine using VT-d, for example. In

		 * this case, simply return -1 to indicate this.

/**

 * ixgbe_wol_supported - Check whether device supports WoL

 * @adapter: the adapter private structure

 * @device_id: the device ID

 * @subdevice_id: the subsystem device ID

 *

 * This function is used by probe and ethtool to determine

 * which devices have WoL support

 *

 WOL not supported on 82598 */

 check eeprom to see if WOL is enabled for X540 and newer */

 WOL is determined based on device IDs for 82599 MACs */

 Only these subdevices could supports WOL */

 only support first port */

 Only these subdevices support WOL */

 All except this subdevice support WOL */

/**

 * ixgbe_set_fw_version - Set FW version

 * @adapter: the adapter private structure

 *

 * This function is used by probe and ethtool to determine the FW version to

 * format to display. The FW version is taken from the EEPROM/NVM.

 Set ETrack ID format */

/**

 * ixgbe_probe - Device Initialization Routine

 * @pdev: PCI device information struct

 * @ent: entry in ixgbe_pci_tbl

 *

 * Returns 0 on success, negative on failure

 *

 * ixgbe_probe initializes an adapter identified by a pci_dev structure.

 * The OS initialization, configuring of the adapter private structure,

 * and a hardware reset occur.

	/* Catch broken hardware that put the wrong VF device ID in

	 * the PCIe SR-IOV capability.

 8 TC w/ 4 queues per TC */

 Setup hw api */

 EEPROM */

 If EEPROM is valid (bit 8 = 1), use default otherwise use bit bang */

 PHY */

 ixgbe_identify_phy_generic will set prtad and mmds properly */

 setup the private structure */

 Make sure the SWFW semaphore is in a valid state */

 Make it possible the adapter to be woken up via WOL */

	/*

	 * If there is a fan on this device and it has failed log the

	 * failure.

 reset_hw fills in the perm_addr as well */

 SR-IOV not supported on the 82598 */

 Mailbox */

 copy netdev features into list of user selectable features */

 set this bit last since it cannot be part of vlan_features */

 MTU range: 68 - 9710 */

 IXGBE_FCOE */

 make sure the EEPROM is good */

 Set hw->mac.addr to permanent MAC address */

 WOL not supported for all devices */

 save off EEPROM version number */

 pick up the PCI bus settings for reporting later */

	/* calculate the expected PCIe bandwidth required for optimal

	 * performance. Note that some older parts will never have enough

	 * bandwidth due to being older generation PCIe parts. We clamp these

	 * parts to ensure no warning is displayed if it can't be fixed.

 don't check link if we failed to enumerate functions */

 reset the hardware with the new settings */

 We are running on a pre-production device, log a warning */

 power down the optics for 82599 SFP+ fiber */

 carrier off reporting is important to ethtool even BEFORE open */

	/* firmware requires driver version to be 0xFFFFFFFF

	 * since os does not support feature

 add san mac addr to netdev */

 CONFIG_IXGBE_HWMON */

 setup link for SFP devices with MNG FW, else wait for IXGBE_UP */

/**

 * ixgbe_remove - Device Removal Routine

 * @pdev: PCI device information struct

 *

 * ixgbe_remove is called by the PCI subsystem to alert the driver

 * that it should release a PCI device.  The could be caused by a

 * Hot-Plug event, or because the driver is going to be removed from

 * memory.

 if !adapter then we already cleaned up in probe */

 CONFIG_IXGBE_HWMON */

 remove the added san mac */

/**

 * ixgbe_io_error_detected - called when PCI error is detected

 * @pdev: Pointer to PCI device

 * @state: The current pci connection state

 *

 * This function is called after a PCI bus error affecting

 * this device has been detected.

 On the 82599 if bit 7 of the requestor ID is set then it's a VF */

 Find the pci device of the offending VF */

		/*

		 * There's a slim chance the VF could have been hot plugged,

		 * so if it is no longer present we don't need to issue the

		 * VFLR.  Just clean up the AER in that case.

 Free device reference count */

	/*

	 * Even though the error may have occurred on the other port

	 * we still need to increment the vf error reference count for

	 * both ports because the I/O resume function will be called

	 * for both of them.

 CONFIG_PCI_IOV */

 Request a slot reset. */

/**

 * ixgbe_io_slot_reset - called after the pci bus has been reset.

 * @pdev: Pointer to PCI device

 *

 * Restart the card from scratch, as if from a cold-boot.

/**

 * ixgbe_io_resume - called when traffic can start flowing again.

 * @pdev: Pointer to PCI device

 *

 * This callback is called when the error recovery driver tells us that

 * its OK to resume normal operation.

/**

 * ixgbe_init_module - Driver Registration Routine

 *

 * ixgbe_init_module is the first routine called when the driver is

 * loaded. All it does is register with the PCI subsystem.

/**

 * ixgbe_exit_module - Driver Exit Cleanup Routine

 *

 * ixgbe_exit_module is called just before the driver is removed

 * from memory.

 CONFIG_IXGBE_DCA */

 ixgbe_main.c */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 don't allow partial reads */

/**

 * ixgbe_dbg_reg_ops_read - read for reg_ops datum

 * @filp: the opened file

 * @buffer: where to write the data for the user to read

 * @count: the size of the user's buffer

 * @ppos: file position offset

/**

 * ixgbe_dbg_reg_ops_write - write into reg_ops datum

 * @filp: the opened file

 * @buffer: where to find the user's data

 * @count: the length of the user's data

 * @ppos: file position offset

 don't allow partial writes */

/**

 * ixgbe_dbg_netdev_ops_read - read for netdev_ops datum

 * @filp: the opened file

 * @buffer: where to write the data for the user to read

 * @count: the size of the user's buffer

 * @ppos: file position offset

/**

 * ixgbe_dbg_netdev_ops_write - write into netdev_ops datum

 * @filp: the opened file

 * @buffer: where to find the user's data

 * @count: the length of the user's data

 * @ppos: file position offset

 don't allow partial writes */

 TX Queue number below is wrong, but ixgbe does not use it */

/**

 * ixgbe_dbg_adapter_init - setup the debugfs directory for the adapter

 * @adapter: the adapter that is starting up

/**

 * ixgbe_dbg_adapter_exit - clear out the adapter's debugfs entries

 * @adapter: the adapter that is exiting

/**

 * ixgbe_dbg_init - start up debugfs for the driver

/**

 * ixgbe_dbg_exit - clean out the driver's debugfs entries

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 * ixgbe_dcb_config_rx_arbiter_82599 - Config Rx Data arbiter

 * @hw: pointer to hardware structure

 * @refill: refill credits index by traffic class

 * @max: max credits index by traffic class

 * @bwg_id: bandwidth grouping indexed by traffic class

 * @prio_type: priority type indexed by traffic class

 * @prio_tc: priority to tc assignments indexed by priority

 *

 * Configure Rx Packet Arbiter and credits for each traffic class.

	/*

	 * Disable the arbiter before changing parameters

	 * (always enable recycle mode; WSP)

 Map all traffic classes to their UP */

 Configure traffic class credits and priority */

	/*

	 * Configure Rx packet plane (recycle mode; WSP) and

	 * enable arbiter

/**

 * ixgbe_dcb_config_tx_desc_arbiter_82599 - Config Tx Desc. arbiter

 * @hw: pointer to hardware structure

 * @refill: refill credits index by traffic class

 * @max: max credits index by traffic class

 * @bwg_id: bandwidth grouping indexed by traffic class

 * @prio_type: priority type indexed by traffic class

 *

 * Configure Tx Descriptor Arbiter and credits for each traffic class.

 Clear the per-Tx queue credits; we use per-TC instead */

 Configure traffic class credits and priority */

	/*

	 * Configure Tx descriptor plane (recycle mode; WSP) and

	 * enable arbiter

/**

 * ixgbe_dcb_config_tx_data_arbiter_82599 - Config Tx Data arbiter

 * @hw: pointer to hardware structure

 * @refill: refill credits index by traffic class

 * @max: max credits index by traffic class

 * @bwg_id: bandwidth grouping indexed by traffic class

 * @prio_type: priority type indexed by traffic class

 * @prio_tc: priority to tc assignments indexed by priority

 *

 * Configure Tx Packet Arbiter and credits for each traffic class.

	/*

	 * Disable the arbiter before changing parameters

	 * (always enable recycle mode; SP; arb delay)

 Map all traffic classes to their UP */

 Configure traffic class credits and priority */

	/*

	 * Configure Tx packet plane (recycle mode; SP; arb delay) and

	 * enable arbiter

/**

 * ixgbe_dcb_config_pfc_82599 - Configure priority flow control

 * @hw: pointer to hardware structure

 * @pfc_en: enabled pfc bitmask

 * @prio_tc: priority to tc assignments indexed by priority

 *

 * Configure Priority Flow Control (PFC) for each traffic class.

 Enable Transmit Priority Flow Control */

 Enable Receive Priority Flow Control */

	/*

	 * X540 & X550 supports per TC Rx priority flow control.

	 * So clear all TCs and only enable those that should be

	 * enabled.

 Configure PFC Tx thresholds per TC */

			/* In order to prevent Tx hangs when the internal Tx

			 * switch is enabled we must set the high water mark

			 * to the Rx packet buffer size - 24KB.  This allows

			 * the Tx switch to function even under heavy Rx

			 * workloads.

 Configure pause time (2 TCs per register) */

 Configure flow control refresh threshold value */

/**

 * ixgbe_dcb_config_tc_stats_82599 - Config traffic class statistics

 * @hw: pointer to hardware structure

 *

 * Configure queue statistics registers, all queues belonging to same traffic

 * class uses a single set of queue statistics counters.

	/*

	 * Receive Queues stats setting

	 * 32 RQSMR registers, each configuring 4 queues.

	 * Set all 16 queues of each TC to the same stat

	 * with TC 'n' going to stat 'n'.

	/*

	 * Transmit Queues stats setting

	 * 32 TQSM registers, each controlling 4 queues.

	 * Set all queues of each TC to the same stat

	 * with TC 'n' going to stat 'n'.

	 * Tx queues are allocated non-uniformly to TCs:

	 * 32, 32, 16, 16, 8, 8, 8, 8.

/**

 * ixgbe_dcb_hw_config_82599 - Configure and enable DCB

 * @hw: pointer to hardware structure

 * @pfc_en: enabled pfc bitmask

 * @refill: refill credits index by traffic class

 * @max: max credits index by traffic class

 * @bwg_id: bandwidth grouping indexed by traffic class

 * @prio_type: priority type indexed by traffic class

 * @prio_tc: priority to tc assignments indexed by priority

 *

 * Configure dcb settings and enable dcb mode.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 * ixgbe_dcb_config_rx_arbiter_82598 - Config Rx data arbiter

 * @hw: pointer to hardware structure

 * @refill: refill credits index by traffic class

 * @max: max credits index by traffic class

 * @prio_type: priority type indexed by traffic class

 *

 * Configure Rx Data Arbiter and credits for each traffic class.

 Enable Arbiter */

 Enable Receive Recycle within the BWG */

 Enable Deficit Fixed Priority arbitration*/

 Configure traffic class credits and priority */

 Make sure there is enough descriptors before arbitration */

/**

 * ixgbe_dcb_config_tx_desc_arbiter_82598 - Config Tx Desc. arbiter

 * @hw: pointer to hardware structure

 * @refill: refill credits index by traffic class

 * @max: max credits index by traffic class

 * @bwg_id: bandwidth grouping indexed by traffic class

 * @prio_type: priority type indexed by traffic class

 *

 * Configure Tx Descriptor Arbiter and credits for each traffic class.

 Enable arbiter */

 Configure Max TSO packet size 34KB including payload and headers */

 Configure traffic class credits and priority */

/**

 * ixgbe_dcb_config_tx_data_arbiter_82598 - Config Tx data arbiter

 * @hw: pointer to hardware structure

 * @refill: refill credits index by traffic class

 * @max: max credits index by traffic class

 * @bwg_id: bandwidth grouping indexed by traffic class

 * @prio_type: priority type indexed by traffic class

 *

 * Configure Tx Data Arbiter and credits for each traffic class.

 Enable Data Plane Arbiter */

 Enable DFP and Transmit Recycle Mode */

 Configure traffic class credits and priority */

 Enable Tx packet buffer division */

/**

 * ixgbe_dcb_config_pfc_82598 - Config priority flow control

 * @hw: pointer to hardware structure

 * @pfc_en: enabled pfc bitmask

 *

 * Configure Priority Flow Control for each traffic class.

 Enable Transmit Priority Flow Control */

 Enable Receive Priority Flow Control */

 Configure PFC Tx thresholds per TC */

 Configure pause time */

 Configure flow control refresh threshold value */

/**

 * ixgbe_dcb_config_tc_stats_82598 - Configure traffic class statistics

 * @hw: pointer to hardware structure

 *

 * Configure queue statistics registers, all queues belonging to same traffic

 * class uses a single set of queue statistics counters.

 Receive Queues stats setting -  8 queues per statistics reg */

 Transmit Queues stats setting -  4 queues per statistics reg */

/**

 * ixgbe_dcb_hw_config_82598 - Config and enable DCB

 * @hw: pointer to hardware structure

 * @pfc_en: enabled pfc bitmask

 * @refill: refill credits index by traffic class

 * @max: max credits index by traffic class

 * @bwg_id: bandwidth grouping indexed by traffic class

 * @prio_type: priority type indexed by traffic class

 *

 * Configure dcb settings and enable dcb mode.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2018 Intel Corporation. */

 Kick start the NAPI context so that receiving will start */

 handle aborts by dropping packet */

 nothing to do */

		/* Refresh the desc even if buffer_addrs didn't change

		 * because each write-back erases this info.

 clear the length for the next_to_use descriptor */

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

 allocate a skb to store the frags */

 return some buffers to hardware, one at a time is too slow */

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we know the

		 * descriptor has been written back

 XDP_PASS path */

 put descriptor type bits */

 issue prefetch for next Tx descriptor */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 * ixgbe_cache_ring_dcb_sriov - Descriptor ring to register mapping for SR-IOV

 * @adapter: board private structure to initialize

 *

 * Cache the descriptor ring offsets for SR-IOV to the assigned rings.  It

 * will also try to cache the proper offsets if RSS/FCoE are enabled along

 * with VMDq.

 *

 IXGBE_FCOE */

 verify we have DCB queueing enabled before proceeding */

 verify we have VMDq enabled before proceeding */

 start at VMDq register offset for SR-IOV enabled setups */

 If we are greater than indices move to next pool */

 If we are greater than indices move to next pool */

 nothing to do if FCoE is disabled */

 The work is already done if the FCoE ring is shared */

 The FCoE rings exist separately, we need to move their reg_idx */

 IXGBE_FCOE */

 ixgbe_get_first_reg_idx - Return first register index associated with ring */

 TxQs/TC: 4	RxQs/TC: 8 */

 0, 4,  8, 12, 16, 20, 24, 28 */

 0, 8, 16, 24, 32, 40, 48, 56 */

			/*

			 * TCs    : TC0/1 TC2/3 TC4-7

			 * TxQs/TC:    32    16     8

			 * RxQs/TC:    16    16    16

   0,  32,  64 */

  80,  96 */

 104, 112, 120 */

			/*

			 * TCs    : TC0 TC1 TC2/3

			 * TxQs/TC:  64  32    16

			 * RxQs/TC:  32  32    32

  0,  64 */

 96, 112 */

/**

 * ixgbe_cache_ring_dcb - Descriptor ring to register mapping for DCB

 * @adapter: board private structure to initialize

 *

 * Cache the descriptor ring offsets for DCB to the assigned rings.

 *

 verify we have DCB queueing enabled before proceeding */

/**

 * ixgbe_cache_ring_sriov - Descriptor ring to register mapping for sriov

 * @adapter: board private structure to initialize

 *

 * SR-IOV doesn't use any descriptor rings but changes the default if

 * no other mapping is used.

 *

 IXGBE_FCOE */

 only proceed if VMDq is enabled */

 start at VMDq register offset for SR-IOV enabled setups */

 Allow first FCoE queue to be mapped as RSS */

 If we are greater than indices move to next pool */

 FCoE uses a linear block of queues so just assigning 1:1 */

 Allow first FCoE queue to be mapped as RSS */

 If we are greater than indices move to next pool */

 FCoE uses a linear block of queues so just assigning 1:1 */

/**

 * ixgbe_cache_ring_rss - Descriptor ring to register mapping for RSS

 * @adapter: board private structure to initialize

 *

 * Cache the descriptor ring offsets for RSS to the assigned rings.

 *

/**

 * ixgbe_cache_ring_register - Descriptor ring to register mapping

 * @adapter: board private structure to initialize

 *

 * Once we know the feature-set enabled for the device, we'll cache

 * the register offset the descriptor ring is assigned to.

 *

 * Note, the order the various feature calls is important.  It must start with

 * the "most" features enabled at the same time, then trickle down to the

 * least amount of features turned on at once.

 start with default case */

/**

 * ixgbe_set_dcb_sriov_queues: Allocate queues for SR-IOV devices w/ DCB

 * @adapter: board private structure to initialize

 *

 * When SR-IOV (Single Root IO Virtualiztion) is enabled, allocate queues

 * and VM pools where appropriate.  Also assign queues based on DCB

 * priorities and map accordingly..

 *

 verify we have DCB queueing enabled before proceeding */

 verify we have VMDq enabled before proceeding */

 limit VMDq instances on the PF by number of Tx queues */

 Add starting offset to total pool count */

 16 pools w/ 8 TC per pool */

 32 pools w/ 4 TC per pool */

 queues in the remaining pools are available for FCoE */

 remove the starting offset from the pool count */

 save features for later use */

	/*

	 * We do not support DCB, VMDq, and RSS all simultaneously

	 * so we will disable RSS since it is the lowest priority

 disable ATR as it is not supported when VMDq is enabled */

 limit ourselves based on feature limits */

 alloc queues for FCoE separately */

 add queues to adapter */

 use queue belonging to FcoE TC */

 IXGBE_FCOE */

 configure TC to queue mapping */

 Map queue offset and counts onto allocated tx queues */

 verify we have DCB queueing enabled before proceeding */

 determine the upper limit for our current DCB mode */

 8 TC w/ 4 queues per TC */

 8 TC w/ 8 queues per TC */

 4 TC w/ 16 queues per TC */

 set RSS mask and indices */

 disable ATR as it is not supported when multiple TCs are enabled */

	/* FCoE enabled queues require special configuration indexed

	 * by feature specific indices and offset. Here we map FCoE

	 * indices onto the DCB queue pairs allowing FCoE to own

	 * configuration later.

 IXGBE_FCOE */

/**

 * ixgbe_set_sriov_queues - Allocate queues for SR-IOV devices

 * @adapter: board private structure to initialize

 *

 * When SR-IOV (Single Root IO Virtualiztion) is enabled, allocate queues

 * and VM pools where appropriate.  If RSS is available, then also try and

 * enable RSS and map accordingly.

 *

 only proceed if SR-IOV is enabled */

 limit l2fwd RSS based on total Tx queue limit */

 Add starting offset to total pool count */

 double check we are limited to maximum pools */

 64 pool mode with 2 queues per pool */

 32 pool mode with up to 4 queues per pool */

 We can support 4, 2, or 1 queues */

 queues in the remaining pools are available for FCoE */

 remove the starting offset from the pool count */

 save features for later use */

 limit RSS based on user input and save for later use */

 disable ATR as it is not supported when VMDq is enabled */

	/*

	 * FCoE can use rings from adjacent buffers to allow RSS

	 * like behavior.  To account for this we need to add the

	 * FCoE indices to the total ring count.

 limit ourselves based on feature limits */

 alloc queues for FCoE separately */

 merge FCoE queues with RSS queues */

 limit indices to rss_i if MSI-X is disabled */

 attempt to reserve some queues for just FCoE */

 add queues to adapter */

	/* To support macvlan offload we have to use num_tc to

	 * restrict the queues that can be used by the device.

	 * By doing this we can avoid reporting a false number of

	 * queues.

 populate TC0 for use by pool 0 */

/**

 * ixgbe_set_rss_queues - Allocate queues for RSS

 * @adapter: board private structure to initialize

 *

 * This is our "base" multiqueue mode.  RSS (Receive Side Scaling) will try

 * to allocate one Rx queue per CPU, and if available, one Tx queue per CPU.

 *

 set mask for 16 queue limit of RSS */

 disable ATR by default, it will be configured below */

	/*

	 * Use Flow Director in addition to RSS to ensure the best

	 * distribution of flows across cores, even when an FDIR flow

	 * isn't matched.

	/*

	 * FCoE can exist on the same rings as standard network traffic

	 * however it is preferred to avoid that if possible.  In order

	 * to get the best performance we allocate as many FCoE queues

	 * as we can and we place them at the end of the ring array to

	 * avoid sharing queues with standard RSS on systems with 24 or

	 * more CPUs.

 merge FCoE queues with RSS queues */

 limit indices to rss_i if MSI-X is disabled */

 attempt to reserve some queues for just FCoE */

 IXGBE_FCOE */

/**

 * ixgbe_set_num_queues - Allocate queues for device, feature dependent

 * @adapter: board private structure to initialize

 *

 * This is the top level queue allocation routine.  The order here is very

 * important, starting with the "most" number of features turned on at once,

 * and ending with the smallest set of features.  This way large combinations

 * can be allocated if they're turned on, and smaller combinations are the

 * fallthrough conditions.

 *

 Start with base case */

/**

 * ixgbe_acquire_msix_vectors - acquire MSI-X vectors

 * @adapter: board private structure

 *

 * Attempts to acquire a suitable range of MSI-X vector interrupts. Will

 * return a negative error code if unable to acquire MSI-X vectors for any

 * reason.

	/* We start by asking for one vector per queue pair with XDP queues

	 * being stacked with TX queues.

	/* It is easy to be greedy for MSI-X vectors. However, it really

	 * doesn't do much good if we have a lot more vectors than CPUs. We'll

	 * be somewhat conservative and only ask for (roughly) the same number

	 * of vectors as there are CPUs.

 Some vectors are necessary for non-queue interrupts */

	/* Hardware can only support a maximum of hw.mac->max_msix_vectors.

	 * With features such as RSS and VMDq, we can easily surpass the

	 * number of Rx and Tx descriptor queues supported by our device.

	 * Thus, we cap the maximum in the rare cases where the CPU count also

	 * exceeds our vector limit

	/* We want a minimum of two MSI-X vectors for (1) a TxQ[0] + RxQ[0]

	 * handler, and (2) an Other (Link Status Change, etc.) handler.

		/* A negative count of allocated vectors indicates an error in

		 * acquiring within the specified range of MSI-X vectors

	/* we successfully allocated some number of vectors within our

	 * requested range.

	/* Adjust for only the vectors we'll use, which is minimum

	 * of max_q_vectors, or the number of vectors we were allocated.

/**

 * ixgbe_alloc_q_vector - Allocate memory for a single interrupt vector

 * @adapter: board private structure to initialize

 * @v_count: q_vectors allocated on adapter, used for ring interleaving

 * @v_idx: index of vector in adapter struct

 * @txr_count: total number of Tx rings to allocate

 * @txr_idx: index of first Tx ring to allocate

 * @xdp_count: total number of XDP rings to allocate

 * @xdp_idx: index of first XDP ring to allocate

 * @rxr_count: total number of Rx rings to allocate

 * @rxr_idx: index of first Rx ring to allocate

 *

 * We allocate one q_vector.  If allocation fails we return -ENOMEM.

 customize cpu for Flow Director mapping */

 allocate q_vector and rings */

 setup affinity mask and node */

 initialize CPU for DCA */

 initialize NAPI */

 tie q_vector and adapter together */

 initialize work limits */

 Initialize setting for adaptive ITR */

 intialize ITR */

 tx only vector */

 rx or rx/tx vector */

 initialize pointer to rings */

 assign generic ring traits */

 configure backlink on ring */

 update q_vector Tx values */

 apply Tx specific ring traits */

 assign ring to adapter */

 update count and index */

 push pointer to next ring */

 assign generic ring traits */

 configure backlink on ring */

 update q_vector Tx values */

 apply Tx specific ring traits */

 assign ring to adapter */

 update count and index */

 push pointer to next ring */

 assign generic ring traits */

 configure backlink on ring */

 update q_vector Rx values */

		/*

		 * 82599 errata, UDP frames with a 0 checksum

		 * can be marked as checksum errors.

 IXGBE_FCOE */

 apply Rx specific ring traits */

 assign ring to adapter */

 update count and index */

 push pointer to next ring */

/**

 * ixgbe_free_q_vector - Free memory allocated for specific interrupt vector

 * @adapter: board private structure to initialize

 * @v_idx: Index of vector to be freed

 *

 * This function frees the memory allocated to the q_vector.  In addition if

 * NAPI is enabled it will delete any references to the NAPI struct prior

 * to freeing the q_vector.

	/*

	 * after a call to __netif_napi_del() napi may still be used and

	 * ixgbe_get_stats64() might access the rings on this vector,

	 * we must wait a grace period before freeing it.

/**

 * ixgbe_alloc_q_vectors - Allocate memory for interrupt vectors

 * @adapter: board private structure to initialize

 *

 * We allocate one q_vector per queue interrupt.  If allocation fails we

 * return -ENOMEM.

 only one q_vector if MSI-X is disabled. */

 update counts and index */

 update counts and index */

/**

 * ixgbe_free_q_vectors - Free memory allocated for interrupt vectors

 * @adapter: board private structure to initialize

 *

 * This function frees the memory allocated to the q_vectors.  In addition if

 * NAPI is enabled it will delete any references to the NAPI struct prior

 * to freeing the q_vector.

/**

 * ixgbe_set_interrupt_capability - set MSI-X or MSI if supported

 * @adapter: board private structure to initialize

 *

 * Attempt to configure the interrupts using the best available

 * capabilities of the hardware and the kernel.

 We will try to get MSI-X interrupts first */

	/* At this point, we do not have MSI-X capabilities. We need to

	 * reconfigure or disable various features which require MSI-X

	 * capability.

 Disable DCB unless we only have a single traffic class */

 Disable SR-IOV support */

 Disable RSS */

	/* recalculate number of queues now that many features have been

	 * changed or disabled.

/**

 * ixgbe_init_interrupt_scheme - Determine proper interrupt scheme

 * @adapter: board private structure to initialize

 *

 * We determine which interrupt scheme to use based on...

 * - Kernel support (MSI, MSI-X)

 *   - which can be user-defined (via MODULE_PARAM)

 * - Hardware queue count (num_*_queues)

 *   - defined by miscellaneous hardware support/features (RSS, etc.)

 Number of supported queues */

 Set interrupt mode */

/**

 * ixgbe_clear_interrupt_scheme - Clear the current interrupt scheme settings

 * @adapter: board private structure to clear interrupt scheme on

 *

 * We go through and clear interrupt specific resources and reset the structure

 * to pre-load conditions

 set bits to identify this as an advanced context descriptor */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2017 Oracle and/or its affiliates. All rights reserved. */

/**

 * ixgbe_ipsec_set_tx_sa - set the Tx SA registers

 * @hw: hw specific details

 * @idx: register index to write

 * @key: key byte array

 * @salt: salt bytes

/**

 * ixgbe_ipsec_set_rx_item - set an Rx table item

 * @hw: hw specific details

 * @idx: register index to write

 * @tbl: table selector

 *

 * Trigger the device to store into a particular Rx table the

 * data that has already been loaded into the input register

/**

 * ixgbe_ipsec_set_rx_sa - set up the register bits to save SA info

 * @hw: hw specific details

 * @idx: register index to write

 * @spi: security parameter index

 * @key: key byte array

 * @salt: salt bytes

 * @mode: rx decrypt control bits

 * @ip_idx: index into IP table for related IP address

 store the SPI (in bigendian) and IPidx */

 store the key, salt, and mode */

/**

 * ixgbe_ipsec_set_rx_ip - set up the register bits to save SA IP addr info

 * @hw: hw specific details

 * @idx: register index to write

 * @addr: IP address byte array

 store the ip address */

/**

 * ixgbe_ipsec_clear_hw_tables - because some tables don't get cleared on reset

 * @adapter: board private structure

 disable Rx and Tx SA lookup */

 scrub the tables - split the loops for the max of the IP table */

/**

 * ixgbe_ipsec_stop_data

 * @adapter: board private structure

 halt data paths */

	/* If both Tx and Rx are ready there are no packets

	 * that we need to flush so the loopback configuration

	 * below is not necessary.

	/* If the tx fifo doesn't have link, but still has data,

	 * we can't clear the tx sec block.  Set the MAC loopback

	 * before block clear

 wait for the paths to empty */

 undo loopback if we played with it earlier */

/**

 * ixgbe_ipsec_stop_engine

 * @adapter: board private structure

 disable Rx and Tx SA lookup */

 disable the Rx and Tx engines and full packet store-n-forward */

 restore the "tx security buffer almost full threshold" to 0x250 */

 Set minimum IFG between packets back to the default 0x1 */

 final set for normal (no ipsec offload) processing */

/**

 * ixgbe_ipsec_start_engine

 * @adapter: board private structure

 *

 * NOTE: this increases power consumption whether being used or not

 Set minimum IFG between packets to 3 */

	/* Set "tx security buffer almost full threshold" to 0x15 so that the

	 * almost full indication is generated only after buffer contains at

	 * least an entire jumbo packet.

 restart the data paths by clearing the DISABLE bits */

 enable Rx and Tx SA lookup */

/**

 * ixgbe_ipsec_restore - restore the ipsec HW settings after a reset

 * @adapter: board private structure

 *

 * Reload the HW tables from the SW tables after they've been bashed

 * by a chip reset.

 *

 * Any VF entries are removed from the SW and HW tables since either

 * (a) the VF also gets reset on PF reset and will ask again for the

 * offloads, or (b) the VF has been removed by a change in the num_vfs.

 clean up and restart the engine */

 reload the Rx and Tx keys */

 reload the IP addrs */

/**

 * ixgbe_ipsec_find_empty_idx - find the first unused security parameter index

 * @ipsec: pointer to ipsec struct

 * @rxtable: true if we need to look in the Rx table

 *

 * Returns the first unused index in either the Rx or Tx SA table

 search rx sa table */

 search tx sa table */

/**

 * ixgbe_ipsec_find_rx_state - find the state that matches

 * @ipsec: pointer to ipsec struct

 * @daddr: inbound address to match

 * @proto: protocol to match

 * @spi: SPI to match

 * @ip4: true if using an ipv4 address

 *

 * Returns a pointer to the matching SA state information

/**

 * ixgbe_ipsec_parse_proto_keys - find the key and salt based on the protocol

 * @xs: pointer to xfrm_state struct

 * @mykey: pointer to key array to populate

 * @mysalt: pointer to salt value to populate

 *

 * This copies the protocol keys and salt to our own data tables.  The

 * 82599 family only supports the one algorithm.

	/* The key bytes come down in a bigendian array of bytes, so

	 * we don't need to do any byteswapping.

	 * 160 accounts for 16 byte key and 4 byte salt

/**

 * ixgbe_ipsec_check_mgmt_ip - make sure there is no clash with mgmt IP filters

 * @xs: pointer to transformer state struct

 are there any IPv4 filters to check? */

 the 4 ipv4 filters are all in MIPAF(3, i) */

 if there are ipv4 filters, they are in the last ipv6 slot */

 did we match all 4 words? */

 did we match all 4 words? */

/**

 * ixgbe_ipsec_add_sa - program device with a security association

 * @xs: pointer to transformer state struct

 find the first unused index */

 get the key and salt */

 get ip for rx sa table */

		/* The HW does not have a 1:1 mapping from keys to IP addrs, so

		 * check for a matching IP addr entry in the table.  If the addr

		 * already exists, use it; else find an unused slot and add the

		 * addr.  If one does not exist and there are no unused table

		 * entries, fail the request.

		/* Find an existing match or first not used, and stop looking

		 * after we've checked all we know we have.

 track the first empty seen */

 addrs are the same, we should use this one */

 no matches, but here's an empty slot */

 no match and no empty slot */

 the preparations worked, so save the info */

 hash the new entry for faster search in Rx path */

 find the first unused index */

 the preparations worked, so save the info */

 enable the engine if not already warmed up */

/**

 * ixgbe_ipsec_del_sa - clear out this specific SA

 * @xs: pointer to transformer state struct

		/* if the IP table entry is referenced by only this SA,

		 * i.e. ref_cnt is only 1, clear the IP table entry as well

 if there are no SAs left, stop the engine to save energy */

/**

 * ixgbe_ipsec_offload_ok - can this packet use the xfrm hw offload

 * @skb: current data packet

 * @xs: pointer to transformer state struct

 Offload with IPv4 options is not supported yet */

 Offload with IPv6 extension headers is not support yet */

/**

 * ixgbe_ipsec_vf_clear - clear the tables of data for a VF

 * @adapter: board private structure

 * @vf: VF id to be removed

 search rx sa table */

 search tx sa table */

/**

 * ixgbe_ipsec_vf_add_sa - translate VF request to SA add

 * @adapter: board private structure

 * @msgbuf: The message buffer

 * @vf: the VF index

 *

 * Make up a new xs and algorithm info from the data sent by the VF.

 * We only need to sketch in just enough to set up the HW offload.

 * Put the resulting offload_handle into the return message to the VF.

 *

 * Returns 0 or error value

	/* Tx IPsec offload doesn't seem to work on this

	 * device, so block these requests for now.

 set up the HW offload */

/**

 * ixgbe_ipsec_vf_del_sa - translate VF request to SA delete

 * @adapter: board private structure

 * @msgbuf: The message buffer

 * @vf: the VF index

 *

 * Given the offload_handle sent by the VF, look for the related SA table

 * entry and use its xs field to call for a delete of the SA.

 *

 * Note: We silently ignore requests to delete entries that are already

 *       set to unused because when a VF is set to "DOWN", the PF first

 *       gets a reset and clears all the VF's entries; then the VF's

 *       XFRM stack sends individual deletes for each entry, which the

 *       reset already removed.  In the future it might be good to try to

 *       optimize this so not so many unnecessary delete messages are sent.

 *

 * Returns 0 or error value

 remove the xs that was made-up in the add request */

/**

 * ixgbe_ipsec_tx - setup Tx flags for ipsec offload

 * @tx_ring: outgoing context

 * @first: current data packet

 * @itd: ipsec Tx data for later use in building context descriptor

		/* The actual trailer length is authlen (16 bytes) plus

		 * 2 bytes for the proto and the padlen values, plus

		 * padlen bytes of padding.  This ends up not the same

		 * as the static value found in xs->props.trailer_len (21).

		 *

		 * ... but if we're doing GSO, don't bother as the stack

		 * doesn't add a trailer for those.

			/* The "correct" way to get the auth length would be

			 * to use

			 *    authlen = crypto_aead_authsize(xs->data);

			 * but since we know we only have one size to worry

			 * about * we can let the compiler use the constant

			 * and save us a few CPU cycles.

/**

 * ixgbe_ipsec_rx - decode ipsec bits from Rx descriptor

 * @rx_ring: receiving ring

 * @rx_desc: receive data descriptor

 * @skb: current data packet

 *

 * Determine if there was an ipsec encapsulation noticed, and if so set up

 * the resulting status for later in the receive stack.

	/* Find the ip and crypto headers in the data.

	 * We can assume no vlan header in the way, b/c the

	 * hw won't recognize the IPsec packet and anyway the

	 * currently vlan device doesn't support xfrm offload.

/**

 * ixgbe_init_ipsec_offload - initialize security registers for IPSec operation

 * @adapter: board private structure

	/* If there is no support for either Tx or Rx offload

	 * we should not be advertising support for IPsec.

/**

 * ixgbe_stop_ipsec_offload - tear down the ipsec offload

 * @adapter: board private structure

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 * ixgbe_ieee_credits - This calculates the ieee traffic class

 * credits from the configured bandwidth percentages. Credits

 * are the smallest unit programmable into the underlying

 * hardware. The IEEE 802.1Qaz specification do not use bandwidth

 * groups so this is much simplified from the CEE case.

 * @bw: bandwidth index by traffic class

 * @refill: refill credits index by traffic class

 * @max: max credits by traffic class

 * @max_frame: maximum frame size

 Find out the hw credits for each TC */

/**

 * ixgbe_dcb_calculate_tc_credits - Calculates traffic class credits

 * @hw: pointer to hardware structure

 * @dcb_config: Struct containing DCB settings

 * @max_frame: Maximum frame size

 * @direction: Configuring either Tx or Rx

 *

 * This function calculates the credits allocated to each traffic class.

 * It should be called only after the rules are checked by

 * ixgbe_dcb_check_config().

 Initialization values default for Tx settings */

 Find smallest link percentage */

	/*

	 * The ratio between traffic classes will control the bandwidth

	 * percentages seen on the wire. To calculate this ratio we use

	 * a multiplier. It is required that the refill credits must be

	 * larger than the max frame size so here we find the smallest

	 * multiplier that will allow all bandwidth percentages to be

	 * greater than the max frame size.

 Find out the link percentage for each TC first */

 Must be careful of integer division for very small nums */

 Save link_percentage for reference */

 Calculate credit refill ratio using multiplier */

 Refill at least minimum credit */

 Calculate maximum credit for the TC */

		/*

		 * Adjustment based on rule checking, if the percentage

		 * of a TC is too small, the maximum credit may not be

		 * enough to send out a jumbo frame in data plane arbitration.

			/*

			 * Adjustment based on rule checking, if the

			 * percentage of a TC is too small, the maximum

			 * credit may not be enough to send out a TSO

			 * packet in descriptor plane arbitration.

 If tc is 0 then DCB is likely not enabled or supported */

	/*

	 * Test from maximum TC to 1 and report the first match we find.  If

	 * we find no match we can assume that the TC is 0 since the TC must

	 * be set for all user priorities

/**

 * ixgbe_dcb_hw_config - Config and enable DCB

 * @hw: pointer to hardware structure

 * @dcb_config: pointer to ixgbe_dcb_config structure

 *

 * Configure dcb settings and enable dcb mode.

 Unpack CEE standard containers */

 Helper routines to abstract HW specifics from DCB netlink ops */

 naively give each TC a bwg to map onto CEE hardware */

 Map TSA onto CEE prio type */

			/* Hardware only supports priority strict or

			 * ETS transmission selection algorithms if

			 * we receive some other value from dcbnl

			 * throw an error

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 set_phy_power was set by default to NULL */

/**

 *  ixgbe_setup_mac_link_X540 - Set the auto advertised capabilitires

 *  @hw: pointer to hardware structure

 *  @speed: new link speed

 *  @autoneg_wait_to_complete: true when waiting for completion is needed

/**

 *  ixgbe_reset_hw_X540 - Perform hardware reset

 *  @hw: pointer to hardware structure

 *

 *  Resets the hardware by resetting the transmit and receive units, masks

 *  and clears all interrupts, perform a PHY reset, and perform a link (MAC)

 *  reset.

 Call adapter stop to disable tx/rx and clear interrupts */

 flush pending Tx transactions */

 Poll for reset bit to self-clear indicating reset is complete */

	/*

	 * Double resets are required for recovery from certain error

	 * conditions.  Between resets, it is necessary to stall to allow time

	 * for any pending HW events to complete.

 Set the Rx packet buffer size. */

 Store the permanent mac address */

	/*

	 * Store MAC address from RAR0, clear receive address registers, and

	 * clear the multicast table.  Also reset num_rar_entries to 128,

	 * since we modify this value when programming the SAN MAC address.

 Store the permanent SAN mac address */

 Add the SAN MAC address to the RAR only if it's a valid address */

 Save the SAN MAC RAR index */

 clear VMDq pool/queue selection for this RAR */

 Reserve the last RAR for the SAN MAC address */

 Store the alternative WWNN/WWPN prefix */

/**

 *  ixgbe_start_hw_X540 - Prepare hardware for Tx/Rx

 *  @hw: pointer to hardware structure

 *

 *  Starts the hardware using the generic start_hw function

 *  and the generation start_hw function.

 *  Then performs revision-specific operations, if any.

/**

 *  ixgbe_init_eeprom_params_X540 - Initialize EEPROM params

 *  @hw: pointer to hardware structure

 *

 *  Initializes the EEPROM parameters ixgbe_eeprom_info within the

 *  ixgbe_hw struct in order to set up EEPROM access.

/**

 *  ixgbe_read_eerd_X540- Read EEPROM word using EERD

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to read

 *  @data: word read from the EEPROM

 *

 *  Reads a 16 bit word from the EEPROM using the EERD register.

/**

 *  ixgbe_read_eerd_buffer_X540 - Read EEPROM word(s) using EERD

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to read

 *  @words: number of words

 *  @data: word(s) read from the EEPROM

 *

 *  Reads a 16 bit word(s) from the EEPROM using the EERD register.

/**

 *  ixgbe_write_eewr_X540 - Write EEPROM word using EEWR

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to write

 *  @data: word write to the EEPROM

 *

 *  Write a 16 bit word to the EEPROM using the EEWR register.

/**

 *  ixgbe_write_eewr_buffer_X540 - Write EEPROM word(s) using EEWR

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to write

 *  @words: number of words

 *  @data: word(s) write to the EEPROM

 *

 *  Write a 16 bit word(s) to the EEPROM using the EEWR register.

/**

 *  ixgbe_calc_eeprom_checksum_X540 - Calculates and returns the checksum

 *

 *  This function does not use synchronization for EERD and EEWR. It can

 *  be used internally by function which utilize ixgbe_acquire_swfw_sync_X540.

 *

 *  @hw: pointer to hardware structure

	/*

	 * Do not use hw->eeprom.ops.read because we do not want to take

	 * the synchronization semaphores here. Instead use

	 * ixgbe_read_eerd_generic

 Include 0x0-0x3F in the checksum */

	/*

	 * Include all data from pointers 0x3, 0x6-0xE.  This excludes the

	 * FW, PHY module, and PCIe Expansion/Option ROM pointers.

 Skip pointer section if the pointer is invalid. */

 Skip pointer section if length is invalid. */

/**

 *  ixgbe_validate_eeprom_checksum_X540 - Validate EEPROM checksum

 *  @hw: pointer to hardware structure

 *  @checksum_val: calculated checksum

 *

 *  Performs checksum calculation and validates the EEPROM checksum.  If the

 *  caller does not need checksum_val, the value can be NULL.

	/* Read the first word from the EEPROM. If this times out or fails, do

	 * not continue or we could be in for a very long wait while every

	 * EEPROM read fails

	/* Do not use hw->eeprom.ops.read because we do not want to take

	 * the synchronization semaphores twice here.

	/* Verify read checksum from EEPROM is the same as

	 * calculated checksum

 If the user cares, return the calculated checksum */

/**

 * ixgbe_update_eeprom_checksum_X540 - Updates the EEPROM checksum and flash

 * @hw: pointer to hardware structure

 *

 * After writing EEPROM to shadow RAM using EEWR register, software calculates

 * checksum and updates the EEPROM and instructs the hardware to update

 * the flash.

	/* Read the first word from the EEPROM. If this times out or fails, do

	 * not continue or we could be in for a very long wait while every

	 * EEPROM read fails

	/* Do not use hw->eeprom.ops.write because we do not want to

	 * take the synchronization semaphores twice here.

/**

 * ixgbe_update_flash_X540 - Instruct HW to copy EEPROM to Flash device

 * @hw: pointer to hardware structure

 *

 * Set FLUP (bit 23) of the EEC register to instruct Hardware to copy

 * EEPROM from shadow RAM to the flash device.

/**

 * ixgbe_poll_flash_update_done_X540 - Poll flash update status

 * @hw: pointer to hardware structure

 *

 * Polls the FLUDONE (bit 26) of the EEC Register to determine when the

 * flash update is done.

/**

 * ixgbe_acquire_swfw_sync_X540 - Acquire SWFW semaphore

 * @hw: pointer to hardware structure

 * @mask: Mask to specify which semaphore to acquire

 *

 * Acquires the SWFW semaphore thought the SW_FW_SYNC register for

 * the specified function (CSR, PHY0, PHY1, NVM, Flash)

 SW only mask does not have FW bit pair */

		/* SW NVM semaphore bit is used for access to all

		 * SW_FW_SYNC bits (not just NVM)

		/* Firmware currently using resource (fwmask), hardware

		 * currently using resource (hwmask), or other software

		 * thread currently using resource (swmask)

	/* If the resource is not released by the FW/HW the SW can assume that

	 * the FW/HW malfunctions. In that case the SW should set the SW bit(s)

	 * of the requested resource(s) while ignoring the corresponding FW/HW

	 * bits in the SW_FW_SYNC register.

	/* If the resource is not released by other SW the SW can assume that

	 * the other SW malfunctions. In that case the SW should clear all SW

	 * flags that it does not own and then repeat the whole process once

	 * again.

/**

 * ixgbe_release_swfw_sync_X540 - Release SWFW semaphore

 * @hw: pointer to hardware structure

 * @mask: Mask to specify which semaphore to release

 *

 * Releases the SWFW semaphore through the SW_FW_SYNC register

 * for the specified function (CSR, PHY0, PHY1, EVM, Flash)

/**

 * ixgbe_get_swfw_sync_semaphore - Get hardware semaphore

 * @hw: pointer to hardware structure

 *

 * Sets the hardware semaphores so SW/FW can gain control of shared resources

 Get SMBI software semaphore between device drivers first */

		/* If the SMBI bit is 0 when we read it, then the bit will be

		 * set and we have the semaphore

 Now get the semaphore between SW/FW through the REGSMP bit */

	/* Release semaphores and return error if SW NVM semaphore

	 * was not granted because we do not have access to the EEPROM

/**

 * ixgbe_release_swfw_sync_semaphore - Release hardware semaphore

 * @hw: pointer to hardware structure

 *

 * This function clears hardware semaphore bits.

 Release both semaphores by writing 0 to the bits REGSMP and SMBI */

/**

 *  ixgbe_init_swfw_sync_X540 - Release hardware semaphore

 *  @hw: pointer to hardware structure

 *

 *  This function reset hardware semaphore bits for a semaphore that may

 *  have be left locked due to a catastrophic failure.

	/* First try to grab the semaphore but we don't need to bother

	 * looking to see whether we got the lock or not since we do

	 * the same thing regardless of whether we got the lock or not.

	 * We got the lock - we release it.

	 * We timeout trying to get the lock - we force its release.

 Acquire and release all software resources. */

/**

 * ixgbe_blink_led_start_X540 - Blink LED based on index.

 * @hw: pointer to hardware structure

 * @index: led number to blink

 *

 * Devices that implement the version 2 interface:

 *   X540

	/* Link should be up in order for the blink bit in the LED control

	 * register to work. Force link and speed in the MAC if link is down.

	 * This will be reversed when we stop the blinking.

 Set the LED to LINK_UP + BLINK. */

/**

 * ixgbe_blink_led_stop_X540 - Stop blinking LED based on index.

 * @hw: pointer to hardware structure

 * @index: led number to stop blinking

 *

 * Devices that implement the version 2 interface:

 *   X540

 Restore the LED to its default value. */

 Unforce link and speed in the MAC. */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 hwmon callback functions */

 reset the temp field */

 display millidegree */

 display millidegree */

 display millidegree */

/**

 * ixgbe_add_hwmon_attr - Create hwmon attr table for a hwmon sysfs file.

 * @adapter: pointer to the adapter structure

 * @offset: offset in the eeprom sensor data table

 * @type: type of sensor data to display

 *

 * For each file we want in hwmon's sysfs interface we need a device_attribute

 * This is included in our hwmon_attr struct that contains the references to

 * the data structures we need to get the data to display.

 These always the same regardless of type */

 called from ixgbe_main.c */

 called from ixgbe_main.c */

 If this method isn't defined we don't support thermals */

 Don't create thermal hwmon interface if no sensors present */

		/*

		 * Only create hwmon sysfs entries for sensors that have

		 * meaningful data for.

 Bail if any hwmon attr struct fails to initialize */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 *  ixgbe_out_i2c_byte_ack - Send I2C byte with ack

 *  @hw: pointer to the hardware structure

 *  @byte: byte to send

 *

 *  Returns an error code on error.

/**

 *  ixgbe_in_i2c_byte_ack - Receive an I2C byte and send ack

 *  @hw: pointer to the hardware structure

 *  @byte: pointer to a u8 to receive the byte

 *

 *  Returns an error code on error.

 ACK */

/**

 *  ixgbe_ones_comp_byte_add - Perform one's complement addition

 *  @add1: addend 1

 *  @add2: addend 2

 *

 *  Returns one's complement 8-bit sum.

/**

 *  ixgbe_read_i2c_combined_generic_int - Perform I2C read combined operation

 *  @hw: pointer to the hardware structure

 *  @addr: I2C bus address to read from

 *  @reg: I2C device register to read from

 *  @val: pointer to location to receive read value

 *  @lock: true if to take and release semaphore

 *

 *  Returns an error code on error.

 Indicate read combined */

 Device Address and write indication */

 Write bits 14:8 */

 Write bits 7:0 */

 Write csum */

 Re-start condition */

 Device Address and read indication */

 Get upper bits */

 Get low bits */

 Get csum */

 NACK */

/**

 *  ixgbe_write_i2c_combined_generic_int - Perform I2C write combined operation

 *  @hw: pointer to the hardware structure

 *  @addr: I2C bus address to write to

 *  @reg: I2C device register to write to

 *  @val: value to write

 *  @lock: true if to take and release semaphore

 *

 *  Returns an error code on error.

 Indicate write combined */

 Device Address and write indication */

 Write bits 14:8 */

 Write bits 7:0 */

 Write data 15:8 */

 Write data 7:0 */

 Write csum */

/**

 *  ixgbe_probe_phy - Probe a single address for a PHY

 *  @hw: pointer to hardware structure

 *  @phy_addr: PHY address to probe

 *

 *  Returns true if PHY found

/**

 *  ixgbe_identify_phy_generic - Get physical layer module

 *  @hw: pointer to hardware structure

 *

 *  Determines the physical layer module found on the current adapter.

	/* Certain media types do not have a phy so an address will not

	 * be found and the code will take this path.  Caller has to

	 * decide if it is an error or not.

/**

 * ixgbe_check_reset_blocked - check status of MNG FW veto bit

 * @hw: pointer to the hardware structure

 *

 * This function checks the MMNGC.MNG_VETO bit to see if there are

 * any constraints on link from manageability.  For MAC's that don't

 * have this bit just return false since the link can not be blocked

 * via this method.

 If we don't have this bit, it can't be blocking */

/**

 *  ixgbe_get_phy_id - Get the phy type

 *  @hw: pointer to hardware structure

 *

/**

 *  ixgbe_get_phy_type_from_id - Get the phy type

 *  @phy_id: hardware phy id

 *

/**

 *  ixgbe_reset_phy_generic - Performs a PHY reset

 *  @hw: pointer to hardware structure

 Don't reset PHY if it's shut down due to overtemp. */

 Blocked by MNG FW so bail */

	/*

	 * Perform soft PHY reset to the PHY_XS.

	 * This will cause a soft reset to the PHY

	/*

	 * Poll for reset bit to self-clear indicating reset is complete.

	 * Some PHYs could take up to 3 seconds to complete and need about

	 * 1.7 usec delay after the reset is complete.

/**

 *  ixgbe_read_phy_reg_mdi - read PHY register

 *  @hw: pointer to hardware structure

 *  @reg_addr: 32 bit address of PHY register to read

 *  @device_type: 5 bit device type

 *  @phy_data: Pointer to read data from PHY register

 *

 *  Reads a value from a specified PHY register without the SWFW lock

 Setup and write the address cycle command */

	/* Check every 10 usec to see if the address cycle completed.

	 * The MDI Command bit will clear when the operation is

	 * complete

	/* Address cycle complete, setup and write the read

	 * command

	/* Check every 10 usec to see if the address cycle

	 * completed. The MDI Command bit will clear when the

	 * operation is complete

	/* Read operation is complete.  Get the data

	 * from MSRWD

/**

 *  ixgbe_read_phy_reg_generic - Reads a value from a specified PHY register

 *  using the SWFW lock - this function is needed in most cases

 *  @hw: pointer to hardware structure

 *  @reg_addr: 32 bit address of PHY register to read

 *  @device_type: 5 bit device type

 *  @phy_data: Pointer to read data from PHY register

/**

 *  ixgbe_write_phy_reg_mdi - Writes a value to specified PHY register

 *  without SWFW lock

 *  @hw: pointer to hardware structure

 *  @reg_addr: 32 bit PHY register to write

 *  @device_type: 5 bit device type

 *  @phy_data: Data to write to the PHY register

 Put the data in the MDI single read and write data register*/

 Setup and write the address cycle command */

	/*

	 * Check every 10 usec to see if the address cycle completed.

	 * The MDI Command bit will clear when the operation is

	 * complete

	/*

	 * Address cycle complete, setup and write the write

	 * command

	/* Check every 10 usec to see if the address cycle

	 * completed. The MDI Command bit will clear when the

	 * operation is complete

/**

 *  ixgbe_write_phy_reg_generic - Writes a value to specified PHY register

 *  using SWFW lock- this function is needed in most cases

 *  @hw: pointer to hardware structure

 *  @reg_addr: 32 bit PHY register to write

 *  @device_type: 5 bit device type

 *  @phy_data: Data to write to the PHY register

/**

 *  ixgbe_msca_cmd - Write the command register and poll for completion/timeout

 *  @hw: pointer to hardware structure

 *  @cmd: command register value to write

/**

 *  ixgbe_mii_bus_read_generic - Read a clause 22/45 register with gssr flags

 *  @hw: pointer to hardware structure

 *  @addr: address

 *  @regnum: register number

 *  @gssr: semaphore flags to acquire

	/* For a clause 45 access the address cycle just completed, we still

	 * need to do the read command, otherwise just get the data

/**

 *  ixgbe_mii_bus_write_generic - Write a clause 22/45 register with gssr flags

 *  @hw: pointer to hardware structure

 *  @addr: address

 *  @regnum: register number

 *  @val: value to write

 *  @gssr: semaphore flags to acquire

	/* For clause 45 this is an address cycle, for clause 22 this is the

	 * entire transaction

/**

 *  ixgbe_mii_bus_read - Read a clause 22/45 register

 *  @bus: pointer to mii_bus structure which points to our driver private

 *  @addr: address

 *  @regnum: register number

/**

 *  ixgbe_mii_bus_write - Write a clause 22/45 register

 *  @bus: pointer to mii_bus structure which points to our driver private

 *  @addr: address

 *  @regnum: register number

 *  @val: value to write

/**

 *  ixgbe_x550em_a_mii_bus_read - Read a clause 22/45 register on x550em_a

 *  @bus: pointer to mii_bus structure which points to our driver private

 *  @addr: address

 *  @regnum: register number

/**

 *  ixgbe_x550em_a_mii_bus_write - Write a clause 22/45 register on x550em_a

 *  @bus: pointer to mii_bus structure which points to our driver private

 *  @addr: address

 *  @regnum: register number

 *  @val: value to write

/**

 * ixgbe_get_first_secondary_devfn - get first device downstream of root port

 * @devfn: PCI_DEVFN of root port on domain 0, bus 0

 *

 * Returns pci_dev pointer to PCI_DEVFN(0, 0) on subordinate side of root

 * on domain 0, bus 0, devfn = 'devfn'

/**

 * ixgbe_x550em_a_has_mii - is this the first ixgbe x550em_a PCI function?

 * @hw: pointer to hardware structure

 *

 * Returns true if hw points to lowest numbered PCI B:D.F x550_em_a device in

 * the SoC.  There are up to 4 MACs sharing a single MDIO bus on the x550em_a,

 * but we only want to register one MDIO bus.

	/* For the C3000 family of SoCs (x550em_a) the internal ixgbe devices

	 * are always downstream of root ports @ 0000:00:16.0 & 0000:00:17.0

	 * It's not valid for function 0 to be disabled and function 1 is up,

	 * so the lowest numbered ixgbe dev will be device 0 function 0 on one

	 * of those two root ports

/**

 * ixgbe_mii_bus_init - mii_bus structure setup

 * @hw: pointer to hardware structure

 *

 * Returns 0 on success, negative on failure

 *

 * ixgbe_mii_bus_init initializes a mii_bus structure in adapter

 C3000 SoCs */

 Use the position of the device in the PCI hierarchy as the id */

	/* Support clause 22/45 natively.  ixgbe_probe() sets MDIO_EMULATE_C22

	 * unfortunately that causes some clause 22 frames to be sent with

	 * clause 45 addressing.  We don't want that.

/**

 *  ixgbe_setup_phy_link_generic - Set and restart autoneg

 *  @hw: pointer to hardware structure

 *

 *  Restart autonegotiation and PHY and waits for completion.

 Set or unset auto-negotiation 10G advertisement */

 Set or unset auto-negotiation 5G advertisement */

 Set or unset auto-negotiation 2.5G advertisement */

 Set or unset auto-negotiation 1G advertisement */

 Set or unset auto-negotiation 100M advertisement */

 Blocked by MNG FW so don't reset PHY */

 Restart PHY autonegotiation and wait for completion */

/**

 *  ixgbe_setup_phy_link_speed_generic - Sets the auto advertised capabilities

 *  @hw: pointer to hardware structure

 *  @speed: new link speed

 *  @autoneg_wait_to_complete: unused

	/* Clear autoneg_advertised and set new values based on input link

	 * speed.

 Setup link based on the new speed settings */

/**

 * ixgbe_get_copper_speeds_supported - Get copper link speed from phy

 * @hw: pointer to hardware structure

 *

 * Determines the supported link capabilities by reading the PHY auto

 * negotiation register.

/**

 * ixgbe_get_copper_link_capabilities_generic - Determines link capabilities

 * @hw: pointer to hardware structure

 * @speed: pointer to link speed

 * @autoneg: boolean auto-negotiation value

/**

 *  ixgbe_check_phy_link_tnx - Determine link and speed status

 *  @hw: pointer to hardware structure

 *  @speed: link speed

 *  @link_up: status of link

 *

 *  Reads the VS1 register to determine if link is up and the current speed for

 *  the PHY.

 Initialize speed and link to default case */

	/*

	 * Check current speed and link status of the PHY register.

	 * This is a vendor specific register and may have to

	 * be changed for other copper PHYs.

/**

 *	ixgbe_setup_phy_link_tnx - Set and restart autoneg

 *	@hw: pointer to hardware structure

 *

 *	Restart autonegotiation and PHY and waits for completion.

 *      This function always returns success, this is nessary since

 *	it is called via a function pointer that could call other

 *	functions that could return an error.

 Set or unset auto-negotiation 10G advertisement */

 Set or unset auto-negotiation 1G advertisement */

 Set or unset auto-negotiation 100M advertisement */

 Blocked by MNG FW so don't reset PHY */

 Restart PHY autonegotiation and wait for completion */

/**

 *  ixgbe_reset_phy_nl - Performs a PHY reset

 *  @hw: pointer to hardware structure

 Blocked by MNG FW so bail */

 reset the PHY and poll for completion */

 Get init offsets */

		/*

		 * Read control word from PHY init contents offset

/**

 *  ixgbe_identify_module_generic - Identifies module type

 *  @hw: pointer to hardware structure

 *

 *  Determines HW type and calls appropriate function.

/**

 *  ixgbe_identify_sfp_module_generic - Identifies SFP modules

 *  @hw: pointer to hardware structure

 *

 *  Searches for and identifies the SFP module and assigns appropriate PHY type.

 LAN ID is needed for sfp_type determination */

	 /* ID Module

	  * =========

	  * 0   SFP_DA_CU

	  * 1   SFP_SR

	  * 2   SFP_LR

	  * 3   SFP_DA_CORE0 - 82599-specific

	  * 4   SFP_DA_CORE1 - 82599-specific

	  * 5   SFP_SR/LR_CORE0 - 82599-specific

	  * 6   SFP_SR/LR_CORE1 - 82599-specific

	  * 7   SFP_act_lmt_DA_CORE0 - 82599-specific

	  * 8   SFP_act_lmt_DA_CORE1 - 82599-specific

	  * 9   SFP_1g_cu_CORE0 - 82599-specific

	  * 10  SFP_1g_cu_CORE1 - 82599-specific

	  * 11  SFP_1g_sx_CORE0 - 82599-specific

	  * 12  SFP_1g_sx_CORE1 - 82599-specific

 Determine if the SFP+ PHY is dual speed or not. */

 Determine PHY vendor */

 Allow any DA cable vendor */

 Verify supported 1G SFP modules */

 Anything else 82598-based is supported */

 Make sure we're a supported PHY type */

/**

 * ixgbe_identify_qsfp_module_generic - Identifies QSFP modules

 * @hw: pointer to hardware structure

 *

 * Searches for and identifies the QSFP module and assigns appropriate PHY type

 LAN ID is needed for sfp_type determination */

			/* check for active DA cables that pre-date

			 * SFF-8436 v3.6

 unsupported module type */

 Determine if the QSFP+ PHY is dual speed or not. */

 Determine PHY vendor for optical modules */

 Make sure we're a supported PHY type */

/**

 *  ixgbe_get_sfp_init_sequence_offsets - Provides offset of PHY init sequence

 *  @hw: pointer to hardware structure

 *  @list_offset: offset to the SFP ID list

 *  @data_offset: offset to the SFP data block

 *

 *  Checks the MAC's EEPROM to see if it supports a given SFP+ module type, if

 *  so it returns the offsets to the phy init sequence block.

	/*

	 * Limiting active cables and 1G Phys must be initialized as

	 * SR modules

 Read offset to PHY init contents */

 Shift offset to first ID word */

	/*

	 * Find the matching SFP ID in the EEPROM

	 * and program the init sequence

/**

 *  ixgbe_read_i2c_eeprom_generic - Reads 8 bit EEPROM word over I2C interface

 *  @hw: pointer to hardware structure

 *  @byte_offset: EEPROM byte offset to read

 *  @eeprom_data: value read

 *

 *  Performs byte read operation to SFP module's EEPROM over I2C interface.

/**

 *  ixgbe_read_i2c_sff8472_generic - Reads 8 bit word over I2C interface

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset at address 0xA2

 *  @sff8472_data: value read

 *

 *  Performs byte read operation to SFP module's SFF-8472 data over I2C

/**

 *  ixgbe_write_i2c_eeprom_generic - Writes 8 bit EEPROM word over I2C interface

 *  @hw: pointer to hardware structure

 *  @byte_offset: EEPROM byte offset to write

 *  @eeprom_data: value to write

 *

 *  Performs byte write operation to SFP module's EEPROM over I2C interface.

/**

 * ixgbe_is_sfp_probe - Returns true if SFP is being detected

 * @hw: pointer to hardware structure

 * @offset: eeprom offset to be read

 * @addr: I2C address to be read

/**

 *  ixgbe_read_i2c_byte_generic_int - Reads 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to read

 *  @dev_addr: device address

 *  @data: value read

 *  @lock: true if to take and release semaphore

 *

 *  Performs byte read operation to SFP module's EEPROM over I2C interface at

 *  a specified device address.

 Device Address and write indication */

 Device Address and read indication */

/**

 *  ixgbe_read_i2c_byte_generic - Reads 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to read

 *  @dev_addr: device address

 *  @data: value read

 *

 *  Performs byte read operation to SFP module's EEPROM over I2C interface at

 *  a specified device address.

/**

 *  ixgbe_read_i2c_byte_generic_unlocked - Reads 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to read

 *  @dev_addr: device address

 *  @data: value read

 *

 *  Performs byte read operation to SFP module's EEPROM over I2C interface at

 *  a specified device address.

/**

 *  ixgbe_write_i2c_byte_generic_int - Writes 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to write

 *  @dev_addr: device address

 *  @data: value to write

 *  @lock: true if to take and release semaphore

 *

 *  Performs byte write operation to SFP module's EEPROM over I2C interface at

 *  a specified device address.

/**

 *  ixgbe_write_i2c_byte_generic - Writes 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to write

 *  @dev_addr: device address

 *  @data: value to write

 *

 *  Performs byte write operation to SFP module's EEPROM over I2C interface at

 *  a specified device address.

/**

 *  ixgbe_write_i2c_byte_generic_unlocked - Writes 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to write

 *  @dev_addr: device address

 *  @data: value to write

 *

 *  Performs byte write operation to SFP module's EEPROM over I2C interface at

 *  a specified device address.

/**

 *  ixgbe_i2c_start - Sets I2C start condition

 *  @hw: pointer to hardware structure

 *

 *  Sets I2C start condition (High -> Low on SDA while SCL is High)

 *  Set bit-bang mode on X550 hardware.

 Start condition must begin with data and clock high */

 Setup time for start condition (4.7us) */

 Hold time for start condition (4us) */

 Minimum low period of clock is 4.7 us */

/**

 *  ixgbe_i2c_stop - Sets I2C stop condition

 *  @hw: pointer to hardware structure

 *

 *  Sets I2C stop condition (Low -> High on SDA while SCL is High)

 *  Disables bit-bang mode and negates data output enable on X550

 *  hardware.

 Stop condition must begin with data low and clock high */

 Setup time for stop condition (4us) */

 bus free time between stop and start (4.7us)*/

/**

 *  ixgbe_clock_in_i2c_byte - Clocks in one byte via I2C

 *  @hw: pointer to hardware structure

 *  @data: data byte to clock in

 *

 *  Clocks in one byte data via I2C data/clock

/**

 *  ixgbe_clock_out_i2c_byte - Clocks out one byte via I2C

 *  @hw: pointer to hardware structure

 *  @data: data byte clocked out

 *

 *  Clocks out one byte data via I2C data/clock

 Release SDA line (set high) */

/**

 *  ixgbe_get_i2c_ack - Polls for I2C ACK

 *  @hw: pointer to hardware structure

 *

 *  Clocks in/out one bit via I2C data/clock

 Minimum high period of clock is 4us */

	/* Poll for ACK.  Note that ACK in I2C spec is

 Minimum low period of clock is 4.7 us */

/**

 *  ixgbe_clock_in_i2c_bit - Clocks in one bit via I2C data/clock

 *  @hw: pointer to hardware structure

 *  @data: read data value

 *

 *  Clocks in one bit via I2C data/clock

 Minimum high period of clock is 4us */

 Minimum low period of clock is 4.7 us */

/**

 *  ixgbe_clock_out_i2c_bit - Clocks in/out one bit via I2C data/clock

 *  @hw: pointer to hardware structure

 *  @data: data value to write

 *

 *  Clocks out one bit via I2C data/clock

 Minimum high period of clock is 4us */

		/* Minimum low period of clock is 4.7 us.

		 * This also takes care of the data hold time.

/**

 *  ixgbe_raise_i2c_clk - Raises the I2C SCL clock

 *  @hw: pointer to hardware structure

 *  @i2cctl: Current value of I2CCTL register

 *

 *  Raises the I2C clock line '0'->'1'

 *  Negates the I2C clock output enable on X550 hardware.

 SCL rise time (1000ns) */

/**

 *  ixgbe_lower_i2c_clk - Lowers the I2C SCL clock

 *  @hw: pointer to hardware structure

 *  @i2cctl: Current value of I2CCTL register

 *

 *  Lowers the I2C clock line '1'->'0'

 *  Asserts the I2C clock output enable on X550 hardware.

 SCL fall time (300ns) */

/**

 *  ixgbe_set_i2c_data - Sets the I2C data bit

 *  @hw: pointer to hardware structure

 *  @i2cctl: Current value of I2CCTL register

 *  @data: I2C data value (0 or 1) to set

 *

 *  Sets the I2C data bit

 *  Asserts the I2C data output enable on X550 hardware.

 Data rise/fall (1000ns/300ns) and set-up time (250ns) */

 Can't verify data in this case */

 Verify data was set correctly */

/**

 *  ixgbe_get_i2c_data - Reads the I2C SDA data bit

 *  @hw: pointer to hardware structure

 *  @i2cctl: Current value of I2CCTL register

 *

 *  Returns the I2C data bit value

 *  Negates the I2C data output enable on X550 hardware.

/**

 *  ixgbe_i2c_bus_clear - Clears the I2C bus

 *  @hw: pointer to hardware structure

 *

 *  Clears the I2C bus by sending nine clock pulses.

 *  Used when data line is stuck low.

 Min high period of clock is 4us */

 Min low period of clock is 4.7us*/

 Put the i2c bus back to default state */

/**

 *  ixgbe_tn_check_overtemp - Checks if an overtemp occurred.

 *  @hw: pointer to hardware structure

 *

 *  Checks if the LASI temp alarm status was triggered due to overtemp

 Check that the LASI temp alarm status was triggered */

/** ixgbe_set_copper_phy_power - Control power for copper phy

 *  @hw: pointer to hardware structure

 *  @on: true for on, false for off

 Bail if we don't have copper phy */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 *  ixgbe_set_pcie_completion_timeout - set pci-e completion timeout

 *  @hw: pointer to the HW structure

 *

 *  The defaults for 82598 should be in the range of 50us to 50ms,

 *  however the hardware default for these parts is 500us to 1ms which is less

 *  than the 10ms recommended by the pci-e spec.  To address this we need to

 *  increase the value to either 10ms to 250ms for capability version 1 config,

 *  or 16ms to 55ms for version 2.

 only take action if timeout value is defaulted to 0 */

	/*

	 * if capababilities version is type 1 we can write the

	 * timeout of 10ms to 250ms through the GCR register

	/*

	 * for version 2 capabilities we need to write the config space

	 * directly in order to set the completion timeout value for

	 * 16ms to 55ms

 disable completion timeout resend */

 Call PHY identify routine to get the phy type */

/**

 *  ixgbe_init_phy_ops_82598 - PHY/SFP specific init

 *  @hw: pointer to hardware structure

 *

 *  Initialize any function pointers that were not able to be

 *  set during get_invariants because the PHY/SFP type was

 *  not known.  Perform the SFP init if necessary.

 *

 Identify the PHY */

 Overwrite the link function pointers if copper PHY */

 Call SFP+ identify routine to get the SFP+ module type */

 Check to see if SFP+ module is supported */

/**

 *  ixgbe_start_hw_82598 - Prepare hardware for Tx/Rx

 *  @hw: pointer to hardware structure

 *

 *  Starts the hardware using the generic start_hw function.

 *  Disables relaxed ordering for archs other than SPARC

 *  Then set pcie completion timeout

 *

 set the completion timeout for interface */

/**

 *  ixgbe_get_link_capabilities_82598 - Determines link capabilities

 *  @hw: pointer to hardware structure

 *  @speed: pointer to link speed

 *  @autoneg: boolean auto-negotiation value

 *

 *  Determines the link capabilities by reading the AUTOC register.

	/*

	 * Determine link capabilities based on the stored value of AUTOC,

	 * which represents EEPROM defaults.  If AUTOC value has not been

	 * stored, use the current register value.

/**

 *  ixgbe_get_media_type_82598 - Determines media type

 *  @hw: pointer to hardware structure

 *

 *  Returns the media type (fiber, copper, backplane)

 Detect if there is a copper PHY attached. */

 Media type for I82598 is based on device ID */

 Default device ID is mezzanine card KX/KX4 */

/**

 *  ixgbe_fc_enable_82598 - Enable flow control

 *  @hw: pointer to hardware structure

 *

 *  Enable flow control according to the current settings.

 Validate the water mark configuration */

 Low water mark of zero causes XOFF floods */

	/*

	 * On 82598 having Rx FC on causes resets while doing 1G

	 * so if it's on turn it off once we know link_speed. For

	 * more details see 82598 Specification update.

 no change */

 Negotiate the fc mode to use */

 Disable any previous flow control settings */

	/*

	 * The possible values of fc.current_mode are:

	 * 0: Flow control is completely disabled

	 * 1: Rx flow control is enabled (we can receive pause frames,

	 *    but not send pause frames).

	 * 2: Tx flow control is enabled (we can send pause frames but

	 *     we do not support receiving pause frames).

	 * 3: Both Rx and Tx flow control (symmetric) are enabled.

	 * other: Invalid.

		/*

		 * Flow control is disabled by software override or autoneg.

		 * The code below will actually disable it in the HW.

		/*

		 * Rx Flow control is enabled and Tx Flow control is

		 * disabled by software override. Since there really

		 * isn't a way to advertise that we are capable of RX

		 * Pause ONLY, we will advertise that we support both

		 * symmetric and asymmetric Rx PAUSE.  Later, we will

		 * disable the adapter's ability to send PAUSE frames.

		/*

		 * Tx Flow control is enabled, and Rx Flow control is

		 * disabled by software override.

 Flow control (both Rx and Tx) is enabled by SW override. */

 Set 802.3x based flow control settings. */

 Set up and enable Rx high/low water mark thresholds, enable XON. */

 Configure pause time (2 TCs per register) */

 Configure flow control refresh threshold value */

/**

 *  ixgbe_start_mac_link_82598 - Configures MAC link settings

 *  @hw: pointer to hardware structure

 *  @autoneg_wait_to_complete: true when waiting for completion is needed

 *

 *  Configures link settings based on values in the ixgbe_hw struct.

 *  Restarts the link.  Performs autonegotiation if needed.

 Restart link */

 Only poll for autoneg to complete if specified to do so */

 Just in case Autoneg time = 0 */

 Add delay to filter out noises during initial link setup */

/**

 *  ixgbe_validate_link_ready - Function looks for phy link

 *  @hw: pointer to hardware structure

 *

 *  Function indicates success when phy link is available. If phy is not ready

 *  within 5 seconds of MAC indicating link, the function returns error.

/**

 *  ixgbe_check_mac_link_82598 - Get link/speed status

 *  @hw: pointer to hardware structure

 *  @speed: pointer to link speed

 *  @link_up: true is link is up, false otherwise

 *  @link_up_wait_to_complete: bool used to wait for link up or not

 *

 *  Reads the links register to determine if link is up and the current speed

	/*

	 * SERDES PHY requires us to read link status from register 0xC79F.

	 * Bit 0 set indicates link is up/ready; clear indicates link down.

	 * 0xC00C is read to check that the XAUI lanes are active.  Bit 0

	 * clear indicates active; set indicates inactive.

/**

 *  ixgbe_setup_mac_link_82598 - Set MAC link speed

 *  @hw: pointer to hardware structure

 *  @speed: new link speed

 *  @autoneg_wait_to_complete: true when waiting for completion is needed

 *

 *  Set the link speed in the AUTOC register and restarts link.

 Check to see if speed passed in is supported. */

 Set KX4/KX support according to speed requested */

	/* Setup and restart the link based on the new values in

	 * ixgbe_hw This will write the AUTOC register based on the new

	 * stored values

/**

 *  ixgbe_setup_copper_link_82598 - Set the PHY autoneg advertised field

 *  @hw: pointer to hardware structure

 *  @speed: new link speed

 *  @autoneg_wait_to_complete: true if waiting is needed to complete

 *

 *  Sets the link speed in the AUTOC register in the MAC and restarts link.

 Setup the PHY according to input speed */

 Set up MAC */

/**

 *  ixgbe_reset_hw_82598 - Performs hardware reset

 *  @hw: pointer to hardware structure

 *

 *  Resets the hardware by resetting the transmit and receive units, masks and

 *  clears all interrupts, performing a PHY reset, and performing a link (MAC)

 *  reset.

 Call adapter stop to disable tx/rx and clear interrupts */

	/*

	 * Power up the Atlas Tx lanes if they are currently powered down.

	 * Atlas Tx lanes are powered down for MAC loopback tests, but

	 * they are not automatically restored on reset.

 Enable Tx Atlas so packets can be transmitted again */

 Reset PHY */

 PHY ops must be identified and initialized prior to reset */

 Init PHY and function pointers, perform SFP setup */

	/*

	 * Issue global reset to the MAC.  This needs to be a SW reset.

	 * If link reset is used, it might reset the MAC when mng is using it

 Poll for reset bit to self-clear indicating reset is complete */

	/*

	 * Double resets are required for recovery from certain error

	 * conditions.  Between resets, it is necessary to stall to allow time

	 * for any pending HW events to complete.

	/*

	 * Store the original AUTOC value if it has not been

	 * stored off yet.  Otherwise restore the stored original

	 * AUTOC value since the reset operation sets back to deaults.

 Store the permanent mac address */

	/*

	 * Store MAC address from RAR0, clear receive address registers, and

	 * clear the multicast table

/**

 *  ixgbe_set_vmdq_82598 - Associate a VMDq set index with a rx address

 *  @hw: pointer to hardware struct

 *  @rar: receive address register index to associate with a VMDq index

 *  @vmdq: VMDq set index

 Make sure we are using a valid rar index range */

/**

 *  ixgbe_clear_vmdq_82598 - Disassociate a VMDq set index from an rx address

 *  @hw: pointer to hardware struct

 *  @rar: receive address register index to associate with a VMDq index

 *  @vmdq: VMDq clear index (not used in 82598, but elsewhere)

 Make sure we are using a valid rar index range */

/**

 *  ixgbe_set_vfta_82598 - Set VLAN filter table

 *  @hw: pointer to hardware structure

 *  @vlan: VLAN id to write to VLAN filter

 *  @vind: VMDq output index that maps queue to VLAN id in VFTA

 *  @vlan_on: boolean flag to turn on/off VLAN in VFTA

 *  @vlvf_bypass: boolean flag - unused

 *

 *  Turn on/off specified VLAN in the VLAN filter table.

 Determine 32-bit word position in array */

 upper seven bits */

 Determine the location of the (VMD) queue index */

 bits (4:3) indicating byte array */

 lower 3 bits indicate nibble */

 Set the nibble for VMD queue index */

 Determine the location of the bit for this VLAN id */

 lower five bits */

 Turn on this VLAN id */

 Turn off this VLAN id */

/**

 *  ixgbe_clear_vfta_82598 - Clear VLAN filter table

 *  @hw: pointer to hardware structure

 *

 *  Clears the VLAN filer table, and the VMDq index associated with the filter

/**

 *  ixgbe_read_analog_reg8_82598 - Reads 8 bit Atlas analog register

 *  @hw: pointer to hardware structure

 *  @reg: analog register to read

 *  @val: read value

 *

 *  Performs read operation to Atlas analog register specified.

/**

 *  ixgbe_write_analog_reg8_82598 - Writes 8 bit Atlas analog register

 *  @hw: pointer to hardware structure

 *  @reg: atlas register to write

 *  @val: value to write

 *

 *  Performs write operation to Atlas analog register specified.

/**

 *  ixgbe_read_i2c_phy_82598 - Reads 8 bit word over I2C interface.

 *  @hw: pointer to hardware structure

 *  @dev_addr: address to read from

 *  @byte_offset: byte offset to read from dev_addr

 *  @eeprom_data: value read

 *

 *  Performs 8 byte read operation to SFP module's data over I2C interface.

		/*

		 * phy SDA/SCL registers are at addresses 0xC30A to

		 * 0xC30D.  These registers are used to talk to the SFP+

		 * module's EEPROM through the SDA/SCL (I2C) interface.

 Poll status */

 Read data */

/**

 *  ixgbe_read_i2c_eeprom_82598 - Reads 8 bit word over I2C interface.

 *  @hw: pointer to hardware structure

 *  @byte_offset: EEPROM byte offset to read

 *  @eeprom_data: value read

 *

 *  Performs 8 byte read operation to SFP module's EEPROM over I2C interface.

/**

 *  ixgbe_read_i2c_sff8472_82598 - Reads 8 bit word over I2C interface.

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset at address 0xA2

 *  @sff8472_data: value read

 *

 *  Performs 8 byte read operation to SFP module's SFF-8472 data over I2C

/**

 *  ixgbe_set_lan_id_multi_port_pcie_82598 - Set LAN id for PCIe multiple

 *  port devices.

 *  @hw: pointer to the HW structure

 *

 *  Calls common function and corrects issue with some single port devices

 *  that enable LAN1 but not LAN0.

 check if LAN0 is disabled */

 if LAN0 is completely disabled force function to 0 */

/**

 * ixgbe_set_rxpba_82598 - Initialize RX packet buffer

 * @hw: pointer to hardware structure

 * @num_pb: number of packet buffers to allocate

 * @headroom: reserve n KB of headroom

 * @strategy: packet buffer allocation strategy

 Setup Rx packet buffer sizes */

 Setup the first four at 80KB */

 Setup the last four at 48KB...don't re-init i */

 Divide the remaining Rx packet buffer evenly among the TCs */

 Setup Tx packet buffer sizes */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 Callbacks for DCB netlink in the kernel */

 Responses for the DCB_C_SET_ALL command */

 DCB configuration changed with reset */

 DCB configuration did not change */

 DCB configuration changed, no reset */

 Fail command if not in CEE mode */

 verify there is something to do, if not then exit */

 Fail command if not in CEE mode */

 Priority to TC mapping in CEE case default to 1:1 */

	/* Reprogram FCoE hardware offloads when the traffic class

	 * FCoE is using changes. This happens if the APP info

	 * changes or the up2tc mapping is updated.

/**

 * ixgbe_dcbnl_getapp - retrieve the DCBX application user priority

 * @netdev : the corresponding netdev

 * @idtype : identifies the id as ether type or TCP/UDP port number

 * @id: id is either ether type or TCP/UDP port number

 *

 * Returns : on success, returns a non-zero 802.1p user priority bitmap

 * otherwise returns -EINVAL as the invalid user priority bitmap to indicate an

 * error.

 No IEEE PFC settings available */

 initialize UP2TC mappings to invalid value */

 if possible update UP2TC mappings from HW */

 No IEEE PFC settings available */

 Enable link flow control parameters if PFC is disabled */

 VF devices should use default UP when available */

 IF default priority is being removed clear VF default UP */

 no support for LLD_MANAGED modes or CEE+IEEE */

 ETS and PFC defaults */

		/* Drop into single TC mode strict priority as this

		 * indicates CEE and IEEE versions are disabled

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

	/* enable the laser control functions for SFP+ fiber

	 * and MNG not enabled

 Set up dual speed SFP+ support */

 PHY config will finish before releasing the semaphore */

 Release the semaphore */

		/*

		 * Delay obtaining semaphore again to allow FW access,

		 * semaphore_delay is in ms usleep_range needs us.

 Restart DSP and set SFI mode */

 Release the semaphore */

	/* Delay obtaining semaphore again to allow FW access,

	 * semaphore_delay is in ms usleep_range needs us.

/**

 *  prot_autoc_read_82599 - Hides MAC differences needed for AUTOC read

 *  @hw: pointer to hardware structure

 *  @locked: Return the if we locked for this read.

 *  @reg_val: Value we read from AUTOC

 *

 *  For this part (82599) we need to wrap read-modify-writes with a possible

 *  FW/SW lock.  It is assumed this lock will be freed with the next

 *  prot_autoc_write_82599().  Note, that locked can only be true in cases

 *  where this function doesn't return an error.

 If LESM is on then we need to hold the SW/FW semaphore. */

/**

 * prot_autoc_write_82599 - Hides MAC differences needed for AUTOC write

 * @hw: pointer to hardware structure

 * @autoc: value to write to AUTOC

 * @locked: bool to indicate whether the SW/FW lock was already taken by

 *	     previous proc_autoc_read_82599.

 *

 * This part (82599) may need to hold a the SW/FW lock around all writes to

 * AUTOC. Likewise after a write we need to do a pipeline reset.

 Blocked by MNG FW so bail */

	/* We only need to get the lock if:

	 *  - We didn't do it already (in the read part of a read-modify-write)

	 *  - LESM is enabled.

	/* Free the SW/FW semaphore as we either grabbed it here or

	 * already had it when this function was called.

/**

 *  ixgbe_init_phy_ops_82599 - PHY/SFP specific init

 *  @hw: pointer to hardware structure

 *

 *  Initialize any function pointers that were not able to be

 *  set during get_invariants because the PHY/SFP type was

 *  not known.  Perform the SFP init if necessary.

 *

 Store flag indicating I2C bus access control unit. */

 Initialize access to QSFP+ I2C bus */

 Identify the PHY or SFP module */

 Setup function pointers based on detected SFP module and speeds */

 If copper media, overwrite with copper function pointers */

 Set necessary function pointers based on phy type */

/**

 *  ixgbe_get_link_capabilities_82599 - Determines link capabilities

 *  @hw: pointer to hardware structure

 *  @speed: pointer to link speed

 *  @autoneg: true when autoneg or autotry is enabled

 *

 *  Determines the link capabilities by reading the AUTOC register.

 Determine 1G link capabilities off of SFP+ type */

	/*

	 * Determine link capabilities based on the stored value of AUTOC,

	 * which represents EEPROM defaults.  If AUTOC value has not been

	 * stored, use the current register value.

 QSFP must not enable auto-negotiation */

/**

 *  ixgbe_get_media_type_82599 - Get media type

 *  @hw: pointer to hardware structure

 *

 *  Returns the media type (fiber, copper, backplane)

 Detect if there is a copper PHY attached. */

 Default device ID is mezzanine card KX/KX4 */

/**

 * ixgbe_stop_mac_link_on_d3_82599 - Disables link on D3

 * @hw: pointer to hardware structure

 *

 * Disables link, should be called during D3 power down sequence.

 *

/**

 *  ixgbe_start_mac_link_82599 - Setup MAC link settings

 *  @hw: pointer to hardware structure

 *  @autoneg_wait_to_complete: true when waiting for completion is needed

 *

 *  Configures link settings based on values in the ixgbe_hw struct.

 *  Restarts the link.  Performs autonegotiation if needed.

 Restart link */

 Only poll for autoneg to complete if specified to do so */

 Just in case Autoneg time = 0 */

 Add delay to filter out noises during initial link setup */

/**

 *  ixgbe_disable_tx_laser_multispeed_fiber - Disable Tx laser

 *  @hw: pointer to hardware structure

 *

 *  The base drivers may require better control over SFP+ module

 *  PHY states.  This includes selectively shutting down the Tx

 *  laser on the PHY, effectively halting physical link.

 Blocked by MNG FW so bail */

 Disable tx laser; allow 100us to go dark per spec */

/**

 *  ixgbe_enable_tx_laser_multispeed_fiber - Enable Tx laser

 *  @hw: pointer to hardware structure

 *

 *  The base drivers may require better control over SFP+ module

 *  PHY states.  This includes selectively turning on the Tx

 *  laser on the PHY, effectively starting physical link.

 Enable tx laser; allow 100ms to light up */

/**

 *  ixgbe_flap_tx_laser_multispeed_fiber - Flap Tx laser

 *  @hw: pointer to hardware structure

 *

 *  When the driver changes the link speeds that it can support,

 *  it sets autotry_restart to true to indicate that we need to

 *  initiate a new autotry session with the link partner.  To do

 *  so, we set the speed then disable and re-enable the tx laser, to

 *  alert the link partner that it also needs to restart autotry on its

 *  end.  This is consistent with true clause 37 autoneg, which also

 *  involves a loss of signal.

 Blocked by MNG FW so bail */

/**

 * ixgbe_set_hard_rate_select_speed - Set module link speed

 * @hw: pointer to hardware structure

 * @speed: link speed to set

 *

 * Set module link speed via RS0/RS1 rate select pins.

/**

 *  ixgbe_setup_mac_link_smartspeed - Set MAC link speed using SmartSpeed

 *  @hw: pointer to hardware structure

 *  @speed: new link speed

 *  @autoneg_wait_to_complete: true when waiting for completion is needed

 *

 *  Implements the Intel SmartSpeed algorithm.

 Set autoneg_advertised value based on input link speed */

	/*

	 * Implement Intel SmartSpeed algorithm.  SmartSpeed will reduce the

	 * autoneg advertisement if link is unable to be established at the

	 * highest negotiated rate.  This can sometimes happen due to integrity

	 * issues with the physical media connection.

 First, try to get link with full advertisement */

		/*

		 * Wait for the controller to acquire link.  Per IEEE 802.3ap,

		 * Section 73.10.2, we may have to wait up to 500ms if KR is

		 * attempted, or 200ms if KX/KX4/BX/BX4 is attempted, per

		 * Table 9 in the AN MAS.

 If we have link, just jump out */

	/*

	 * We didn't get link.  If we advertised KR plus one of KX4/KX

	 * (or BX4/BX), then disable KR and try again.

 Turn SmartSpeed on to disable KR support */

	/*

	 * Wait for the controller to acquire link.  600ms will allow for

	 * the AN link_fail_inhibit_timer as well for multiple cycles of

	 * parallel detect, both 10g and 1g. This allows for the maximum

	 * connect attempts as defined in the AN MAS table 73-7.

 If we have link, just jump out */

 We didn't get link.  Turn SmartSpeed back off. */

/**

 *  ixgbe_setup_mac_link_82599 - Set MAC link speed

 *  @hw: pointer to hardware structure

 *  @speed: new link speed

 *  @autoneg_wait_to_complete: true when waiting for completion is needed

 *

 *  Set the link speed in the AUTOC register and restarts link.

 holds the value of AUTOC register at this current point in time */

 holds the cached value of AUTOC register */

 temporary variable used for comparison purposes */

 Check to see if speed passed in is supported. */

 Use stored value (EEPROM defaults) of AUTOC to find KR/KX4 support*/

 Set KX4/KX/KR support according to speed requested */

 Switch from 1G SFI to 10G SFI if requested */

 Switch from 10G SFI to 1G SFI if requested */

 Restart link */

 Only poll for autoneg to complete if specified to do so */

Just in case Autoneg time=0*/

 Add delay to filter out noises during initial link setup */

/**

 *  ixgbe_setup_copper_link_82599 - Set the PHY autoneg advertised field

 *  @hw: pointer to hardware structure

 *  @speed: new link speed

 *  @autoneg_wait_to_complete: true if waiting is needed to complete

 *

 *  Restarts link on PHY and MAC based on settings passed in.

 Setup the PHY according to input speed */

 Set up MAC */

/**

 *  ixgbe_reset_hw_82599 - Perform hardware reset

 *  @hw: pointer to hardware structure

 *

 *  Resets the hardware by resetting the transmit and receive units, masks

 *  and clears all interrupts, perform a PHY reset, and perform a link (MAC)

 *  reset.

 Call adapter stop to disable tx/rx and clear interrupts */

 flush pending Tx transactions */

 PHY ops must be identified and initialized prior to reset */

 Identify PHY and related function pointers */

 Setup SFP module if there is one present. */

 Reset PHY */

 remember AUTOC from before we reset */

	/*

	 * Issue global reset to the MAC. Needs to be SW reset if link is up.

	 * If link reset is used when link is up, it might reset the PHY when

	 * mng is using it.  If link is down or the flag to force full link

	 * reset is set, then perform link reset.

 Poll for reset bit to self-clear indicating reset is complete */

	/*

	 * Double resets are required for recovery from certain error

	 * conditions.  Between resets, it is necessary to stall to allow time

	 * for any pending HW events to complete.

	/*

	 * Store the original AUTOC/AUTOC2 values if they have not been

	 * stored off yet.  Otherwise restore the stored original

	 * values since the reset operation sets back to defaults.

 Enable link if disabled in NVM */

		/* If MNG FW is running on a multi-speed device that

		 * doesn't autoneg with out driver support we need to

		 * leave LMS in the state it was before we MAC reset.

		 * Likewise if we support WoL we don't want change the

		 * LMS state either.

 Store the permanent mac address */

	/*

	 * Store MAC address from RAR0, clear receive address registers, and

	 * clear the multicast table.  Also reset num_rar_entries to 128,

	 * since we modify this value when programming the SAN MAC address.

 Store the permanent SAN mac address */

 Add the SAN MAC address to the RAR only if it's a valid address */

 Save the SAN MAC RAR index */

 clear VMDq pool/queue selection for this RAR */

 Reserve the last RAR for the SAN MAC address */

 Store the alternative WWNN/WWPN prefix */

/**

 * ixgbe_fdir_check_cmd_complete - poll to check whether FDIRCMD is complete

 * @hw: pointer to hardware structure

 * @fdircmd: current value of FDIRCMD register

/**

 *  ixgbe_reinit_fdir_tables_82599 - Reinitialize Flow Director tables.

 *  @hw: pointer to hardware structure

	/*

	 * Before starting reinitialization process,

	 * FDIRCMD.CMD must be zero.

	/*

	 * 82599 adapters flow director init flow cannot be restarted,

	 * Workaround 82599 silicon errata by performing the following steps

	 * before re-writing the FDIRCTRL control register with the same value.

	 * - write 1 to bit 8 of FDIRCMD register &

	 * - write 0 to bit 8 of FDIRCMD register

	/*

	 * Clear FDIR Hash register to clear any leftover hashes

	 * waiting to be programmed.

 Poll init-done after we write FDIRCTRL register */

 Clear FDIR statistics registers (read to clear) */

/**

 *  ixgbe_fdir_enable_82599 - Initialize Flow Director control registers

 *  @hw: pointer to hardware structure

 *  @fdirctrl: value to write to flow director control register

 Prime the keys for hashing */

	/*

	 * Poll init-done after we write the register.  Estimated times:

	 *      10G: PBALLOC = 11b, timing is 60us

	 *       1G: PBALLOC = 11b, timing is 600us

	 *     100M: PBALLOC = 11b, timing is 6ms

	 *

	 *     Multiple these timings by 4 if under full Rx load

	 *

	 * So we'll poll for IXGBE_FDIR_INIT_DONE_POLL times, sleeping for

	 * 1 msec per poll time.  If we're at line rate and drop to 100M, then

	 * this might not finish in our poll time, but we can live with that

	 * for now.

/**

 *  ixgbe_init_fdir_signature_82599 - Initialize Flow Director signature filters

 *  @hw: pointer to hardware structure

 *  @fdirctrl: value to write to flow director control register, initially

 *             contains just the value of the Rx packet buffer allocation

	/*

	 * Continue setup of fdirctrl register bits:

	 *  Move the flexible bytes to use the ethertype - shift 6 words

	 *  Set the maximum length per hash bucket to 0xA filters

	 *  Send interrupt when 64 filters are left

 write hashes and fdirctrl register, poll for completion */

/**

 *  ixgbe_init_fdir_perfect_82599 - Initialize Flow Director perfect filters

 *  @hw: pointer to hardware structure

 *  @fdirctrl: value to write to flow director control register, initially

 *             contains just the value of the Rx packet buffer allocation

	/*

	 * Continue setup of fdirctrl register bits:

	 *  Turn perfect match filtering on

	 *  Initialize the drop queue

	 *  Move the flexible bytes to use the ethertype - shift 6 words

	 *  Set the maximum length per hash bucket to 0xA filters

	 *  Send interrupt when 64 (0x4 * 16) filters are left

 write hashes and fdirctrl register, poll for completion */

/*

 * These defines allow us to quickly generate all of the necessary instructions

 * in the function below by simply calling out IXGBE_COMPUTE_SIG_HASH_ITERATION

 * for values 0 through 15

/**

 *  ixgbe_atr_compute_sig_hash_82599 - Compute the signature hash

 *  @input: input bitstream to compute the hash on

 *  @common: compressed common input dword

 *

 *  This function is almost identical to the function above but contains

 *  several optimizations such as unwinding all of the loops, letting the

 *  compiler work out all of the conditional ifs since the keys are static

 *  defines, and computing two keys at once since the hashed dword stream

 *  will be the same for both keys.

 record the flow_vm_vlan bits as they are a key part to the hash */

 generate common hash dword */

 low dword is word swapped version of common */

 apply flow ID/VM pool/VLAN ID bits to hash words */

 Process bits 0 and 16 */

	/*

	 * apply flow ID/VM pool/VLAN ID bits to lo hash dword, we had to

	 * delay this because bit 0 of the stream should not be processed

	 * so we do not add the vlan until after bit 0 was processed

 Process remaining 30 bit of the key */

 combine common_hash result with signature and bucket hashes */

 return completed signature hash */

/**

 *  ixgbe_fdir_add_signature_filter_82599 - Adds a signature hash filter

 *  @hw: pointer to hardware structure

 *  @input: unique input dword

 *  @common: compressed common input dword

 *  @queue: queue index to direct traffic to

 *

 * Note that the tunnel bit in input must not be set when the hardware

 * tunneling support does not exist.

	/*

	 * Get the flow_type in order to program FDIRCMD properly

	 * lowest 2 bits are FDIRCMD.L4TYPE, third lowest bit is FDIRCMD.IPV6

 configure FDIRCMD register */

	/*

	 * The lower 32-bits of fdirhashcmd is for FDIRHASH, the upper 32-bits

	 * is for FDIRCMD.  Then do a 64-bit register write from FDIRHASH.

/**

 *  ixgbe_atr_compute_perfect_hash_82599 - Compute the perfect filter hash

 *  @input: input bitstream to compute the hash on

 *  @input_mask: mask for the input bitstream

 *

 *  This function serves two main purposes.  First it applies the input_mask

 *  to the atr_input resulting in a cleaned up atr_input data stream.

 *  Secondly it computes the hash and stores it in the bkt_hash field at

 *  the end of the input byte stream.  This way it will be available for

 *  future use without needing to recompute the hash.

 Apply masks to input data */

 record the flow_vm_vlan bits as they are a key part to the hash */

 generate common hash dword */

 low dword is word swapped version of common */

 apply flow ID/VM pool/VLAN ID bits to hash words */

 Process bits 0 and 16 */

	/*

	 * apply flow ID/VM pool/VLAN ID bits to lo hash dword, we had to

	 * delay this because bit 0 of the stream should not be processed

	 * so we do not add the vlan until after bit 0 was processed

 Process remaining 30 bit of the key */

	/*

	 * Limit hash to 13 bits since max bucket count is 8K.

	 * Store result at the end of the input stream.

/**

 *  ixgbe_get_fdirtcpm_82599 - generate a tcp port from atr_input_masks

 *  @input_mask: mask to be bit swapped

 *

 *  The source and destination port masks for flow director are bit swapped

 *  in that bit 15 effects bit 0, 14 effects 1, 13, 2 etc.  In order to

 *  generate a correctly swapped value we need to bit swap the mask and that

 *  is what is accomplished by this function.

/*

 * These two macros are meant to address the fact that we have registers

 * that are either all or in part big-endian.  As a result on big-endian

 * systems we will end up byte swapping the value to little-endian before

 * it is byte swapped again and written to the hardware in the original

 * big-endian format.

 mask IPv6 since it is currently not supported */

	/*

	 * Program the relevant mask registers.  If src/dst_port or src/dst_addr

	 * are zero, then assume a full mask for that field.  Also assume that

	 * a VLAN of 0 is unspecified, so mask that out as well.  L4type

	 * cannot be masked out in this implementation.

	 *

	 * This also assumes IPv4 only.  IPv6 masking isn't supported at this

	 * point in time.

 verify bucket hash is cleared on hash generation */

 Program FDIRM and verify partial masks */

 mask VLAN ID */

 mask VLAN priority */

 mask VLAN ID only */

 no VLAN fields masked */

 Mask Flex Bytes */

 Now mask VM pool and destination IPv6 - bits 5 and 2 */

 store the TCP/UDP port masks, bit reversed from port layout */

 write both the same so that UDP and TCP use the same mask */

 also use it for SCTP */

 store source and destination IP masks (big-enian) */

 currently IPv6 is not supported, must be programmed with 0 */

 record the source address (big-endian) */

 record the first 32 bits of the destination address (big-endian) */

 record source and destination port (little-endian)*/

 record vlan (little-endian) and flex_bytes(big-endian) */

 configure FDIRHASH register */

	/*

	 * flush all previous writes to make certain registers are

	 * programmed prior to issuing the command

 configure FDIRCMD register */

 configure FDIRHASH register */

 flush hash to HW */

 Query if filter is present */

 if filter exists in hardware then remove it */

/**

 *  ixgbe_read_analog_reg8_82599 - Reads 8 bit Omer analog register

 *  @hw: pointer to hardware structure

 *  @reg: analog register to read

 *  @val: read value

 *

 *  Performs read operation to Omer analog register specified.

/**

 *  ixgbe_write_analog_reg8_82599 - Writes 8 bit Omer analog register

 *  @hw: pointer to hardware structure

 *  @reg: atlas register to write

 *  @val: value to write

 *

 *  Performs write operation to Omer analog register specified.

/**

 *  ixgbe_start_hw_82599 - Prepare hardware for Tx/Rx

 *  @hw: pointer to hardware structure

 *

 *  Starts the hardware using the generic start_hw function

 *  and the generation start_hw function.

 *  Then performs revision-specific operations, if any.

 We need to run link autotry after the driver loads */

/**

 *  ixgbe_identify_phy_82599 - Get physical layer module

 *  @hw: pointer to hardware structure

 *

 *  Determines the physical layer module found on the current adapter.

 *  If PHY already detected, maintains current PHY type in hw struct,

 *  otherwise executes the PHY detection routine.

 Detect PHY if not unknown - returns success if already detected. */

 82599 10GBASE-T requires an external PHY */

 Set PHY type none if no PHY detected */

 Return error if SFP module has been detected but is not supported */

/**

 *  ixgbe_enable_rx_dma_82599 - Enable the Rx DMA unit on 82599

 *  @hw: pointer to hardware structure

 *  @regval: register value to write to RXCTRL

 *

 *  Enables the Rx DMA unit for 82599

	/*

	 * Workaround for 82599 silicon errata when enabling the Rx datapath.

	 * If traffic is incoming before we enable the Rx unit, it could hang

	 * the Rx DMA unit.  Therefore, make sure the security engine is

	 * completely disabled prior to enabling the Rx unit.

/**

 *  ixgbe_verify_fw_version_82599 - verify fw version for 82599

 *  @hw: pointer to hardware structure

 *

 *  Verifies that installed the firmware version is 0.6 or higher

 *  for SFI devices. All 82599 SFI devices should have version 0.6 or higher.

 *

 *  Returns IXGBE_ERR_EEPROM_VERSION if the FW is not present or

 *  if the FW version is not supported.

 firmware check is only necessary for SFI devices */

 get the offset to the Firmware Module block */

 get the offset to the Pass Through Patch Configuration block */

 get the firmware version */

/**

 *  ixgbe_verify_lesm_fw_enabled_82599 - Checks LESM FW module state.

 *  @hw: pointer to hardware structure

 *

 *  Returns true if the LESM FW module is present and enabled. Otherwise

 *  returns false. Smart Speed must be disabled if LESM FW module is enabled.

 get the offset to the Firmware Module block */

 get the offset to the LESM Parameters block */

 get the lesm state word */

/**

 *  ixgbe_read_eeprom_buffer_82599 - Read EEPROM word(s) using

 *  fastest available method

 *

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in EEPROM to read

 *  @words: number of words

 *  @data: word(s) read from the EEPROM

 *

 *  Retrieves 16 bit word(s) read from EEPROM

	/* If EEPROM is detected and can be addressed using 14 bits,

	 * use EERD otherwise use bit bang

/**

 *  ixgbe_read_eeprom_82599 - Read EEPROM word using

 *  fastest available method

 *

 *  @hw: pointer to hardware structure

 *  @offset: offset of  word in the EEPROM to read

 *  @data: word read from the EEPROM

 *

 *  Reads a 16 bit word from the EEPROM

	/*

	 * If EEPROM is detected and can be addressed using 14 bits,

	 * use EERD otherwise use bit bang

/**

 * ixgbe_reset_pipeline_82599 - perform pipeline reset

 *

 * @hw: pointer to hardware structure

 *

 * Reset pipeline by asserting Restart_AN together with LMS change to ensure

 * full pipeline reset.  Note - We must hold the SW/FW semaphore before writing

 * to AUTOC, so this function assumes the semaphore is held.

 Enable link if disabled in NVM */

 Write AUTOC register with toggled LMS[2] bit and Restart_AN */

 Wait for AN to leave state 0 */

 Write AUTOC register with original LMS field and Restart_AN */

/**

 *  ixgbe_read_i2c_byte_82599 - Reads 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to read

 *  @dev_addr: address to read from

 *  @data: value read

 *

 *  Performs byte read operation to SFP module's EEPROM over I2C interface at

 *  a specified device address.

 Acquire I2C bus ownership. */

 Release I2C bus ownership. */

/**

 *  ixgbe_write_i2c_byte_82599 - Writes 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to write

 *  @dev_addr: address to write to

 *  @data: value to write

 *

 *  Performs byte write operation to SFP module's EEPROM over I2C interface at

 *  a specified device address.

 Acquire I2C bus ownership. */

 Release I2C bus ownership. */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 Initialize list of VF macvlans */

 Enable VMDq flag so device will be set in VM mode */

 Allocate memory for per VF control structures */

 Initialize default switching mode VEB */

 limit trafffic classes based on VFs enabled */

 Disable RSC when in SR-IOV mode */

 enable spoof checking for all VFs */

		/* We support VF RSS querying only for 82599 and x540

		 * devices at the moment. These devices share RSS

		 * indirection table and RSS hash key with PF therefore

		 * we want to disable the querying by default.

 Untrust all VFs */

 set the default xcast mode */

/**

 * ixgbe_get_vfs - Find and take references to all vf devices

 * @adapter: Pointer to adapter struct

/* Note this function is called when the user wants to enable SR-IOV

 * VFs using the now deprecated module parameter

	/* If there are pre-existing VFs then we have to force

	 * use of that many - over ride any module parameter value.

	 * This may result from the user unloading the PF driver

	 * while VFs were assigned to guest VMs or because the VFs

	 * have been created via the new PCI SR-IOV sysfs interface.

		/*

		 * The 82599 supports up to 64 VFs per physical function

		 * but this implementation limits allocation to 63 so that

		 * basic networking resources are still available to the

		 * physical function.  If the user requests greater than

		 * 63 VFs then it is an error - reset to default of zero.

	/* If we have gotten to this point then there is no memory available

	 * to manage the VF devices - print message and bail.

 #ifdef CONFIG_PCI_IOV */

 set num VFs to 0 to prevent access to vfinfo */

 put the reference to all of the vf devices */

 free VF control structures */

 free macvlan list */

 if SR-IOV is already disabled then there is nothing to do */

	/*

	 * If our VFs are assigned we cannot shut down SR-IOV

	 * without causing issues, so just leave the hardware

	 * available but disabled

 disable iov and allow time for transactions to clear */

 Disable VMDq flag so device will be set in VM mode */

 take a breather then clean up driver data */

	/* While the SR-IOV capability structure reports total VFs to be 64,

	 * we limit the actual number allocated as below based on two factors.

	 *    Num_TCs	MAX_VFs

	 *	1	  63

	 *	<=4	  31

	 *	>4	  15

	 * First, we reserve some transmit/receive resources for the PF.

	 * Second, VMDQ also uses the same pools that SR-IOV does. We need to

	 * account for this, so that we don't accidentally allocate more VFs

	 * than we have available pools. The PCI bus driver already checks for

	 * other values out of range.

 reset before enabling SRIOV to avoid mailbox issues */

 Only reinit if no error and state changed */

 only so many hash values supported */

	/*

	 * salt away the number of multi cast addresses assigned

	 * to this VF for later use to restore when the PF multi cast

	 * list changes

	/*

	 * VFs are limited to using the MTA hash table for their multicast

	 * addresses

 Restore any VF macvlans */

	/* If VLAN overlaps with one the PF is currently monitoring make

	 * sure that we are able to allocate a VLVF entry.  This may be

	 * redundant but it guarantees PF will maintain visibility to

	 * the VLAN.

	/* If we failed to add the VF VLAN or we are removing the VF VLAN

	 * we may need to drop the PF pool bit in order to allow us to free

	 * up the VLVF resources.

	/*

	 * For 82599EB we have to keep all PFs and VFs operating with

	 * the same max_frame value in order to avoid sending an oversize

	 * frame to a VF.  In order to guarantee this is handled correctly

	 * for all cases we have several special exceptions to take into

	 * account before we can enable the VF for receive

 CONFIG_FCOE */

			/* Version 1.1 supports jumbo frames on VFs if PF has

			 * jumbo frames enabled which means legacy VFs are

			 * disabled

			/* If the PF or VF are running w/ jumbo frames enabled

			 * we need to shut down the VF Rx path as we cannot

			 * support jumbo frames on legacy VFs

 determine VF receive enable location */

 enable or disable receive depending on error */

 pull current max frame size from hardware */

 create mask for VF and other pools */

 post increment loop, covers VLVF_ENTRIES - 1 to 0 */

 if our bit isn't set we can skip it */

 clear our bit from vlvfb */

 create 64b mask to chedk to see if we should clear VLVF */

 if other pools are present, just remove ourselves */

 if PF is present, leave VFTA */

 if we cannot determine VLAN just remove ourselves */

 clear bit from VFTA */

 clear POOL selection enable */

 clear pool bits */

	/*

	 * If index was zero then we were asked to clear the uc list

	 * for the VF.  We're done.

	/*

	 * If we traversed the entire list and didn't find a free entry

	 * then we're out of space on the RAR table.  Also entry may

	 * be NULL because the original memory allocation for the list

	 * failed, which is not fatal but does mean we can't support

	 * VF requests for MACVLAN because we couldn't allocate

	 * memory for the list management required.

 remove VLAN filters beloning to this VF */

 add back PF assigned VLAN or VLAN 0 */

 reset offloads to defaults */

 set outgoing tags for VFs */

 reset multicast table array for vf */

 clear any ipsec table info */

 Flush and reset the mta with the new values */

 reset VF api back to unknown */

 Restart each queue for given VF */

 Re-enabling only configured queues */

 Clear VF's mailbox memory */

 flush previous write */

 indicate to hardware that we want to set drop enable */

 reset the filters for the device */

 set vf mac address */

 enable transmit for vf */

 force drop enable for all VF Rx queues */

 enable receive for vf */

	/*

	 * The 82599 cannot support a mix of jumbo and non-jumbo PF/VFs.

	 * For more info take a look at ixgbe_set_vf_lpe

 CONFIG_FCOE */

 enable VF mailbox for further messages */

 Enable counting of spoofed packets in the SSVPC register */

	/*

	 * Reset the VFs TDWBAL and TDWBAH registers

	 * which are not cleared by an FLR

 reply to reset with ack and vf mac address */

	/*

	 * Piggyback the multicast filter type so VF can compute the

	 * correct vectors

 VLAN 0 is a special case, don't allow it to be removed */

 An non-zero index indicates the VF is setting a filter */

		/*

		 * If the VF is allowed to set MAC filters then turn off

		 * anti-spoofing to avoid false positives.

 verify the PF is supporting the correct APIs */

 only allow 1 Tx queue for bandwidth limiting */

 if TCs > 1 determine which TC belongs to default user priority */

 notify VF of need for VLAN tag stripping, and correct queue */

 notify VF of default queue */

 Check if operation is permitted */

 verify the PF is supporting the correct API */

	/* This mailbox command is supported (required) only for 82599 and x540

	 * VFs which support up to 4 RSS queues. Therefore we will compress the

	 * RETA by saving only 2 bits from each entry. This way we will be able

	 * to transfer the whole RETA in a single mailbox operation.

 Check if the operation is permitted */

 verify the PF is supporting the correct API */

 verify the PF is supporting the correct APIs */

 promisc introduced in 1.3 version */

 VF promisc requires PF in promisc */

 this is a message we already processed, do nothing */

 flush the ack before we write any messages back */

	/*

	 * until the vf completes a virtual function reset it should not be

	 * allowed to start any configuration.

 notify the VF of the results of what it sent us */

 if device isn't clear to send it shouldn't be reading either */

 process any reset requests */

 process any messages pending */

 process any acks */

 disable transmit and receive for all vfs */

 nothing to do */

 Revoke tagless access via VLAN 0 */

 enable hide vlan on X550 */

 Restore tagless access via VLAN 0 */

 disable hide VLAN on X550 */

		/* Check if there is already a port VLAN set, if so

		 * we have to delete the old one first before we

		 * can set the new one.  The usage model had

		 * previously assumed the user would delete the

		 * old port VLAN before setting a new one but this

		 * is not necessarily the case.

 start with base link speed value */

 Calculate the rate factor values to set */

 clear everything but the rate factor */

 enable the rate scheduler */

	/*

	 * Set global transmit compensation time to the MMW_SIZE in RTTBCNRM

	 * register. Typically MMW_SIZE=0x014 if 9728-byte jumbo is supported

	 * and 0x004 otherwise.

 determine how many queues per pool based on VMDq mask */

 write value for all Tx queues belonging to VF */

 VF Tx rate limit was not set */

 verify VF is active */

 verify link is up */

 verify we are linked at 10Gbps */

 rate limit cannot be less than 10Mbs or greater than link speed */

 store values */

 update hardware configuration */

 configure MAC spoofing */

 configure VLAN spoofing */

	/* Ensure LLDP and FC is set for Ethertype Antispoofing if we will be

	 * calling set_ethertype_anti_spoofing for each VF in loop below

	/* This operation is currently supported only for 82599 and x540

	 * devices.

 nothing to do */

 reset VF to reconfigure features */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/*

 * The 82599 and the X540 do not have true 64bit nanosecond scale

 * counter registers. Instead, SYSTIME is defined by a fixed point

 * system which allows the user to define the scale counter increment

 * value at every level change of the oscillator driving the SYSTIME

 * value. For both devices the TIMINCA:IV field defines this

 * increment. On the X540 device, 31 bits are provided. However on the

 * 82599 only provides 24 bits. The time unit is determined by the

 * clock frequency of the oscillator in combination with the TIMINCA

 * register. When these devices link at 10Gb the oscillator has a

 * period of 6.4ns. In order to convert the scale counter into

 * nanoseconds the cyclecounter and timecounter structures are

 * used. The SYSTIME registers need to be converted to ns values by use

 * of only a right shift (division by power of 2). The following math

 * determines the largest incvalue that will fit into the available

 * bits in the TIMINCA register.

 *

 * PeriodWidth: Number of bits to store the clock period

 * MaxWidth: The maximum width value of the TIMINCA register

 * Period: The clock period for the oscillator

 * round(): discard the fractional portion of the calculation

 *

 * Period * [ 2 ^ ( MaxWidth - PeriodWidth ) ]

 *

 * For the X540, MaxWidth is 31 bits, and the base period is 6.4 ns

 * For the 82599, MaxWidth is 24 bits, and the base period is 6.4 ns

 *

 * The period also changes based on the link speed:

 * At 10Gb link or no link, the period remains the same.

 * At 1Gb link, the period is multiplied by 10. (64ns)

 * At 100Mb link, the period is multiplied by 100. (640ns)

 *

 * The calculated value allows us to right shift the SYSTIME register

 * value in order to quickly convert it into a nanosecond clock,

 * while allowing for the maximum possible adjustment value.

 *

 * These diagrams are only for the 10Gb link period

 *

 *           SYSTIMEH            SYSTIMEL

 *       +--------------+  +--------------+

 * X540  |      32      |  | 1 | 3 |  28  |

 *       *--------------+  +--------------+

 *        \________ 36 bits ______/  fract

 *

 *       +--------------+  +--------------+

 * 82599 |      32      |  | 8 | 3 |  21  |

 *       *--------------+  +--------------+

 *        \________ 43 bits ______/  fract

 *

 * The 36 bit X540 SYSTIME overflows every

 *   2^36 * 10^-9 / 60 = 1.14 minutes or 69 seconds

 *

 * The 43 bit 82599 SYSTIME overflows every

 *   2^43 * 10^-9 / 3600 = 2.4 hours

/* We use our own definitions instead of NSEC_PER_SEC because we want to mark

 * the value as a ULL to force precision when bit shifting.

/* In contrast, the X550 controller has two registers, SYSTIMEH and SYSTIMEL

 * which contain measurements of seconds and nanoseconds respectively. This

 * matches the standard linux representation of time in the kernel. In addition,

 * the X550 also has a SYSTIMER register which represents residue, or

 * subnanosecond overflow adjustments. To control clock adjustment, the TIMINCA

 * register is used, but it is unlike the X540 and 82599 devices. TIMINCA

 * represents units of 2^-32 nanoseconds, and uses 31 bits for this, with the

 * high bit representing whether the adjustent is positive or negative. Every

 * clock cycle, the X550 will add 12.5 ns + TIMINCA which can result in a range

 * of 12 to 13 nanoseconds adjustment. Unlike the 82599 and X540 devices, the

 * X550's clock for purposes of SYSTIME generation is constant and not dependent

 * on the link speed.

 *

 *           SYSTIMEH           SYSTIMEL        SYSTIMER

 *       +--------------+  +--------------+  +-------------+

 * X550  |      32      |  |      32      |  |     32      |

 *       *--------------+  +--------------+  +-------------+

 *       \____seconds___/   \_nanoseconds_/  \__2^-32 ns__/

 *

 * This results in a full 96 bits to represent the clock, with 32 bits for

 * seconds, 32 bits for nanoseconds (largest value is 0d999999999 or just under

 * 1 second) and an additional 32 bits to measure sub nanosecond adjustments for

 * underflow of adjustments.

 *

 * The 32 bits of seconds for the X550 overflows every

 *   2^32 / ( 365.25 * 24 * 60 * 60 ) = ~136 years.

 *

 * In order to adjust the clock frequency for the X550, the TIMINCA register is

 * provided. This register represents a + or minus nearly 0.5 ns adjustment to

 * the base frequency. It is measured in 2^-32 ns units, with the high bit being

 * the sign bit. This register enables software to calculate frequency

 * adjustments and apply them directly to the clock rate.

 *

 * The math for converting ppb into TIMINCA values is fairly straightforward.

 *   TIMINCA value = ( Base_Frequency * ppb ) / 1000000000ULL

 *

 * This assumes that ppb is never high enough to create a value bigger than

 * TIMINCA's 31 bits can store. This is ensured by the stack. Calculating this

 * value is also simple.

 *   Max ppb = ( Max Adjustment / Base Frequency ) / 1000000000ULL

 *

 * For the X550, the Max adjustment is +/- 0.5 ns, and the base frequency is

 * 12.5 nanoseconds. This means that the Max ppb is 39999999

 *   Note: We subtract one in order to ensure no overflow, because the TIMINCA

 *         register can only hold slightly under 0.5 nanoseconds.

 *

 * Because TIMINCA is measured in 2^-32 ns units, we have to convert 12.5 ns

 * into 2^-32 units, which is

 *

 *  12.5 * 2^32 = C80000000

 *

 * Some revisions of hardware have a faster base frequency than the registers

 * were defined for. To fix this, we use a timecounter structure with the

 * proper mult and shift to convert the cycles into nanoseconds of time.

/**

 * ixgbe_ptp_setup_sdp_X540

 * @adapter: private adapter structure

 *

 * this function enables or disables the clock out feature on SDP0 for

 * the X540 device. It will create a 1 second periodic output that can

 * be used as the PPS (via an interrupt).

 *

 * It calculates when the system time will be on an exact second, and then

 * aligns the start of the PPS signal to that value.

 *

 * This works by using the cycle counter shift and mult values in reverse, and

 * assumes that the values we're shifting will not overflow.

 disable the pin first */

	/* enable the SDP0 pin as output, and connected to the

	 * native function for Timesync (ClockOut)

	/* enable the Clock Out feature on SDP0, and allow

	 * interrupts to occur when the pin changes

	/* Determine the clock time period to use. This assumes that the

	 * cycle counter shift is small enough to avoid overflow.

 Read the current clock time, and save the cycle counter value */

 Figure out how many seconds to add in order to round up */

	/* Figure out how many nanoseconds to add to round the clock edge up

	 * to the next full second

 Adjust the clock edge to align with the next full second. */

/**

 * ixgbe_ptp_setup_sdp_X550

 * @adapter: private adapter structure

 *

 * Enable or disable a clock output signal on SDP 0 for X550 hardware.

 *

 * Use the target time feature to align the output signal on the next full

 * second.

 *

 * This works by using the cycle counter shift and mult values in reverse, and

 * assumes that the values we're shifting will not overflow.

 disable the pin first */

	/* enable the SDP0 pin as output, and connected to the

	 * native function for Timesync (ClockOut)

	/* enable the Clock Out feature on SDP0, and use Target Time 0 to

	 * enable generation of interrupts on the clock change.

	/* Determine the clock time period to use. This assumes that the

	 * cycle counter shift is small enough to avoid overflowing a 32bit

	 * value.

 Read the current clock time, and save the cycle counter value */

 Figure out how far past the next second we are */

	/* Figure out how many nanoseconds to add to round the clock edge up

	 * to the next full second

 Adjust the clock edge to align with the next full second. */

	/* X550 hardware stores the time in 32bits of 'billions of cycles' and

	 * 32bits of 'cycles'. There's no guarantee that cycles represents

	 * nanoseconds. However, we can use the math from a timespec64 to

	 * convert into the hardware representation.

	 *

	 * See ixgbe_ptp_read_X550() for more details.

/**

 * ixgbe_ptp_read_X550 - read cycle counter value

 * @cc: cyclecounter structure

 *

 * This function reads SYSTIME registers. It is called by the cyclecounter

 * structure to convert from internal representation into nanoseconds. We need

 * this for X550 since some skews do not have expected clock frequency and

 * result of SYSTIME is 32bits of "billions of cycles" and 32 bits of

 * "cycles", rather than seconds and nanoseconds.

	/* storage is 32 bits of 'billions of cycles' and 32 bits of 'cycles'.

	 * Some revisions of hardware run at a higher frequency and so the

	 * cycles are not guaranteed to be nanoseconds. The timespec64 created

	 * here is used for its math/conversions but does not necessarily

	 * represent nominal time.

	 *

	 * It should be noted that this cyclecounter will overflow at a

	 * non-bitmask field since we have to convert our billions of cycles

	 * into an actual cycles count. This results in some possible weird

	 * situations at high cycle counter stamps. However given that 32 bits

	 * of "seconds" is ~138 years this isn't a problem. Even at the

	 * increased frequency of some revisions, this is still ~103 years.

	 * Since the SYSTIME values start at 0 and we never write them, it is

	 * highly unlikely for the cyclecounter to overflow in practice.

/**

 * ixgbe_ptp_read_82599 - read raw cycle counter (to be used by time counter)

 * @cc: the cyclecounter structure

 *

 * this function reads the cyclecounter registers and is called by the

 * cyclecounter structure used to construct a ns counter from the

 * arbitrary fixed point registers

/**

 * ixgbe_ptp_convert_to_hwtstamp - convert register value to hw timestamp

 * @adapter: private adapter structure

 * @hwtstamp: stack timestamp structure

 * @timestamp: unsigned 64bit system time value

 *

 * We need to convert the adapter's RX/TXSTMP registers into a hwtstamp value

 * which can be used by the stack's ptp functions.

 *

 * The lock is used to protect consistency of the cyclecounter and the SYSTIME

 * registers. However, it does not need to protect against the Rx or Tx

 * timestamp registers, as there can't be a new timestamp until the old one is

 * unlatched by reading.

 *

 * In addition to the timestamp in hardware, some controllers need a software

 * overflow cyclecounter, and this function takes this into account as well.

	/* X550 and later hardware supposedly represent time using a seconds

	 * and nanoseconds counter, instead of raw 64bits nanoseconds. We need

	 * to convert the timestamp into cycles before it can be fed to the

	 * cyclecounter. We need an actual cyclecounter because some revisions

	 * of hardware run at a higher frequency and thus the counter does

	 * not represent seconds/nanoseconds. Instead it can be thought of as

	 * cycles and billions of cycles.

		/* Upper 32 bits represent billions of cycles, lower 32 bits

		 * represent cycles. However, we use timespec64_to_ns for the

		 * correct math even though the units haven't been corrected

		 * yet.

/**

 * ixgbe_ptp_adjfreq_82599

 * @ptp: the ptp clock structure

 * @ppb: parts per billion adjustment from base

 *

 * adjust the frequency of the ptp cycle counter by the

 * indicated ppb from the base frequency.

/**

 * ixgbe_ptp_adjfreq_X550

 * @ptp: the ptp clock structure

 * @ppb: parts per billion adjustment from base

 *

 * adjust the frequency of the SYSTIME registers by the indicated ppb from base

 * frequency

 warn if rate is too large */

/**

 * ixgbe_ptp_adjtime

 * @ptp: the ptp clock structure

 * @delta: offset to adjust the cycle counter by

 *

 * adjust the timer by resetting the timecounter structure.

/**

 * ixgbe_ptp_gettimex

 * @ptp: the ptp clock structure

 * @ts: timespec to hold the PHC timestamp

 * @sts: structure to hold the system time before and after reading the PHC

 *

 * read the timecounter and return the correct value on ns,

 * after converting it into a struct timespec.

		/* Upper 32 bits represent billions of cycles, lower 32 bits

		 * represent cycles. However, we use timespec64_to_ns for the

		 * correct math even though the units haven't been corrected

		 * yet.

/**

 * ixgbe_ptp_settime

 * @ptp: the ptp clock structure

 * @ts: the timespec containing the new time for the cycle counter

 *

 * reset the timecounter to use a new base value instead of the kernel

 * wall timer value.

 reset the timecounter */

/**

 * ixgbe_ptp_feature_enable

 * @ptp: the ptp clock structure

 * @rq: the requested feature to change

 * @on: whether to enable or disable the feature

 *

 * enable (or disable) ancillary features of the phc subsystem.

 * our driver only supports the PPS feature on the X540

	/**

	 * When PPS is enabled, unmask the interrupt for the ClockOut

	 * feature, so that the interrupt handler can send the PPS

	 * event when the clock SDP triggers. Clear mask when PPS is

	 * disabled

/**

 * ixgbe_ptp_check_pps_event

 * @adapter: the private adapter structure

 *

 * This function is called by the interrupt routine when checking for

 * interrupts. It will check and handle a pps event.

	/* this check is necessary in case the interrupt was enabled via some

	 * alternative means (ex. debug_fs). Better to check here than

	 * everywhere that calls this function.

/**

 * ixgbe_ptp_overflow_check - watchdog task to detect SYSTIME overflow

 * @adapter: private adapter struct

 *

 * this watchdog task periodically reads the timecounter

 * in order to prevent missing when the system time registers wrap

 * around. This needs to be run approximately twice a minute.

 Update the timecounter */

/**

 * ixgbe_ptp_rx_hang - detect error case when Rx timestamp registers latched

 * @adapter: private network adapter structure

 *

 * this watchdog task is scheduled to detect error case where hardware has

 * dropped an Rx packet that was timestamped when the ring is full. The

 * particular error is rare but leaves the device in a state unable to timestamp

 * any future packets.

	/* if we don't have a valid timestamp in the registers, just update the

	 * timeout counter and exit

 determine the most recent watchdog or rx_timestamp event */

 only need to read the high RXSTMP register to clear the lock */

/**

 * ixgbe_ptp_clear_tx_timestamp - utility function to clear Tx timestamp state

 * @adapter: the private adapter structure

 *

 * This function should be called whenever the state related to a Tx timestamp

 * needs to be cleared. This helps ensure that all related bits are reset for

 * the next Tx timestamp event.

/**

 * ixgbe_ptp_tx_hang - detect error case where Tx timestamp never finishes

 * @adapter: private network adapter structure

	/* If we haven't received a timestamp within the timeout, it is

	 * reasonable to assume that it will never occur, so we can unlock the

	 * timestamp bit when this occurs.

/**

 * ixgbe_ptp_tx_hwtstamp - utility function which checks for TX time stamp

 * @adapter: the private adapter struct

 *

 * if the timestamp is valid, we convert it into the timecounter ns

 * value, then store that result into the shhwtstamps structure which

 * is passed up the network stack

	/* Handle cleanup of the ptp_tx_skb ourselves, and unlock the state

	 * bit prior to notifying the stack via skb_tstamp_tx(). This prevents

	 * well behaved applications from attempting to timestamp again prior

	 * to the lock bit being clear.

 Notify the stack and then free the skb after we've unlocked */

/**

 * ixgbe_ptp_tx_hwtstamp_work

 * @work: pointer to the work struct

 *

 * This work item polls TSYNCTXCTL valid bit to determine when a Tx hardware

 * timestamp has been taken for the current skb. It is necessary, because the

 * descriptor's "done" bit does not correlate with the timestamp event.

 we have to have a valid skb to poll for a timestamp */

 stop polling once we have a valid timestamp */

 reschedule to keep checking if it's not available yet */

/**

 * ixgbe_ptp_rx_pktstamp - utility function to get RX time stamp from buffer

 * @q_vector: structure containing interrupt and ring information

 * @skb: the packet

 *

 * This function will be called by the Rx routine of the timestamp for this

 * packet is stored in the buffer. The value is stored in little endian format

 * starting at the end of the packet data.

 copy the bits out of the skb, and then trim the skb length */

	/* The timestamp is recorded in little endian format, and is stored at

	 * the end of the packet.

	 *

	 * DWORD: N              N + 1      N + 2

	 * Field: End of Packet  SYSTIMH    SYSTIML

/**

 * ixgbe_ptp_rx_rgtstamp - utility function which checks for RX time stamp

 * @q_vector: structure containing interrupt and ring information

 * @skb: particular skb to send timestamp with

 *

 * if the timestamp is valid, we convert it into the timecounter ns

 * value, then store that result into the shhwtstamps structure which

 * is passed up the network stack

 we cannot process timestamps on a ring without a q_vector */

	/* Read the tsyncrxctl register afterwards in order to prevent taking an

	 * I/O hit on every packet.

/**

 * ixgbe_ptp_get_ts_config - get current hardware timestamping configuration

 * @adapter: pointer to adapter structure

 * @ifr: ioctl data

 *

 * This function returns the current timestamping settings. Rather than

 * attempt to deconstruct registers to fill in the values, simply keep a copy

 * of the old settings around, and return a copy when requested.

/**

 * ixgbe_ptp_set_timestamp_mode - setup the hardware for the requested mode

 * @adapter: the private ixgbe adapter structure

 * @config: the hwtstamp configuration requested

 *

 * Outgoing time stamping can be enabled and disabled. Play nice and

 * disable it when requested, although it shouldn't cause any overhead

 * when no packet needs it. At most one packet in the queue may be

 * marked for time stamping, otherwise it would be impossible to tell

 * for sure to which packet the hardware time stamp belongs.

 *

 * Incoming time stamping has to be configured via the hardware

 * filters. Not all combinations are supported, in particular event

 * type has to be specified. Matching the kind of event packet is

 * not supported, with the exception of "all V2 events regardless of

 * level 2 or 4".

 *

 * Since hardware always timestamps Path delay packets when timestamping V2

 * packets, regardless of the type specified in the register, only use V2

 * Event mode. This more accurately tells the user what the hardware is going

 * to do anyways.

 *

 * Note: this may modify the hwtstamp configuration towards a more general

 * mode, if required to support the specifically requested mode.

 reserved for future extensions */

		/* The X550 controller is capable of timestamping all packets,

		 * which allows it to accept any filter.

		/*

		 * register RXMTRL must be set in order to do V1 packets,

		 * therefore it is not possible to time stamp both V1 Sync and

		 * Delay_Req messages and hardware does not support

		 * timestamping all packets => return error

	/* Per-packet timestamping only works if the filter is set to all

	 * packets. Since this is desired, always timestamp all packets as long

	 * as any Rx filter was configured.

		/* enable timestamping all packets only if at least some

		 * packets were requested. Otherwise, play nice and disable

		 * timestamping

 define ethertype filter for timestamping L2 packets */

 enable filter */

 enable timestamping */

 1588 eth protocol type */

 enable/disable TX */

 enable/disable RX */

 define which PTP packets are time stamped */

 clear TX/RX time stamp registers, just to be sure */

/**

 * ixgbe_ptp_set_ts_config - user entry point for timestamp mode

 * @adapter: pointer to adapter struct

 * @ifr: ioctl data

 *

 * Set hardware to requested mode. If unsupported, return an error with no

 * changes. Otherwise, store the mode for future reference.

 save these settings for future reference */

	/**

	 * Scale the NIC cycle counter by a large factor so that

	 * relatively small corrections to the frequency can be added

	 * or subtracted. The drawbacks of a large factor include

	 * (a) the clock register overflows more quickly, (b) the cycle

	 * counter structure must be able to convert the systime value

	 * to nanoseconds using only a multiplier and a right-shift,

	 * and (c) the value must fit within the timinca register space

	 * => math based on internal DMA clock rate and available bits

	 *

	 * Note that when there is no link, internal DMA clock is same as when

	 * link speed is 10Gb. Set the registers correctly even when link is

	 * down to preserve the clock setting

/**

 * ixgbe_ptp_start_cyclecounter - create the cycle counter from hw

 * @adapter: pointer to the adapter structure

 *

 * This function should be called to set the proper values for the TIMINCA

 * register and tell the cyclecounter structure what the tick rate of SYSTIME

 * is. It does not directly modify SYSTIME registers or the timecounter

 * structure. It should be called whenever a new TIMINCA value is necessary,

 * such as during initialization or when the link speed changes.

	/* For some of the boards below this mask is technically incorrect.

	 * The timestamp mask overflows at approximately 61bits. However the

	 * particular hardware does not overflow on an even bitmask value.

	 * Instead, it overflows due to conversion of upper 32bits billions of

	 * cycles. Timecounters are not really intended for this purpose so

	 * they do not properly function if the overflow point isn't 2^N-1.

	 * However, the actual SYSTIME values in question take ~138 years to

	 * overflow. In practice this means they won't actually overflow. A

	 * proper fix to this problem would require modification of the

	 * timecounter delta calculations.

		/* SYSTIME assumes X550EM_x board frequency is 300Mhz, and is

		 * designed to represent seconds and nanoseconds when this is

		 * the case. However, some revisions of hardware have a 400Mhz

		 * clock and we have to compensate for this frequency

		 * variation using corrected mult and shift values.

 enable SYSTIME counter */

 other devices aren't supported */

 update the base incval used to calculate frequency adjustment */

 need lock to prevent incorrect read while modifying cyclecounter */

/**

 * ixgbe_ptp_reset

 * @adapter: the ixgbe private board structure

 *

 * When the MAC resets, all the hardware bits for timesync are reset. This

 * function is used to re-enable the device for PTP based on current settings.

 * We do lose the current clock time, so just reset the cyclecounter to the

 * system real clock time.

 *

 * This function will maintain hwtstamp_config settings, and resets the SDP

 * output if it was enabled.

 reset the hardware timestamping mode */

 82598 does not support PTP */

	/* Now that the shift has been calculated and the systime

	 * registers reset, (re-)enable the Clock out feature

/**

 * ixgbe_ptp_create_clock

 * @adapter: the ixgbe private adapter structure

 *

 * This function performs setup of the user entry point function table and

 * initializes the PTP clock device, which is used to access the clock-like

 * features of the PTP core. It will be called by ixgbe_ptp_init, and may

 * reuse a previously initialized clock (such as during a suspend/resume

 * cycle).

 do nothing if we already have a clock device */

	/* set default timestamp mode to disabled here. We do this in

	 * create_clock instead of init, because we don't want to override the

	 * previous settings during a resume cycle.

/**

 * ixgbe_ptp_init

 * @adapter: the ixgbe private adapter structure

 *

 * This function performs the required steps for enabling PTP

 * support. If PTP support has already been loaded it simply calls the

 * cyclecounter init routine and exits.

	/* initialize the spin lock first since we can't control when a user

	 * will call the entry functions once we have initialized the clock

	 * device

 obtain a PTP device, or re-use an existing device */

 we have a clock so we can initialize work now */

 reset the PTP related hardware bits */

 enter the IXGBE_PTP_RUNNING state */

/**

 * ixgbe_ptp_suspend - stop PTP work items

 * @adapter: pointer to adapter struct

 *

 * this function suspends PTP activity, and prevents more PTP work from being

 * generated, but does not destroy the PTP clock device.

 Leave the IXGBE_PTP_RUNNING state. */

 ensure that we cancel any pending PTP Tx work item in progress */

/**

 * ixgbe_ptp_stop - close the PTP device

 * @adapter: pointer to adapter struct

 *

 * completely destroy the PTP device, should only be called when the device is

 * being fully closed.

 first, suspend PTP activity */

 disable the PTP clock device */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 *  e1000_raise_eec_clk - Raise EEPROM clock

 *  @hw: pointer to the HW structure

 *  @eecd: pointer to the EEPROM

 *

 *  Enable/Raise the EEPROM clock bit.

/**

 *  e1000_lower_eec_clk - Lower EEPROM clock

 *  @hw: pointer to the HW structure

 *  @eecd: pointer to the EEPROM

 *

 *  Clear/Lower the EEPROM clock bit.

/**

 *  e1000_shift_out_eec_bits - Shift data bits our to the EEPROM

 *  @hw: pointer to the HW structure

 *  @data: data to send to the EEPROM

 *  @count: number of bits to shift out

 *

 *  We need to shift 'count' bits out to the EEPROM.  So, the value in the

 *  "data" parameter will be shifted out to the EEPROM one bit at a time.

 *  In order to do this, "data" must be broken down into bits.

/**

 *  e1000_shift_in_eec_bits - Shift data bits in from the EEPROM

 *  @hw: pointer to the HW structure

 *  @count: number of bits to shift in

 *

 *  In order to read a register from the EEPROM, we need to shift 'count' bits

 *  in from the EEPROM.  Bits are "shifted in" by raising the clock input to

 *  the EEPROM (setting the SK bit), and then reading the value of the data out

 *  "DO" bit.  During this "shifting in" process the data in "DI" bit should

 *  always be clear.

/**

 *  e1000e_poll_eerd_eewr_done - Poll for EEPROM read/write completion

 *  @hw: pointer to the HW structure

 *  @ee_reg: EEPROM flag for polling

 *

 *  Polls the EEPROM status bit for either read or write completion based

 *  upon the value of 'ee_reg'.

/**

 *  e1000e_acquire_nvm - Generic request for access to EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Set the EEPROM access request bit and wait for EEPROM access grant bit.

 *  Return successful if access grant bit set, else clear the request for

 *  EEPROM access and return -E1000_ERR_NVM (-1).

/**

 *  e1000_standby_nvm - Return EEPROM to standby state

 *  @hw: pointer to the HW structure

 *

 *  Return the EEPROM to a standby state.

 Toggle CS to flush commands */

/**

 *  e1000_stop_nvm - Terminate EEPROM command

 *  @hw: pointer to the HW structure

 *

 *  Terminates the current command by inverting the EEPROM's chip select pin.

 Pull CS high */

/**

 *  e1000e_release_nvm - Release exclusive access to EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Stop any current commands to the EEPROM and clear the EEPROM request bit.

/**

 *  e1000_ready_nvm_eeprom - Prepares EEPROM for read/write

 *  @hw: pointer to the HW structure

 *

 *  Setups the EEPROM for reading and writing.

 Clear SK and CS */

		/* Read "Status Register" repeatedly until the LSB is cleared.

		 * The EEPROM will signal that the command has been completed

		 * by clearing bit 0 of the internal status register.  If it's

		 * not cleared within 'timeout', then error out.

/**

 *  e1000e_read_nvm_eerd - Reads EEPROM using EERD register

 *  @hw: pointer to the HW structure

 *  @offset: offset of word in the EEPROM to read

 *  @words: number of words to read

 *  @data: word read from the EEPROM

 *

 *  Reads a 16 bit word from the EEPROM using the EERD register.

	/* A check for invalid values:  offset too large, too many words,

	 * too many words for the offset, and not enough words.

/**

 *  e1000e_write_nvm_spi - Write to EEPROM using SPI

 *  @hw: pointer to the HW structure

 *  @offset: offset within the EEPROM to be written to

 *  @words: number of words to write

 *  @data: 16 bit word(s) to be written to the EEPROM

 *

 *  Writes data to EEPROM at offset using SPI interface.

 *

 *  If e1000e_update_nvm_checksum is not called after this function , the

 *  EEPROM will most likely contain an invalid checksum.

	/* A check for invalid values:  offset too large, too many words,

	 * and not enough words.

 Send the WRITE ENABLE command (8 bit opcode) */

		/* Some SPI eeproms use the 8th address bit embedded in the

		 * opcode

 Send the Write command (8-bit opcode + addr) */

 Loop to allow for up to whole page write of eeprom */

/**

 *  e1000_read_pba_string_generic - Read device part number

 *  @hw: pointer to the HW structure

 *  @pba_num: pointer to device part number

 *  @pba_num_size: size of part number buffer

 *

 *  Reads the product board assembly (PBA) number from the EEPROM and stores

 *  the value in pba_num.

	/* if nvm_data is not ptr guard the PBA must be in legacy format which

	 * means pba_ptr is actually our second data word for the PBA number

	 * and we can decode it into an ascii string

 make sure callers buffer is big enough to store the PBA */

 extract hex string from data and pba_ptr */

 put a null character on the end of our string */

 switch all the data but the '-' to hex char */

 check if pba_num buffer is big enough */

 trim pba length from start of string */

/**

 *  e1000_read_mac_addr_generic - Read device MAC address

 *  @hw: pointer to the HW structure

 *

 *  Reads the device MAC address from the EEPROM and stores the value.

 *  Since devices with two ports use the same EEPROM, we increment the

 *  last bit in the MAC address for the second port.

/**

 *  e1000e_validate_nvm_checksum_generic - Validate EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Calculates the EEPROM checksum by reading/adding each word of the EEPROM

 *  and then verifies that the sum of the EEPROM is equal to 0xBABA.

/**

 *  e1000e_update_nvm_checksum_generic - Update EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Updates the EEPROM checksum by reading/adding each word of the EEPROM

 *  up to the checksum.  Then calculates the EEPROM checksum and writes the

 *  value to the EEPROM.

/**

 *  e1000e_reload_nvm_generic - Reloads EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Reloads the EEPROM by setting the "Reinitialize from EEPROM" bit in the

 *  extended control register.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/* 82571EB Gigabit Ethernet Controller

 * 82571EB Gigabit Ethernet Controller (Copper)

 * 82571EB Gigabit Ethernet Controller (Fiber)

 * 82571EB Dual Port Gigabit Mezzanine Adapter

 * 82571EB Quad Port Gigabit Mezzanine Adapter

 * 82571PT Gigabit PT Quad Port Server ExpressModule

 * 82572EI Gigabit Ethernet Controller (Copper)

 * 82572EI Gigabit Ethernet Controller (Fiber)

 * 82572EI Gigabit Ethernet Controller

 * 82573V Gigabit Ethernet Controller (Copper)

 * 82573E Gigabit Ethernet Controller (Copper)

 * 82573L Gigabit Ethernet Controller

 * 82574L Gigabit Network Connection

 * 82583V Gigabit Network Connection

/**

 *  e1000_init_phy_params_82571 - Init PHY func ptrs.

 *  @hw: pointer to the HW structure

 This can only be done after all function pointers are setup. */

 Verify phy id */

/**

 *  e1000_init_nvm_params_82571 - Init NVM func ptrs.

 *  @hw: pointer to the HW structure

			/* Autonomous Flash update bit must be cleared due

			 * to Flash update issue.

		/* Added to a constant, "size" becomes the left-shift value

		 * for setting word_size.

 EEPROM access above 16k is unsupported */

 Function Pointers */

/**

 *  e1000_init_mac_params_82571 - Init MAC func ptrs.

 *  @hw: pointer to the HW structure

 Set media type and media-dependent function pointers */

 Set mta register count */

 Set rar entry count */

 Adaptive IFS supported */

 MAC-specific function pointers */

 FWSM register */

		/* ARC supported; valid only if manageability features are

		 * enabled.

 FWSM register */

	/* Ensure that the inter-port SWSM.SMBI lock bit is clear before

	 * first NVM or PHY access. This should be done for single-port

	 * devices, and for one port only on dual-port devices so that

	 * for those devices we can still use the SMBI lock to synchronize

	 * inter-port accesses to the PHY & NVM.

 Only do this for the first interface on this card */

 Make sure SWSM.SMBI is clear */

			/* This bit should not be set on a first interface, and

			 * indicates that the bootagent or EFI code has

			 * improperly left this bit enabled

 Initialize device specific counter of SMBI acquisition timeouts. */

 global port a indication */

 tag quad port adapters first, it's used below */

 mark the first port */

 Reset for multiple quad port adapters */

 these dual ports don't have WoL on port B at all */

 quad ports only support WoL on port A */

 Does not support WoL on any port */

/**

 *  e1000_get_phy_id_82571 - Retrieve the PHY ID and revision

 *  @hw: pointer to the HW structure

 *

 *  Reads the PHY registers and stores the PHY ID and possibly the PHY

 *  revision in the hardware structure.

		/* The 82571 firmware may still be configuring the PHY.

		 * In this case, we cannot access the PHY until the

		 * configuration is done.  So we explicitly set the

		 * PHY ID.

/**

 *  e1000_get_hw_semaphore_82571 - Acquire hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Acquire the HW semaphore to access the PHY or NVM

	/* If we have timedout 3 times on trying to acquire

	 * the inter-port SMBI semaphore, there is old code

	 * operating on the other port, and it is not

	 * releasing SMBI. Modify the number of times that

	 * we try for the semaphore to interwork with this

	 * older code.

 Get the SW semaphore */

 Get the FW semaphore. */

 Semaphore acquired if bit latched */

 Release semaphores */

/**

 *  e1000_put_hw_semaphore_82571 - Release hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Release hardware semaphore used to access the PHY or NVM

/**

 *  e1000_get_hw_semaphore_82573 - Acquire hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Acquire the HW semaphore during reset.

 *

 Release semaphores */

/**

 *  e1000_put_hw_semaphore_82573 - Release hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Release hardware semaphore used during reset.

 *

/**

 *  e1000_get_hw_semaphore_82574 - Acquire hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Acquire the HW semaphore to access the PHY or NVM.

 *

/**

 *  e1000_put_hw_semaphore_82574 - Release hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Release hardware semaphore used to access the PHY or NVM

 *

/**

 *  e1000_set_d0_lplu_state_82574 - Set Low Power Linkup D0 state

 *  @hw: pointer to the HW structure

 *  @active: true to enable LPLU, false to disable

 *

 *  Sets the LPLU D0 state according to the active flag.

 *  LPLU will not be activated unless the

 *  device autonegotiation advertisement meets standards of

 *  either 10 or 10/100 or 10/100/1000 at all duplexes.

 *  This is a function pointer entry point only called by

 *  PHY setup routines.

/**

 *  e1000_set_d3_lplu_state_82574 - Sets low power link up state for D3

 *  @hw: pointer to the HW structure

 *  @active: boolean used to enable/disable lplu

 *

 *  The low power link up (lplu) state is set to the power management level D3

 *  when active is true, else clear lplu for D3. LPLU

 *  is used during Dx states where the power conservation is most important.

 *  During driver activity, SmartSpeed should be enabled so performance is

 *  maintained.

/**

 *  e1000_acquire_nvm_82571 - Request for access to the EEPROM

 *  @hw: pointer to the HW structure

 *

 *  To gain access to the EEPROM, first we must obtain a hardware semaphore.

 *  Then for non-82573 hardware, set the EEPROM access request bit and wait

 *  for EEPROM access grant bit.  If the access grant bit is not set, release

 *  hardware semaphore.

/**

 *  e1000_release_nvm_82571 - Release exclusive access to EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Stop any current commands to the EEPROM and clear the EEPROM request bit.

/**

 *  e1000_write_nvm_82571 - Write to EEPROM using appropriate interface

 *  @hw: pointer to the HW structure

 *  @offset: offset within the EEPROM to be written to

 *  @words: number of words to write

 *  @data: 16 bit word(s) to be written to the EEPROM

 *

 *  For non-82573 silicon, write data to EEPROM at offset using SPI interface.

 *

 *  If e1000e_update_nvm_checksum is not called after this function, the

 *  EEPROM will most likely contain an invalid checksum.

/**

 *  e1000_update_nvm_checksum_82571 - Update EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Updates the EEPROM checksum by reading/adding each word of the EEPROM

 *  up to the checksum.  Then calculates the EEPROM checksum and writes the

 *  value to the EEPROM.

	/* If our nvm is an EEPROM, then we're done

	 * otherwise, commit the checksum to the flash NVM.

 Check for pending operations. */

 Reset the firmware if using STM opcode. */

		/* The enabling of and the actual reset must be done

		 * in two write cycles.

 Commit the write to flash */

/**

 *  e1000_validate_nvm_checksum_82571 - Validate EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Calculates the EEPROM checksum by reading/adding each word of the EEPROM

 *  and then verifies that the sum of the EEPROM is equal to 0xBABA.

/**

 *  e1000_write_nvm_eewr_82571 - Write to EEPROM for 82573 silicon

 *  @hw: pointer to the HW structure

 *  @offset: offset within the EEPROM to be written to

 *  @words: number of words to write

 *  @data: 16 bit word(s) to be written to the EEPROM

 *

 *  After checking for invalid values, poll the EEPROM to ensure the previous

 *  command has completed before trying to write the next word.  After write

 *  poll for completion.

 *

 *  If e1000e_update_nvm_checksum is not called after this function, the

 *  EEPROM will most likely contain an invalid checksum.

	/* A check for invalid values:  offset too large, too many words,

	 * and not enough words.

/**

 *  e1000_get_cfg_done_82571 - Poll for configuration done

 *  @hw: pointer to the HW structure

 *

 *  Reads the management control register for the config done bit to be set.

/**

 *  e1000_set_d0_lplu_state_82571 - Set Low Power Linkup D0 state

 *  @hw: pointer to the HW structure

 *  @active: true to enable LPLU, false to disable

 *

 *  Sets the LPLU D0 state according to the active flag.  When activating LPLU

 *  this function also disables smart speed and vice versa.  LPLU will not be

 *  activated unless the device autonegotiation advertisement meets standards

 *  of either 10 or 10/100 or 10/100/1000 at all duplexes.  This is a function

 *  pointer entry point only called by PHY setup routines.

 When LPLU is enabled, we should disable SmartSpeed */

		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used

		 * during Dx states where the power conservation is most

		 * important.  During driver activity we should enable

		 * SmartSpeed, so performance is maintained.

/**

 *  e1000_reset_hw_82571 - Reset hardware

 *  @hw: pointer to the HW structure

 *

 *  This resets the hardware into a known state.

	/* Prevent the PCI-E bus from sticking if there is no TLP connection

	 * on the last TLP read/write transaction when MAC is reset.

	/* Must acquire the MDIO ownership before MAC reset.

	 * Ownership defaults to firmware after a reset.

 Must release MDIO ownership and mutex after MAC reset. */

 Release mutex only if the hw semaphore is acquired */

 Release mutex only if the hw semaphore is acquired */

 We don't want to continue accessing MAC registers. */

	/* Phy configuration from NVM just starts after EECD_AUTO_RD is set.

	 * Need to wait for Phy configuration completion before accessing

	 * NVM and Phy.

		/* REQ and GNT bits need to be cleared when using AUTO_RD

		 * to access the EEPROM.

 Clear any pending interrupt events. */

 Install any alternate MAC address into RAR0 */

 Reinitialize the 82571 serdes link state machine */

/**

 *  e1000_init_hw_82571 - Initialize hardware

 *  @hw: pointer to the HW structure

 *

 *  This inits the hardware readying it for operation.

 Initialize identification LED */

 An error is not fatal and we should not stop init due to this */

 Disabling VLAN filtering */

	/* Setup the receive address.

	 * If, however, a locally administered address was assigned to the

	 * 82571, we must reserve a RAR for it to work around an issue where

	 * resetting one port will reload the MAC on the other port.

 Zero out the Multicast HASH table */

 Setup link and flow control */

 Set the transmit descriptor write-back policy */

 ...for both queues. */

	/* Clear all of the statistics registers (clear on read).  It is

	 * important that we do this after we have tried to establish link

	 * because the symbol error count will increment wildly if there

	 * is no link.

/**

 *  e1000_initialize_hw_bits_82571 - Initialize hardware-dependent bits

 *  @hw: pointer to the HW structure

 *

 *  Initializes required hardware-dependent bits needed for normal operation.

 Transmit Descriptor Control 0 */

 Transmit Descriptor Control 1 */

 Transmit Arbitration Control 0 */

 30:27 */

 Transmit Arbitration Control 1 */

 Device Control */

 Extended Device Control */

	/* Workaround for hardware errata.

	 * Ensure that DMA Dynamic Clock gating is disabled on 82571 and 82572

	/* Disable IPv6 extension header parsing because some malformed

	 * IPv6 headers can hang the Rx.

 PCI-Ex Control Registers */

		/* Workaround for hardware errata.

		 * apply workaround for hardware errata documented in errata

		 * docs Fixes issue where some error prone or unreliable PCIe

		 * completions are occurring, particularly with ASPM enabled.

		 * Without fix, issue can cause Tx timeouts.

/**

 *  e1000_clear_vfta_82571 - Clear VLAN filter table

 *  @hw: pointer to the HW structure

 *

 *  Clears the register array which contains the VLAN filter table by

 *  setting all the values to 0.

			/* The VFTA is a 4096b bit-field, each identifying

			 * a single VLAN ID.  The following operations

			 * determine which 32b entry (i.e. offset) into the

			 * array we want to set the VLAN ID (i.e. bit) of

			 * the manageability unit.

		/* If the offset we want to clear is the same offset of the

		 * manageability VLAN ID, then clear all bits except that of

		 * the manageability unit.

/**

 *  e1000_check_mng_mode_82574 - Check manageability is enabled

 *  @hw: pointer to the HW structure

 *

 *  Reads the NVM Initialization Control Word 2 and returns true

 *  (>0) if any manageability is enabled, else false (0).

/**

 *  e1000_led_on_82574 - Turn LED on

 *  @hw: pointer to the HW structure

 *

 *  Turn LED on.

		/* If no link, then turn LED on by setting the invert bit

		 * for each LED that's "on" (0x0E) in ledctl_mode2.

/**

 *  e1000_check_phy_82574 - check 82574 phy hung state

 *  @hw: pointer to the HW structure

 *

 *  Returns whether phy is hung or not

	/* Read PHY Receive Error counter first, if its is max - all F's then

	 * read the Base1000T status register If both are max then PHY is hung.

/**

 *  e1000_setup_link_82571 - Setup flow control and link settings

 *  @hw: pointer to the HW structure

 *

 *  Determines which flow control settings to use, then configures flow

 *  control.  Calls the appropriate media-specific link configuration

 *  function.  Assuming the adapter has a valid link partner, a valid link

 *  should be established.  Assumes the hardware has previously been reset

 *  and the transmitter and receiver are not enabled.

	/* 82573 does not have a word in the NVM to determine

	 * the default flow control setting, so we explicitly

	 * set it to full.

/**

 *  e1000_setup_copper_link_82571 - Configure copper link settings

 *  @hw: pointer to the HW structure

 *

 *  Configures the link for auto-neg or forced speed and duplex.  Then we check

 *  for link, once link is established calls to configure collision distance

 *  and flow control are called.

/**

 *  e1000_setup_fiber_serdes_link_82571 - Setup link for fiber/serdes

 *  @hw: pointer to the HW structure

 *

 *  Configures collision distance and flow control for fiber and serdes links.

 *  Upon successful setup, poll for link.

		/* If SerDes loopback mode is entered, there is no form

		 * of reset to take the adapter out of that mode.  So we

		 * have to explicitly take the adapter out of loopback

		 * mode.  This prevents drivers from twiddling their thumbs

		 * if another tool failed to take it out of loopback mode.

/**

 *  e1000_check_for_serdes_link_82571 - Check for link (Serdes)

 *  @hw: pointer to the HW structure

 *

 *  Reports the link state as up or down.

 *

 *  If autonegotiation is supported by the link partner, the link state is

 *  determined by the result of autonegotiation. This is the most likely case.

 *  If autonegotiation is not supported by the link partner, and the link

 *  has a valid signal, force the link up.

 *

 *  The link state is represented internally here by 4 states:

 *

 *  1) down

 *  2) autoneg_progress

 *  3) autoneg_complete (the link successfully autonegotiated)

 *  4) forced_up (the link has been forced up, it did not autonegotiate)

 *

 SYNCH bit and IV bit are sticky */

 Receiver is synchronized with no invalid bits.  */

				/* We have lost link, retry autoneg before

				 * reporting link failure

			/* If we are receiving /C/ ordered sets, re-enable

			 * auto-negotiation in the TXCW register and disable

			 * forced link in the Device Control register in an

			 * attempt to auto-negotiate with our link partner.

 Enable autoneg, and unforce link up */

				/* We received /C/ ordered sets, meaning the

				 * link partner has autonegotiated, and we can

				 * trust the Link Up (LU) status bit.

 Autoneg completed, but failed. */

				/* The link partner did not autoneg.

				 * Force link up and full duplex, and change

				 * state to forced.

 Configure Flow Control after link up. */

			/* The link was down but the receiver has now gained

			 * valid sync, so lets see if we can bring the link

			 * up.

			/* Check several times, if SYNCH bit and CONFIG

			 * bit both are consistently 1 then simply ignore

			 * the IV bit and restart Autoneg

/**

 *  e1000_valid_led_default_82571 - Verify a valid default LED config

 *  @hw: pointer to the HW structure

 *  @data: pointer to the NVM (EEPROM)

 *

 *  Read the EEPROM for the current default LED configuration.  If the

 *  LED configuration is not valid, set to a valid LED configuration.

/**

 *  e1000e_get_laa_state_82571 - Get locally administered address state

 *  @hw: pointer to the HW structure

 *

 *  Retrieve and return the current locally administered address state.

/**

 *  e1000e_set_laa_state_82571 - Set locally administered address state

 *  @hw: pointer to the HW structure

 *  @state: enable/disable locally administered address

 *

 *  Enable/Disable the current locally administered address state.

 If workaround is activated... */

		/* Hold a copy of the LAA in RAR[14] This is done so that

		 * between the time RAR[0] gets clobbered and the time it

		 * gets fixed, the actual LAA is in one of the RARs and no

		 * incoming packets directed to this port are dropped.

		 * Eventually the LAA will be in RAR[0] and RAR[14].

/**

 *  e1000_fix_nvm_checksum_82571 - Fix EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Verifies that the EEPROM has completed the update.  After updating the

 *  EEPROM, we need to check bit 15 in work 0x23 for the checksum fix.  If

 *  the checksum fix is not implemented, we need to set the bit and update

 *  the checksum.  Otherwise, if bit 15 is set and the checksum is incorrect,

 *  we need to return bad checksum.

	/* Check bit 4 of word 10h.  If it is 0, firmware is done updating

	 * 10h-12h.  Checksum may need to be fixed.

		/* Read 0x23 and check bit 15.  This bit is a 1

		 * when the checksum has already been fixed.  If

		 * the checksum is still wrong and this bit is a

		 * 1, we need to return bad checksum.  Otherwise,

		 * we need to set this bit to a 1 and update the

		 * checksum.

/**

 *  e1000_read_mac_addr_82571 - Read device MAC address

 *  @hw: pointer to the HW structure

		/* If there's an alternate MAC address place it in RAR0

		 * so that it will override the Si installed default perm

		 * address.

/**

 * e1000_power_down_phy_copper_82571 - Remove link during PHY power down

 * @hw: pointer to the HW structure

 *

 * In the case of a PHY power down to save power, or to turn off link during a

 * driver unload, or wake on lan is not enabled, remove the link.

 If the management interface is not enabled, then power down */

/**

 *  e1000_clear_hw_cntrs_82571 - Clear device specific hardware counters

 *  @hw: pointer to the HW structure

 *

 *  Clears the hardware counters by reading the counter registers.

 .check_mng_mode: mac type dependent */

 .check_for_link: media type dependent */

 .get_link_up_info: media type dependent */

 .led_on: mac type dependent */

 .setup_physical_interface: media type dependent */

 errata */

 errata */

 errata 13 */

 errata */

 errata 13 */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/* PTP 1588 Hardware Clock (PHC)

 * Derived from PTP Hardware Clock driver for Intel 82576 and 82580 (igb)

 * Copyright (C) 2011 Richard Cochran <richardcochran@gmail.com>

/**

 * e1000e_phc_adjfreq - adjust the frequency of the hardware clock

 * @ptp: ptp clock structure

 * @delta: Desired frequency change in parts per billion

 *

 * Adjust the frequency of the PHC cycle counter by the indicated delta from

 * the base frequency.

 Get the System Time Register SYSTIM base frequency */

/**

 * e1000e_phc_adjtime - Shift the time of the hardware clock

 * @ptp: ptp clock structure

 * @delta: Desired change in nanoseconds

 *

 * Adjust the timer by resetting the timecounter structure.

/**

 * e1000e_phc_get_syncdevicetime - Callback given to timekeeping code reads system/device registers

 * @device: current device time

 * @system: system counter value read synchronously with device time

 * @ctx: context provided by timekeeping code

 *

 * Read device and system (ART) clock simultaneously and return the corrected

 * clock values in ns.

/**

 * e1000e_phc_getcrosststamp - Reads the current system/device cross timestamp

 * @ptp: ptp clock structure

 * @xtstamp: structure containing timestamp

 *

 * Read device and system (ART) clock simultaneously and return the scaled

 * clock values in ns.

CONFIG_E1000E_HWTS*/

/**

 * e1000e_phc_gettimex - Reads the current time from the hardware clock and

 *                       system clock

 * @ptp: ptp clock structure

 * @ts: timespec structure to hold the current PHC time

 * @sts: structure to hold the current system time

 *

 * Read the timecounter and return the correct value in ns after converting

 * it into a struct timespec.

 NOTE: Non-monotonic SYSTIM readings may be returned */

/**

 * e1000e_phc_settime - Set the current time on the hardware clock

 * @ptp: ptp clock structure

 * @ts: timespec containing the new time for the cycle counter

 *

 * Reset the timecounter to use a new base value instead of the kernel

 * wall timer value.

 reset the timecounter */

/**

 * e1000e_phc_enable - enable or disable an ancillary feature

 * @ptp: ptp clock structure

 * @request: Desired resource to enable or disable

 * @on: Caller passes one to enable or zero to disable

 *

 * Enable (or disable) ancillary features of the PHC subsystem.

 * Currently, no ancillary features are supported.

 Update the timecounter */

/**

 * e1000e_ptp_init - initialize PTP for devices which support it

 * @adapter: board private structure

 *

 * This function performs the required steps for enabling PTP support.

 * If PTP support has already been loaded it simply calls the cyclecounter

 * init routine and exits.

 CPU must have ART and GBe must be from Sunrise Point or greater */

CONFIG_E1000E_HWTS*/

/**

 * e1000e_ptp_remove - disable PTP device and stop the overflow check

 * @adapter: board private structure

 *

 * Stop the PTP support, and cancel the delayed work.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/* 82562G 10/100 Network Connection

 * 82562G-2 10/100 Network Connection

 * 82562GT 10/100 Network Connection

 * 82562GT-2 10/100 Network Connection

 * 82562V 10/100 Network Connection

 * 82562V-2 10/100 Network Connection

 * 82566DC-2 Gigabit Network Connection

 * 82566DC Gigabit Network Connection

 * 82566DM-2 Gigabit Network Connection

 * 82566DM Gigabit Network Connection

 * 82566MC Gigabit Network Connection

 * 82566MM Gigabit Network Connection

 * 82567LM Gigabit Network Connection

 * 82567LF Gigabit Network Connection

 * 82567V Gigabit Network Connection

 * 82567LM-2 Gigabit Network Connection

 * 82567LF-2 Gigabit Network Connection

 * 82567V-2 Gigabit Network Connection

 * 82567LF-3 Gigabit Network Connection

 * 82567LM-3 Gigabit Network Connection

 * 82567LM-4 Gigabit Network Connection

 * 82577LM Gigabit Network Connection

 * 82577LC Gigabit Network Connection

 * 82578DM Gigabit Network Connection

 * 82578DC Gigabit Network Connection

 * 82579LM Gigabit Network Connection

 * 82579V Gigabit Network Connection

 * Ethernet Connection I217-LM

 * Ethernet Connection I217-V

 * Ethernet Connection I218-V

 * Ethernet Connection I218-LM

 * Ethernet Connection (2) I218-LM

 * Ethernet Connection (2) I218-V

 * Ethernet Connection (3) I218-LM

 * Ethernet Connection (3) I218-V

 ICH GbE Flash Hardware Sequencing Flash Status Register bit breakdown */

 Offset 04h HSFSTS */

 bit 0 Flash Cycle Done */

 bit 1 Flash Cycle Error */

 bit 2 Direct Access error Log */

 bit 4:3 Sector Erase Size */

 bit 5 flash cycle in Progress */

 bit 13:6 Reserved */

 bit 13:6 Reserved */

 bit 14 Flash Descriptor Valid */

 bit 15 Flash Config Lock-Down */

 ICH GbE Flash Hardware Sequencing Flash control Register bit breakdown */

 Offset 06h FLCTL */

 0 Flash Cycle Go */

 2:1 Flash Cycle */

 7:3 Reserved  */

 9:8 Flash Data Byte Count */

 15:10 Reserved */

 ICH Flash Region Access Permissions */

 0:7 GbE region Read Access */

 8:15 GbE region Write Access */

 23:16 GbE Master Read Access Grant */

 31:24 GbE Master Write Access Grant */

 ICH Flash Protected Region */

 0:12 Protected Range Base */

 13:14 Reserved */

 15 Read Protection Enable */

 16:28 Protected Range Limit */

 29:30 Reserved */

 31 Write Protection Enable */

/**

 *  e1000_phy_is_accessible_pchlan - Check if able to access PHY registers

 *  @hw: pointer to the HW structure

 *

 *  Test access to the PHY registers by reading the PHY ID registers.  If

 *  the PHY ID is already known (e.g. resume path) compare it with known ID,

 *  otherwise assume the read PHY ID is correct if it is valid.

 *

 *  Assumes the sw/fw/hw semaphore is already acquired.

	/* In case the PHY needs to be in mdio slow mode,

	 * set slow mode and try to get the PHY id again.

 Only unforce SMBus if ME is not active */

 Unforce SMBus mode in PHY */

 Unforce SMBus mode in MAC */

/**

 *  e1000_toggle_lanphypc_pch_lpt - toggle the LANPHYPC pin value

 *  @hw: pointer to the HW structure

 *

 *  Toggling the LANPHYPC pin value fully power-cycles the PHY and is

 *  used to reset the PHY to a quiescent state when necessary.

 Set Phy Config Counter to 50msec */

 Toggle LANPHYPC Value bit */

/**

 *  e1000_init_phy_workarounds_pchlan - PHY initialization workarounds

 *  @hw: pointer to the HW structure

 *

 *  Workarounds/flow necessary for PHY initialization during driver load

 *  and resume paths.

	/* Gate automatic PHY configuration by hardware on managed and

	 * non-managed 82579 and newer adapters.

	/* It is not possible to be certain of the current state of ULP

	 * so forcibly disable it.

	/* The MAC-PHY interconnect may be in SMBus mode.  If the PHY is

	 * inaccessible and resetting the PHY is not blocked, toggle the

	 * LANPHYPC Value bit to force the interconnect to PCIe mode.

		/* Before toggling LANPHYPC, see if PHY is accessible by

		 * forcing MAC to SMBus mode first.

		/* Wait 50 milliseconds for MAC to finish any retries

		 * that it might be trying to perform from previous

		 * attempts to acknowledge any phy read requests.

 Toggle LANPHYPC Value bit */

			/* Toggling LANPHYPC brings the PHY out of SMBus mode

			 * so ensure that the MAC is also out of SMBus mode

 Check to see if able to reset PHY.  Print error if not */

		/* Reset the PHY before any access to it.  Doing so, ensures

		 * that the PHY is in a known good state before we read/write

		 * PHY registers.  The generic reset is sufficient here,

		 * because we haven't determined the PHY type yet.

		/* On a successful reset, possibly need to wait for the PHY

		 * to quiesce to an accessible state before returning control

		 * to the calling function.  If the PHY does not quiesce, then

		 * return E1000E_BLK_PHY_RESET, as this is the condition that

		 *  the PHY is in.

 Ungate automatic PHY configuration on non-managed 82579 */

/**

 *  e1000_init_phy_params_pchlan - Initialize PHY function pointers

 *  @hw: pointer to the HW structure

 *

 *  Initialize family-specific PHY parameters and function pointers.

			/* In case the PHY needs to be in mdio slow mode,

			 * set slow mode and try to get the PHY id again.

/**

 *  e1000_init_phy_params_ich8lan - Initialize PHY function pointers

 *  @hw: pointer to the HW structure

 *

 *  Initialize family-specific PHY parameters and function pointers.

	/* We may need to do this twice - once for IGP and if that fails,

	 * we'll set BM func pointers and try again

 Verify phy id */

/**

 *  e1000_init_nvm_params_ich8lan - Initialize NVM function pointers

 *  @hw: pointer to the HW structure

 *

 *  Initialize family-specific NVM parameters and function

 *  pointers.

		/* in SPT, gfpreg doesn't exist. NVM size is taken from the

		 * STRAP register. This is because in SPT the GbE Flash region

		 * is no longer accessed through the flash registers. Instead,

		 * the mechanism has changed, and the Flash region access

		 * registers are now implemented in GbE memory space.

 Adjust to word count */

 Set the base address for flash register access */

 Can't read flash registers if register set isn't mapped. */

		/* sector_X_addr is a "sector"-aligned address (4096 bytes)

		 * Add 1 to sector_end_addr since this sector is included in

		 * the overall size.

 flash_base_addr is byte-aligned */

		/* find total size of the NVM, then cut in half since the total

		 * size represents two separate NVM banks.

 Adjust to word count */

 Clear shadow ram */

/**

 *  e1000_init_mac_params_ich8lan - Initialize MAC function pointers

 *  @hw: pointer to the HW structure

 *

 *  Initialize family-specific MAC parameters and function

 *  pointers.

 Set media type function pointer */

 Set mta register count */

 Set rar entry count */

 FWSM register */

 ARC subsystem not supported */

 Adaptive IFS supported */

 LED and other operations */

 check management mode */

 ID LED init */

 blink LED */

 setup LED */

 cleanup LED */

 turn on/off LED */

 check management mode */

 ID LED init */

 setup LED */

 cleanup LED */

 turn on/off LED */

 Enable PCS Lock-loss workaround for ICH8 */

/**

 *  __e1000_access_emi_reg_locked - Read/write EMI register

 *  @hw: pointer to the HW structure

 *  @address: EMI address to program

 *  @data: pointer to value to read/write from/to the EMI address

 *  @read: boolean flag to indicate read or write

 *

 *  This helper function assumes the SW/FW/HW Semaphore is already acquired.

/**

 *  e1000_read_emi_reg_locked - Read Extended Management Interface register

 *  @hw: pointer to the HW structure

 *  @addr: EMI address to program

 *  @data: value to be read from the EMI address

 *

 *  Assumes the SW/FW/HW Semaphore is already acquired.

/**

 *  e1000_write_emi_reg_locked - Write Extended Management Interface register

 *  @hw: pointer to the HW structure

 *  @addr: EMI address to program

 *  @data: value to be written to the EMI address

 *

 *  Assumes the SW/FW/HW Semaphore is already acquired.

/**

 *  e1000_set_eee_pchlan - Enable/disable EEE support

 *  @hw: pointer to the HW structure

 *

 *  Enable/disable EEE based on setting in dev_spec structure, the duplex of

 *  the link and the EEE capabilities of the link partner.  The LPI Control

 *  register bits will remain set only if/when link is up.

 *

 *  EEE LPI must not be asserted earlier than one second after link is up.

 *  On 82579, EEE LPI should not be enabled until such time otherwise there

 *  can be link issues with some switches.  Other devices can have EEE LPI

 *  enabled immediately upon link up since they have a timer in hardware which

 *  prevents LPI from being asserted too early.

 Clear bits that enable EEE in various speeds */

 Enable EEE if not disabled by user */

 Save off link partner's EEE ability */

 Read EEE advertisement */

		/* Enable EEE only for speeds in which the link partner is

		 * EEE capable and for which we advertise EEE.

				/* EEE is not supported in 100Half, so ignore

				 * partner's EEE in 100 ability if full-duplex

				 * is not advertised.

 R/Clr IEEE MMD 3.1 bits 11:10 - Tx/Rx LPI Received */

/**

 *  e1000_k1_workaround_lpt_lp - K1 workaround on Lynxpoint-LP

 *  @hw:   pointer to the HW structure

 *  @link: link up bool flag

 *

 *  When K1 is enabled for 1Gbps, the MAC can miss 2 DMA completion indications

 *  preventing further DMA write requests.  Workaround the issue by disabling

 *  the de-assertion of the clock request when in 1Gpbs mode.

 *  Also, set appropriate Tx re-transmission timeouts for 10 and 100Half link

 *  speeds in order to avoid Tx hangs.

 clear FEXTNVM6 bit 8 on link down or 10/100 */

 Clear link status transmit timeout */

 Set inband Tx timeout to 5x10us for 100Half */

 Do not extend the K1 entry latency for 100Half */

 Set inband Tx timeout to 50x10us for 10Full/Half */

 Extend the K1 entry latency for 10 Mbps */

/**

 *  e1000_platform_pm_pch_lpt - Set platform power management values

 *  @hw: pointer to the HW structure

 *  @link: bool indicating link status

 *

 *  Set the Latency Tolerance Reporting (LTR) values for the "PCIe-like"

 *  GbE MAC in the Lynx Point PCH based on Rx buffer size and link speed

 *  when link is up (which must not exceed the maximum latency supported

 *  by the platform), otherwise specify there is no LTR requirement.

 *  Unlike true-PCIe devices which set the LTR maximum snoop/no-snoop

 *  latencies in the LTR Extended Capability Structure in the PCIe Extended

 *  Capability register set, on this device LTR is set by writing the

 *  equivalent snoop/no-snoop latencies in the LTRV register in the MAC and

 *  set the SEND bit to send an Intel On-chip System Fabric sideband (IOSF-SB)

 *  message to the PMC.

 maximum LTR decoded by platform */

 latency decoded */

 latency encoded */

 max LTR latency encoded */

 Rx Packet Buffer Allocation size (KB) */

		/* Determine the maximum latency tolerated by the device.

		 *

		 * Per the PCIe spec, the tolerated latencies are encoded as

		 * a 3-bit encoded scale (only 0-5 are valid) multiplied by

		 * a 10-bit value (0-1023) to provide a range from 1 ns to

		 * 2^25*(2^10-1) ns.  The scale is encoded as 0=2^0ns,

		 * 1=2^5ns, 2=2^10ns,...5=2^25ns.

 Determine the maximum latency tolerated by the platform */

 Set Snoop and No-Snoop latencies the same */

/**

 *  e1000_enable_ulp_lpt_lp - configure Ultra Low Power mode for LynxPoint-LP

 *  @hw: pointer to the HW structure

 *  @to_sx: boolean indicating a system power state transition to Sx

 *

 *  When link is down, configure ULP mode to significantly reduce the power

 *  to the PHY.  If on a Manageability Engine (ME) enabled system, tell the

 *  ME firmware to start the ULP configuration.  If not on an ME enabled

 *  system, configure the ULP mode by software.

 Request ME configure ULP mode in the PHY */

 Poll up to 5 seconds for Cable Disconnected indication */

 Bail if link is re-acquired */

 Force SMBus mode in PHY */

 Force SMBus mode in MAC */

	/* Si workaround for ULP entry flow on i127/rev6 h/w.  Enable

	 * LPLU and disable Gig speed when entering ULP

	/* Set Inband ULP Exit, Reset to SMBus mode and

	 * Disable SMBus Release on PERST# in PHY

 Set Disable SMBus Release on PERST# in MAC */

 Commit ULP changes in PHY by starting auto ULP configuration */

/**

 *  e1000_disable_ulp_lpt_lp - unconfigure Ultra Low Power mode for LynxPoint-LP

 *  @hw: pointer to the HW structure

 *  @force: boolean indicating whether or not to force disabling ULP

 *

 *  Un-configure ULP mode when link is up, the system is transitioned from

 *  Sx or the driver is unloaded.  If on a Manageability Engine (ME) enabled

 *  system, poll for an indication from ME that ULP has been un-configured.

 *  If not on an ME enabled system, un-configure the ULP mode by software.

 *

 *  During nominal operation, this function is called when link is acquired

 *  to disable ULP mode (force=false); otherwise, for example when unloading

 *  the driver or during Sx->S0 transitions, this is called with force=true

 *  to forcibly disable ULP.

 Request ME un-configure ULP mode in the PHY */

		/* Poll up to 2.5 seconds for ME to clear ULP_CFG_DONE.

		 * If this takes more than 1 second, show a warning indicating a

		 * firmware bug

 Clear H2ME.ULP after ME ULP configuration */

 Toggle LANPHYPC Value bit */

 Unforce SMBus mode in PHY */

		/* The MAC might be in PCIe mode, so temporarily force to

		 * SMBus mode in order to access the PHY.

 Unforce SMBus mode in MAC */

	/* When ULP mode was previously entered, K1 was disabled by the

	 * hardware.  Re-Enable K1 in the PHY when exiting ULP.

 Clear ULP enabled configuration */

 Commit ULP changes by starting auto ULP configuration */

 Clear Disable SMBus Release on PERST# in MAC */

/**

 *  e1000_check_for_copper_link_ich8lan - Check for link (Copper)

 *  @hw: pointer to the HW structure

 *

 *  Checks to see of the link status of the hardware has changed.  If a

 *  change in link status has been detected, then we read the PHY registers

 *  to get the current speed/duplex if link exists.

	/* We only want to go out to the PHY registers to see if Auto-Neg

	 * has completed and/or if our link status has changed.  The

	 * get_link_status flag is set upon receiving a Link Status

	 * Change or Rx Sequence Error interrupt.

	/* First we want to see if the MII Status Register reports

	 * link.  If so, then we want to get the current speed/duplex

	 * of the PHY.

	/* When connected at 10Mbps half-duplex, some parts are excessively

	 * aggressive resulting in many collisions. To avoid this, increase

	 * the IPG and reduce Rx latency in the PHY.

 Reduce Rx latency in analog PHY */

 Roll back the default values */

	/* I217 Packet Loss issue:

	 * ensure that FEXTNVM4 Beacon Duration is set correctly

	 * on power up.

	 * Set the Beacon Duration for I217 to 8 usec

 Work-around I218 hang issue */

		/* Set platform power management values for

		 * Latency Tolerance Reporting (LTR)

 Clear link partner's EEE ability */

 FEXTNVM6 K1-off workaround - for SPT only */

		/* Workaround for PCHx parts in half-duplex:

		 * Set the number of preambles removed from the packet

		 * when it is passed from the PHY to the MAC to prevent

		 * the MAC from misinterpreting the packet type.

	/* Check if there was DownShift, must be checked

	 * immediately after link-up

 Enable/Disable EEE after link up */

	/* If we are forcing speed/duplex, then we simply return since

	 * we have already determined whether we have link or not.

	/* Auto-Neg is enabled.  Auto Speed Detection takes care

	 * of MAC speed/duplex configuration.  So we only need to

	 * configure Collision Distance in the MAC.

	/* Configure Flow Control now that Auto-Neg has completed.

	 * First, we need to restore the desired flow control

	 * settings because we may have had to re-autoneg with a

	 * different link partner.

	/* Disable Jumbo Frame support on parts with Intel 10/100 PHY or

	 * on parts with MACsec enabled in NVM (reflected in CTRL_EXT).

 Enable workaround for 82579 w/ ME enabled */

/**

 *  e1000_acquire_nvm_ich8lan - Acquire NVM mutex

 *  @hw: pointer to the HW structure

 *

 *  Acquires the mutex for performing NVM operations.

/**

 *  e1000_release_nvm_ich8lan - Release NVM mutex

 *  @hw: pointer to the HW structure

 *

 *  Releases the mutex used while performing NVM operations.

/**

 *  e1000_acquire_swflag_ich8lan - Acquire software control flag

 *  @hw: pointer to the HW structure

 *

 *  Acquires the software control flag for performing PHY and select

 *  MAC CSR accesses.

/**

 *  e1000_release_swflag_ich8lan - Release software control flag

 *  @hw: pointer to the HW structure

 *

 *  Releases the software control flag for performing PHY and select

 *  MAC CSR accesses.

/**

 *  e1000_check_mng_mode_ich8lan - Checks management mode

 *  @hw: pointer to the HW structure

 *

 *  This checks if the adapter has any manageability enabled.

 *  This is a function pointer entry point only called by read/write

 *  routines for the PHY and NVM parts.

/**

 *  e1000_check_mng_mode_pchlan - Checks management mode

 *  @hw: pointer to the HW structure

 *

 *  This checks if the adapter has iAMT enabled.

 *  This is a function pointer entry point only called by read/write

 *  routines for the PHY and NVM parts.

/**

 *  e1000_rar_set_pch2lan - Set receive address register

 *  @hw: pointer to the HW structure

 *  @addr: pointer to the receive address

 *  @index: receive address array register

 *

 *  Sets the receive address array register at index to the address passed

 *  in by addr.  For 82579, RAR[0] is the base address register that is to

 *  contain the MAC address but RAR[1-6] are reserved for manageability (ME).

 *  Use SHRA[0-3] in place of those reserved for ME.

	/* HW expects these in little endian so we reverse the byte order

	 * from network order (big endian) to little endian

 If MAC address zero, no need to set the AV bit */

	/* RAR[1-6] are owned by manageability.  Skip those and program the

	 * next address into the SHRA register array.

 verify the register updates */

/**

 *  e1000_rar_get_count_pch_lpt - Get the number of available SHRA

 *  @hw: pointer to the HW structure

 *

 *  Get the number of available receive registers that the Host can

 *  program. SHRA[0-10] are the shared receive address registers

 *  that are shared between the Host and manageability engine (ME).

 *  ME can reserve any number of addresses and the host needs to be

 *  able to tell how many available registers it has access to.

 All SHRA[0..10] and RAR[0] available */

 Only RAR[0] available */

 SHRA[0..(wlock_mac - 1)] available + RAR[0] */

/**

 *  e1000_rar_set_pch_lpt - Set receive address registers

 *  @hw: pointer to the HW structure

 *  @addr: pointer to the receive address

 *  @index: receive address array register

 *

 *  Sets the receive address register array at index to the address passed

 *  in by addr. For LPT, RAR[0] is the base address register that is to

 *  contain the MAC address. SHRA[0-10] are the shared receive address

 *  registers that are shared between the Host and manageability engine (ME).

	/* HW expects these in little endian so we reverse the byte order

	 * from network order (big endian) to little endian

 If MAC address zero, no need to set the AV bit */

	/* The manageability engine (ME) can lock certain SHRAR registers that

	 * it is using - those registers are unavailable for use.

 Check if all SHRAR registers are locked */

 verify the register updates */

/**

 *  e1000_check_reset_block_ich8lan - Check if PHY reset is blocked

 *  @hw: pointer to the HW structure

 *

 *  Checks if firmware is blocking the reset of the PHY.

 *  This is a function pointer entry point only called by

 *  reset routines.

/**

 *  e1000_write_smbus_addr - Write SMBus address to PHY needed during Sx states

 *  @hw: pointer to the HW structure

 *

 *  Assumes semaphore already acquired.

 *

 Restore SMBus frequency */

/**

 *  e1000_sw_lcd_config_ich8lan - SW-based LCD Configuration

 *  @hw:   pointer to the HW structure

 *

 *  SW should configure the LCD from the NVM extended configuration region

 *  as a workaround for certain parts.

	/* Initialize the PHY from the NVM on ICH platforms.  This

	 * is needed due to an issue where the NVM configuration is

	 * not properly autoloaded after power transitions.

	 * Therefore, after each PHY reset, we will load the

	 * configuration data out of the NVM manually.

	/* Make sure HW does not configure LCD from PHY

	 * extended configuration before SW configuration

		/* HW configures the SMBus address and LEDs when the

		 * OEM and LCD Write Enable bits are set in the NVM.

		 * When both NVM bits are cleared, SW will configure

		 * them instead.

 Configure LCD from extended configuration region. */

 cnf_base_addr is in DWORD */

 Save off the PHY page for future writes. */

/**

 *  e1000_k1_gig_workaround_hv - K1 Si workaround

 *  @hw:   pointer to the HW structure

 *  @link: link up bool flag

 *

 *  If K1 is enabled for 1Gbps, the MAC might stall when transitioning

 *  from a lower speed.  This workaround disables K1 whenever link is at 1Gig

 *  If link is down, the function will restore the default K1 setting located

 *  in the NVM.

 Wrap the whole flow with the sw flag */

 Disable K1 when link is 1Gbps, otherwise use the NVM setting */

 Link stall fix for link up */

 Link stall fix for link down */

/**

 *  e1000_configure_k1_ich8lan - Configure K1 power state

 *  @hw: pointer to the HW structure

 *  @k1_enable: K1 state to configure

 *

 *  Configure the K1 power state based on the provided parameter.

 *  Assumes semaphore already acquired.

 *

 *  Success returns 0, Failure returns -E1000_ERR_PHY (-2)

/**

 *  e1000_oem_bits_config_ich8lan - SW-based LCD Configuration

 *  @hw:       pointer to the HW structure

 *  @d0_state: boolean if entering d0 or d3 device state

 *

 *  SW will configure Gbe Disable and LPLU based on the NVM. The four bits are

 *  collectively called OEM bits.  The OEM Write Enable bit and SW Config bit

 *  in NVM determines whether HW should configure LPLU and Gbe Disable.

 Set Restart auto-neg to activate the bits */

/**

 *  e1000_set_mdio_slow_mode_hv - Set slow MDIO access mode

 *  @hw:   pointer to the HW structure

/**

 *  e1000_hv_phy_workarounds_ich8lan - apply PHY workarounds

 *  @hw: pointer to the HW structure

 *

 *  A series of PHY workarounds to be done after every PHY reset.

 Set MDIO slow mode before any other MDIO access */

 Disable generation of early preamble */

 Preamble tuning for SSC */

		/* Return registers to default by doing a soft reset then

		 * writing 0x3140 to the control register.

 Select page 0 */

	/* Configure the K1 Si workaround during phy reset assuming there is

	 * link so that it disables K1 if link is in 1Gbps.

 Workaround for link disconnects on a busy hub in half duplex */

 set MSE higher to enable link to stay up when noise is high */

/**

 *  e1000_copy_rx_addrs_to_phy_ich8lan - Copy Rx addresses from MAC to PHY

 *  @hw:   pointer to the HW structure

 Copy both RAL/H (rar_entry_count) and SHRAL/H to PHY */

/**

 *  e1000_lv_jumbo_workaround_ich8lan - required for jumbo frame operation

 *  with 82579 PHY

 *  @hw: pointer to the HW structure

 *  @enable: flag to enable/disable workaround when enabling/disabling jumbos

 disable Rx path while enabling/disabling workaround */

		/* Write Rx addresses (rar_entry_count for RAL/H, and

		 * SHRAL/H) and initial CRC values to the MAC

 Write Rx addresses to the PHY */

 Enable jumbo frame workaround in the MAC */

 Enable jumbo frame workaround in the PHY */

 Write MAC register values back to h/w defaults */

 Write PHY register values back to h/w defaults */

 re-enable Rx path after enabling/disabling workaround */

/**

 *  e1000_lv_phy_workarounds_ich8lan - apply ich8 specific workarounds

 *  @hw: pointer to the HW structure

 *

 *  A series of PHY workarounds to be done after every PHY reset.

 Set MDIO slow mode before any other MDIO access */

 set MSE higher to enable link to stay up when noise is high */

 drop link after 5 times MSE threshold was reached */

/**

 *  e1000_k1_workaround_lv - K1 Si workaround

 *  @hw:   pointer to the HW structure

 *

 *  Workaround to set the K1 beacon duration for 82579 parts in 10Mbps

 *  Disable K1 in 1000Mbps and 100Mbps

 Set K1 beacon duration based on 10Mbs speed */

 LV 1G/100 Packet drop issue wa  */

/**

 *  e1000_gate_hw_phy_config_ich8lan - disable PHY config via hardware

 *  @hw:   pointer to the HW structure

 *  @gate: boolean set to true to gate, false to ungate

 *

 *  Gate/ungate the automatic PHY configuration via hardware; perform

 *  the configuration via software instead.

/**

 *  e1000_lan_init_done_ich8lan - Check for PHY config completion

 *  @hw: pointer to the HW structure

 *

 *  Check the appropriate indication the MAC has finished configuring the

 *  PHY after a software reset.

 Wait for basic configuration completes before proceeding */

	/* If basic configuration is incomplete before the above loop

	 * count reaches 0, loading the configuration from NVM will

	 * leave the PHY in a bad state possibly resulting in no link.

 Clear the Init Done bit for the next init event */

/**

 *  e1000_post_phy_reset_ich8lan - Perform steps required after a PHY reset

 *  @hw: pointer to the HW structure

 Allow time for h/w to get to quiescent state after reset */

 Perform any necessary post-reset workarounds */

 Clear the host wakeup bit after lcd reset */

 Configure the LCD with the extended configuration region in NVM */

 Configure the LCD with the OEM bits in NVM */

 Ungate automatic PHY configuration on non-managed 82579 */

 Set EEE LPI Update Timer to 200usec */

/**

 *  e1000_phy_hw_reset_ich8lan - Performs a PHY reset

 *  @hw: pointer to the HW structure

 *

 *  Resets the PHY

 *  This is a function pointer entry point called by drivers

 *  or other shared routines.

 Gate automatic PHY configuration by hardware on non-managed 82579 */

/**

 *  e1000_set_lplu_state_pchlan - Set Low Power Link Up state

 *  @hw: pointer to the HW structure

 *  @active: true to enable LPLU, false to disable

 *

 *  Sets the LPLU state according to the active flag.  For PCH, if OEM write

 *  bit are disabled in the NVM, writing the LPLU bits in the MAC will not set

 *  the phy speed. This function will manually set the LPLU bit and restart

 *  auto-neg as hw would do. D3 and D0 LPLU will call the same function

 *  since it configures the same bit.

/**

 *  e1000_set_d0_lplu_state_ich8lan - Set Low Power Linkup D0 state

 *  @hw: pointer to the HW structure

 *  @active: true to enable LPLU, false to disable

 *

 *  Sets the LPLU D0 state according to the active flag.  When

 *  activating LPLU this function also disables smart speed

 *  and vice versa.  LPLU will not be activated unless the

 *  device autonegotiation advertisement meets standards of

 *  either 10 or 10/100 or 10/100/1000 at all duplexes.

 *  This is a function pointer entry point only called by

 *  PHY setup routines.

		/* Call gig speed drop workaround on LPLU before accessing

		 * any PHY registers

 When LPLU is enabled, we should disable SmartSpeed */

		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used

		 * during Dx states where the power conservation is most

		 * important.  During driver activity we should enable

		 * SmartSpeed, so performance is maintained.

/**

 *  e1000_set_d3_lplu_state_ich8lan - Set Low Power Linkup D3 state

 *  @hw: pointer to the HW structure

 *  @active: true to enable LPLU, false to disable

 *

 *  Sets the LPLU D3 state according to the active flag.  When

 *  activating LPLU this function also disables smart speed

 *  and vice versa.  LPLU will not be activated unless the

 *  device autonegotiation advertisement meets standards of

 *  either 10 or 10/100 or 10/100/1000 at all duplexes.

 *  This is a function pointer entry point only called by

 *  PHY setup routines.

		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used

		 * during Dx states where the power conservation is most

		 * important.  During driver activity we should enable

		 * SmartSpeed, so performance is maintained.

		/* Call gig speed drop workaround on LPLU before accessing

		 * any PHY registers

 When LPLU is enabled, we should disable SmartSpeed */

/**

 *  e1000_valid_nvm_bank_detect_ich8lan - finds out the valid bank 0 or 1

 *  @hw: pointer to the HW structure

 *  @bank:  pointer to the variable that returns the active bank

 *

 *  Reads signature byte from the NVM using the flash access registers.

 *  Word 0x13 bits 15:14 = 10b indicate a valid signature for that bank.

 set bank to 0 in case flash read fails */

 Check bank 0 */

 Check bank 1 */

 set bank to 0 in case flash read fails */

 Check bank 0 */

 Check bank 1 */

/**

 *  e1000_read_nvm_spt - NVM access for SPT

 *  @hw: pointer to the HW structure

 *  @offset: The offset (in bytes) of the word(s) to read.

 *  @words: Size of data to read in words.

 *  @data: pointer to the word(s) to read at offset.

 *

 *  Reads a word(s) from the NVM

/**

 *  e1000_read_nvm_ich8lan - Read word(s) from the NVM

 *  @hw: pointer to the HW structure

 *  @offset: The offset (in bytes) of the word(s) to read.

 *  @words: Size of data to read in words

 *  @data: Pointer to the word(s) to read at offset.

 *

 *  Reads a word(s) from the NVM using the flash access registers.

/**

 *  e1000_flash_cycle_init_ich8lan - Initialize flash

 *  @hw: pointer to the HW structure

 *

 *  This function does initial flash setup so that a new read/write/erase cycle

 *  can be started.

 Check if the flash descriptor is valid */

 Clear FCERR and DAEL in hw status by writing 1 */

	/* Either we should have a hardware SPI cycle in progress

	 * bit to check against, in order to start a new cycle or

	 * FDONE bit should be changed in the hardware so that it

	 * is 1 after hardware reset, which can then be used as an

	 * indication whether a cycle is in progress or has been

	 * completed.

		/* There is no cycle running at present,

		 * so we can start a cycle.

		 * Begin by setting Flash Cycle Done.

		/* Otherwise poll for sometime so the current

		 * cycle has a chance to end before giving up.

			/* Successful in waiting for previous cycle to timeout,

			 * now set the Flash Cycle Done.

/**

 *  e1000_flash_cycle_ich8lan - Starts flash cycle (read/write/erase)

 *  @hw: pointer to the HW structure

 *  @timeout: maximum time to wait for completion

 *

 *  This function starts a flash cycle and waits for its completion.

 Start a cycle by writing 1 in Flash Cycle Go in Hw Flash Control */

 wait till FDONE bit is set to 1 */

/**

 *  e1000_read_flash_dword_ich8lan - Read dword from flash

 *  @hw: pointer to the HW structure

 *  @offset: offset to data location

 *  @data: pointer to the location for storing the data

 *

 *  Reads the flash dword at offset into data.  Offset is converted

 *  to bytes before read.

 Must convert word offset into bytes. */

/**

 *  e1000_read_flash_word_ich8lan - Read word from flash

 *  @hw: pointer to the HW structure

 *  @offset: offset to data location

 *  @data: pointer to the location for storing the data

 *

 *  Reads the flash word at offset into data.  Offset is converted

 *  to bytes before read.

 Must convert offset into bytes. */

/**

 *  e1000_read_flash_byte_ich8lan - Read byte from flash

 *  @hw: pointer to the HW structure

 *  @offset: The offset of the byte to read.

 *  @data: Pointer to a byte to store the value read.

 *

 *  Reads a single byte from the NVM using the flash access registers.

	/* In SPT, only 32 bits access is supported,

	 * so this function should not be called.

/**

 *  e1000_read_flash_data_ich8lan - Read byte or word from NVM

 *  @hw: pointer to the HW structure

 *  @offset: The offset (in bytes) of the byte or word to read.

 *  @size: Size of data to read, 1=byte 2=word

 *  @data: Pointer to the word to store the value read.

 *

 *  Reads a byte or word from the NVM using the flash access registers.

 Steps */

 0b/1b corresponds to 1 or 2 byte size, respectively. */

		/* Check if FCERR is set to 1, if set to 1, clear it

		 * and try the whole sequence a few more times, else

		 * read in (shift in) the Flash Data0, the order is

		 * least significant byte first msb to lsb

			/* If we've gotten here, then things are probably

			 * completely hosed, but if the error condition is

			 * detected, it won't hurt to give it another try...

			 * ICH_FLASH_CYCLE_REPEAT_COUNT times.

 Repeat for some time before giving up. */

/**

 *  e1000_read_flash_data32_ich8lan - Read dword from NVM

 *  @hw: pointer to the HW structure

 *  @offset: The offset (in bytes) of the dword to read.

 *  @data: Pointer to the dword to store the value read.

 *

 *  Reads a byte or word from the NVM using the flash access registers.

 Steps */

		/* In SPT, This register is in Lan memory space, not flash.

		 * Therefore, only 32 bit access is supported

 0b/1b corresponds to 1 or 2 byte size, respectively. */

		/* In SPT, This register is in Lan memory space, not flash.

		 * Therefore, only 32 bit access is supported

		/* Check if FCERR is set to 1, if set to 1, clear it

		 * and try the whole sequence a few more times, else

		 * read in (shift in) the Flash Data0, the order is

		 * least significant byte first msb to lsb

			/* If we've gotten here, then things are probably

			 * completely hosed, but if the error condition is

			 * detected, it won't hurt to give it another try...

			 * ICH_FLASH_CYCLE_REPEAT_COUNT times.

 Repeat for some time before giving up. */

/**

 *  e1000_write_nvm_ich8lan - Write word(s) to the NVM

 *  @hw: pointer to the HW structure

 *  @offset: The offset (in bytes) of the word(s) to write.

 *  @words: Size of data to write in words

 *  @data: Pointer to the word(s) to write at offset.

 *

 *  Writes a byte or word to the NVM using the flash access registers.

/**

 *  e1000_update_nvm_checksum_spt - Update the checksum for NVM

 *  @hw: pointer to the HW structure

 *

 *  The NVM checksum is updated by calling the generic update_nvm_checksum,

 *  which writes the checksum to the shadow ram.  The changes in the shadow

 *  ram are then committed to the EEPROM by processing each bank at a time

 *  checking for the modified bit and writing only the pending changes.

 *  After a successful commit, the shadow ram is cleared and is ready for

 *  future writes.

	/* We're writing to the opposite bank so if we're on bank 1,

	 * write to bank 0 etc.  We also need to erase the segment that

	 * is going to be written

		/* Determine whether to write the value stored

		 * in the other NVM bank or a modified value stored

		 * in the shadow RAM

		/* If the word is 0x13, then make sure the signature bits

		 * (15:14) are 11b until the commit has completed.

		 * This will allow us to write 10b which indicates the

		 * signature is valid.  We want to do this after the write

		 * has completed so that we don't mark the segment valid

		 * while the write is still in progress

 Convert offset to bytes. */

 Write the data to the new bank. Offset in words */

	/* Don't bother writing the segment valid bits if sector

	 * programming failed.

 Possibly read-only, see e1000e_write_protect_nvm_ich8lan() */

	/* Finally validate the new segment by setting bit 15:14

	 * to 10b in word 0x13 , this can be done without an

	 * erase as well since these bits are 11 to start with

	 * and we need to change bit 14 to 0b

offset in words but we read dword */

 offset in words but we read dword */

 Great!  Everything worked, we can now clear the cached entries. */

	/* Reload the EEPROM, or else modifications will not appear

	 * until after the next adapter reset.

/**

 *  e1000_update_nvm_checksum_ich8lan - Update the checksum for NVM

 *  @hw: pointer to the HW structure

 *

 *  The NVM checksum is updated by calling the generic update_nvm_checksum,

 *  which writes the checksum to the shadow ram.  The changes in the shadow

 *  ram are then committed to the EEPROM by processing each bank at a time

 *  checking for the modified bit and writing only the pending changes.

 *  After a successful commit, the shadow ram is cleared and is ready for

 *  future writes.

	/* We're writing to the opposite bank so if we're on bank 1,

	 * write to bank 0 etc.  We also need to erase the segment that

	 * is going to be written

		/* If the word is 0x13, then make sure the signature bits

		 * (15:14) are 11b until the commit has completed.

		 * This will allow us to write 10b which indicates the

		 * signature is valid.  We want to do this after the write

		 * has completed so that we don't mark the segment valid

		 * while the write is still in progress

 Convert offset to bytes. */

 Write the bytes to the new bank. */

	/* Don't bother writing the segment valid bits if sector

	 * programming failed.

 Possibly read-only, see e1000e_write_protect_nvm_ich8lan() */

	/* Finally validate the new segment by setting bit 15:14

	 * to 10b in word 0x13 , this can be done without an

	 * erase as well since these bits are 11 to start with

	 * and we need to change bit 14 to 0b

	/* And invalidate the previously valid segment by setting

	 * its signature word (0x13) high_byte to 0b. This can be

	 * done without an erase because flash erase sets all bits

	 * to 1's. We can write 1's to 0's without an erase

 Great!  Everything worked, we can now clear the cached entries. */

	/* Reload the EEPROM, or else modifications will not appear

	 * until after the next adapter reset.

/**

 *  e1000_validate_nvm_checksum_ich8lan - Validate EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Check to see if checksum needs to be fixed by reading bit 6 in word 0x19.

 *  If the bit is 0, that the EEPROM had been modified, but the checksum was not

 *  calculated, in which case we need to calculate the checksum and set bit 6.

	/* Read NVM and check Invalid Image CSUM bit.  If this bit is 0,

	 * the checksum needs to be fixed.  This bit is an indication that

	 * the NVM was prepared by OEM software and did not calculate

	 * the checksum...a likely scenario.

/**

 *  e1000e_write_protect_nvm_ich8lan - Make the NVM read-only

 *  @hw: pointer to the HW structure

 *

 *  To prevent malicious write/erase of the NVM, set it to be read-only

 *  so that the hardware ignores all write/erase cycles of the NVM via

 *  the flash control registers.  The shadow-ram copy of the NVM will

 *  still be updated, however any updates to this copy will not stick

 *  across driver reloads.

 Write-protect GbE Sector of NVM */

	/* Lock down a subset of GbE Flash Control Registers, e.g.

	 * PR0 to prevent the write-protection from being lifted.

	 * Once FLOCKDN is set, the registers protected by it cannot

	 * be written until FLOCKDN is cleared by a hardware reset.

/**

 *  e1000_write_flash_data_ich8lan - Writes bytes to the NVM

 *  @hw: pointer to the HW structure

 *  @offset: The offset (in bytes) of the byte/word to read.

 *  @size: Size of data to read, 1=byte 2=word

 *  @data: The byte(s) to write to the NVM.

 *

 *  Writes one/two bytes to the NVM using the flash access registers.

 Steps */

		/* In SPT, This register is in Lan memory space, not

		 * flash.  Therefore, only 32 bit access is supported

 0b/1b corresponds to 1 or 2 byte size, respectively. */

		/* In SPT, This register is in Lan memory space,

		 * not flash.  Therefore, only 32 bit access is

		 * supported

		/* check if FCERR is set to 1 , if set to 1, clear it

		 * and try the whole sequence a few more times else done

		/* If we're here, then things are most likely

		 * completely hosed, but if the error condition

		 * is detected, it won't hurt to give it another

		 * try...ICH_FLASH_CYCLE_REPEAT_COUNT times.

 Repeat for some time before giving up. */

/**

*  e1000_write_flash_data32_ich8lan - Writes 4 bytes to the NVM

*  @hw: pointer to the HW structure

*  @offset: The offset (in bytes) of the dwords to read.

*  @data: The 4 bytes to write to the NVM.

*

*  Writes one/two/four bytes to the NVM using the flash access registers.

 Steps */

		/* In SPT, This register is in Lan memory space, not

		 * flash.  Therefore, only 32 bit access is supported

		/* In SPT, This register is in Lan memory space,

		 * not flash.  Therefore, only 32 bit access is

		 * supported

		/* check if FCERR is set to 1 , if set to 1, clear it

		 * and try the whole sequence a few more times else done

		/* If we're here, then things are most likely

		 * completely hosed, but if the error condition

		 * is detected, it won't hurt to give it another

		 * try...ICH_FLASH_CYCLE_REPEAT_COUNT times.

 Repeat for some time before giving up. */

/**

 *  e1000_write_flash_byte_ich8lan - Write a single byte to NVM

 *  @hw: pointer to the HW structure

 *  @offset: The index of the byte to read.

 *  @data: The byte to write to the NVM.

 *

 *  Writes a single byte to the NVM using the flash access registers.

/**

*  e1000_retry_write_flash_dword_ich8lan - Writes a dword to NVM

*  @hw: pointer to the HW structure

*  @offset: The offset of the word to write.

*  @dword: The dword to write to the NVM.

*

*  Writes a single dword to the NVM using the flash access registers.

*  Goes through a retry algorithm before giving up.

 Must convert word offset into bytes. */

/**

 *  e1000_retry_write_flash_byte_ich8lan - Writes a single byte to NVM

 *  @hw: pointer to the HW structure

 *  @offset: The offset of the byte to write.

 *  @byte: The byte to write to the NVM.

 *

 *  Writes a single byte to the NVM using the flash access registers.

 *  Goes through a retry algorithm before giving up.

/**

 *  e1000_erase_flash_bank_ich8lan - Erase a bank (4k) from NVM

 *  @hw: pointer to the HW structure

 *  @bank: 0 for first bank, 1 for second bank, etc.

 *

 *  Erases the bank specified. Each bank is a 4k block. Banks are 0 based.

 *  bank N is 4096 * N + flash_reg_addr.

 bank size is in 16bit words - adjust to bytes */

	/* Determine HW Sector size: Read BERASE bits of hw flash status

	 * register

	 * 00: The Hw sector is 256 bytes, hence we need to erase 16

	 *     consecutive sectors.  The start index for the nth Hw sector

	 *     can be calculated as = bank * 4096 + n * 256

	 * 01: The Hw sector is 4K bytes, hence we need to erase 1 sector.

	 *     The start index for the nth Hw sector can be calculated

	 *     as = bank * 4096

	 * 10: The Hw sector is 8K bytes, nth sector = bank * 8192

	 *     (ich9 only, otherwise error condition)

	 * 11: The Hw sector is 64K bytes, nth sector = bank * 65536

 Hw sector size 256 */

 Start with the base address, then add the sector offset. */

 Steps */

			/* Write a value 11 (block Erase) in Flash

			 * Cycle field in hw flash control

			/* Write the last 24 bits of an index within the

			 * block into Flash Linear address field in Flash

			 * Address.

			/* Check if FCERR is set to 1.  If 1,

			 * clear it and try the whole sequence

			 * a few more times else Done

 repeat for some time before giving up */

/**

 *  e1000_valid_led_default_ich8lan - Set the default LED settings

 *  @hw: pointer to the HW structure

 *  @data: Pointer to the LED settings

 *

 *  Reads the LED default settings from the NVM to data.  If the NVM LED

 *  settings is all 0's or F's, set the LED default to a valid LED default

 *  setting.

/**

 *  e1000_id_led_init_pchlan - store LED configurations

 *  @hw: pointer to the HW structure

 *

 *  PCH does not control LEDs via the LEDCTL register, rather it uses

 *  the PHY LED configuration register.

 *

 *  PCH also does not have an "always on" or "always off" mode which

 *  complicates the ID feature.  Instead of using the "on" mode to indicate

 *  in ledctl_mode2 the LEDs to use for ID (see e1000e_id_led_init_generic()),

 *  use "link_up" mode.  The LEDs will still ID on request if there is no

 *  link based on logic in e1000_led_[on|off]_pchlan().

 Get default ID LED modes */

 Do nothing */

 Do nothing */

/**

 *  e1000_get_bus_info_ich8lan - Get/Set the bus type and width

 *  @hw: pointer to the HW structure

 *

 *  ICH8 use the PCI Express bus, but does not contain a PCI Express Capability

 *  register, so the bus width is hard coded.

	/* ICH devices are "PCI Express"-ish.  They have

	 * a configuration space, but do not contain

	 * PCI Express Capability registers, so bus width

	 * must be hardcoded.

/**

 *  e1000_reset_hw_ich8lan - Reset the hardware

 *  @hw: pointer to the HW structure

 *

 *  Does a full reset of the hardware which includes a reset of the PHY and

 *  MAC.

	/* Prevent the PCI-E bus from sticking if there is no TLP connection

	 * on the last TLP read/write transaction when MAC is reset.

	/* Disable the Transmit and Receive units.  Then delay to allow

	 * any pending transactions to complete before we hit the MAC

	 * with the global reset.

 Workaround for ICH8 bit corruption issue in FIFO memory */

 Set Tx and Rx buffer allocation to 8k apiece. */

 Set Packet Buffer Size to 16k. */

 Save the NVM K1 bit setting */

		/* Full-chip reset requires MAC and PHY reset at the same

		 * time to make sure the interface between MAC and the

		 * external PHY is reset.

		/* Gate automatic PHY configuration by hardware on

		 * non-managed 82579

 cannot issue a flush here because it hangs the hardware */

 Set Phy Config Counter to 50msec */

	/* For PCH, this write will make sure that any noise

	 * will be detected as a CRC error and be dropped rather than show up

	 * as a bad packet to the DMA engine.

/**

 *  e1000_init_hw_ich8lan - Initialize the hardware

 *  @hw: pointer to the HW structure

 *

 *  Prepares the hardware for transmit and receive by doing the following:

 *   - initialize hardware bits

 *   - initialize LED identification

 *   - setup receive address registers

 *   - setup flow control

 *   - setup transmit descriptors

 *   - clear statistics

 Initialize identification LED */

 An error is not fatal and we should not stop init due to this */

 Setup the receive address. */

 Zero out the Multicast HASH table */

	/* The 82578 Rx buffer will stall if wakeup is enabled in host and

	 * the ME.  Disable wakeup by clearing the host wakeup bit.

	 * Reset the phy after disabling host wakeup to reset the Rx buffer.

 Setup link and flow control */

 Set the transmit descriptor write-back policy for both queues */

	/* ICH8 has opposite polarity of no_snoop bits.

	 * By default, we should use snoop behavior.

	/* Enable workaround for packet loss issue on TGP PCH

	 * Do not gate DMA clock from the modPHY block

	/* Clear all of the statistics registers (clear on read).  It is

	 * important that we do this after we have tried to establish link

	 * because the symbol error count will increment wildly if there

	 * is no link.

/**

 *  e1000_initialize_hw_bits_ich8lan - Initialize required hardware bits

 *  @hw: pointer to the HW structure

 *

 *  Sets/Clears required hardware bits necessary for correctly setting up the

 *  hardware for transmit and receive.

 Extended Device Control */

 Enable PHY low-power state when MAC is at D3 w/o WoL */

 Transmit Descriptor Control 0 */

 Transmit Descriptor Control 1 */

 Transmit Arbitration Control 0 */

 Transmit Arbitration Control 1 */

 Device Status */

	/* work-around descriptor data corruption issue during nfs v2 udp

	 * traffic, just disable the nfs filtering capability

	/* Disable IPv6 extension header parsing because some malformed

	 * IPv6 headers can hang the Rx.

 Enable ECC on Lynxpoint */

/**

 *  e1000_setup_link_ich8lan - Setup flow control and link settings

 *  @hw: pointer to the HW structure

 *

 *  Determines which flow control settings to use, then configures flow

 *  control.  Calls the appropriate media-specific link configuration

 *  function.  Assuming the adapter has a valid link partner, a valid link

 *  should be established.  Assumes the hardware has previously been reset

 *  and the transmitter and receiver are not enabled.

	/* ICH parts do not have a word in the NVM to determine

	 * the default flow control setting, so we explicitly

	 * set it to full.

 Workaround h/w hang when Tx flow control enabled */

	/* Save off the requested flow control mode for use later.  Depending

	 * on the link partner's capabilities, we may or may not use this mode.

 Continue to configure the copper link. */

/**

 *  e1000_setup_copper_link_ich8lan - Configure MAC/PHY interface

 *  @hw: pointer to the HW structure

 *

 *  Configures the kumeran interface to the PHY to wait the appropriate time

 *  when polling the PHY, then call the generic setup_copper_link to finish

 *  configuring the copper link.

	/* Set the mac to wait the maximum time between each iteration

	 * and increase the max iterations when polling the phy;

	 * this fixes erroneous timeouts at 10Mbps.

/**

 *  e1000_setup_copper_link_pch_lpt - Configure MAC/PHY interface

 *  @hw: pointer to the HW structure

 *

 *  Calls the PHY specific link setup function and then calls the

 *  generic setup_copper_link to finish configuring the link for

 *  Lynxpoint PCH devices

/**

 *  e1000_get_link_up_info_ich8lan - Get current link speed and duplex

 *  @hw: pointer to the HW structure

 *  @speed: pointer to store current link speed

 *  @duplex: pointer to store the current link duplex

 *

 *  Calls the generic get_speed_and_duplex to retrieve the current link

 *  information and then calls the Kumeran lock loss workaround for links at

 *  gigabit speeds.

/**

 *  e1000_kmrn_lock_loss_workaround_ich8lan - Kumeran workaround

 *  @hw: pointer to the HW structure

 *

 *  Work-around for 82566 Kumeran PCS lock loss:

 *  On link status change (i.e. PCI reset, speed change) and link is up and

 *  speed is gigabit-

 *    0) if workaround is optionally disabled do nothing

 *    1) wait 1ms for Kumeran link to come up

 *    2) check Kumeran Diagnostic register PCS lock loss bit

 *    3) if not set the link is locked (all is good), otherwise...

 *    4) reset the PHY

 *    5) repeat up to 10 times

 *  Note: this is only called for IGP3 copper when speed is 1gb.

	/* Make sure link is up before proceeding.  If not just return.

	 * Attempting this while link is negotiating fouled up link

	 * stability

 read once to clear */

 and again to get new status */

 check for PCS lock */

 Issue PHY reset */

 Disable GigE link negotiation */

	/* Call gig speed drop workaround on Gig disable before accessing

	 * any PHY registers

 unable to acquire PCS lock */

/**

 *  e1000e_set_kmrn_lock_loss_workaround_ich8lan - Set Kumeran workaround state

 *  @hw: pointer to the HW structure

 *  @state: boolean value used to set the current Kumeran workaround state

 *

 *  If ICH8, set the current Kumeran workaround state (enabled - true

 *  /disabled - false).

/**

 *  e1000e_igp3_phy_powerdown_workaround_ich8lan - Power down workaround on D3

 *  @hw: pointer to the HW structure

 *

 *  Workaround for 82566 power-down on D3 entry:

 *    1) disable gigabit link

 *    2) write VR power-down enable

 *    3) read it back

 *  Continue if successful, else issue LCD reset and repeat

 Try the workaround twice (if needed) */

 Disable link */

		/* Call gig speed drop workaround on Gig disable before

		 * accessing any PHY registers

 Write VR power-down enable */

 Read it back and test */

 Issue PHY reset and repeat at most one more time */

/**

 *  e1000e_gig_downshift_workaround_ich8lan - WoL from S5 stops working

 *  @hw: pointer to the HW structure

 *

 *  Steps to take when dropping from 1Gb/s (eg. link cable removal (LSC),

 *  LPLU, Gig disable, MDIC PHY reset):

 *    1) Set Kumeran Near-end loopback

 *    2) Clear Kumeran Near-end loopback

 *  Should only be called for ICH8[m] devices with any 1G Phy.

/**

 *  e1000_suspend_workarounds_ich8lan - workarounds needed during S0->Sx

 *  @hw: pointer to the HW structure

 *

 *  During S0 to Sx transition, it is possible the link remains at gig

 *  instead of negotiating to a lower speed.  Before going to Sx, set

 *  'Gig Disable' to force link speed negotiation to a lower speed based on

 *  the LPLU setting in the NVM or custom setting.  For PCH and newer parts,

 *  the OEM bits PHY register (LED, GbE disable and LPLU configurations) also

 *  needs to be written.

 *  Parts that support (and are linked to a partner which support) EEE in

 *  100Mbps should disable LPLU since 100Mbps w/ EEE requires less power

 *  than 10Mbps w/o EEE.

			/* Disable LPLU if both link partners support 100BaseT

			 * EEE and 100Full is advertised on both ends of the

			 * link, and enable Auto Enable LPI since there will

			 * be no driver to enable LPI while in Sx.

 Set Auto Enable LPI after link up */

		/* For i217 Intel Rapid Start Technology support,

		 * when the system is going into Sx and no manageability engine

		 * is present, the driver must configure proxy to reset only on

		 * power good.  LPI (Low Power Idle) state must also reset only

		 * on power good, as well as the MTA (Multicast table array).

		 * The SMBus release must also be disabled on LCD reset.

 Enable proxy to reset only on power good. */

			/* Set bit enable LPI (EEE) to reset only on

			 * power good.

 Disable the SMB release on LCD reset. */

		/* Enable MTA to reset for Intel Rapid Start Technology

		 * Support

 Reset PHY to activate OEM bits on 82577/8 */

/**

 *  e1000_resume_workarounds_pchlan - workarounds needed during Sx->S0

 *  @hw: pointer to the HW structure

 *

 *  During Sx to S0 transitions on non-managed devices or managed devices

 *  on which PHY resets are not blocked, if the PHY registers cannot be

 *  accessed properly by the s/w toggle the LANPHYPC value to power cycle

 *  the PHY.

 *  On i217, setup Intel Rapid Start Technology.

	/* For i217 Intel Rapid Start Technology support when the system

	 * is transitioning from Sx and no manageability engine is present

	 * configure SMBus to restore on reset, disable proxy, and enable

	 * the reset on MTA (Multicast table array).

 Clear Auto Enable LPI after link up */

			/* Restore clear on SMB if no manageability engine

			 * is present

 Disable Proxy */

 Enable reset on MTA */

/**

 *  e1000_cleanup_led_ich8lan - Restore the default LED operation

 *  @hw: pointer to the HW structure

 *

 *  Return the LED back to the default configuration.

/**

 *  e1000_led_on_ich8lan - Turn LEDs on

 *  @hw: pointer to the HW structure

 *

 *  Turn on the LEDs.

/**

 *  e1000_led_off_ich8lan - Turn LEDs off

 *  @hw: pointer to the HW structure

 *

 *  Turn off the LEDs.

/**

 *  e1000_setup_led_pchlan - Configures SW controllable LED

 *  @hw: pointer to the HW structure

 *

 *  This prepares the SW controllable LED for use.

/**

 *  e1000_cleanup_led_pchlan - Restore the default LED operation

 *  @hw: pointer to the HW structure

 *

 *  Return the LED back to the default configuration.

/**

 *  e1000_led_on_pchlan - Turn LEDs on

 *  @hw: pointer to the HW structure

 *

 *  Turn on the LEDs.

	/* If no link, then turn LED on by setting the invert bit

	 * for each LED that's mode is "link_up" in ledctl_mode2.

/**

 *  e1000_led_off_pchlan - Turn LEDs off

 *  @hw: pointer to the HW structure

 *

 *  Turn off the LEDs.

	/* If no link, then turn LED off by clearing the invert bit

	 * for each LED that's mode is "link_up" in ledctl_mode1.

/**

 *  e1000_get_cfg_done_ich8lan - Read config done bit after Full or PHY reset

 *  @hw: pointer to the HW structure

 *

 *  Read appropriate register for the config done bit for completion status

 *  and configure the PHY through s/w for EEPROM-less parts.

 *

 *  NOTE: some silicon which is EEPROM-less will fail trying to read the

 *  config done bit, so only an error is logged and continues.  If we were

 *  to return with error, EEPROM-less silicon would not be able to be reset

 *  or change link.

 Wait for indication from h/w that it has completed basic config */

			/* When auto config read does not complete, do not

			 * return with an error. This can happen in situations

			 * where there is no eeprom and prevents getting link.

 Clear PHY Reset Asserted bit */

 If EEPROM is not marked present, init the IGP 3 PHY manually */

 Maybe we should do a basic PHY config */

/**

 * e1000_power_down_phy_copper_ich8lan - Remove link during PHY power down

 * @hw: pointer to the HW structure

 *

 * In the case of a PHY power down to save power, or to turn off link during a

 * driver unload, or wake on lan is not enabled, remove the link.

 If the management interface is not enabled, then power down */

/**

 *  e1000_clear_hw_cntrs_ich8lan - Clear statistical counters

 *  @hw: pointer to the HW structure

 *

 *  Clears hardware counters specific to the silicon family and calls

 *  clear_hw_cntrs_generic to clear all general purpose counters.

 Clear PHY statistics registers */

 check_mng_mode dependent on mac type */

 cleanup_led dependent on mac type */

 led_on dependent on mac type */

 led_off dependent on mac type */

 id_led_init dependent on mac type */

 errata */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 *  e1000e_get_bus_info_pcie - Get PCIe bus information

 *  @hw: pointer to the HW structure

 *

 *  Determines and stores the system bus information for a particular

 *  network interface.  The following bus information is determined and stored:

 *  bus speed, bus width, type (PCIe), and PCIe function.

/**

 *  e1000_set_lan_id_multi_port_pcie - Set LAN id for PCIe multiple port devices

 *

 *  @hw: pointer to the HW structure

 *

 *  Determines the LAN function id by reading memory-mapped registers

 *  and swaps the port value if requested.

	/* The status register reports the correct function number

	 * for the device regardless of function swap state.

/**

 *  e1000_set_lan_id_single_port - Set LAN id for a single port device

 *  @hw: pointer to the HW structure

 *

 *  Sets the LAN function id to zero for a single port device.

/**

 *  e1000_clear_vfta_generic - Clear VLAN filter table

 *  @hw: pointer to the HW structure

 *

 *  Clears the register array which contains the VLAN filter table by

 *  setting all the values to 0.

/**

 *  e1000_write_vfta_generic - Write value to VLAN filter table

 *  @hw: pointer to the HW structure

 *  @offset: register offset in VLAN filter table

 *  @value: register value written to VLAN filter table

 *

 *  Writes value at the given offset in the register array which stores

 *  the VLAN filter table.

/**

 *  e1000e_init_rx_addrs - Initialize receive address's

 *  @hw: pointer to the HW structure

 *  @rar_count: receive address registers

 *

 *  Setup the receive address registers by setting the base receive address

 *  register to the devices MAC address and clearing all the other receive

 *  address registers to 0.

 Setup the receive address */

 Zero out the other (rar_entry_count - 1) receive addresses */

/**

 *  e1000_check_alt_mac_addr_generic - Check for alternate MAC addr

 *  @hw: pointer to the HW structure

 *

 *  Checks the nvm for an alternate MAC address.  An alternate MAC address

 *  can be setup by pre-boot software and must be treated like a permanent

 *  address and must override the actual permanent MAC address. If an

 *  alternate MAC address is found it is programmed into RAR0, replacing

 *  the permanent address that was installed into RAR0 by the Si on reset.

 *  This function will return SUCCESS unless it encounters an error while

 *  reading the EEPROM.

 not supported on 82573 */

 There is no Alternate MAC Address */

 if multicast bit is set, the alternate address will not be used */

	/* We have a valid alternate MAC address, and we want to treat it the

	 * same as the normal permanent MAC address stored by the HW into the

	 * RAR. Do this by mapping this address into RAR0.

/**

 *  e1000e_rar_set_generic - Set receive address register

 *  @hw: pointer to the HW structure

 *  @addr: pointer to the receive address

 *  @index: receive address array register

 *

 *  Sets the receive address array register at index to the address passed

 *  in by addr.

	/* HW expects these in little endian so we reverse the byte order

	 * from network order (big endian) to little endian

 If MAC address zero, no need to set the AV bit */

	/* Some bridges will combine consecutive 32-bit writes into

	 * a single burst write, which will malfunction on some parts.

	 * The flushes avoid this.

/**

 *  e1000_hash_mc_addr - Generate a multicast hash value

 *  @hw: pointer to the HW structure

 *  @mc_addr: pointer to a multicast address

 *

 *  Generates a multicast address hash value which is used to determine

 *  the multicast filter table array address and new table value.

 Register count multiplied by bits per register */

	/* For a mc_filter_type of 0, bit_shift is the number of left-shifts

	 * where 0xFF would still fall within the hash mask.

	/* The portion of the address that is used for the hash table

	 * is determined by the mc_filter_type setting.

	 * The algorithm is such that there is a total of 8 bits of shifting.

	 * The bit_shift for a mc_filter_type of 0 represents the number of

	 * left-shifts where the MSB of mc_addr[5] would still fall within

	 * the hash_mask.  Case 0 does this exactly.  Since there are a total

	 * of 8 bits of shifting, then mc_addr[4] will shift right the

	 * remaining number of bits. Thus 8 - bit_shift.  The rest of the

	 * cases are a variation of this algorithm...essentially raising the

	 * number of bits to shift mc_addr[5] left, while still keeping the

	 * 8-bit shifting total.

	 *

	 * For example, given the following Destination MAC Address and an

	 * mta register count of 128 (thus a 4096-bit vector and 0xFFF mask),

	 * we can see that the bit_shift for case 0 is 4.  These are the hash

	 * values resulting from each mc_filter_type...

	 * [0] [1] [2] [3] [4] [5]

	 * 01  AA  00  12  34  56

	 * LSB           MSB

	 *

	 * case 0: hash_value = ((0x34 >> 4) | (0x56 << 4)) & 0xFFF = 0x563

	 * case 1: hash_value = ((0x34 >> 3) | (0x56 << 5)) & 0xFFF = 0xAC6

	 * case 2: hash_value = ((0x34 >> 2) | (0x56 << 6)) & 0xFFF = 0x163

	 * case 3: hash_value = ((0x34 >> 0) | (0x56 << 8)) & 0xFFF = 0x634

/**

 *  e1000e_update_mc_addr_list_generic - Update Multicast addresses

 *  @hw: pointer to the HW structure

 *  @mc_addr_list: array of multicast addresses to program

 *  @mc_addr_count: number of multicast addresses to program

 *

 *  Updates entire Multicast Table Array.

 *  The caller must have a packed mc_addr_list of multicast addresses.

 clear mta_shadow */

 update mta_shadow from mc_addr_list */

 replace the entire MTA table */

/**

 *  e1000e_clear_hw_cntrs_base - Clear base hardware counters

 *  @hw: pointer to the HW structure

 *

 *  Clears the base hardware counters by reading the counter registers.

/**

 *  e1000e_check_for_copper_link - Check for link (Copper)

 *  @hw: pointer to the HW structure

 *

 *  Checks to see of the link status of the hardware has changed.  If a

 *  change in link status has been detected, then we read the PHY registers

 *  to get the current speed/duplex if link exists.

	/* We only want to go out to the PHY registers to see if Auto-Neg

	 * has completed and/or if our link status has changed.  The

	 * get_link_status flag is set upon receiving a Link Status

	 * Change or Rx Sequence Error interrupt.

	/* First we want to see if the MII Status Register reports

	 * link.  If so, then we want to get the current speed/duplex

	 * of the PHY.

	/* Check if there was DownShift, must be checked

	 * immediately after link-up

	/* If we are forcing speed/duplex, then we simply return since

	 * we have already determined whether we have link or not.

	/* Auto-Neg is enabled.  Auto Speed Detection takes care

	 * of MAC speed/duplex configuration.  So we only need to

	 * configure Collision Distance in the MAC.

	/* Configure Flow Control now that Auto-Neg has completed.

	 * First, we need to restore the desired flow control

	 * settings because we may have had to re-autoneg with a

	 * different link partner.

/**

 *  e1000e_check_for_fiber_link - Check for link (Fiber)

 *  @hw: pointer to the HW structure

 *

 *  Checks for link up on the hardware.  If link is not up and we have

 *  a signal, then we need to force link up.

	/* If we don't have link (auto-negotiation failed or link partner

	 * cannot auto-negotiate), the cable is plugged in (we have signal),

	 * and our link partner is not trying to auto-negotiate with us (we

	 * are receiving idles or data), we need to force link up. We also

	 * need to give auto-negotiation time to complete, in case the cable

	 * was just plugged in. The autoneg_failed flag does this.

 (ctrl & E1000_CTRL_SWDPIN1) == 1 == have signal */

 Disable auto-negotiation in the TXCW register */

 Force link-up and also force full-duplex. */

 Configure Flow Control after forcing link up. */

		/* If we are forcing link and we are receiving /C/ ordered

		 * sets, re-enable auto-negotiation in the TXCW register

		 * and disable forced link in the Device Control register

		 * in an attempt to auto-negotiate with our link partner.

/**

 *  e1000e_check_for_serdes_link - Check for link (Serdes)

 *  @hw: pointer to the HW structure

 *

 *  Checks for link up on the hardware.  If link is not up and we have

 *  a signal, then we need to force link up.

	/* If we don't have link (auto-negotiation failed or link partner

	 * cannot auto-negotiate), and our link partner is not trying to

	 * auto-negotiate with us (we are receiving idles or data),

	 * we need to force link up. We also need to give auto-negotiation

	 * time to complete.

 (ctrl & E1000_CTRL_SWDPIN1) == 1 == have signal */

 Disable auto-negotiation in the TXCW register */

 Force link-up and also force full-duplex. */

 Configure Flow Control after forcing link up. */

		/* If we are forcing link and we are receiving /C/ ordered

		 * sets, re-enable auto-negotiation in the TXCW register

		 * and disable forced link in the Device Control register

		 * in an attempt to auto-negotiate with our link partner.

		/* If we force link for non-auto-negotiation switch, check

		 * link status based on MAC synchronization for internal

		 * serdes media type.

 SYNCH bit and IV bit are sticky. */

 SYNCH bit and IV bit are sticky, so reread rxcw. */

/**

 *  e1000_set_default_fc_generic - Set flow control default values

 *  @hw: pointer to the HW structure

 *

 *  Read the EEPROM for the default values for flow control and store the

 *  values.

	/* Read and store word 0x0F of the EEPROM. This word contains bits

	 * that determine the hardware's default PAUSE (flow control) mode,

	 * a bit that determines whether the HW defaults to enabling or

	 * disabling auto-negotiation, and the direction of the

	 * SW defined pins. If there is no SW over-ride of the flow

	 * control setting, then the variable hw->fc will

	 * be initialized based on a value in the EEPROM.

/**

 *  e1000e_setup_link_generic - Setup flow control and link settings

 *  @hw: pointer to the HW structure

 *

 *  Determines which flow control settings to use, then configures flow

 *  control.  Calls the appropriate media-specific link configuration

 *  function.  Assuming the adapter has a valid link partner, a valid link

 *  should be established.  Assumes the hardware has previously been reset

 *  and the transmitter and receiver are not enabled.

	/* In the case of the phy reset being blocked, we already have a link.

	 * We do not need to set it up again.

	/* If requested flow control is set to default, set flow control

	 * based on the EEPROM flow control settings.

	/* Save off the requested flow control mode for use later.  Depending

	 * on the link partner's capabilities, we may or may not use this mode.

 Call the necessary media_type subroutine to configure the link. */

	/* Initialize the flow control address, type, and PAUSE timer

	 * registers to their default values.  This is done even if flow

	 * control is disabled, because it does not hurt anything to

	 * initialize these registers.

/**

 *  e1000_commit_fc_settings_generic - Configure flow control

 *  @hw: pointer to the HW structure

 *

 *  Write the flow control settings to the Transmit Config Word Register (TXCW)

 *  base on the flow control settings in e1000_mac_info.

	/* Check for a software override of the flow control settings, and

	 * setup the device accordingly.  If auto-negotiation is enabled, then

	 * software will have to set the "PAUSE" bits to the correct value in

	 * the Transmit Config Word Register (TXCW) and re-start auto-

	 * negotiation.  However, if auto-negotiation is disabled, then

	 * software will have to manually configure the two flow control enable

	 * bits in the CTRL register.

	 *

	 * The possible values of the "fc" parameter are:

	 *      0:  Flow control is completely disabled

	 *      1:  Rx flow control is enabled (we can receive pause frames,

	 *          but not send pause frames).

	 *      2:  Tx flow control is enabled (we can send pause frames but we

	 *          do not support receiving pause frames).

	 *      3:  Both Rx and Tx flow control (symmetric) are enabled.

 Flow control completely disabled by a software over-ride. */

		/* Rx Flow control is enabled and Tx Flow control is disabled

		 * by a software over-ride. Since there really isn't a way to

		 * advertise that we are capable of Rx Pause ONLY, we will

		 * advertise that we support both symmetric and asymmetric Rx

		 * PAUSE.  Later, we will disable the adapter's ability to send

		 * PAUSE frames.

		/* Tx Flow control is enabled, and Rx Flow control is disabled,

		 * by a software over-ride.

		/* Flow control (both Rx and Tx) is enabled by a software

		 * over-ride.

/**

 *  e1000_poll_fiber_serdes_link_generic - Poll for link up

 *  @hw: pointer to the HW structure

 *

 *  Polls for link up by reading the status register, if link fails to come

 *  up with auto-negotiation, then the link is forced if a signal is detected.

	/* If we have a signal (the cable is plugged in, or assumed true for

	 * serdes media) then poll for a "Link-Up" indication in the Device

	 * Status Register.  Time-out if a link isn't seen in 500 milliseconds

	 * seconds (Auto-negotiation should complete in less than 500

	 * milliseconds even if the other end is doing it in SW).

		/* AutoNeg failed to achieve a link, so we'll call

		 * mac->check_for_link. This routine will force the

		 * link up if we detect a signal. This will allow us to

		 * communicate with non-autonegotiating link partners.

/**

 *  e1000e_setup_fiber_serdes_link - Setup link for fiber/serdes

 *  @hw: pointer to the HW structure

 *

 *  Configures collision distance and flow control for fiber and serdes

 *  links.  Upon successful setup, poll for link.

 Take the link out of reset */

	/* Since auto-negotiation is enabled, take the link out of reset (the

	 * link will be in reset, because we previously reset the chip). This

	 * will restart auto-negotiation.  If auto-negotiation is successful

	 * then the link-up status bit will be set and the flow control enable

	 * bits (RFCE and TFCE) will be set according to their negotiated value.

	/* For these adapters, the SW definable pin 1 is set when the optics

	 * detect a signal.  If we have a signal, then poll for a "Link-Up"

	 * indication.

/**

 *  e1000e_config_collision_dist_generic - Configure collision distance

 *  @hw: pointer to the HW structure

 *

 *  Configures the collision distance to the default value and is used

 *  during link setup.

/**

 *  e1000e_set_fc_watermarks - Set flow control high/low watermarks

 *  @hw: pointer to the HW structure

 *

 *  Sets the flow control high/low threshold (watermark) registers.  If

 *  flow control XON frame transmission is enabled, then set XON frame

 *  transmission as well.

	/* Set the flow control receive threshold registers.  Normally,

	 * these registers will be set to a default threshold that may be

	 * adjusted later by the driver's runtime code.  However, if the

	 * ability to transmit pause frames is not enabled, then these

	 * registers will be set to 0.

		/* We need to set up the Receive Threshold high and low water

		 * marks as well as (optionally) enabling the transmission of

		 * XON frames.

/**

 *  e1000e_force_mac_fc - Force the MAC's flow control settings

 *  @hw: pointer to the HW structure

 *

 *  Force the MAC's flow control settings.  Sets the TFCE and RFCE bits in the

 *  device control register to reflect the adapter settings.  TFCE and RFCE

 *  need to be explicitly set by software when a copper PHY is used because

 *  autonegotiation is managed by the PHY rather than the MAC.  Software must

 *  also configure these bits when link is forced on a fiber connection.

	/* Because we didn't get link via the internal auto-negotiation

	 * mechanism (we either forced link or we got link via PHY

	 * auto-neg), we have to manually enable/disable transmit an

	 * receive flow control.

	 *

	 * The "Case" statement below enables/disable flow control

	 * according to the "hw->fc.current_mode" parameter.

	 *

	 * The possible values of the "fc" parameter are:

	 *      0:  Flow control is completely disabled

	 *      1:  Rx flow control is enabled (we can receive pause

	 *          frames but not send pause frames).

	 *      2:  Tx flow control is enabled (we can send pause frames

	 *          frames but we do not receive pause frames).

	 *      3:  Both Rx and Tx flow control (symmetric) is enabled.

	 *  other:  No other values should be possible at this point.

/**

 *  e1000e_config_fc_after_link_up - Configures flow control after link

 *  @hw: pointer to the HW structure

 *

 *  Checks the status of auto-negotiation after link up to ensure that the

 *  speed and duplex were not forced.  If the link needed to be forced, then

 *  flow control needs to be forced also.  If auto-negotiation is enabled

 *  and did not fail, then we configure flow control based on our link

 *  partner.

	/* Check for the case where we have fiber media and auto-neg failed

	 * so we had to force link.  In this case, we need to force the

	 * configuration of the MAC to match the "fc" parameter.

	/* Check for the case where we have copper media and auto-neg is

	 * enabled.  In this case, we need to check and see if Auto-Neg

	 * has completed, and if so, how the PHY and link partner has

	 * flow control configured.

		/* Read the MII Status Register and check to see if AutoNeg

		 * has completed.  We read this twice because this reg has

		 * some "sticky" (latched) bits.

		/* The AutoNeg process has completed, so we now need to

		 * read both the Auto Negotiation Advertisement

		 * Register (Address 4) and the Auto_Negotiation Base

		 * Page Ability Register (Address 5) to determine how

		 * flow control was negotiated.

		/* Two bits in the Auto Negotiation Advertisement Register

		 * (Address 4) and two bits in the Auto Negotiation Base

		 * Page Ability Register (Address 5) determine flow control

		 * for both the PHY and the link partner.  The following

		 * table, taken out of the IEEE 802.3ab/D6.0 dated March 25,

		 * 1999, describes these PAUSE resolution bits and how flow

		 * control is determined based upon these settings.

		 * NOTE:  DC = Don't Care

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | NIC Resolution

		 *-------|---------|-------|---------|--------------------

		 *   0   |    0    |  DC   |   DC    | e1000_fc_none

		 *   0   |    1    |   0   |   DC    | e1000_fc_none

		 *   0   |    1    |   1   |    0    | e1000_fc_none

		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause

		 *   1   |    0    |   0   |   DC    | e1000_fc_none

		 *   1   |   DC    |   1   |   DC    | e1000_fc_full

		 *   1   |    1    |   0   |    0    | e1000_fc_none

		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause

		 *

		 * Are both PAUSE bits set to 1?  If so, this implies

		 * Symmetric Flow Control is enabled at both ends.  The

		 * ASM_DIR bits are irrelevant per the spec.

		 *

		 * For Symmetric Flow Control:

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   1   |   DC    |   1   |   DC    | E1000_fc_full

		 *

			/* Now we need to check if the user selected Rx ONLY

			 * of pause frames.  In this case, we had to advertise

			 * FULL flow control because we could not advertise Rx

			 * ONLY. Hence, we must now check to see if we need to

			 * turn OFF the TRANSMISSION of PAUSE frames.

		/* For receiving PAUSE frames ONLY.

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause

		/* For transmitting PAUSE frames ONLY.

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause

			/* Per the IEEE spec, at this point flow control

			 * should be disabled.

		/* Now we need to do one last check...  If we auto-

		 * negotiated to HALF DUPLEX, flow control should not be

		 * enabled per IEEE 802.3 spec.

		/* Now we call a subroutine to actually force the MAC

		 * controller to use the correct flow control settings.

	/* Check for the case where we have SerDes media and auto-neg is

	 * enabled.  In this case, we need to check and see if Auto-Neg

	 * has completed, and if so, how the PHY and link partner has

	 * flow control configured.

		/* Read the PCS_LSTS and check to see if AutoNeg

		 * has completed.

		/* The AutoNeg process has completed, so we now need to

		 * read both the Auto Negotiation Advertisement

		 * Register (PCS_ANADV) and the Auto_Negotiation Base

		 * Page Ability Register (PCS_LPAB) to determine how

		 * flow control was negotiated.

		/* Two bits in the Auto Negotiation Advertisement Register

		 * (PCS_ANADV) and two bits in the Auto Negotiation Base

		 * Page Ability Register (PCS_LPAB) determine flow control

		 * for both the PHY and the link partner.  The following

		 * table, taken out of the IEEE 802.3ab/D6.0 dated March 25,

		 * 1999, describes these PAUSE resolution bits and how flow

		 * control is determined based upon these settings.

		 * NOTE:  DC = Don't Care

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | NIC Resolution

		 *-------|---------|-------|---------|--------------------

		 *   0   |    0    |  DC   |   DC    | e1000_fc_none

		 *   0   |    1    |   0   |   DC    | e1000_fc_none

		 *   0   |    1    |   1   |    0    | e1000_fc_none

		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause

		 *   1   |    0    |   0   |   DC    | e1000_fc_none

		 *   1   |   DC    |   1   |   DC    | e1000_fc_full

		 *   1   |    1    |   0   |    0    | e1000_fc_none

		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause

		 *

		 * Are both PAUSE bits set to 1?  If so, this implies

		 * Symmetric Flow Control is enabled at both ends.  The

		 * ASM_DIR bits are irrelevant per the spec.

		 *

		 * For Symmetric Flow Control:

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   1   |   DC    |   1   |   DC    | e1000_fc_full

		 *

			/* Now we need to check if the user selected Rx ONLY

			 * of pause frames.  In this case, we had to advertise

			 * FULL flow control because we could not advertise Rx

			 * ONLY. Hence, we must now check to see if we need to

			 * turn OFF the TRANSMISSION of PAUSE frames.

		/* For receiving PAUSE frames ONLY.

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause

		/* For transmitting PAUSE frames ONLY.

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause

			/* Per the IEEE spec, at this point flow control

			 * should be disabled.

		/* Now we call a subroutine to actually force the MAC

		 * controller to use the correct flow control settings.

/**

 *  e1000e_get_speed_and_duplex_copper - Retrieve current speed/duplex

 *  @hw: pointer to the HW structure

 *  @speed: stores the current speed

 *  @duplex: stores the current duplex

 *

 *  Read the status register for the current speed/duplex and store the current

 *  speed and duplex for copper connections.

/**

 *  e1000e_get_speed_and_duplex_fiber_serdes - Retrieve current speed/duplex

 *  @hw: pointer to the HW structure

 *  @speed: stores the current speed

 *  @duplex: stores the current duplex

 *

 *  Sets the speed and duplex to gigabit full duplex (the only possible option)

 *  for fiber/serdes links.

/**

 *  e1000e_get_hw_semaphore - Acquire hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Acquire the HW semaphore to access the PHY or NVM

 Get the SW semaphore */

 Get the FW semaphore. */

 Semaphore acquired if bit latched */

 Release semaphores */

/**

 *  e1000e_put_hw_semaphore - Release hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Release hardware semaphore used to access the PHY or NVM

/**

 *  e1000e_get_auto_rd_done - Check for auto read completion

 *  @hw: pointer to the HW structure

 *

 *  Check EEPROM for Auto Read done bit.

/**

 *  e1000e_valid_led_default - Verify a valid default LED config

 *  @hw: pointer to the HW structure

 *  @data: pointer to the NVM (EEPROM)

 *

 *  Read the EEPROM for the current default LED configuration.  If the

 *  LED configuration is not valid, set to a valid LED configuration.

/**

 *  e1000e_id_led_init_generic -

 *  @hw: pointer to the HW structure

 *

 Do nothing */

 Do nothing */

/**

 *  e1000e_setup_led_generic - Configures SW controllable LED

 *  @hw: pointer to the HW structure

 *

 *  This prepares the SW controllable LED for use and saves the current state

 *  of the LED so it can be later restored.

 Turn off LED0 */

/**

 *  e1000e_cleanup_led_generic - Set LED config to default operation

 *  @hw: pointer to the HW structure

 *

 *  Remove the current LED configuration and set the LED configuration

 *  to the default value, saved from the EEPROM.

/**

 *  e1000e_blink_led_generic - Blink LED

 *  @hw: pointer to the HW structure

 *

 *  Blink the LEDs which are set to be on.

 always blink LED0 for PCI-E fiber */

		/* Set the blink bit for each LED that's "on" (0x0E)

		 * (or "off" if inverted) in ledctl_mode2.  The blink

		 * logic in hardware only works when mode is set to "on"

		 * so it must be changed accordingly when the mode is

		 * "off" and inverted.

/**

 *  e1000e_led_on_generic - Turn LED on

 *  @hw: pointer to the HW structure

 *

 *  Turn LED on.

/**

 *  e1000e_led_off_generic - Turn LED off

 *  @hw: pointer to the HW structure

 *

 *  Turn LED off.

/**

 *  e1000e_set_pcie_no_snoop - Set PCI-express capabilities

 *  @hw: pointer to the HW structure

 *  @no_snoop: bitmap of snoop events

 *

 *  Set the PCI-express register to snoop for events enabled in 'no_snoop'.

/**

 *  e1000e_disable_pcie_master - Disables PCI-express master access

 *  @hw: pointer to the HW structure

 *

 *  Returns 0 if successful, else returns -10

 *  (-E1000_ERR_MASTER_REQUESTS_PENDING) if master disable bit has not caused

 *  the master requests to be disabled.

 *

 *  Disables PCI-Express master access and verifies there are no pending

 *  requests.

/**

 *  e1000e_reset_adaptive - Reset Adaptive Interframe Spacing

 *  @hw: pointer to the HW structure

 *

 *  Reset the Adaptive Interframe Spacing throttle to default values.

/**

 *  e1000e_update_adaptive - Update Adaptive Interframe Spacing

 *  @hw: pointer to the HW structure

 *

 *  Update the Adaptive Interframe Spacing Throttle value based on the

 *  time between transmitted packets and time between collisions.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 ethtool support for e1000 */

 the e1000 autoneg seems to match ethtool nicely */

 MDI-X => 2; MDI =>1; Invalid =>0 */

	/* Make sure dplx is at most 1 bit and lsb of speed is not set

	 * for the switch() below to work

 Fiber NICs only allow 1000 gbps Full duplex */

 not supported */

 clear MDI, MDI(-X) override is only allowed when autoneg enabled */

	/* When SoL/IDER sessions are active, autoneg/speed/duplex

	 * cannot be changed

	/* MDI setting is only allowed when autoneg enabled because

	 * some hardware doesn't allow MDI setting when speed or

	 * duplex is forced.

 calling this overrides forced MDI setting */

 MDI-X => 2; MDI => 1; Auto => 3 */

		/* fix up the value for auto (3 => 0) as zero is mapped

		 * internally to auto

 reset the link */

 implicit goto out */

 overestimate */

 PHY type (IGP=1, M88=0) */

	/* ethtool doesn't use anything past this point, so all this

	 * code is likely legacy junk for apps that may or may not exist

 cable length */

 Dummy (to align w/ IGP phy reg dump) */

 Dummy (to align w/ IGP phy reg dump) */

 Dummy (to align w/ IGP phy reg dump) */

 extended 10bt distance */

 cable polarity */

 Dummy (to align w/ IGP phy reg dump) */

 polarity correction */

 phy receive errors */

 mdix mode */

 was idle_errors */

 phy local receiver status */

 phy remote receiver status */

 a read error occurred, throw away the result */

 Device's eeprom is always little-endian, word addressable */

 need read/modify/write of first changed EEPROM word */

 only the second byte of the word is being modified */

 need read/modify/write of last changed EEPROM word */

 only the first byte of the word is being modified */

 Device's eeprom is always little-endian, word addressable */

	/* Update the checksum over the first part of the EEPROM if needed

	 * and flush shadow RAM for applicable controllers

	/* EEPROM image version # is reported as firmware version # for

	 * PCI-E controllers

 nothing to do */

 Set counts now and allocate resources during open() */

 Allocate temporary storage for ring updates */

	/* We can't just free everything and then setup again, because the

	 * ISRs in MSI-X mode get passed pointers to the Tx and Rx ring

	 * structs.  First, attempt to allocate new resources...

 ...then free the old resources and copy back any new ring data */

	/* The status register is Read Only, so a write should fail.

	 * Some bits that get toggled are ignored.  There are several bits

	 * on newer hardware that are r/w.

 restore previous status */

 Cannot test write-protected SHRAL[n] registers */

 SHRAH[9] different than the others */

 SHRAH[0,1,2] different than previous */

 SHRAH[3] different than SHRAH[0,1,2] */

 RAR[1-6] owned by management engine - skipping */

 reset index to actual value */

 Read and add up the contents of the EEPROM */

 If Checksum is not Correct return error else test passed */

 NOTE: we don't test MSI/MSI-X interrupts here, yet */

 Hook up test interrupt handler just for this test */

 Disable all the interrupts */

 Test each interrupt */

 Interrupt to test */

			/* Disable the interrupt to be reported in

			 * the cause register and then force the same

			 * interrupt and see if one gets posted.  If

			 * an interrupt was posted to the bus, the

			 * test failed.

		/* Enable the interrupt to be reported in

		 * the cause register and then force the same

		 * interrupt and see if one gets posted.  If

		 * an interrupt was not posted to the bus, the

		 * test failed.

			/* Disable the other interrupts to be reported in

			 * the cause register and then force the other

			 * interrupts and see if any get posted.  If

			 * an interrupt was posted to the bus, the

			 * test failed.

 Disable all the interrupts */

 Unhook test interrupt handler */

 Setup Tx descriptor ring and Tx buffers */

 Setup Rx descriptor ring and Rx buffers */

 Write out to PHY registers 29 and 30 to disable the Receiver. */

 force 100, set loopback */

 Now set up the MAC to the same speed/duplex as the PHY. */

 Clear the speed sel bits */

 Set the Force Speed Bit */

 Set the Force Duplex Bit */

 Force Speed to 100 */

 Force Duplex to FULL */

 Specific PHY configuration for loopback */

 Auto-MDI/MDIX Off */

 reset to update Auto-MDI/MDIX */

 autoneg off */

 Set Default MAC Interface speed to 1GB */

 Assert SW reset for above settings to take effect */

 Force Full Duplex */

 Set Link Up (in force link) */

 Force Link */

 Set Early Link Enable */

 Workaround: K1 must be disabled for stable 1Gbps operation */

 Disable PHY energy detect power down */

 Disable full chip energy detect */

 Enable loopback on the PHY */

 force 1000, set loopback */

 Now set up the MAC to the same speed/duplex as the PHY. */

 Clear the speed sel bits */

 Set the Force Speed Bit */

 Set the Force Duplex Bit */

 Force Speed to 1000 */

 Force Duplex to FULL */

 Set Link Up */

 Invert Loss of Signal */

		/* Set the ILOS bit on the fiber Nic if half duplex link is

		 * detected.

	/* Disable the receiver on the PHY so when a cable is plugged in, the

	 * PHY does not begin to autoneg when a cable is reconnected to the NIC.

 special requirements for 82571/82572 fiber adapters */

	/* jump through hoops to make sure link is up because serdes

	 * link is hardwired up

 disable autoneg */

 set invert loss of signal */

	/* special write to serdes control register to enable SerDes analog

	 * loopback

 only call this for fiber/serdes connections to es2lan */

	/* save CTRL_EXT to restore later, reuse an empty variable (unused

	 * on mac_type 80003es2lan)

 clear the serdes mode bits, putting the device into mac loopback */

 force speed to 1000/FD, link up */

 set mac loopback */

 set testing mode parameters (no need to reset later) */

 clear bits 28 & 29 (control of MULR concurrent requests) */

 set bit 29 (value of MULR requests is now 2) */

 clear bits 28 & 29 (control of MULR concurrent requests) */

 set bit 29 (value of MULR requests is now 0) */

 restore CTRL_EXT, stealing space from tx_fifo_head */

	/* Calculate the loop count based on the largest descriptor ring

	 * The idea is to wrap the largest ring a number of times using 64

	 * send/receive pairs during each loop

 loop count loop */

 send the packets */

 set the start time for the receive */

 receive the sent packets */

			/* time + 20 msecs (200 msecs on 2.4) is more than

			 * enough time to complete the receives, if it's

			 * exceeded, break and error off

 ret_val is the same as mis-compare */

 error code for time out error */

 PHY loopback cannot be performed if SoL/IDER sessions are active */

		/* On some blade server designs, link establishment

		 * could take as long as 2-3 minutes

			/* On some Phy/switch combinations, link establishment

			 * can take a few seconds more than expected.

 Get control of and reset hardware */

 Offline tests */

 save speed, duplex, autoneg settings */

 indicate we're in test mode */

 force this routine to wait until autoneg complete/timeout */

 restore speed, duplex, autoneg settings */

 Online tests */

 register, eeprom, intr and loopback tests not run online */

 apply any specific unsupported masks here */

 these settings will always override what we currently have */

 cycle on/off twice per second */

 EEE Capability */

 EEE Advertised */

 EEE Link Partner Advertised */

 EEE PCS Status */

	/* Result of the EEE auto negotiation - there is no register that

	 * has the status of the EEE negotiation so do a best-guess based

	 * on whether Tx or Rx LPI indications have been received.

 reset the link */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/* 80003ES2LAN Gigabit Ethernet Controller (Copper)

 * 80003ES2LAN Gigabit Ethernet Controller (Serdes)

/* A table for the GG82563 cable length where the range is defined

 * with a lower bound at "index" and the upper bound at

 * "index + 5".

/**

 *  e1000_init_phy_params_80003es2lan - Init ESB2 PHY func ptrs.

 *  @hw: pointer to the HW structure

 This can only be done after all function pointers are setup. */

 Verify phy id */

/**

 *  e1000_init_nvm_params_80003es2lan - Init ESB2 NVM func ptrs.

 *  @hw: pointer to the HW structure

	/* Added to a constant, "size" becomes the left-shift value

	 * for setting word_size.

 EEPROM access above 16k is unsupported */

/**

 *  e1000_init_mac_params_80003es2lan - Init ESB2 MAC func ptrs.

 *  @hw: pointer to the HW structure

 Set media type and media-dependent function pointers */

 Set mta register count */

 Set rar entry count */

 FWSM register */

 ARC supported; valid only if manageability features are enabled. */

 Adaptive IFS not supported */

 set lan id for port to determine which phy lock to use */

/**

 *  e1000_acquire_phy_80003es2lan - Acquire rights to access PHY

 *  @hw: pointer to the HW structure

 *

 *  A wrapper to acquire access rights to the correct PHY.

/**

 *  e1000_release_phy_80003es2lan - Release rights to access PHY

 *  @hw: pointer to the HW structure

 *

 *  A wrapper to release access rights to the correct PHY.

/**

 *  e1000_acquire_mac_csr_80003es2lan - Acquire right to access Kumeran register

 *  @hw: pointer to the HW structure

 *

 *  Acquire the semaphore to access the Kumeran interface.

 *

/**

 *  e1000_release_mac_csr_80003es2lan - Release right to access Kumeran Register

 *  @hw: pointer to the HW structure

 *

 *  Release the semaphore used to access the Kumeran interface

/**

 *  e1000_acquire_nvm_80003es2lan - Acquire rights to access NVM

 *  @hw: pointer to the HW structure

 *

 *  Acquire the semaphore to access the EEPROM.

/**

 *  e1000_release_nvm_80003es2lan - Relinquish rights to access NVM

 *  @hw: pointer to the HW structure

 *

 *  Release the semaphore used to access the EEPROM.

/**

 *  e1000_acquire_swfw_sync_80003es2lan - Acquire SW/FW semaphore

 *  @hw: pointer to the HW structure

 *  @mask: specifies which semaphore to acquire

 *

 *  Acquire the SW/FW semaphore to access the PHY or NVM.  The mask

 *  will also specify which port we're acquiring the lock for.

		/* Firmware currently using resource (fwmask)

		 * or other software thread using resource (swmask)

/**

 *  e1000_release_swfw_sync_80003es2lan - Release SW/FW semaphore

 *  @hw: pointer to the HW structure

 *  @mask: specifies which semaphore to acquire

 *

 *  Release the SW/FW semaphore used to access the PHY or NVM.  The mask

 *  will also specify which port we're releasing the lock for.

 Empty */

/**

 *  e1000_read_phy_reg_gg82563_80003es2lan - Read GG82563 PHY register

 *  @hw: pointer to the HW structure

 *  @offset: offset of the register to read

 *  @data: pointer to the data returned from the operation

 *

 *  Read the GG82563 PHY register.

 Select Configuration Page */

		/* Use Alternative Page Select register to access

		 * registers 30 and 31

		/* The "ready" bit in the MDIC register may be incorrectly set

		 * before the device has completed the "Page Select" MDI

		 * transaction.  So we wait 200us after each MDI command...

 ...and verify the command was successful. */

/**

 *  e1000_write_phy_reg_gg82563_80003es2lan - Write GG82563 PHY register

 *  @hw: pointer to the HW structure

 *  @offset: offset of the register to read

 *  @data: value to write to the register

 *

 *  Write to the GG82563 PHY register.

 Select Configuration Page */

		/* Use Alternative Page Select register to access

		 * registers 30 and 31

		/* The "ready" bit in the MDIC register may be incorrectly set

		 * before the device has completed the "Page Select" MDI

		 * transaction.  So we wait 200us after each MDI command...

 ...and verify the command was successful. */

/**

 *  e1000_write_nvm_80003es2lan - Write to ESB2 NVM

 *  @hw: pointer to the HW structure

 *  @offset: offset of the register to read

 *  @words: number of words to write

 *  @data: buffer of data to write to the NVM

 *

 *  Write "words" of data to the ESB2 NVM.

/**

 *  e1000_get_cfg_done_80003es2lan - Wait for configuration to complete

 *  @hw: pointer to the HW structure

 *

 *  Wait a specific amount of time for manageability processes to complete.

 *  This is a function pointer entry point called by the phy module.

/**

 *  e1000_phy_force_speed_duplex_80003es2lan - Force PHY speed and duplex

 *  @hw: pointer to the HW structure

 *

 *  Force the speed and duplex settings onto the PHY.  This is a

 *  function pointer entry point called by the phy module.

	/* Clear Auto-Crossover to force MDI manually.  M88E1000 requires MDI

	 * forced whenever speed and duplex are forced.

 Reset the phy to commit changes. */

			/* We didn't get link.

			 * Reset the DSP and cross our fingers.

 Try once more */

	/* Resetting the phy means we need to verify the TX_CLK corresponds

	 * to the link speed.  10Mbps -> 2.5MHz, else 25MHz.

	/* In addition, we must re-enable CRS on Tx for both half and full

	 * duplex.

/**

 *  e1000_get_cable_length_80003es2lan - Set approximate cable length

 *  @hw: pointer to the HW structure

 *

 *  Find the approximate cable length as measured by the GG82563 PHY.

 *  This is a function pointer entry point called by the phy module.

/**

 *  e1000_get_link_up_info_80003es2lan - Report speed and duplex

 *  @hw: pointer to the HW structure

 *  @speed: pointer to speed buffer

 *  @duplex: pointer to duplex buffer

 *

 *  Retrieve the current speed and duplex configuration.

/**

 *  e1000_reset_hw_80003es2lan - Reset the ESB2 controller

 *  @hw: pointer to the HW structure

 *

 *  Perform a global reset to the ESB2 controller.

	/* Prevent the PCI-E bus from sticking if there is no TLP connection

	 * on the last TLP read/write transaction when MAC is reset.

 Disable IBIST slave mode (far-end loopback) */

 We don't want to continue accessing MAC registers. */

 Clear any pending interrupt events. */

/**

 *  e1000_init_hw_80003es2lan - Initialize the ESB2 controller

 *  @hw: pointer to the HW structure

 *

 *  Initialize the hw bits, LED, VFTA, MTA, link and hw counters.

 Initialize identification LED */

 An error is not fatal and we should not stop init due to this */

 Disabling VLAN filtering */

 Setup the receive address. */

 Zero out the Multicast HASH table */

 Setup link and flow control */

 Disable IBIST slave mode (far-end loopback) */

 Set the transmit descriptor write-back policy */

 ...for both queues. */

 Enable retransmit on late collisions */

 Configure Gigabit Carry Extend Padding */

 Configure Transmit Inter-Packet Gap */

 default to true to enable the MDIC W/A */

	/* Clear all of the statistics registers (clear on read).  It is

	 * important that we do this after we have tried to establish link

	 * because the symbol error count will increment wildly if there

	 * is no link.

/**

 *  e1000_initialize_hw_bits_80003es2lan - Init hw bits of ESB2

 *  @hw: pointer to the HW structure

 *

 *  Initializes required hardware-dependent bits needed for normal operation.

 Transmit Descriptor Control 0 */

 Transmit Descriptor Control 1 */

 Transmit Arbitration Control 0 */

 30:27 */

 Transmit Arbitration Control 1 */

	/* Disable IPv6 extension header parsing because some malformed

	 * IPv6 headers can hang the Rx.

/**

 *  e1000_copper_link_setup_gg82563_80003es2lan - Configure GG82563 Link

 *  @hw: pointer to the HW structure

 *

 *  Setup some GG82563 PHY registers for obtaining link

 Use 25MHz for both link down and 1000Base-T for Tx clock. */

	/* Options:

	 *   MDI/MDI-X = 0 (default)

	 *   0 - Auto for all speeds

	 *   1 - MDI mode

	 *   2 - MDI-X mode

	 *   3 - Auto for 1000Base-T only (MDI-X for 10/100Base-T modes)

	/* Options:

	 *   disable_polarity_correction = 0 (default)

	 *       Automatic Correction for Reversed Cable Polarity

	 *   0 - Disabled

	 *   1 - Enabled

 SW Reset the PHY so all changes take effect */

 Bypass Rx and Tx FIFO's */

	/* Do not init these registers when the HW is in IAMT mode, since the

	 * firmware will have already initialized them.  We only initialize

	 * them if the HW is not in IAMT mode.

 Enable Electrical Idle on the PHY */

	/* Workaround: Disable padding in Kumeran interface in the MAC

	 * and in the PHY to avoid CRC errors.

/**

 *  e1000_setup_copper_link_80003es2lan - Setup Copper Link for ESB2

 *  @hw: pointer to the HW structure

 *

 *  Essentially a wrapper for setting up all things "copper" related.

 *  This is a function pointer entry point called by the mac module.

	/* Set the mac to wait the maximum time between each

	 * iteration and increase the max iterations when

	 * polling the phy; this fixes erroneous timeouts at 10Mbps.

/**

 *  e1000_cfg_on_link_up_80003es2lan - es2 link configuration after link-up

 *  @hw: pointer to the HW structure

 *

 *  Configure the KMRN interface by applying last minute quirks for

 *  10/100 operation.

/**

 *  e1000_cfg_kmrn_10_100_80003es2lan - Apply "quirks" for 10/100 operation

 *  @hw: pointer to the HW structure

 *  @duplex: current duplex setting

 *

 *  Configure the KMRN interface by applying last minute quirks for

 *  10/100 operation.

 Configure Transmit Inter-Packet Gap */

/**

 *  e1000_cfg_kmrn_1000_80003es2lan - Apply "quirks" for gigabit operation

 *  @hw: pointer to the HW structure

 *

 *  Configure the KMRN interface by applying last minute quirks for

 *  gigabit operation.

 Configure Transmit Inter-Packet Gap */

/**

 *  e1000_read_kmrn_reg_80003es2lan - Read kumeran register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Acquire semaphore, then read the PHY register at offset

 *  using the kumeran interface.  The information retrieved is stored in data.

 *  Release the semaphore before exiting.

/**

 *  e1000_write_kmrn_reg_80003es2lan - Write kumeran register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Acquire semaphore, then write the data to PHY register

 *  at the offset using the kumeran interface.  Release semaphore

 *  before exiting.

/**

 *  e1000_read_mac_addr_80003es2lan - Read device MAC address

 *  @hw: pointer to the HW structure

	/* If there's an alternate MAC address place it in RAR0

	 * so that it will override the Si installed default perm

	 * address.

/**

 * e1000_power_down_phy_copper_80003es2lan - Remove link during PHY power down

 * @hw: pointer to the HW structure

 *

 * In the case of a PHY power down to save power, or to turn off link during a

 * driver unload, or wake on lan is not enabled, remove the link.

 If the management interface is not enabled, then power down */

/**

 *  e1000_clear_hw_cntrs_80003es2lan - Clear device specific hardware counters

 *  @hw: pointer to the HW structure

 *

 *  Clears the hardware counters by reading the counter registers.

 check_for_link dependent on media type */

 setup_physical_interface dependent on media type */

 errata */

 errata */

 errata */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/* This is the only thing that needs to be changed to adjust the

 * maximum number of ports that the driver can manage.

/* All parameters are treated the same, as an integer array of values.

 * This macro just reduces the need to repeat the same declaration code

 * over and over (plus this helps to avoid typo bugs).

/* Transmit Interrupt Delay in units of 1.024 microseconds

 * Tx interrupt delay needs to typically be set to something non-zero

 *

 * Valid Range: 0-65535

/* Transmit Absolute Interrupt Delay in units of 1.024 microseconds

 *

 * Valid Range: 0-65535

/* Receive Interrupt Delay in units of 1.024 microseconds

 * hardware will likely hang if you set this to anything but zero.

 *

 * Burst variant is used as default if device has FLAG2_DMA_BURST.

 *

 * Valid Range: 0-65535

/* Receive Absolute Interrupt Delay in units of 1.024 microseconds

 *

 * Burst variant is used as default if device has FLAG2_DMA_BURST.

 *

 * Valid Range: 0-65535

/* Interrupt Throttle Rate (interrupts/sec)

 *

 * Valid Range: 100-100000 or one of: 0=off, 1=dynamic, 3=dynamic conservative

/* IntMode (Interrupt Mode)

 *

 * Valid Range: varies depending on kernel configuration & hardware support

 *

 * legacy=0, MSI=1, MSI-X=2

 *

 * When MSI/MSI-X support is enabled in kernel-

 *   Default Value: 2 (MSI-X) when supported by hardware, 1 (MSI) otherwise

 * When MSI/MSI-X support is not enabled in kernel-

 *   Default Value: 0 (legacy)

 *

 * When a mode is specified that is not allowed/supported, it will be

 * demoted to the most advanced interrupt mode available.

/* Enable Smart Power Down of the PHY

 *

 * Valid Range: 0, 1

 *

 * Default Value: 0 (disabled)

/* Enable Kumeran Lock Loss workaround

 *

 * Valid Range: 0, 1

 *

 * Default Value: 1 (enabled)

/* Write Protect NVM

 *

 * Valid Range: 0, 1

 *

 * Default Value: 1 (enabled)

/* Enable CRC Stripping

 *

 * Valid Range: 0, 1

 *

 * Default Value: 1 (enabled)

 range_option info */

 list_option info */

/**

 * e1000e_check_options - Range Checking for Command Line Parameters

 * @adapter: board private structure

 *

 * This routine checks all command line parameters for valid user

 * input.  If an invalid value is given, or if no user specified

 * value exists, a default value is used.  The final value is stored

 * in a variable in the adapter structure.

 Transmit Interrupt Delay */

 Transmit Absolute Interrupt Delay */

 Receive Interrupt Delay */

 Receive Absolute Interrupt Delay */

 Interrupt Throttling Rate */

			/* Make sure a message is printed for non-special

			 * values. And in case of an invalid option, display

			 * warning, use default and go through itr/itr_setting

			 * adjustment logic below

			/* If no option specified, use default value and go

			 * through the logic below to adjust itr/itr_setting

			/* Make sure a message is printed for non-special

			 * default values

			/* Save the setting, because the dynamic bits

			 * change itr.

			 *

			 * Clear the lower two bits because

			 * they are used as control.

 Interrupt Mode */

 Smart Power Down */

 CRC Stripping */

 Kumeran Lock Loss Workaround */

 Write-protect NVM */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 General Registers */

 Interrupt Registers */

 Rx Registers */

 Tx Registers */

 List Terminator */

/**

 * __ew32_prepare - prepare to write to MAC CSR register on certain parts

 * @hw: pointer to the HW structure

 *

 * When updating the MAC CSR registers, the Manageability Engine (ME) could

 * be accessing the registers at the same time.  Normally, this is handled in

 * h/w by an arbiter but on some parts there is a bug that acknowledges Host

 * accesses later than it should which could result in the register to have

 * an incorrect value.  Workaround this by checking the FWSM register which

 * has bit 24 set while ME is accessing MAC CSR registers, wait if it is set

 * and try again a number of times.

/**

 * e1000_regdump - register printout routine

 * @hw: pointer to the HW structure

 * @reginfo: pointer to the register info table

/**

 * e1000e_dump - Print registers, Tx-ring and Rx-ring

 * @adapter: board private structure

 Print netdevice Info */

 Print Registers */

 Print Tx Ring Summary */

 Print Tx Ring */

	/* Transmit Descriptor Formats - DEXT[29] is 0 (Legacy) or 1 (Extended)

	 *

	 * Legacy Transmit Descriptor

	 *   +--------------------------------------------------------------+

	 * 0 |         Buffer Address [63:0] (Reserved on Write Back)       |

	 *   +--------------------------------------------------------------+

	 * 8 | Special  |    CSS     | Status |  CMD    |  CSO   |  Length  |

	 *   +--------------------------------------------------------------+

	 *   63       48 47        36 35    32 31     24 23    16 15        0

	 *

	 * Extended Context Descriptor (DTYP=0x0) for TSO or checksum offload

	 *   63      48 47    40 39       32 31             16 15    8 7      0

	 *   +----------------------------------------------------------------+

	 * 0 |  TUCSE  | TUCS0  |   TUCSS   |     IPCSE       | IPCS0 | IPCSS |

	 *   +----------------------------------------------------------------+

	 * 8 |   MSS   | HDRLEN | RSV | STA | TUCMD | DTYP |      PAYLEN      |

	 *   +----------------------------------------------------------------+

	 *   63      48 47    40 39 36 35 32 31   24 23  20 19                0

	 *

	 * Extended Data Descriptor (DTYP=0x1)

	 *   +----------------------------------------------------------------+

	 * 0 |                     Buffer Address [63:0]                      |

	 *   +----------------------------------------------------------------+

	 * 8 | VLAN tag |  POPTS  | Rsvd | Status | Command | DTYP |  DTALEN  |

	 *   +----------------------------------------------------------------+

	 *   63       48 47     40 39  36 35    32 31     24 23  20 19        0

 Print Rx Ring Summary */

 Print Rx Ring */

		/* [Extended] Packet Split Receive Descriptor Format

		 *

		 *    +-----------------------------------------------------+

		 *  0 |                Buffer Address 0 [63:0]              |

		 *    +-----------------------------------------------------+

		 *  8 |                Buffer Address 1 [63:0]              |

		 *    +-----------------------------------------------------+

		 * 16 |                Buffer Address 2 [63:0]              |

		 *    +-----------------------------------------------------+

		 * 24 |                Buffer Address 3 [63:0]              |

		 *    +-----------------------------------------------------+

		/* [Extended] Receive Descriptor (Write-Back) Format

		 *

		 *   63       48 47    32 31     13 12    8 7    4 3        0

		 *   +------------------------------------------------------+

		 * 0 | Packet   | IP     |  Rsvd   | MRQ   | Rsvd | MRQ RSS |

		 *   | Checksum | Ident  |         | Queue |      |  Type   |

		 *   +------------------------------------------------------+

		 * 8 | VLAN Tag | Length | Extended Error | Extended Status |

		 *   +------------------------------------------------------+

		 *   63       48 47    32 31            20 19               0

 Descriptor Done */

		/* Extended Receive Descriptor (Read) Format

		 *

		 *   +-----------------------------------------------------+

		 * 0 |                Buffer Address [63:0]                |

		 *   +-----------------------------------------------------+

		 * 8 |                      Reserved                       |

		 *   +-----------------------------------------------------+

		/* Extended Receive Descriptor (Write-Back) Format

		 *

		 *   63       48 47    32 31    24 23            4 3        0

		 *   +------------------------------------------------------+

		 *   |     RSS Hash      |        |               |         |

		 * 0 +-------------------+  Rsvd  |   Reserved    | MRQ RSS |

		 *   | Packet   | IP     |        |               |  Type   |

		 *   | Checksum | Ident  |        |               |         |

		 *   +------------------------------------------------------+

		 * 8 | VLAN Tag | Length | Extended Error | Extended Status |

		 *   +------------------------------------------------------+

		 *   63       48 47    32 31            20 19               0

 Descriptor Done */

/**

 * e1000_desc_unused - calculate if we have unused descriptors

 * @ring: pointer to ring struct to perform calculation on

/**

 * e1000e_systim_to_hwtstamp - convert system time value to hw time stamp

 * @adapter: board private structure

 * @hwtstamps: time stamp structure to update

 * @systim: unsigned 64bit system time value.

 *

 * Convert the system time value stored in the RX/TXSTMP registers into a

 * hwtstamp which can be used by the upper level time stamping functions.

 *

 * The 'systim_lock' spinlock is used to protect the consistency of the

 * system time value. This is needed because reading the 64 bit time

 * value involves reading two 32 bit registers. The first read latches the

 * value.

/**

 * e1000e_rx_hwtstamp - utility function which checks for Rx time stamp

 * @adapter: board private structure

 * @status: descriptor extended error and status field

 * @skb: particular skb to include time stamp

 *

 * If the time stamp is valid, convert it into the timecounter ns value

 * and store that result into the shhwtstamps structure which is passed

 * up the network stack.

	/* The Rx time stamp registers contain the time stamp.  No other

	 * received packet will be time stamped until the Rx time stamp

	 * registers are read.  Because only one packet can be time stamped

	 * at a time, the register values must belong to this packet and

	 * therefore none of the other additional attributes need to be

	 * compared.

/**

 * e1000_receive_skb - helper function to handle Rx indications

 * @adapter: board private structure

 * @netdev: pointer to netdev struct

 * @staterr: descriptor extended error and status field as written by hardware

 * @vlan: descriptor vlan field as written by hardware (no le/be conversion)

 * @skb: pointer to sk_buff to be indicated to stack

/**

 * e1000_rx_checksum - Receive Checksum Offload

 * @adapter: board private structure

 * @status_err: receive descriptor status and error fields

 * @skb: socket buffer with received data

 Rx checksum disabled */

 Ignore Checksum bit is set */

 TCP/UDP checksum error bit or IP checksum error bit is set */

 let the stack verify checksum errors */

 TCP/UDP Checksum has not been calculated */

 It must be a TCP or UDP packet with a valid checksum */

/**

 * e1000_alloc_rx_buffers - Replace used receive buffers

 * @rx_ring: Rx descriptor ring

 * @cleaned_count: number to reallocate

 * @gfp: flags for allocation

 Better luck next round */

			/* Force memory writes to complete before letting h/w

			 * know there are new descriptors to fetch.  (Only

			 * applicable for weak-ordered memory model archs,

			 * such as IA-64).

/**

 * e1000_alloc_rx_buffers_ps - Replace used receive buffers; packet split

 * @rx_ring: Rx descriptor ring

 * @cleaned_count: number to reallocate

 * @gfp: flags for allocation

 all unused desc entries get hw null ptr */

			/* Refresh the desc even if buffer_addrs

			 * didn't change because each write-back

			 * erases this info.

 cleanup skb */

			/* Force memory writes to complete before letting h/w

			 * know there are new descriptors to fetch.  (Only

			 * applicable for weak-ordered memory model archs,

			 * such as IA-64).

/**

 * e1000_alloc_jumbo_rx_buffers - Replace used jumbo receive buffers

 * @rx_ring: Rx descriptor ring

 * @cleaned_count: number of buffers to allocate this pass

 * @gfp: flags for allocation

 for skb_reserve */

 Better luck next round */

 allocate a new page if necessary */

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

/**

 * e1000_clean_rx_irq - Send received data up the network stack

 * @rx_ring: Rx descriptor ring

 * @work_done: output parameter for indicating completed work

 * @work_to_do: how many packets we can clean

 *

 * the return value indicates whether actual cleaning was done, there

 * is no guarantee that everything was cleaned

 read descriptor and rx_buffer_info after status DD */

		/* !EOP means multiple descriptors were used to store a single

		 * packet, if that's the case we need to toss it.  In fact, we

		 * need to toss every packet with the EOP bit clear and the

		 * next frame that _does_ have the EOP bit set, as it is by

		 * definition only a frame fragment

 All receives must fit into a single buffer */

 recycle */

 recycle */

 adjust length to remove Ethernet CRC */

			/* If configured to store CRC, don't subtract FCS,

			 * but keep the FCS bytes out of the total_rx_bytes

			 * counter

		/* code added for copybreak, this should improve

		 * performance for small packets with large amounts

		 * of reassembly being done in the stack

 save the skb in buffer_info as good */

 else just continue with the old one */

 end copybreak code */

 Receive Checksum Offload */

 return some buffers to hardware, one at a time is too slow */

 use prefetched values */

		/* May be block on write-back, flush and detect again

		 * flush pending descriptor writebacks to memory

 execute the writes immediately */

		/* Due to rare timing issues, write to TIDV again to ensure

		 * the write is successful

 execute the writes immediately */

 Real hang detected */

 detected Hardware unit hang */

 Suggest workaround for known h/w issue */

/**

 * e1000e_tx_hwtstamp_work - check for Tx time stamp

 * @work: pointer to work struct

 *

 * This work function polls the TSYNCTXCTL valid bit to determine when a

 * timestamp has been taken for the current stored skb.  The timestamp must

 * be for this skb because only one such packet is allowed in the queue.

		/* Clear the global tx_hwtstamp_skb pointer and force writes

		 * prior to notifying the stack of a Tx timestamp.

 force write prior to skb_tstamp_tx */

 reschedule to check later */

/**

 * e1000_clean_tx_irq - Reclaim resources after transmit completes

 * @tx_ring: Tx descriptor ring

 *

 * the return value indicates whether actual cleaning was done, there

 * is no guarantee that everything was cleaned

 read buffer_info after eop_desc */

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

		/* Detect a transmit hang in hardware, this serializes the

		 * check with the clearing of time_stamp and movement of i

/**

 * e1000_clean_rx_irq_ps - Send received data up the network stack; packet split

 * @rx_ring: Rx descriptor ring

 * @work_done: output parameter for indicating completed work

 * @work_to_do: how many packets we can clean

 *

 * the return value indicates whether actual cleaning was done, there

 * is no guarantee that everything was cleaned

 read descriptor and rx_buffer_info after status DD */

 in the packet split case this is header only */

 see !EOP comment in other Rx routine */

 Good Receive */

			/* this looks ugly, but it seems compiler issues make

			 * it more efficient than reusing j

			/* page alloc/put takes too long and effects small

			 * packet throughput, so unsplit small packets and

			 * save the alloc/put only valid in softirq (napi)

			 * context to call kmap_*

				/* there is no documentation about how to call

				 * kmap_atomic, so we can't hold the mapping

				 * very long

 remove the CRC */

 if */

		/* strip the ethernet crc, problem is we're using pages now so

		 * this whole operation can get a little cpu intensive

 return some buffers to hardware, one at a time is too slow */

 use prefetched values */

/**

 * e1000_clean_jumbo_rx_irq - Send received data up the network stack; legacy

 * @rx_ring: Rx descriptor ring

 * @work_done: output parameter for indicating completed work

 * @work_to_do: how many packets we can clean

 *

 * the return value indicates whether actual cleaning was done, there

 * is no guarantee that everything was cleaned

 read descriptor and rx_buffer_info after status DD */

 errors is only valid for DD + EOP descriptors */

 recycle both page and skb */

 an error means any chain goes out the window too */

 this descriptor is only the beginning (or middle) */

 this is the beginning of a chain */

 this is the middle of a chain */

 re-use the skb, only consumed the page */

 end of the chain */

				/* re-use the current skb, we only consumed the

				 * page

				/* no chain, got EOP, this buf is the packet

				 * copybreak to save the put_page/alloc_page

					/* re-use the page, so don't erase

					 * buffer_info->page

 Receive Checksum Offload */

 probably a little skewed due to removing CRC */

 eth type trans needs skb->data to point to something */

 return some buffers to hardware, one at a time is too slow */

 use prefetched values */

/**

 * e1000_clean_rx_ring - Free Rx Buffers per Queue

 * @rx_ring: Rx descriptor ring

 Free all the Rx ring sk_buffs */

 there also may be some cached data from a chained receive */

 Zero out the descriptor ring */

/**

 * e1000_intr_msi - Interrupt Handler

 * @irq: interrupt number

 * @data: pointer to a network interface device structure

 read ICR disables interrupts using IAM */

		/* ICH8 workaround-- Call gig speed drop workaround on cable

		 * disconnect (LSC) before accessing any PHY registers

		/* 80003ES2LAN workaround-- For packet buffer work-around on

		 * link down event; disable receives here in the ISR and reset

		 * adapter in watchdog

 disable receives */

 guard against interrupt when we're going down */

 Reset on uncorrectable ECC error */

 Do the reset outside of interrupt context */

 return immediately since reset is imminent */

/**

 * e1000_intr - Interrupt Handler

 * @irq: interrupt number

 * @data: pointer to a network interface device structure

 Not our interrupt */

	/* IMS will not auto-mask if INT_ASSERTED is not set, and if it is

	 * not set, then the adapter didn't send an interrupt

	/* Interrupt Auto-Mask...upon reading ICR,

	 * interrupts are masked.  No need for the

	 * IMC write

		/* ICH8 workaround-- Call gig speed drop workaround on cable

		 * disconnect (LSC) before accessing any PHY registers

		/* 80003ES2LAN workaround--

		 * For packet buffer work-around on link down event;

		 * disable receives here in the ISR and

		 * reset adapter in watchdog

 disable receives */

 guard against interrupt when we're going down */

 Reset on uncorrectable ECC error */

 Do the reset outside of interrupt context */

 return immediately since reset is imminent */

 guard against interrupt when we're going down */

 Ring was not completely cleaned, so fire another interrupt */

	/* Write the ITR value calculated at the end of the

	 * previous interrupt.

/**

 * e1000_configure_msix - Configure MSI-X hardware

 * @adapter: board private structure

 *

 * e1000_configure_msix sets up the hardware to properly

 * generate MSI-X interrupts.

 Workaround issue with spurious interrupts on 82574 in MSI-X mode */

 Configure Rx vector */

 Configure Tx vector */

 set vector for Other Causes, e.g. link changes */

 Cause Tx interrupts on every write back */

 enable MSI-X PBA support */

/**

 * e1000e_set_interrupt_capability - set MSI or MSI-X if supported

 * @adapter: board private structure

 *

 * Attempt to configure interrupts using the best available

 * capabilities of the hardware and kernel.

 RxQ0, TxQ0 and other */

 MSI-X failed, so fall through and try MSI */

 Don't do anything; this is the system default */

 store the number of vectors being used */

/**

 * e1000_request_msix - Initialize MSI-X interrupts

 * @adapter: board private structure

 *

 * e1000_request_msix allocates MSI-X vectors and requests interrupts from the

 * kernel.

/**

 * e1000_request_irq - initialize interrupts

 * @adapter: board private structure

 *

 * Attempts to configure interrupts using the best available

 * capabilities of the hardware and kernel.

 fall back to MSI */

 fall back to legacy interrupt */

 Other Causes interrupt vector */

/**

 * e1000_irq_disable - Mask off interrupt generation on the NIC

 * @adapter: board private structure

/**

 * e1000_irq_enable - Enable default interrupt generation settings

 * @adapter: board private structure

/**

 * e1000e_get_hw_control - get control of the h/w from f/w

 * @adapter: address of board private structure

 *

 * e1000e_get_hw_control sets {CTRL_EXT|SWSM}:DRV_LOAD bit.

 * For ASF and Pass Through versions of f/w this means that

 * the driver is loaded. For AMT version (only with 82573)

 * of the f/w this means that the network i/f is open.

 Let firmware know the driver has taken over */

/**

 * e1000e_release_hw_control - release control of the h/w to f/w

 * @adapter: address of board private structure

 *

 * e1000e_release_hw_control resets {CTRL_EXT|SWSM}:DRV_LOAD bit.

 * For ASF and Pass Through versions of f/w this means that the

 * driver is no longer loaded. For AMT version (only with 82573) i

 * of the f/w this means that the network i/f is closed.

 *

 Let firmware taken over control of h/w */

/**

 * e1000_alloc_ring_dma - allocate memory for a ring structure

 * @adapter: board private structure

 * @ring: ring struct for which to allocate dma

/**

 * e1000e_setup_tx_resources - allocate Tx resources (Descriptors)

 * @tx_ring: Tx descriptor ring

 *

 * Return 0 on success, negative on failure

 round up to nearest 4K */

/**

 * e1000e_setup_rx_resources - allocate Rx resources (Descriptors)

 * @rx_ring: Rx descriptor ring

 *

 * Returns 0 on success, negative on failure

 Round up to nearest 4K */

/**

 * e1000_clean_tx_ring - Free Tx Buffers

 * @tx_ring: Tx descriptor ring

/**

 * e1000e_free_tx_resources - Free Tx Resources per Queue

 * @tx_ring: Tx descriptor ring

 *

 * Free all transmit software resources

/**

 * e1000e_free_rx_resources - Free Rx Resources

 * @rx_ring: Rx descriptor ring

 *

 * Free all receive software resources

/**

 * e1000_update_itr - update the dynamic ITR value based on statistics

 * @itr_setting: current adapter->itr

 * @packets: the number of packets during this measurement interval

 * @bytes: the number of bytes during this measurement interval

 *

 *      Stores a new ITR value based on packets and byte

 *      counts during the last interrupt.  The advantage of per interrupt

 *      computation is faster updates and more accurate ITR for the current

 *      traffic pattern.  Constants in this function were computed

 *      based on theoretical maximum wire speed and thresholds were set based

 *      on testing data as well as attempting to minimize response time

 *      while increasing bulk throughput.  This functionality is controlled

 *      by the InterruptThrottleRate module parameter.

 handle TSO and jumbo frames */

 50 usec aka 20000 ints/s */

 this if handles the TSO accounting */

 250 usec aka 4000 ints/s */

 for non-gigabit speeds, just fix the interrupt rate at 4000 */

 conservative mode (itr 3) eliminates the lowest_latency setting */

 conservative mode (itr 3) eliminates the lowest_latency setting */

 counts and packets in update_itr are dependent on these numbers */

 aka hwitr = ~200 */

		/* this attempts to bias the interrupt rate towards Bulk

		 * by adding intermediate steps when interrupt rate is

		 * increasing

/**

 * e1000e_write_itr - write the ITR value to the appropriate registers

 * @adapter: address of board private structure

 * @itr: new ITR value to program

 *

 * e1000e_write_itr determines if the adapter is in MSI-X mode

 * and, if so, writes the EITR registers with the ITR value.

 * Otherwise, it writes the ITR value into the ITR register.

/**

 * e1000_alloc_queues - Allocate memory for all rings

 * @adapter: board private structure to initialize

/**

 * e1000e_poll - NAPI Rx polling callback

 * @napi: struct associated with this polling callback

 * @budget: number of packets driver is allowed to process this poll

	/* Exit the polling mode, but don't re-enable interrupts if stack might

	 * poll us due to busy-polling

 don't update vlan cookie if already programmed */

 add VID to filter table */

 release control to f/w */

 remove VID from filter table */

/**

 * e1000e_vlan_filter_disable - helper to disable hw VLAN filtering

 * @adapter: board private structure to initialize

 disable VLAN receive filtering */

/**

 * e1000e_vlan_filter_enable - helper to enable HW VLAN filtering

 * @adapter: board private structure to initialize

 enable VLAN receive filtering */

/**

 * e1000e_vlan_strip_disable - helper to disable HW VLAN stripping

 * @adapter: board private structure to initialize

 disable VLAN tag insert/strip */

/**

 * e1000e_vlan_strip_enable - helper to enable HW VLAN stripping

 * @adapter: board private structure to initialize

 enable VLAN tag insert/strip */

	/* enable receiving management packets to the host. this will probably

	 * generate destination unreachable messages from the host OS, but

	 * the packets will be handled on SMBUS

		/* Check if IPMI pass-through decision filter already exists;

		 * if so, enable it.

 Ignore filters with anything other than IPMI ports */

 Enable this decision filter in MANC2H */

 Create new decision filter in an empty filter */

/**

 * e1000_configure_tx - Configure Transmit Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Tx unit of the MAC after a reset.

 Setup the HW Tx Head and Tail descriptor pointers */

 Set the Tx Interrupt Delay register */

 Tx irq moderation */

		/* set up some performance related parameters to encourage the

		 * hardware to use the bus more efficiently in bursts, depends

		 * on the tx_int_delay to be enabled,

		 * wthresh = 1 ==> burst write is disabled to avoid Tx stalls

		 * hthresh = 1 ==> prefetch when one or more available

		 * pthresh = 0x1f ==> prefetch if internal cache 31 or less

		 * BEWARE: this seems to work but should be considered first if

		 * there are Tx hangs or other Tx related bugs

 erratum work around: set txdctl the same for both queues */

 Program the Transmit Control Register */

		/* set the speed mode bit, we'll clear it if we're not at

		 * gigabit link later

 errata: program both queues to unweighted RR */

 Setup Transmit Descriptor Settings for eop descriptor */

 only set IDE if we are delaying interrupts using the timers */

 enable Report Status bit */

 SPT and KBL Si errata workaround to avoid data corruption */

		/* SPT and KBL Si errata workaround to avoid Tx hang.

		 * Dropping the number of outstanding requests from

		 * 3 to 2 in order to avoid a buffer overrun.

/**

 * e1000_setup_rctl - configure the receive control registers

 * @adapter: Board private structure

	/* Workaround Si errata on PCHx - configure jumbo frame flow.

	 * If jumbo frames not set, program related MAC/PHY registers

	 * to h/w defaults

 Program MC offset vector base */

 Do not Store bad packets */

 Enable Long Packet receive */

	/* Some systems expect that the CRC is included in SMBUS traffic. The

	 * hardware strips the CRC before sending to both SMBUS (BMC) and to

	 * host memory when this is enabled

 Workaround Si errata on 82577 PHY - configure IPG for jumbos */

 Setup buffer sizes */

 Enable Extended Status in all Receive Descriptors */

	/* 82571 and greater support packet-split where the protocol

	 * header is placed in skb->data and the packet data is

	 * placed in pages hanging off of skb_shinfo(skb)->nr_frags.

	 * In the case of a non-split, skb->data is linearly filled,

	 * followed by the page buffers.  Therefore, skb->data is

	 * sized to hold the largest protocol header.

	 *

	 * allocations using alloc_page take too long for regular MTU

	 * so only enable packet split for jumbo frames

	 *

	 * Using pages when the page size is greater than 16k wastes

	 * a lot of memory, since we allocate 3 pages at all times

	 * per packet.

 Enable Packet split descriptors */

 This is useful for sniffing bad packets. */

		/* UPE and MPE will be handled by normal PROMISC logic

		 * in e1000e_set_rx_mode

 Receive bad packets */

 RX All Bcast Pkts */

 RX All MAC Ctrl Pkts */

 Disable VLAN filter */

 Allow filtered pause */

 Dis VLAN CFIEN Filter */

		/* Do not mess with E1000_CTRL_VME, it affects transmit as well,

		 * and that breaks VLANs.

 just started the receive unit, no need to restart */

/**

 * e1000_configure_rx - Configure Receive Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Rx unit of the MAC after a reset.

 this is a 32 byte descriptor */

 disable receives while setting up the descriptors */

		/* set the writeback threshold (only takes effect if the RDTR

		 * is set). set GRAN=1 and write back up to 0x4 worth, and

		 * enable prefetching of 0x20 Rx descriptors

		 * granularity = 01

		 * wthresh = 04,

		 * hthresh = 04,

		 * pthresh = 0x20

 set the Receive Delay Timer Register */

 irq moderation */

 Auto-Mask interrupts upon ICR access */

	/* Setup the HW Rx Head and Tail Descriptor Pointers and

	 * the Base and Length of the Rx Descriptor Ring

 Enable Receive Checksum Offload for TCP and UDP */

	/* With jumbo frames, excessive C-state transition latencies result

	 * in dropped transactions.

 Enable Receives */

/**

 * e1000e_write_mc_addr_list - write multicast addresses to MTA

 * @netdev: network interface device structure

 *

 * Writes multicast address list to the MTA hash table.

 * Returns: -ENOMEM on failure

 *                0 on no addresses written

 *                X on writing X addresses to MTA

 nothing to program, so clear mc list */

 update_mc_addr_list expects a packed array of only addresses. */

/**

 * e1000e_write_uc_addr_list - write unicast addresses to RAR table

 * @netdev: network interface device structure

 *

 * Writes unicast address list to the RAR table.

 * Returns: -ENOMEM on failure/insufficient address space

 *                0 on no addresses written

 *                X on writing X addresses to the RAR table

 save a rar entry for our hardware address */

 save a rar entry for the LAA workaround */

 return ENOMEM indicating insufficient memory for addresses */

		/* write the addresses in reverse order to avoid write

		 * combining

 zero out the remaining RAR entries not used above */

/**

 * e1000e_set_rx_mode - secondary unicast, Multicast and Promiscuous mode set

 * @netdev: network interface device structure

 *

 * The ndo_set_rx_mode entry point is called whenever the unicast or multicast

 * address list or the network interface flags are updated.  This routine is

 * responsible for configuring the hardware for proper unicast, multicast,

 * promiscuous mode, and all-multi behavior.

 Check for Promiscuous and All Multicast modes */

 clear the affected bits */

 Do not hardware filter VLANs in promisc mode */

			/* Write addresses to the MTA, if the attempt fails

			 * then we should just turn on promiscuous mode so

			 * that we can at least receive multicast traffic

		/* Write addresses to available RAR registers, if there is not

		 * sufficient space to store all the addresses then enable

		 * unicast promiscuous mode

 Direct all traffic to queue 0 */

	/* Disable raw packet checksumming so that RSS hash is placed in

	 * descriptor on writeback.

/**

 * e1000e_get_base_timinca - get default SYSTIM time increment attributes

 * @adapter: board private structure

 * @timinca: pointer to returned time increment attributes

 *

 * Get attributes for incrementing the System Time Register SYSTIML/H at

 * the default base frequency, and set the cyclecounter shift value.

	/* Make sure clock is enabled on I217/I218/I219  before checking

	 * the frequency

 Stable 96MHz frequency */

 Stable 96MHz frequency */

 Stable 25MHz frequency */

 Stable 24MHz frequency */

 Stable 24MHz frequency */

 Stable 38400KHz frequency */

 Stable 25MHz frequency */

/**

 * e1000e_config_hwtstamp - configure the hwtstamp registers and enable/disable

 * @adapter: board private structure

 * @config: timestamp configuration

 *

 * Outgoing time stamping can be enabled and disabled. Play nice and

 * disable it when requested, although it shouldn't cause any overhead

 * when no packet needs it. At most one packet in the queue may be

 * marked for time stamping, otherwise it would be impossible to tell

 * for sure to which packet the hardware time stamp belongs.

 *

 * Incoming time stamping has to be configured via the hardware filters.

 * Not all combinations are supported, in particular event type has to be

 * specified. Matching the kind of event packet is not supported, with the

 * exception of "all V2 events regardless of level 2 or 4".

 flags reserved for future extensions - must be zero */

 Also time stamps V2 L2 Path Delay Request/Response */

 Also time stamps V2 L2 Path Delay Request/Response. */

 Hardware cannot filter just V2 L4 Sync messages */

 Also time stamps V2 Path Delay Request/Response. */

 Hardware cannot filter just V2 L4 Delay Request messages */

 Also time stamps V2 Path Delay Request/Response. */

 Hardware cannot filter just V2 L4 or L2 Event messages */

		/* For V1, the hardware can only filter Sync messages or

		 * Delay Request messages but not both so fall-through to

		 * time stamp all packets.

 enable/disable Tx h/w time stamping */

 enable/disable Rx h/w time stamping */

 L2: define ethertype filter for time stamped packets */

 define which PTP packets get time stamped */

 Filter by destination port */

 Clear TSYNCRXCTL_VALID & TSYNCTXCTL_VALID bit */

/**

 * e1000_configure - configure the hardware for Rx and Tx

 * @adapter: private board structure

/**

 * e1000e_power_up_phy - restore link in case the phy was powered down

 * @adapter: address of board private structure

 *

 * The phy may be powered down to save power and turn off link when the

 * driver is unloaded and wake on lan is not enabled (among others)

 * *** this routine MUST be followed by a call to e1000e_reset ***

/**

 * e1000_power_down_phy - Power down the PHY

 * @adapter: board private structure

 *

 * Power down the PHY so no link is implied when interface is down.

 * The PHY cannot be powered down if management or WoL is active.

/**

 * e1000_flush_tx_ring - remove all descriptors from the tx_ring

 * @adapter: board private structure

 *

 * We want to clear all pending descriptors from the TX ring.

 * zeroing happens when the HW reads the regs. We  assign the ring itself as

 * the data of the next descriptor. We don't care about the data we are about

 * to reset the HW.

 flush descriptors to memory before notifying the HW */

/**

 * e1000_flush_rx_ring - remove all descriptors from the rx_ring

 * @adapter: board private structure

 *

 * Mark all descriptors in the RX ring as consumed and disable the rx ring

 zero the lower 14 bits (prefetch and host thresholds) */

	/* update thresholds: prefetch threshold to 31, host threshold to 1

	 * and make sure the granularity is "descriptors" and not "cache lines"

 momentarily enable the RX ring for the changes to take effect */

/**

 * e1000_flush_desc_rings - remove all descriptors from the descriptor rings

 * @adapter: board private structure

 *

 * In i219, the descriptor rings must be emptied before resetting the HW

 * or before changing the device state to D3 during runtime (runtime PM).

 *

 * Failure to do this will cause the HW to enter a unit hang state which can

 * only be released by PCI reset on the device

 *

 First, disable MULR fix in FEXTNVM11 */

 do nothing if we're not in faulty state, or if the queue is empty */

 recheck, maybe the fault is caused by the rx ring */

/**

 * e1000e_systim_reset - reset the timesync registers after a hardware reset

 * @adapter: board private structure

 *

 * When the MAC is reset, all hardware bits for timesync will be reset to the

 * default values. This function will restore the settings last in place.

 * Since the clock SYSTIME registers are reset, we will simply restore the

 * cyclecounter to the kernel real clock time.

 restore the previous ptp frequency delta */

 set the default base frequency if no adjustment possible */

 reset the systim ns time counter */

 restore the previous hwtstamp configuration settings */

/**

 * e1000e_reset - bring the hardware into a known good state

 * @adapter: board private structure

 *

 * This function boots the hardware and enables some settings that

 * require a configuration cycle of the hardware - those cannot be

 * set/changed during runtime. After reset the device needs to be

 * properly configured for Rx, Tx etc.

 reset Packet Buffer Allocation to default */

		/* To maintain wire speed transmits, the Tx FIFO should be

		 * large enough to accommodate two full transmit packets,

		 * rounded up to the next 1KB and expressed in KB.  Likewise,

		 * the Rx FIFO should be large enough to accommodate at least

		 * one full receive packet and is similarly rounded up and

		 * expressed in KB.

 upper 16 bits has Tx packet buffer allocation size in KB */

 lower 16 bits has Rx packet buffer allocation size in KB */

		/* the Tx fifo also stores 16 bytes of information about the Tx

		 * but don't include ethernet FCS because hardware appends it

 software strips receive CRC, so leave room for it */

		/* If current Tx allocation is less than the min Tx FIFO size,

		 * and the min Tx FIFO size is less than the current Rx FIFO

		 * allocation, take space away from current Rx allocation

			/* if short on Rx space, Rx wins and must trump Tx

			 * adjustment

	/* flow control settings

	 *

	 * The high water mark must be low enough to fit one full frame

	 * (or the size used for early receive) above it in the Rx FIFO.

	 * Set it to the lower of:

	 * - 90% of the Rx FIFO size, and

	 * - the full Rx FIFO size minus one full frame

 8-byte granularity */

		/* Workaround PCH LOM adapter hangs with certain network

		 * loads.  If hangs persist, try disabling Tx flow control.

	/* Alignment of Tx data is on an arbitrary byte boundary with the

	 * maximum size per Tx descriptor limited only to the transmit

	 * allocation of the packet buffer minus 96 bytes with an upper

	 * limit of 24KB due to receive synchronization limitations.

	/* Disable Adaptive Interrupt Moderation if 2 full packets cannot

	 * fit in receive buffer.

 Allow time for pending master requests to run */

	/* For parts with AMT enabled, let the firmware know

	 * that the network interface is in control

 Enable h/w to recognize an 802.1Q VLAN Ethernet packet */

 restore systim and hwtstamp settings */

 Set EEE advertisement as appropriate */

		/* speed up time to link by disabling smart power down, ignore

		 * the return value of this function because there is nothing

		 * different we would do if it failed

 Fextnvm7 @ 0xe4[2] = 1 */

 Fextnvm9 @ 0x5bb4[13:12] = 11 */

/**

 * e1000e_trigger_lsc - trigger an LSC interrupt

 * @adapter: 

 *

 * Fire a link status change interrupt to start the watchdog.

 hardware has been reset, we need to reload some things */

 Tx queue started by watchdog timer when link is up */

 flush pending descriptor writebacks to memory */

 execute the writes immediately */

	/* due to rare timing issues, write to TIDV/RDTR again to ensure the

	 * write is successful

 execute the writes immediately */

/**

 * e1000e_down - quiesce the device and optionally reset the hardware

 * @adapter: board private structure

 * @reset: boolean flag to reset the hardware or not

	/* signal that we're down so the interrupt handler does not

	 * reschedule our watchdog timer

 disable receives in the hardware */

 flush and sleep below */

 disable transmits in the hardware */

 flush both disables and wait for them to finish */

 Disable Si errata workaround on PCHx for jumbo frame flow */

/**

 * e1000e_sanitize_systim - sanitize raw cycle counter reads

 * @hw: pointer to the HW structure

 * @systim: PHC time value read, sanitized and returned

 * @sts: structure to hold system time before and after reading SYSTIML,

 * may be NULL

 *

 * Errata for 82574/82583 possible bad bits read from SYSTIMH/L:

 * check to see that the time is incrementing at a reasonable

 * rate and is a multiple of incvalue.

 latch SYSTIMH on read of SYSTIML */

 VMWare users have seen incvalue of zero, don't div / 0 */

/**

 * e1000e_read_systim - read SYSTIM register

 * @adapter: board private structure

 * @sts: structure which will contain system time before and after reading

 * SYSTIML, may be NULL

	/* SYSTIMH latching upon SYSTIML read does not work well.

	 * This means that if SYSTIML overflows after we read it but before

	 * we read SYSTIMH, the value of SYSTIMH has been incremented and we

	 * will experience a huge non linear increment in the systime value

	 * to fix that we test for overflow and if true, we re-read systime.

 Is systimel is so large that overflow is possible? */

			/* There was an overflow, read again SYSTIMH, and use

			 * systimel_2

/**

 * e1000e_cyclecounter_read - read raw cycle counter (used by time counter)

 * @cc: cyclecounter structure

/**

 * e1000_sw_init - Initialize general software structures (struct e1000_adapter)

 * @adapter: board private structure to initialize

 *

 * e1000_sw_init initializes the Adapter private data structure.

 * Fields are initialized based on PCI device information and

 * OS network device settings (MTU size).

 Setup hardware time stamping cyclecounter */

 cc.shift set in e1000e_get_base_tininca() */

 Explicitly disable IRQ since the NIC can be in any state. */

/**

 * e1000_intr_msi_test - Interrupt Handler

 * @irq: interrupt number

 * @data: pointer to a network interface device structure

		/* Force memory writes to complete before acknowledging the

		 * interrupt is handled.

/**

 * e1000_test_msi_interrupt - Returns 0 for successful test

 * @adapter: board private struct

 *

 * code flow taken from tg3.c

 poll_enable hasn't been called yet, so don't need disable */

 clear any pending events */

 free the real vector and request a test handler */

	/* Assume that the test fails, if it succeeds then the test

	 * MSI irq handler will unset this flag

	/* Force memory writes to complete before enabling and firing an

	 * interrupt.

 fire an unusual interrupt on the test handler */

 read flags after interrupt has been fired */

/**

 * e1000_test_msi - Returns 0 if MSI test succeeds or INTx mode is restored

 * @adapter: board private struct

 *

 * code flow taken from tg3.c, called with e1000 interrupts disabled.

 disable SERR in case the MSI write causes a master abort */

 re-enable SERR */

/**

 * e1000e_open - Called when a network interface is made active

 * @netdev: network interface device structure

 *

 * Returns 0 on success, negative value on failure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP).  At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the watchdog timer is started,

 * and the stack is notified that the interface is ready.

 disallow open during test */

 allocate transmit descriptors */

 allocate receive descriptors */

	/* If AMT is enabled, let the firmware know that the network

	 * interface is now open and reset the part to a known state.

 DMA latency requirement to workaround jumbo issue */

	/* before we allocate an interrupt, we must be ready to handle it.

	 * Setting DEBUG_SHIRQ in the kernel makes it fire an interrupt

	 * as soon as we call pci_request_irq, so we have to setup our

	 * clean_rx handler before we do so.

	/* Work around PCIe errata with MSI interrupts causing some chipsets to

	 * ignore e1000e MSI messages, which means we need to test our MSI

	 * interrupt now

 From here on the code is the same as e1000e_up() */

/**

 * e1000e_close - Disables a network interface

 * @netdev: network interface device structure

 *

 * Returns 0, this is not allowed to fail

 *

 * The close entry point is called when an interface is de-activated

 * by the OS.  The hardware is still under the drivers control, but

 * needs to be disabled.  A global MAC reset is issued to stop the

 * hardware, and all transmit and receive resources are freed.

 Link status message must follow this format */

	/* kill manageability vlan ID if supported, but not if a vlan with

	 * the same ID is registered on the host OS (let 8021q kill it)

	/* If AMT is enabled, let the firmware know that the network

	 * interface is now closed

/**

 * e1000_set_mac - Change the Ethernet Address of the NIC

 * @netdev: network interface device structure

 * @p: pointer to an address structure

 *

 * Returns 0 on success, negative on failure

 activate the work around */

		/* Hold a copy of the LAA in RAR[14] This is done so that

		 * between the time RAR[0] gets clobbered  and the time it

		 * gets fixed (in e1000_watchdog), the actual LAA is in one

		 * of the RARs and no incoming packets directed to this port

		 * are dropped. Eventually the LAA will be in RAR[0] and

		 * RAR[14]

/**

 * e1000e_update_phy_task - work thread to update phy

 * @work: pointer to our work struct

 *

 * this worker thread exists because we must acquire a

 * semaphore to read the phy, which we could msleep while

 * waiting for it, and we can't msleep in a timer.

 Enable EEE on 82579 after link up */

/**

 * e1000_update_phy_info - timre call-back to update PHY info

 * @t: pointer to timer_list containing private info adapter

 *

 * Need to wait a few seconds after link up to get diagnostic information from

 * the phy

/**

 * e1000e_update_phy_stats - Update the PHY statistics counters

 * @adapter: board private structure

 *

 * Read/clear the upper 16-bit PHY registers and read/accumulate lower

	/* A page set is expensive so check if already on desired page.

	 * If not, set to the page with the PHY status registers.

 Single Collision Count */

 Excessive Collision Count */

 Multiple Collision Count */

 Late Collision Count */

 Collision Count - also used for adaptive IFS */

 Defer Count */

 Transmit with no CRS */

/**

 * e1000e_update_stats - Update the board statistics counters

 * @adapter: board private structure

	/* Prevent stats update while adapter is being reset, or if the pci

	 * connection is down.

 Clear gorc */

 Half-duplex statistics */

 Clear gotc */

 used for adaptive IFS */

 Fill out the OS statistics structure */

 Rx Errors */

	/* RLEC on some newer hardware can be incorrect so build

	 * our own version based on RUC and ROC

 Tx Errors */

 Tx Dropped needs to be maintained elsewhere */

 Management Stats */

 Correctable ECC Errors */

/**

 * e1000_phy_read_status - Update the PHY register status snapshot

 * @adapter: board private structure

		/* Do not read PHY registers if link is not up

		 * Set values to typical power-on defaults

 Link status message must follow this format for user tools */

	/* get_link_status is set on LSC (link status) interrupt or

	 * Rx sequence error interrupt.  get_link_status will stay

	 * true until the check_for_link establishes link

	 * for copper adapters ONLY

 See e1000_kmrn_lock_loss_workaround_ich8lan() */

 make sure the receive unit is started */

	/* With 82574 controllers, PHY needs to be checked periodically

	 * for hung state and reset, if two calls return true

/**

 * e1000_watchdog - Timer Call-back

 * @t: pointer to timer_list containing private info adapter

 Do the rest outside of interrupt context */

 TODO: make this use queue_delayed_work() */

 Cancel scheduled suspend requests. */

 Cancel scheduled suspend requests. */

 Checking if MAC is in DMoff state*/

 Checking if MAC exited DMoff state */

 update snapshot of PHY registers on LSC */

 check if SmartSpeed worked */

			/* On supported PHYs, check for duplex mismatch only

			 * if link has autonegotiated at 10/100 half

 adjust timeout factor according to speed/duplex */

			/* workaround: re-program speed mode bit after

			 * link-up event

			/* disable TSO for pcie and 10/100 speeds, to avoid

			 * some hardware issues

 oops */

			/* enable transmits in the hardware, need to do this

			 * after setting TARC(0)

			/* Perform any post-link-up configuration before

			 * reporting link up.

 Link status message must follow this format */

			/* 8000ES2LAN requires a Rx packet buffer work-around

			 * on link down event; reset the controller to flush

			 * the Rx packet buffer.

	/* If the link is lost the controller stops DMA, but

	 * if there is queued Tx work it cannot be done.  So

	 * reset the controller to flush the Tx packet buffers.

 If reset is necessary, do it outside of interrupt context. */

 return immediately since reset is imminent */

 Simple mode for Interrupt Throttle Rate (ITR) */

		/* Symmetric Tx/Rx gets a reduced ITR=2000;

		 * Total asymmetrical Tx or Rx gets ITR=8000;

		 * everyone else is between 2000-8000.

 Cause software interrupt to ensure Rx ring is cleaned */

 flush pending descriptors to memory before detecting Tx hang */

 Force detection of hung controller every watchdog period */

	/* With 82571 controllers, LAA may be overwritten due to controller

	 * reset from the other port. Set the appropriate LAA in RAR[0]

 Clear valid timestamp stuck in RXSTMPL/H due to a Rx error */

 Reset the timer */

 XXX not handling all IPV6 headers */

 multiply data chunks by size of headers */

 txd_cmd re-enables FCS, so we'll re-disable it here as desired. */

	/* Force memory writes to complete before letting h/w

	 * know there are new descriptors to fetch.  (Only

	 * applicable for weak-ordered memory model archs,

	 * such as IA-64).

	/* Herbert's original patch had:

	 *  smp_mb__after_netif_stop_queue();

	 * but since that doesn't exist yet, just open code it.

	/* We need to check again in a case another CPU has just

	 * made room available.

 A reprieve! */

	/* The minimum packet size with TCTL.PSP set is 17 bytes so

	 * pad skb in order to meet this minimum size requirement

		/* TSO Workaround for 82571/2/3 Controllers -- if skb->data

		 * points to just header, pull a few bytes of payload from

		 * frags into skb->data

		/* we do this workaround for ES2LAN, but it is un-necessary,

		 * avoiding it could save a lot of cycles

 reserve a descriptor for the offload context */

	/* need: count + 2 desc gap to keep tail from touching

	 * head, otherwise try next time

	/* Old method was to assume IPv4 packet by default if TSO was enabled.

	 * 82571 hardware supports TSO capabilities for IPv6 as well...

	 * no longer assume, we must.

 if count is 0 then mapping error has occurred */

 Make sure there is space in the ring for the next send. */

/**

 * e1000_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: index of the hung queue (unused)

 Do the reset outside of interrupt context */

 don't run the task if already down */

/**

 * e1000e_get_stats64 - Get System Network Statistics

 * @netdev: network interface device structure

 * @stats: rtnl_link_stats64 pointer

 *

 * Returns the address of the device statistics structure.

 Fill out the OS statistics structure */

 Rx Errors */

	/* RLEC on some newer hardware can be incorrect so build

	 * our own version based on RUC and ROC

 Tx Errors */

 Tx Dropped needs to be maintained elsewhere */

/**

 * e1000_change_mtu - Change the Maximum Transfer Unit

 * @netdev: network interface device structure

 * @new_mtu: new value for maximum frame size

 *

 * Returns 0 on success, negative on failure

 Jumbo frame support */

 Jumbo frame workaround on 82579 and newer requires CRC be stripped */

 e1000e_down -> e1000e_reset dependent on max_frame_size & mtu */

	/* NOTE: netdev_alloc_skb reserves 16 bytes, and typically NET_IP_ALIGN

	 * means we reserve 2 more, this pushes us to allocate from the next

	 * larger slab size.

	 * i.e. RXBUFFER_2048 --> size-4096 slab

	 * However with the new *_jumbo_rx* routines, jumbo receives will use

	 * fragmented skbs

 adjust allocation if LPE protects us, and we aren't using SBP */

/**

 * e1000e_hwtstamp_set - control hardware time stamping

 * @netdev: network interface device structure

 * @ifr: interface request

 *

 * Outgoing time stamping can be enabled and disabled. Play nice and

 * disable it when requested, although it shouldn't cause any overhead

 * when no packet needs it. At most one packet in the queue may be

 * marked for time stamping, otherwise it would be impossible to tell

 * for sure to which packet the hardware time stamp belongs.

 *

 * Incoming time stamping has to be configured via the hardware filters.

 * Not all combinations are supported, in particular event type has to be

 * specified. Matching the kind of event packet is not supported, with the

 * exception of "all V2 events regardless of level 2 or 4".

		/* With V2 type filters which specify a Sync or Delay Request,

		 * Path Delay Request/Response messages are also time stamped

		 * by hardware so notify the caller the requested packets plus

		 * some others are time stamped.

 copy MAC RARs to PHY RARs */

 Enable access to wakeup registers on and set page to BM_WUC_PAGE */

 copy MAC MTA to PHY MTA - only needed for pchlan */

 configure PHY Rx Control register */

 enable PHY wakeup in MAC register */

 configure and enable PHY wakeup in PHY registers */

 activate PHY wakeup */

 S0ix implementation */

 Request ME configure the device for S0ix */

 Request driver configure the device to S0ix */

		/* Disable the periodic inband message,

		 * don't request PCIe clock in K1 page770_17[10:9] = 10b

		/* Make sure we don't exit K1 every time a new packet arrives

		 * 772_29[5] = 1 CS_Mode_Stay_In_K1

		/* Change the MAC/PHY interface to SMBus

		 * Force the SMBus in PHY page769_23[0] = 1

		 * Force the SMBus in MAC CTRL_EXT[11] = 1

		/* DFT control: PHY bit: page769_20[0] = 1

		 * page769_20[7] - PHY PLL stop

		 * page769_20[8] - PHY go to the electrical idle

		 * page769_20[9] - PHY serdes disable

		 * Gate PPW via EXTCNF_CTRL - set 0x0F00[7] = 1

 Enable the Dynamic Power Gating in the MAC */

 Disable disconnected cable conditioning for Power Gating */

 Don't wake from dynamic Power Gating with clock request */

 Ungate PGCB clock */

 Enable K1 off to enable mPHY Power Gating */

 Enable mPHY power gating for any link and speed */

 Enable the Dynamic Clock Gating in the DMA and MAC */

		/* No MAC DPG gating SLP_S0 in modern standby

		 * Switch the logic of the lanphypc to use PMC counter

 Disable the time synchronization clock */

 Dynamic Power Gating Enable */

	/* Check MAC Tx/Rx packet buffer pointers.

	 * Reset MAC Tx/Rx packet buffer pointers to suppress any

	 * pending traffic indication that would prevent power gating.

 Request ME unconfigure the device from S0ix */

		/* Poll up to 2.5 seconds for ME to unconfigure DPG.

		 * If this takes more than 1 second, show a warning indicating a

		 * firmware bug

 Request driver unconfigure the device from S0ix */

 Disable the Dynamic Power Gating in the MAC */

 Disable mPHY power gating for any link and speed */

 Disable K1 off */

 Disable Ungate PGCB clock */

		/* Cancel not waking from dynamic

		 * Power Gating with clock request

		/* Cancel disable disconnected cable conditioning

		 * for Power Gating

 Disable the Dynamic Clock Gating in the DMA and MAC */

		/* Revert the lanphypc logic to use the internal Gbe counter

		 * and not the PMC counter

		/* Enable the periodic inband message,

		 * Request PCIe clock in K1 page770_17[10:9] =01b

		/* Return back configuration

		 * 772_29[5] = 0 CS_Mode_Stay_In_K1

		/* Change the MAC/PHY interface to Kumeran

		 * Unforce the SMBus in PHY page769_23[0] = 0

		 * Unforce the SMBus in MAC CTRL_EXT[11] = 0

 Disable Dynamic Power Gating */

 Enable the time synchronization clock */

 Quiesce the device without resetting the hardware */

 Allow time for pending master requests to run */

 Runtime suspend should only enable wakeup for link changes */

 turn on all-multi mode if wake on multicast is enabled */

 keep the laser running in D3 */

 enable wakeup by the PHY */

 enable wakeup by the MAC */

			/* ULP does not support wake from unicast, multicast

			 * or broadcast.

	/* Ensure that the appropriate bits are set in LPI_CTRL

	 * for EEE in Sx

	/* Release control of h/w to f/w.  If f/w is AMT enabled, this

	 * would have already happened in close and is redundant.

	/* The pci-e switch on some quad port adapters will report a

	 * correctable error when the MAC transitions from D0 to D3.  To

	 * prevent this we need to mask off the correctable errors on the

	 * downstream port of the pci-e switch.

	 *

	 * We don't have the associated upstream bridge while assigning

	 * the PCI device into guest. For example, the KVM on power is

	 * one of the cases.

/**

 * __e1000e_disable_aspm - Disable ASPM states

 * @pdev: pointer to PCI device struct

 * @state: bit-mask of ASPM states to disable

 * @locked: indication if this context holds pci_bus_sem locked.

 *

 * Some devices *must* have certain ASPM states disabled per hardware errata.

 can't have L1 without L0s */

 Nothing to do if the ASPM states to be disabled already are */

	/* Double-check ASPM control.  If not disabled by the above, the

	 * BIOS is preventing that from happening (or CONFIG_PCIEASPM is

	 * not enabled); override by writing PCI config space directly.

	/* Both device and parent should have the same ASPM setting.

	 * Disable ASPM in downstream component first and then upstream.

/**

 * e1000e_disable_aspm - Disable ASPM states.

 * @pdev: pointer to PCI device struct

 * @state: bit-mask of ASPM states to disable

 *

 * This function acquires the pci_bus_sem!

 * Some devices *must* have certain ASPM states disabled per hardware errata.

/**

 * e1000e_disable_aspm_locked - Disable ASPM states.

 * @pdev: pointer to PCI device struct

 * @state: bit-mask of ASPM states to disable

 *

 * This function must be called with pci_bus_sem acquired!

 * Some devices *must* have certain ASPM states disabled per hardware errata.

 report the system wakeup cause from S3/S4 */

	/* If the controller has AMT, do not set DRV_LOAD until the interface

	 * is up.  For all other cases, let the f/w know that the h/w is now

	 * under the control of the driver.

 Introduce S0ix implementation */

 Introduce S0ix implementation */

 Down the device without resetting the hardware */

/**

 * e1000_netpoll

 * @netdev: network interface device structure

 *

 * Polling 'interrupt' - used by things like netconsole to send skbs

 * without having to re-enable interrupts. It's not called while

 * the interrupt routine is executing.

 E1000E_INT_MODE_LEGACY */

/**

 * e1000_io_error_detected - called when PCI error is detected

 * @pdev: Pointer to PCI device

 * @state: The current pci connection state

 *

 * This function is called after a PCI bus error affecting

 * this device has been detected.

 Request a slot reset. */

/**

 * e1000_io_slot_reset - called after the pci bus has been reset.

 * @pdev: Pointer to PCI device

 *

 * Restart the card from scratch, as if from a cold-boot. Implementation

 * resembles the first-half of the e1000e_pm_resume routine.

/**

 * e1000_io_resume - called when traffic can start flowing again.

 * @pdev: Pointer to PCI device

 *

 * This callback is called when the error recovery driver tells us that

 * its OK to resume normal operation. Implementation resembles the

 * second-half of the e1000e_pm_resume routine.

	/* If the controller has AMT, do not set DRV_LOAD until the interface

	 * is up.  For all other cases, let the f/w know that the h/w is now

	 * under the control of the driver.

 print bus type/speed/width info */

 bus width */

 MAC address */

 Deep Smart Power Down (DSPD) */

 Jumbo frame workaround on 82579 and newer requires CRC be stripped */

	/* Since there is no support for separate Rx/Tx vlan accel

	 * enable/disable make sure Tx flag is always in same state as Rx.

			/* We need to take it back to defaults, which might mean

			 * stripping is still disabled at the adapter level.

/**

 * e1000_probe - Device Initialization Routine

 * @pdev: PCI device information struct

 * @ent: entry in e1000_pci_tbl

 *

 * Returns 0 on success, negative on failure

 *

 * e1000_probe initializes an adapter identified by a pci_dev structure.

 * The OS initialization, configuring of the adapter private structure,

 * and a hardware reset occur.

 AER (Advanced Error Reporting) hooks */

 PCI config space info */

 Set default EEE advertisement */

 construct the net_device struct */

 setup adapter struct */

 Copper options */

 Set initial default active device features */

 Set user-changeable features (subset of all device features) */

 MTU range: 68 - max_hw_frame_size */

	/* before reading the NVM, reset the controller to

	 * put the device in a known good starting state

	/* systems with ASPM and others may see the checksum fail on the first

	 * attempt. Let's give it a few tries

 copy the MAC address */

 Initialize link parameters. User can change them with ethtool */

	/* Initial Wake on LAN setting - If APM wake is enabled in

	 * the EEPROM, enable the ACPI Magic Packet filter

 APME bit in EEPROM is mapped to WUC.APME */

 fetch WoL from EEPROM */

	/* now that we have the eeprom settings, apply the special cases

	 * where the eeprom may be wrong or the board simply won't support

	 * wake on lan on a particular port

 initialize the wol settings based on the eeprom settings */

 make sure adapter isn't asleep if manageability is enabled */

 save off EEPROM version number */

 init PTP hardware clock */

 reset the hardware with the new settings */

	/* If the controller has AMT, do not set DRV_LOAD until the interface

	 * is up.  For all other cases, let the f/w know that the h/w is now

	 * under the control of the driver.

 carrier off reporting is important to ethtool even BEFORE open */

/**

 * e1000_remove - Device Removal Routine

 * @pdev: PCI device information struct

 *

 * e1000_remove is called by the PCI subsystem to alert the driver

 * that it should release a PCI device.  This could be caused by a

 * Hot-Plug event, or because the driver is going to be removed from

 * memory.

	/* The timers may be rescheduled, so explicitly disable them

	 * from being rescheduled.

	/* Release control of h/w to f/w.  If f/w is AMT enabled, this

	 * would have already happened in close and is redundant.

 AER disable */

 PCI Error Recovery (ERS) */

 terminate list */

 PCI Device API Driver */

/**

 * e1000_init_module - Driver Registration Routine

 *

 * e1000_init_module is the first routine called when the driver is

 * loaded. All it does is register with the PCI subsystem.

/**

 * e1000_exit_module - Driver Exit Cleanup Routine

 *

 * e1000_exit_module is called just before the driver is removed

 * from memory.

 netdev.c */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

/**

 *  e1000_calculate_checksum - Calculate checksum for buffer

 *  @buffer: pointer to EEPROM

 *  @length: size of EEPROM to calculate a checksum for

 *

 *  Calculates the checksum for some buffer on a specified length.  The

 *  checksum calculated is returned.

/**

 *  e1000_mng_enable_host_if - Checks host interface is enabled

 *  @hw: pointer to the HW structure

 *

 *  Returns 0 upon success, else -E1000_ERR_HOST_INTERFACE_COMMAND

 *

 *  This function checks whether the HOST IF is enabled for command operation

 *  and also checks whether the previous command is completed.  It busy waits

 *  in case of previous command is not completed.

 Check that the host interface is enabled. */

 check the previous command is completed */

/**

 *  e1000e_check_mng_mode_generic - Generic check management mode

 *  @hw: pointer to the HW structure

 *

 *  Reads the firmware semaphore register and returns true (>0) if

 *  manageability is enabled, else false (0).

/**

 *  e1000e_enable_tx_pkt_filtering - Enable packet filtering on Tx

 *  @hw: pointer to the HW structure

 *

 *  Enables packet filtering on transmit packets if manageability is enabled

 *  and host interface is enabled.

 No manageability, no filtering */

	/* If we can't read from the host interface for whatever

	 * reason, disable filtering.

 Read in the header.  Length and offset are in dwords. */

	/* If either the checksums or signature don't match, then

	 * the cookie area isn't considered valid, in which case we

	 * take the safe route of assuming Tx filtering is enabled.

 Cookie area is valid, make the final check for filtering. */

/**

 *  e1000_mng_write_cmd_header - Writes manageability command header

 *  @hw: pointer to the HW structure

 *  @hdr: pointer to the host interface command header

 *

 *  Writes the command header after does the checksum calculation.

 Write the whole command header structure with new checksum. */

 Write the relevant command block into the ram area. */

/**

 *  e1000_mng_host_if_write - Write to the manageability host interface

 *  @hw: pointer to the HW structure

 *  @buffer: pointer to the host interface buffer

 *  @length: size of the buffer

 *  @offset: location in the buffer to write to

 *  @sum: sum of the data (not checksum)

 *

 *  This function writes the buffer content at the offset given on the host if.

 *  It also does alignment considerations to do the writes in most efficient

 *  way.  Also fills up the sum of the buffer in *buffer parameter.

 sum = only sum of the data and it is not checksum */

 Calculate length in DWORDs */

	/* The device driver writes the relevant command block into the

	 * ram area.

/**

 *  e1000e_mng_write_dhcp_info - Writes DHCP info to host interface

 *  @hw: pointer to the HW structure

 *  @buffer: pointer to the host interface

 *  @length: size of the buffer

 *

 *  Writes the DHCP information to the host interface.

 Enable the host interface */

 Populate the host interface with the contents of "buffer". */

 Write the manageability command header */

 Tell the ARC a new command is pending. */

/**

 *  e1000e_enable_mng_pass_thru - Check if management passthrough is needed

 *  @hw: pointer to the HW structure

 *

 *  Verifies the hardware needs to leave interface enabled so that frames can

 *  be directed to and from the management interface.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2018 Intel Corporation. */

 Cable length tables */

/**

 *  e1000e_check_reset_block_generic - Check if PHY reset is blocked

 *  @hw: pointer to the HW structure

 *

 *  Read the PHY management control register and check whether a PHY reset

 *  is blocked.  If a reset is not blocked return 0, otherwise

 *  return E1000_BLK_PHY_RESET (12).

/**

 *  e1000e_get_phy_id - Retrieve the PHY ID and revision

 *  @hw: pointer to the HW structure

 *

 *  Reads the PHY registers and stores the PHY ID and possibly the PHY

 *  revision in the hardware structure.

/**

 *  e1000e_phy_reset_dsp - Reset PHY DSP

 *  @hw: pointer to the HW structure

 *

 *  Reset the digital signal processor.

/**

 *  e1000e_read_phy_reg_mdic - Read MDI control register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Reads the MDI control register in the PHY at offset and stores the

 *  information read to data.

	/* Set up Op-code, Phy Address, and register offset in the MDI

	 * Control register.  The MAC will take care of interfacing with the

	 * PHY to retrieve the desired data.

	/* Poll the ready bit to see if the MDI read completed

	 * Increasing the time out as testing showed failures with

	 * the lower time out

	/* Allow some time after each MDIC transaction to avoid

	 * reading duplicate data in the next MDIC transaction.

/**

 *  e1000e_write_phy_reg_mdic - Write MDI control register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write to register at offset

 *

 *  Writes data to MDI control register in the PHY at offset.

	/* Set up Op-code, Phy Address, and register offset in the MDI

	 * Control register.  The MAC will take care of interfacing with the

	 * PHY to retrieve the desired data.

	/* Poll the ready bit to see if the MDI read completed

	 * Increasing the time out as testing showed failures with

	 * the lower time out

	/* Allow some time after each MDIC transaction to avoid

	 * reading duplicate data in the next MDIC transaction.

/**

 *  e1000e_read_phy_reg_m88 - Read m88 PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Acquires semaphore, if necessary, then reads the PHY register at offset

 *  and storing the retrieved information in data.  Release any acquired

 *  semaphores before exiting.

/**

 *  e1000e_write_phy_reg_m88 - Write m88 PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Acquires semaphore, if necessary, then writes the data to PHY register

 *  at the offset.  Release any acquired semaphores before exiting.

/**

 *  e1000_set_page_igp - Set page as on IGP-like PHY(s)

 *  @hw: pointer to the HW structure

 *  @page: page to set (shifted left when necessary)

 *

 *  Sets PHY page required for PHY register access.  Assumes semaphore is

 *  already acquired.  Note, this function sets phy.addr to 1 so the caller

 *  must set it appropriately (if necessary) after this function returns.

/**

 *  __e1000e_read_phy_reg_igp - Read igp PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *  @locked: semaphore has already been acquired or not

 *

 *  Acquires semaphore, if necessary, then reads the PHY register at offset

 *  and stores the retrieved information in data.  Release any acquired

 *  semaphores before exiting.

/**

 *  e1000e_read_phy_reg_igp - Read igp PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Acquires semaphore then reads the PHY register at offset and stores the

 *  retrieved information in data.

 *  Release the acquired semaphore before exiting.

/**

 *  e1000e_read_phy_reg_igp_locked - Read igp PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Reads the PHY register at offset and stores the retrieved information

 *  in data.  Assumes semaphore already acquired.

/**

 *  __e1000e_write_phy_reg_igp - Write igp PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *  @locked: semaphore has already been acquired or not

 *

 *  Acquires semaphore, if necessary, then writes the data to PHY register

 *  at the offset.  Release any acquired semaphores before exiting.

/**

 *  e1000e_write_phy_reg_igp - Write igp PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Acquires semaphore then writes the data to PHY register

 *  at the offset.  Release any acquired semaphores before exiting.

/**

 *  e1000e_write_phy_reg_igp_locked - Write igp PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Writes the data to PHY register at the offset.

 *  Assumes semaphore already acquired.

/**

 *  __e1000_read_kmrn_reg - Read kumeran register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *  @locked: semaphore has already been acquired or not

 *

 *  Acquires semaphore, if necessary.  Then reads the PHY register at offset

 *  using the kumeran interface.  The information retrieved is stored in data.

 *  Release any acquired semaphores before exiting.

/**

 *  e1000e_read_kmrn_reg -  Read kumeran register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Acquires semaphore then reads the PHY register at offset using the

 *  kumeran interface.  The information retrieved is stored in data.

 *  Release the acquired semaphore before exiting.

/**

 *  e1000e_read_kmrn_reg_locked -  Read kumeran register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Reads the PHY register at offset using the kumeran interface.  The

 *  information retrieved is stored in data.

 *  Assumes semaphore already acquired.

/**

 *  __e1000_write_kmrn_reg - Write kumeran register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *  @locked: semaphore has already been acquired or not

 *

 *  Acquires semaphore, if necessary.  Then write the data to PHY register

 *  at the offset using the kumeran interface.  Release any acquired semaphores

 *  before exiting.

/**

 *  e1000e_write_kmrn_reg -  Write kumeran register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Acquires semaphore then writes the data to the PHY register at the offset

 *  using the kumeran interface.  Release the acquired semaphore before exiting.

/**

 *  e1000e_write_kmrn_reg_locked -  Write kumeran register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Write the data to PHY register at the offset using the kumeran interface.

 *  Assumes semaphore already acquired.

/**

 *  e1000_set_master_slave_mode - Setup PHY for Master/slave mode

 *  @hw: pointer to the HW structure

 *

 *  Sets up Master/slave mode

 Resolve Master/Slave mode */

 load defaults for future use */

/**

 *  e1000_copper_link_setup_82577 - Setup 82577 PHY for copper link

 *  @hw: pointer to the HW structure

 *

 *  Sets up Carrier-sense on Transmit and downshift values.

 Enable CRS on Tx. This must be set for half-duplex operation. */

 Enable downshift */

 Set MDI/MDIX mode */

	/* Options:

	 *   0 - Auto (default)

	 *   1 - MDI mode

	 *   2 - MDI-X mode

/**

 *  e1000e_copper_link_setup_m88 - Setup m88 PHY's for copper link

 *  @hw: pointer to the HW structure

 *

 *  Sets up MDI/MDI-X and polarity for m88 PHY's.  If necessary, transmit clock

 *  and downshift values are set also.

 Enable CRS on Tx. This must be set for half-duplex operation. */

 For BM PHY this bit is downshift enable */

	/* Options:

	 *   MDI/MDI-X = 0 (default)

	 *   0 - Auto for all speeds

	 *   1 - MDI mode

	 *   2 - MDI-X mode

	 *   3 - Auto for 1000Base-T only (MDI-X for 10/100Base-T modes)

	/* Options:

	 *   disable_polarity_correction = 0 (default)

	 *       Automatic Correction for Reversed Cable Polarity

	 *   0 - Disabled

	 *   1 - Enabled

 Enable downshift on BM (disabled by default) */

 For 82574/82583, first disable then enable downshift */

 Commit the changes. */

		/* Force TX_CLK in the Extended PHY Specific Control Register

		 * to 25MHz clock.

 82573L PHY - set the downshift counter to 5x. */

 Configure Master and Slave downshift values */

 Set PHY page 0, register 29 to 0x0003 */

 Set PHY page 0, register 30 to 0x0000 */

 Commit the changes. */

 82578 PHY - set the downshift count to 1x. */

/**

 *  e1000e_copper_link_setup_igp - Setup igp PHY's for copper link

 *  @hw: pointer to the HW structure

 *

 *  Sets up LPLU, MDI/MDI-X, polarity, Smartspeed and Master/Slave config for

 *  igp PHY's.

	/* Wait 100ms for MAC to configure PHY from NVM settings, to avoid

	 * timeout issues when LFS is enabled.

 disable lplu d0 during driver init */

 Configure mdi-mdix settings */

 set auto-master slave resolution settings */

		/* when autonegotiation advertisement is only 1000Mbps then we

		 * should disable SmartSpeed and enable Auto MasterSlave

		 * resolution as hardware default.

 Disable SmartSpeed */

 Set auto Master/Slave resolution process */

/**

 *  e1000_phy_setup_autoneg - Configure PHY for auto-negotiation

 *  @hw: pointer to the HW structure

 *

 *  Reads the MII auto-neg advertisement register and/or the 1000T control

 *  register and if the PHY is already setup for auto-negotiation, then

 *  return successful.  Otherwise, setup advertisement and flow control to

 *  the appropriate values for the wanted auto-negotiation.

 Read the MII Auto-Neg Advertisement Register (Address 4). */

 Read the MII 1000Base-T Control Register (Address 9). */

	/* Need to parse both autoneg_advertised and fc and set up

	 * the appropriate PHY registers.  First we will parse for

	 * autoneg_advertised software override.  Since we can advertise

	 * a plethora of combinations, we need to check each bit

	 * individually.

	/* First we clear all the 10/100 mb speed bits in the Auto-Neg

	 * Advertisement Register (Address 4) and the 1000 mb speed bits in

	 * the  1000Base-T Control Register (Address 9).

 Do we want to advertise 10 Mb Half Duplex? */

 Do we want to advertise 10 Mb Full Duplex? */

 Do we want to advertise 100 Mb Half Duplex? */

 Do we want to advertise 100 Mb Full Duplex? */

 We do not allow the Phy to advertise 1000 Mb Half Duplex */

 Do we want to advertise 1000 Mb Full Duplex? */

	/* Check for a software override of the flow control settings, and

	 * setup the PHY advertisement registers accordingly.  If

	 * auto-negotiation is enabled, then software will have to set the

	 * "PAUSE" bits to the correct value in the Auto-Negotiation

	 * Advertisement Register (MII_ADVERTISE) and re-start auto-

	 * negotiation.

	 *

	 * The possible values of the "fc" parameter are:

	 *      0:  Flow control is completely disabled

	 *      1:  Rx flow control is enabled (we can receive pause frames

	 *          but not send pause frames).

	 *      2:  Tx flow control is enabled (we can send pause frames

	 *          but we do not support receiving pause frames).

	 *      3:  Both Rx and Tx flow control (symmetric) are enabled.

	 *  other:  No software override.  The flow control configuration

	 *          in the EEPROM is used.

		/* Flow control (Rx & Tx) is completely disabled by a

		 * software over-ride.

		/* Rx Flow control is enabled, and Tx Flow control is

		 * disabled, by a software over-ride.

		 *

		 * Since there really isn't a way to advertise that we are

		 * capable of Rx Pause ONLY, we will advertise that we

		 * support both symmetric and asymmetric Rx PAUSE.  Later

		 * (in e1000e_config_fc_after_link_up) we will disable the

		 * hw's ability to send PAUSE frames.

		/* Tx Flow control is enabled, and Rx Flow control is

		 * disabled, by a software over-ride.

		/* Flow control (both Rx and Tx) is enabled by a software

		 * over-ride.

/**

 *  e1000_copper_link_autoneg - Setup/Enable autoneg for copper link

 *  @hw: pointer to the HW structure

 *

 *  Performs initial bounds checking on autoneg advertisement parameter, then

 *  configure to advertise the full capability.  Setup the PHY to autoneg

 *  and restart the negotiation process between the link partner.  If

 *  autoneg_wait_to_complete, then wait for autoneg to complete before exiting.

	/* Perform some bounds checking on the autoneg advertisement

	 * parameter.

	/* If autoneg_advertised is zero, we assume it was not defaulted

	 * by the calling code so we set to advertise full capability.

	/* Restart auto-negotiation by setting the Auto Neg Enable bit and

	 * the Auto Neg Restart bit in the PHY control register.

	/* Does the user want to wait for Auto-Neg to complete here, or

	 * check at a later time (for example, callback routine).

/**

 *  e1000e_setup_copper_link - Configure copper link settings

 *  @hw: pointer to the HW structure

 *

 *  Calls the appropriate function to configure the link for auto-neg or forced

 *  speed and duplex.  Then we check for link, once link is established calls

 *  to configure collision distance and flow control are called.  If link is

 *  not established, we return -E1000_ERR_PHY (-2).

		/* Setup autoneg and flow control advertisement and perform

		 * autonegotiation.

		/* PHY will be set to 10H, 10F, 100H or 100F

		 * depending on user settings.

	/* Check link status. Wait up to 100 microseconds for link to become

	 * valid.

/**

 *  e1000e_phy_force_speed_duplex_igp - Force speed/duplex for igp PHY

 *  @hw: pointer to the HW structure

 *

 *  Calls the PHY setup function to force speed and duplex.  Clears the

 *  auto-crossover to force MDI manually.  Waits for link and returns

 *  successful if link up is successful, else -E1000_ERR_PHY (-2).

	/* Clear Auto-Crossover to force MDI manually.  IGP requires MDI

	 * forced whenever speed and duplex are forced.

 Try once more */

/**

 *  e1000e_phy_force_speed_duplex_m88 - Force speed/duplex for m88 PHY

 *  @hw: pointer to the HW structure

 *

 *  Calls the PHY setup function to force speed and duplex.  Clears the

 *  auto-crossover to force MDI manually.  Resets the PHY to commit the

 *  changes.  If time expires while waiting for link up, we reset the DSP.

 *  After reset, TX_CLK and CRS on Tx must be set.  Return successful upon

 *  successful completion, else return corresponding error code.

	/* Clear Auto-Crossover to force MDI manually.  M88E1000 requires MDI

	 * forced whenever speed and duplex are forced.

 Reset the phy to commit changes. */

				/* We didn't get link.

				 * Reset the DSP and cross our fingers.

 Try once more */

	/* Resetting the phy means we need to re-force TX_CLK in the

	 * Extended PHY Specific Control Register to 25MHz clock from

	 * the reset value of 2.5MHz.

	/* In addition, we must re-enable CRS on Tx for both half and full

	 * duplex.

/**

 *  e1000_phy_force_speed_duplex_ife - Force PHY speed & duplex

 *  @hw: pointer to the HW structure

 *

 *  Forces the speed and duplex settings of the PHY.

 *  This is a function pointer entry point only called by

 *  PHY setup routines.

 Disable MDI-X support for 10/100 */

 Try once more */

/**

 *  e1000e_phy_force_speed_duplex_setup - Configure forced PHY speed/duplex

 *  @hw: pointer to the HW structure

 *  @phy_ctrl: pointer to current value of MII_BMCR

 *

 *  Forces speed and duplex on the PHY by doing the following: disable flow

 *  control, force speed/duplex on the MAC, disable auto speed detection,

 *  disable auto-negotiation, configure duplex, configure speed, configure

 *  the collision distance, write configuration to CTRL register.  The

 *  caller must write to the MII_BMCR register for these settings to

 *  take affect.

 Turn off flow control when forcing speed/duplex */

 Force speed/duplex on the mac */

 Disable Auto Speed Detection */

 Disable autoneg on the phy */

 Forcing Full or Half Duplex? */

 Forcing 10mb or 100mb? */

/**

 *  e1000e_set_d3_lplu_state - Sets low power link up state for D3

 *  @hw: pointer to the HW structure

 *  @active: boolean used to enable/disable lplu

 *

 *  Success returns 0, Failure returns 1

 *

 *  The low power link up (lplu) state is set to the power management level D3

 *  and SmartSpeed is disabled when active is true, else clear lplu for D3

 *  and enable Smartspeed.  LPLU and Smartspeed are mutually exclusive.  LPLU

 *  is used during Dx states where the power conservation is most important.

 *  During driver activity, SmartSpeed should be enabled so performance is

 *  maintained.

		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used

		 * during Dx states where the power conservation is most

		 * important.  During driver activity we should enable

		 * SmartSpeed, so performance is maintained.

 When LPLU is enabled, we should disable SmartSpeed */

/**

 *  e1000e_check_downshift - Checks whether a downshift in speed occurred

 *  @hw: pointer to the HW structure

 *

 *  Success returns 0, Failure returns 1

 *

 *  A downshift is detected by querying the PHY link health.

 speed downshift not supported */

/**

 *  e1000_check_polarity_m88 - Checks the polarity.

 *  @hw: pointer to the HW structure

 *

 *  Success returns 0, Failure returns -E1000_ERR_PHY (-2)

 *

 *  Polarity is determined based on the PHY specific status register.

/**

 *  e1000_check_polarity_igp - Checks the polarity.

 *  @hw: pointer to the HW structure

 *

 *  Success returns 0, Failure returns -E1000_ERR_PHY (-2)

 *

 *  Polarity is determined based on the PHY port status register, and the

 *  current speed (since there is no polarity at 100Mbps).

	/* Polarity is determined based on the speed of

	 * our connection.

		/* This really only applies to 10Mbps since

		 * there is no polarity for 100Mbps (always 0).

/**

 *  e1000_check_polarity_ife - Check cable polarity for IFE PHY

 *  @hw: pointer to the HW structure

 *

 *  Polarity is determined on the polarity reversal feature being enabled.

	/* Polarity is determined based on the reversal feature being enabled.

/**

 *  e1000_wait_autoneg - Wait for auto-neg completion

 *  @hw: pointer to the HW structure

 *

 *  Waits for auto-negotiation to complete or for the auto-negotiation time

 *  limit to expire, which ever happens first.

 Break after autoneg completes or PHY_AUTO_NEG_LIMIT expires. */

	/* PHY_AUTO_NEG_TIME expiration doesn't guarantee auto-negotiation

	 * has completed.

/**

 *  e1000e_phy_has_link_generic - Polls PHY for link

 *  @hw: pointer to the HW structure

 *  @iterations: number of times to poll for link

 *  @usec_interval: delay between polling attempts

 *  @success: pointer to whether polling was successful or not

 *

 *  Polls the PHY status register for link, 'iterations' number of times.

		/* Some PHYs require the MII_BMSR register to be read

		 * twice due to the link bit being sticky.  No harm doing

		 * it across the board.

			/* If the first read fails, another entity may have

			 * ownership of the resources, wait and try again to

			 * see if they have relinquished the resources yet.

/**

 *  e1000e_get_cable_length_m88 - Determine cable length for m88 PHY

 *  @hw: pointer to the HW structure

 *

 *  Reads the PHY specific status register to retrieve the cable length

 *  information.  The cable length is determined by averaging the minimum and

 *  maximum values to get the "average" cable length.  The m88 PHY has four

 *  possible cable length values, which are:

 *	Register Value		Cable Length

 *	0			< 50 meters

 *	1			50 - 80 meters

 *	2			80 - 110 meters

 *	3			110 - 140 meters

 *	4			> 140 meters

/**

 *  e1000e_get_cable_length_igp_2 - Determine cable length for igp2 PHY

 *  @hw: pointer to the HW structure

 *

 *  The automatic gain control (agc) normalizes the amplitude of the

 *  received signal, adjusting for the attenuation produced by the

 *  cable.  By reading the AGC registers, which represent the

 *  combination of coarse and fine gain value, the value can be put

 *  into a lookup table to obtain the approximate cable length

 *  for each channel.

 Read the AGC registers for all channels */

		/* Getting bits 15:9, which represent the combination of

		 * coarse and fine gain values.  The result is a number

		 * that can be put into the lookup table to obtain the

		 * approximate cable length.

 Array index bound check. */

 Remove min & max AGC values from calculation. */

 Calculate cable length with the error range of +/- 10 meters. */

/**

 *  e1000e_get_phy_info_m88 - Retrieve PHY information

 *  @hw: pointer to the HW structure

 *

 *  Valid for only copper links.  Read the PHY status register (sticky read)

 *  to verify that link is up.  Read the PHY special control register to

 *  determine the polarity and 10base-T extended distance.  Read the PHY

 *  special status register to determine MDI/MDIx and current speed.  If

 *  speed is 1000, then determine cable length, local and remote receiver.

 Set values to "undefined" */

/**

 *  e1000e_get_phy_info_igp - Retrieve igp PHY information

 *  @hw: pointer to the HW structure

 *

 *  Read PHY status to determine if link is up.  If link is up, then

 *  set/determine 10base-T extended distance and polarity correction.  Read

 *  PHY port status to determine MDI/MDIx and speed.  Based on the speed,

 *  determine on the cable length, local and remote receiver.

/**

 *  e1000_get_phy_info_ife - Retrieves various IFE PHY states

 *  @hw: pointer to the HW structure

 *

 *  Populates "phy" structure with various feature states.

 Polarity is forced */

 The following parameters are undefined for 10/100 operation. */

/**

 *  e1000e_phy_sw_reset - PHY software reset

 *  @hw: pointer to the HW structure

 *

 *  Does a software reset of the PHY by reading the PHY control register and

 *  setting/write the control register reset bit to the PHY.

/**

 *  e1000e_phy_hw_reset_generic - PHY hardware reset

 *  @hw: pointer to the HW structure

 *

 *  Verify the reset block is not blocking us from resetting.  Acquire

 *  semaphore (if necessary) and read/set/write the device control reset

 *  bit in the PHY.  Wait the appropriate delay time for the device to

 *  reset and release the semaphore (if necessary).

/**

 *  e1000e_get_cfg_done_generic - Generic configuration done

 *  @hw: pointer to the HW structure

 *

 *  Generic function to wait 10 milli-seconds for configuration to complete

 *  and return success.

/**

 *  e1000e_phy_init_script_igp3 - Inits the IGP3 PHY

 *  @hw: pointer to the HW structure

 *

 *  Initializes a Intel Gigabit PHY3 when an EEPROM is not present.

 PHY init IGP 3 */

 Enable rise/fall, 10-mode work in class-A */

 Remove all caps from Replica path filter */

 Bias trimming for ADC, AFE and Driver (Default) */

 Increase Hybrid poly bias */

 Add 4% to Tx amplitude in Gig mode */

 Disable trimming (TTT) */

 Poly DC correction to 94.6% + 2% for all channels */

 ABS DC correction to 95.9% */

 BG temp curve trim */

 Increasing ADC OPAMP stage 1 currents to max */

 Force 1000 ( required for enabling PHY regs configuration) */

 Set upd_freq to 6 */

 Disable NPDFE */

 Disable adaptive fixed FFE (Default) */

 Enable FFE hysteresis */

 Fixed FFE for short cable lengths */

 Fixed FFE for medium cable lengths */

 Fixed FFE for long cable lengths */

 Enable Adaptive Clip Threshold */

 AHT reset limit to 1 */

 Set AHT master delay to 127 msec */

 Set scan bits for AHT */

 Set AHT Preset bits */

 Change integ_factor of channel A to 3 */

 Change prop_factor of channels BCD to 8 */

 Change cg_icount + enable integbp for channels BCD */

	/* Change cg_icount + enable integbp + change prop_factor_master

	 * to 8 for channel A

 Disable AHT in Slave mode on channel A */

	/* Enable LPLU and disable AN to 1000 in non-D0a states,

	 * Enable SPD+B2B

 Enable restart AN on an1000_dis change */

 Enable wh_fifo read clock in 10/100 modes */

 Restart AN, Speed selection is 1000 */

/**

 *  e1000e_get_phy_type_from_id - Get PHY type from id

 *  @phy_id: phy_id read from the phy

 *

 *  Returns the phy type from the id.

 IGP 1 & 2 share this */

/**

 *  e1000e_determine_phy_address - Determines PHY address.

 *  @hw: pointer to the HW structure

 *

 *  This uses a trial and error method to loop through possible PHY

 *  addresses. It tests each by reading the PHY ID registers and

 *  checking for a match.

			/* If phy_type is valid, break - we found our

			 * PHY address

/**

 *  e1000_get_phy_addr_for_bm_page - Retrieve PHY page address

 *  @page: page to access

 *  @reg: register to check

 *

 *  Returns the phy address for the page requested.

/**

 *  e1000e_write_phy_reg_bm - Write BM PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Acquires semaphore, if necessary, then writes the data to PHY register

 *  at the offset.  Release any acquired semaphores before exiting.

 Page 800 works differently than the rest so it has its own func */

		/* Page select is register 31 for phy address 1 and 22 for

		 * phy address 2 and 3. Page select is shifted only for

		 * phy address 1.

 Page is shifted left, PHY expects (page x 32) */

/**

 *  e1000e_read_phy_reg_bm - Read BM PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Acquires semaphore, if necessary, then reads the PHY register at offset

 *  and storing the retrieved information in data.  Release any acquired

 *  semaphores before exiting.

 Page 800 works differently than the rest so it has its own func */

		/* Page select is register 31 for phy address 1 and 22 for

		 * phy address 2 and 3. Page select is shifted only for

		 * phy address 1.

 Page is shifted left, PHY expects (page x 32) */

/**

 *  e1000e_read_phy_reg_bm2 - Read BM PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Acquires semaphore, if necessary, then reads the PHY register at offset

 *  and storing the retrieved information in data.  Release any acquired

 *  semaphores before exiting.

 Page 800 works differently than the rest so it has its own func */

 Page is shifted left, PHY expects (page x 32) */

/**

 *  e1000e_write_phy_reg_bm2 - Write BM PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Acquires semaphore, if necessary, then writes the data to PHY register

 *  at the offset.  Release any acquired semaphores before exiting.

 Page 800 works differently than the rest so it has its own func */

 Page is shifted left, PHY expects (page x 32) */

/**

 *  e1000_enable_phy_wakeup_reg_access_bm - enable access to BM wakeup registers

 *  @hw: pointer to the HW structure

 *  @phy_reg: pointer to store original contents of BM_WUC_ENABLE_REG

 *

 *  Assumes semaphore already acquired and phy_reg points to a valid memory

 *  address to store contents of the BM_WUC_ENABLE_REG register.

 All page select, port ctrl and wakeup registers use phy address 1 */

 Select Port Control Registers page */

	/* Enable both PHY wakeup mode and Wakeup register page writes.

	 * Prevent a power state change by disabling ME and Host PHY wakeup.

	/* Select Host Wakeup Registers page - caller now able to write

	 * registers on the Wakeup registers page

/**

 *  e1000_disable_phy_wakeup_reg_access_bm - disable access to BM wakeup regs

 *  @hw: pointer to the HW structure

 *  @phy_reg: pointer to original contents of BM_WUC_ENABLE_REG

 *

 *  Restore BM_WUC_ENABLE_REG to its original value.

 *

 *  Assumes semaphore already acquired and *phy_reg is the contents of the

 *  BM_WUC_ENABLE_REG before register(s) on BM_WUC_PAGE were accessed by

 *  caller.

 Select Port Control Registers page */

 Restore 769.17 to its original value */

/**

 *  e1000_access_phy_wakeup_reg_bm - Read/write BM PHY wakeup register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read or written

 *  @data: pointer to the data to read or write

 *  @read: determines if operation is read or write

 *  @page_set: BM_WUC_PAGE already set and access enabled

 *

 *  Read the PHY register at offset and store the retrieved information in

 *  data, or write data to PHY register at offset.  Note the procedure to

 *  access the PHY wakeup registers is different than reading the other PHY

 *  registers. It works as such:

 *  1) Set 769.17.2 (page 769, register 17, bit 2) = 1

 *  2) Set page to 800 for host (801 if we were manageability)

 *  3) Write the address using the address opcode (0x11)

 *  4) Read or write the data using the data opcode (0x12)

 *  5) Restore 769.17.2 to its original value

 *

 *  Steps 1 and 2 are done by e1000_enable_phy_wakeup_reg_access_bm() and

 *  step 5 is done by e1000_disable_phy_wakeup_reg_access_bm().

 *

 *  Assumes semaphore is already acquired.  When page_set==true, assumes

 *  the PHY page is set to BM_WUC_PAGE (i.e. a function in the call stack

 *  is responsible for calls to e1000_[enable|disable]_phy_wakeup_reg_bm()).

 Gig must be disabled for MDIO accesses to Host Wakeup reg page */

 Enable access to PHY wakeup registers */

 Write the Wakeup register page offset value using opcode 0x11 */

 Read the Wakeup register page value using opcode 0x12 */

 Write the Wakeup register page value using opcode 0x12 */

/**

 * e1000_power_up_phy_copper - Restore copper link in case of PHY power down

 * @hw: pointer to the HW structure

 *

 * In the case of a PHY power down to save power, or to turn off link during a

 * driver unload, or wake on lan is not enabled, restore the link to previous

 * settings.

 The PHY will retain its settings across a power down/up cycle */

/**

 * e1000_power_down_phy_copper - Restore copper link in case of PHY power down

 * @hw: pointer to the HW structure

 *

 * In the case of a PHY power down to save power, or to turn off link during a

 * driver unload, or wake on lan is not enabled, restore the link to previous

 * settings.

 The PHY will retain its settings across a power down/up cycle */

/**

 *  __e1000_read_phy_reg_hv -  Read HV PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *  @locked: semaphore has already been acquired or not

 *  @page_set: BM_WUC_PAGE already set and access enabled

 *

 *  Acquires semaphore, if necessary, then reads the PHY register at offset

 *  and stores the retrieved information in data.  Release any acquired

 *  semaphore before exiting.

 Page 800 works differently than the rest so it has its own func */

 Page is shifted left, PHY expects (page x 32) */

/**

 *  e1000_read_phy_reg_hv -  Read HV PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Acquires semaphore then reads the PHY register at offset and stores

 *  the retrieved information in data.  Release the acquired semaphore

 *  before exiting.

/**

 *  e1000_read_phy_reg_hv_locked -  Read HV PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Reads the PHY register at offset and stores the retrieved information

 *  in data.  Assumes semaphore already acquired.

/**

 *  e1000_read_phy_reg_page_hv - Read HV PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Reads the PHY register at offset and stores the retrieved information

 *  in data.  Assumes semaphore already acquired and page already set.

/**

 *  __e1000_write_phy_reg_hv - Write HV PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *  @locked: semaphore has already been acquired or not

 *  @page_set: BM_WUC_PAGE already set and access enabled

 *

 *  Acquires semaphore, if necessary, then writes the data to PHY register

 *  at the offset.  Release any acquired semaphores before exiting.

 Page 800 works differently than the rest so it has its own func */

		/* Workaround MDIO accesses being disabled after entering IEEE

		 * Power Down (when bit 11 of the PHY Control register is set)

 Page is shifted left, PHY expects (page x 32) */

/**

 *  e1000_write_phy_reg_hv - Write HV PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Acquires semaphore then writes the data to PHY register at the offset.

 *  Release the acquired semaphores before exiting.

/**

 *  e1000_write_phy_reg_hv_locked - Write HV PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Writes the data to PHY register at the offset.  Assumes semaphore

 *  already acquired.

/**

 *  e1000_write_phy_reg_page_hv - Write HV PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Writes the data to PHY register at the offset.  Assumes semaphore

 *  already acquired and page already set.

/**

 *  e1000_get_phy_addr_for_hv_page - Get PHY address based on page

 *  @page: page to be accessed

/**

 *  e1000_access_phy_debug_regs_hv - Read HV PHY vendor specific high registers

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read or written

 *  @data: pointer to the data to be read or written

 *  @read: determines if operation is read or write

 *

 *  Reads the PHY register at offset and stores the retrieved information

 *  in data.  Assumes semaphore already acquired.  Note that the procedure

 *  to access these regs uses the address port and data port to read/write.

 *  These accesses done with PHY address 2 and without using pages.

 This takes care of the difference with desktop vs mobile phy */

 All operations in this function are phy address 2 */

 masking with 0x3F to remove the page from offset */

 Read or write the data value next */

/**

 *  e1000_link_stall_workaround_hv - Si workaround

 *  @hw: pointer to the HW structure

 *

 *  This function works around a Si bug where the link partner can get

 *  a link up indication before the PHY does.  If small packets are sent

 *  by the link partner they can be placed in the packet buffer without

 *  being properly accounted for by the PHY and will stall preventing

 *  further packets from being received.  The workaround is to clear the

 *  packet buffer after the PHY detects link up.

 Do not apply workaround if in PHY loopback bit 14 set */

 check if link is up and at 1Gbps */

 flush the packets in the fifo buffer */

/**

 *  e1000_check_polarity_82577 - Checks the polarity.

 *  @hw: pointer to the HW structure

 *

 *  Success returns 0, Failure returns -E1000_ERR_PHY (-2)

 *

 *  Polarity is determined based on the PHY specific status register.

/**

 *  e1000_phy_force_speed_duplex_82577 - Force speed/duplex for I82577 PHY

 *  @hw: pointer to the HW structure

 *

 *  Calls the PHY setup function to force speed and duplex.

 Try once more */

/**

 *  e1000_get_phy_info_82577 - Retrieve I82577 PHY information

 *  @hw: pointer to the HW structure

 *

 *  Read PHY status to determine if link is up.  If link is up, then

 *  set/determine 10base-T extended distance and polarity correction.  Read

 *  PHY port status to determine MDI/MDIx and speed.  Based on the speed,

 *  determine on the cable length, local and remote receiver.

/**

 *  e1000_get_cable_length_82577 - Determine cable length for 82577 PHY

 *  @hw: pointer to the HW structure

 *

 * Reads the diagnostic status register and verifies result is valid before

 * placing it in the phy_cable_length field.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2009 - 2018 Intel Corporation. */

 ethtool support for igbvf */

 nothing to do */

	/* We can't just free everything and then setup again,

	 * because the ISRs in MSI-X mode get passed pointers

	 * to the Tx and Rx ring structs.

	/* Link test performed before hardware reset so autoneg doesn't

	 * interfere with test result

		/* The user's desire is to turn off interrupt throttling

		 * altogether, but due to HW limitations, we can't do that.

		 * Instead we set a very small value in EITR, which would

		 * allow ~967k interrupts per second, but allow the adapter's

		 * internal clocking to still function properly.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2009 - 2018 Intel Corporation. */

/**

 *  e1000_init_mac_params_vf - Inits MAC params

 *  @hw: pointer to the HW structure

 VF's have no MTA Registers - PF feature only */

 VF's have no access to RAR entries  */

 Function pointers */

 reset */

 hw initialization */

 check for link */

 link info */

 multicast address update */

 set mac address */

 read mac address */

 set mac filter */

 set vlan filter table array */

/**

 *  e1000_init_function_pointers_vf - Inits function pointers

 *  @hw: pointer to the HW structure

/**

 *  e1000_get_link_up_info_vf - Gets link info.

 *  @hw: pointer to the HW structure

 *  @speed: pointer to 16 bit value to store link speed.

 *  @duplex: pointer to 16 bit value to store duplex.

 *

 *  Since we cannot read the PHY and get accurate link info, we must rely upon

 *  the status register's data which is often stale and inaccurate.

/**

 *  e1000_reset_hw_vf - Resets the HW

 *  @hw: pointer to the HW structure

 *

 *  VF's provide a function level reset. This is done using bit 26 of ctrl_reg.

 *  This is all the reset we can perform on a VF.

 assert VF queue/interrupt reset */

 we cannot initialize while the RSTI / RSTD bits are asserted */

 mailbox timeout can now become active */

 notify PF of VF reset completion */

 set our "perm_addr" based on info provided by PF */

/**

 *  e1000_init_hw_vf - Inits the HW

 *  @hw: pointer to the HW structure

 *

 *  Not much to do here except clear the PF Reset indication if there is one.

 attempt to set and restore our mac address */

/**

 *  e1000_hash_mc_addr_vf - Generate a multicast hash value

 *  @hw: pointer to the HW structure

 *  @mc_addr: pointer to a multicast address

 *

 *  Generates a multicast address hash value which is used to determine

 *  the multicast filter table array address and new table value.  See

 *  e1000_mta_set_generic()

 Register count multiplied by bits per register */

	/* The bit_shift is the number of left-shifts

	 * where 0xFF would still fall within the hash mask.

/**

 *  e1000_update_mc_addr_list_vf - Update Multicast addresses

 *  @hw: pointer to the HW structure

 *  @mc_addr_list: array of multicast addresses to program

 *  @mc_addr_count: number of multicast addresses to program

 *  @rar_used_count: the first RAR register free to program

 *  @rar_count: total number of supported Receive Address Registers

 *

 *  Updates the Receive Address Registers and Multicast Table Array.

 *  The caller must have a packed mc_addr_list of multicast addresses.

 *  The parameter rar_count will usually be hw->mac.rar_entry_count

 *  unless there are workarounds that change this.

	/* Each entry in the list uses 1 16 bit word.  We have 30

	 * 16 bit words available in our HW msg buffer (minus 1 for the

	 * msg type).  That's 30 hash values if we pack 'em right.  If

	 * there are more than 30 MC addresses to add then punt the

	 * extras for now and then add code to handle more than 30 later.

	 * It would be unusual for a server to request that many multi-cast

	 * addresses except for in large enterprise network environments.

/**

 *  e1000_set_vfta_vf - Set/Unset vlan filter table address

 *  @hw: pointer to the HW structure

 *  @vid: determines the vfta register and bit to set/unset

 *  @set: if true then set bit, else clear bit

 Setting the 8 bit field MSG INFO to true indicates "add" */

 if nacked the vlan was rejected */

/**

 *  e1000_rlpml_set_vf - Set the maximum receive packet length

 *  @hw: pointer to the HW structure

 *  @max_size: value to assign to max frame size

/**

 *  e1000_rar_set_vf - set device MAC address

 *  @hw: pointer to the HW structure

 *  @addr: pointer to the receive address

 *  @index: receive address array register

 if nacked the address was rejected, use "perm_addr" */

/**

 *  e1000_read_mac_addr_vf - Read device MAC address

 *  @hw: pointer to the HW structure

/**

 *  e1000_set_uc_addr_vf - Set or clear unicast filters

 *  @hw: pointer to the HW structure

 *  @sub_cmd: add or clear filters

 *  @addr: pointer to the filter MAC address

/**

 *  e1000_check_for_link_vf - Check for link for a virtual interface

 *  @hw: pointer to the HW structure

 *

 *  Checks to see if the underlying PF is still talking to the VF and

 *  if it is then it reports the link state to the hardware, otherwise

 *  it reports link down and returns an error.

	/* We only want to run this if there has been a rst asserted.

	 * in this case that could mean a link change, device reset,

	 * or a virtual function reset

 If we were hit with a reset or timeout drop the link */

 if link status is down no point in checking to see if PF is up */

	/* if the read failed it could just be a mailbox collision, best wait

	 * until we are called again and don't report an error

 if incoming message isn't clear to send we are waiting on response */

 msg is not CTS and is NACK we must have lost CTS status */

 the PF is talking, if we timed out in the past we reinit */

	/* if we passed all the tests above then the link is up and we no

	 * longer need to check for link

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2009 - 2018 Intel Corporation. */

/**

 *  e1000_poll_for_msg - Wait for message notification

 *  @hw: pointer to the HW structure

 *

 *  returns SUCCESS if it successfully received a message notification

 if we failed, all future posted messages fail until reset */

/**

 *  e1000_poll_for_ack - Wait for message acknowledgment

 *  @hw: pointer to the HW structure

 *

 *  returns SUCCESS if it successfully received a message acknowledgment

 if we failed, all future posted messages fail until reset */

/**

 *  e1000_read_posted_mbx - Wait for message notification and receive message

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *

 *  returns SUCCESS if it successfully received a message notification and

 *  copied it into the receive buffer.

 if ack received read message, otherwise we timed out */

/**

 *  e1000_write_posted_mbx - Write a message to the mailbox, wait for ack

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *

 *  returns SUCCESS if it successfully copied message into the buffer and

 *  received an ack to that message within delay * timeout period

 exit if we either can't write or there isn't a defined timeout */

 send msg*/

 if msg sent wait until we receive an ack */

/**

 *  e1000_read_v2p_mailbox - read v2p mailbox

 *  @hw: pointer to the HW structure

 *

 *  This function is used to read the v2p mailbox without losing the read to

 *  clear status bits.

/**

 *  e1000_check_for_bit_vf - Determine if a status bit was set

 *  @hw: pointer to the HW structure

 *  @mask: bitmask for bits to be tested and cleared

 *

 *  This function is used to check for the read to clear bits within

 *  the V2P mailbox.

/**

 *  e1000_check_for_msg_vf - checks to see if the PF has sent mail

 *  @hw: pointer to the HW structure

 *

 *  returns SUCCESS if the PF has set the Status bit or else ERR_MBX

/**

 *  e1000_check_for_ack_vf - checks to see if the PF has ACK'd

 *  @hw: pointer to the HW structure

 *

 *  returns SUCCESS if the PF has set the ACK bit or else ERR_MBX

/**

 *  e1000_check_for_rst_vf - checks to see if the PF has reset

 *  @hw: pointer to the HW structure

 *

 *  returns true if the PF has set the reset done bit or else false

/**

 *  e1000_obtain_mbx_lock_vf - obtain mailbox lock

 *  @hw: pointer to the HW structure

 *

 *  return SUCCESS if we obtained the mailbox lock

 Take ownership of the buffer */

 reserve mailbox for VF use */

/**

 *  e1000_write_mbx_vf - Write a message to the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *

 *  returns SUCCESS if it successfully copied message into the buffer

 lock the mailbox to prevent pf/vf race condition */

 flush any ack or msg as we are going to overwrite mailbox */

 copy the caller specified message to the mailbox memory buffer */

 update stats */

 Drop VFU and interrupt the PF to tell it a message has been sent */

/**

 *  e1000_read_mbx_vf - Reads a message from the inbox intended for VF

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *

 *  returns SUCCESS if it successfully read message from buffer

 lock the mailbox to prevent pf/vf race condition */

 copy the message from the mailbox memory buffer */

 Acknowledge receipt and release mailbox, then we're done */

 update stats */

/**

 *  e1000_init_mbx_params_vf - set initial values for VF mailbox

 *  @hw: pointer to the HW structure

 *

 *  Initializes the hw->mbx struct to correct values for VF mailbox

	/* start mailbox as timed out and let the reset_hw call set the timeout

	 * value to being communications

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2009 - 2018 Intel Corporation. */

/**

 * igbvf_desc_unused - calculate if we have unused descriptors

 * @ring: address of receive ring structure

/**

 * igbvf_receive_skb - helper function to handle Rx indications

 * @adapter: board private structure

 * @netdev: pointer to netdev struct

 * @skb: skb to indicate to stack

 * @status: descriptor status field as written by hardware

 * @vlan: descriptor vlan field as written by hardware (no le/be conversion)

 * @skb: pointer to sk_buff to be indicated to stack

 Ignore Checksum bit is set or checksum is disabled through ethtool */

 TCP/UDP checksum error bit is set */

 let the stack verify checksum errors */

 It must be a TCP or UDP packet with a valid checksum */

/**

 * igbvf_alloc_rx_buffers - Replace used receive buffers; packet split

 * @rx_ring: address of ring structure to repopulate

 * @cleaned_count: number of buffers to repopulate

		/* Refresh the desc even if buffer_addrs didn't change because

		 * each write-back erases this info.

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

/**

 * igbvf_clean_rx_irq - Send received data up the network stack; legacy

 * @adapter: board private structure

 * @work_done: output parameter used to indicate completed work

 * @work_to_do: input parameter setting limit of work

 *

 * the return value indicates whether actual cleaning was done, there

 * is no guarantee that everything was cleaned

 read descriptor and rx_buffer_info after status DD */

		/* HW will not DMA in data larger than the given buffer, even

		 * if it parses the (NFS, of course) header to be larger.  In

		 * that case, it fills the header buffer and spills the rest

		 * into the page.

 return some buffers to hardware, one at a time is too slow */

 use prefetched values */

/**

 * igbvf_setup_tx_resources - allocate Tx resources (Descriptors)

 * @adapter: board private structure

 * @tx_ring: ring being initialized

 *

 * Return 0 on success, negative on failure

 round up to nearest 4K */

/**

 * igbvf_setup_rx_resources - allocate Rx resources (Descriptors)

 * @adapter: board private structure

 * @rx_ring: ring being initialized

 *

 * Returns 0 on success, negative on failure

 Round up to nearest 4K */

/**

 * igbvf_clean_tx_ring - Free Tx Buffers

 * @tx_ring: ring to be cleaned

 Free all the Tx ring sk_buffs */

 Zero out the descriptor ring */

/**

 * igbvf_free_tx_resources - Free Tx Resources per Queue

 * @tx_ring: ring to free resources from

 *

 * Free all transmit software resources

/**

 * igbvf_clean_rx_ring - Free Rx Buffers per Queue

 * @rx_ring: ring structure pointer to free buffers from

 Free all the Rx ring sk_buffs */

 Zero out the descriptor ring */

/**

 * igbvf_free_rx_resources - Free Rx Resources

 * @rx_ring: ring to clean the resources from

 *

 * Free all receive software resources

/**

 * igbvf_update_itr - update the dynamic ITR value based on statistics

 * @adapter: pointer to adapter

 * @itr_setting: current adapter->itr

 * @packets: the number of packets during this measurement interval

 * @bytes: the number of bytes during this measurement interval

 *

 * Stores a new ITR value based on packets and byte counts during the last

 * interrupt.  The advantage of per interrupt computation is faster updates

 * and more accurate ITR for the current traffic pattern.  Constants in this

 * function were computed based on theoretical maximum wire speed and thresholds

 * were set based on testing data as well as attempting to minimize response

 * time while increasing bulk throughput.

 handle TSO and jumbo frames */

 50 usec aka 20000 ints/s */

 this if handles the TSO accounting */

 250 usec aka 4000 ints/s */

 counts and packets in update_itr are dependent on these numbers */

 conservative mode (itr 3) eliminates the lowest_latency setting */

		/* this attempts to bias the interrupt rate towards Bulk

		 * by adding intermediate steps when interrupt rate is

		 * increasing

/**

 * igbvf_clean_tx_irq - Reclaim resources after transmit completes

 * @tx_ring: ring structure to clean descriptors from

 *

 * returns true if ring is completely cleaned

 if next_to_watch is not set then there is no work pending */

 prevent any other reads prior to eop_desc */

 if DD is not set pending work has not been completed */

 clear next_to_watch to prevent false hangs */

 gso_segs is currently only valid for tcp */

 multiply data chunks by size of headers */

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

	/* auto mask will automatically re-enable the interrupt when we write

	 * EICS

 Ring was not completely cleaned, so fire another interrupt */

	/* Write the ITR value calculated at the end of the

	 * previous interrupt.

	/* 82576 uses a table-based method for assigning vectors.

	 * Each queue has a single entry in the table to which we write

	 * a vector number along with a "valid" bit.  Sadly, the layout

	 * of the table is somewhat counterintuitive.

 vector goes into third byte of register */

 vector goes into low byte of register */

 vector goes into high byte of register */

 vector goes into second byte of register */

/**

 * igbvf_configure_msix - Configure MSI-X hardware

 * @adapter: board private structure

 *

 * igbvf_configure_msix sets up the hardware to properly

 * generate MSI-X interrupts.

 set vector for other causes, i.e. link changes */

/**

 * igbvf_set_interrupt_capability - set MSI or MSI-X if supported

 * @adapter: board private structure

 *

 * Attempt to configure interrupts using the best available

 * capabilities of the hardware and kernel.

 we allocate 3 vectors, 1 for Tx, 1 for Rx, one for PF messages */

 MSI-X failed */

/**

 * igbvf_request_msix - Initialize MSI-X interrupts

 * @adapter: board private structure

 *

 * igbvf_request_msix allocates MSI-X vectors and requests interrupts from the

 * kernel.

/**

 * igbvf_alloc_queues - Allocate memory for all rings

 * @adapter: board private structure to initialize

/**

 * igbvf_request_irq - initialize interrupts

 * @adapter: board private structure

 *

 * Attempts to configure interrupts using the best available

 * capabilities of the hardware and kernel.

 igbvf supports msi-x only */

/**

 * igbvf_irq_disable - Mask off interrupt generation on the NIC

 * @adapter: board private structure

/**

 * igbvf_irq_enable - Enable default interrupt generation settings

 * @adapter: board private structure

/**

 * igbvf_poll - NAPI Rx polling callback

 * @napi: struct associated with this polling callback

 * @budget: amount of packets driver is allowed to process this poll

	/* Exit the polling mode, but don't re-enable interrupts if stack might

	 * poll us due to busy-polling

/**

 * igbvf_set_rlpml - set receive large packet maximum length

 * @adapter: board private structure

 *

 * Configure the maximum size of packets that will be received

/**

 * igbvf_configure_tx - Configure Transmit Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Tx unit of the MAC after a reset.

 disable transmits */

 Setup the HW Tx Head and Tail descriptor pointers */

	/* Turn off Relaxed Ordering on head write-backs.  The writebacks

	 * MUST be delivered in order or it will completely screw up

	 * our bookkeeping.

 enable transmits */

 Setup Transmit Descriptor Settings for eop descriptor */

 enable Report Status bit */

/**

 * igbvf_setup_srrctl - configure the receive control registers

 * @adapter: Board private structure

 Enable queue drop to avoid head of line blocking */

 Setup buffer sizes */

/**

 * igbvf_configure_rx - Configure Receive Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Rx unit of the MAC after a reset.

 disable receives */

	/* Setup the HW Rx Head and Tail Descriptor Pointers and

	 * the Base and Length of the Rx Descriptor Ring

 enable receives */

/**

 * igbvf_set_multi - Multicast and Promiscuous mode set

 * @netdev: network interface device structure

 *

 * The set_multi entry point is called whenever the multicast address

 * list or the network interface flags are updated.  This routine is

 * responsible for configuring the hardware for proper multicast,

 * promiscuous mode, and all-multi behavior.

 prepare a packed array of only addresses. */

/**

 * igbvf_set_uni - Configure unicast MAC filters

 * @netdev: network interface device structure

 *

 * This routine is responsible for configuring the hardware for proper

 * unicast filters.

 Clear all unicast MAC filters */

 Add MAC filters one by one */

/**

 * igbvf_configure - configure the hardware for Rx and Tx

 * @adapter: private board structure

/* igbvf_reset - bring the hardware into a known good state

 * @adapter: private board structure

 *

 * This function boots the hardware and enables some settings that

 * require a configuration cycle of the hardware - those cannot be

 * set/changed during runtime. After reset the device needs to be

 * properly configured for Rx, Tx etc.

 Allow time for pending master requests to run */

 hardware has been reset, we need to reload some things */

 Clear any pending interrupts. */

 start the watchdog */

	/* signal that we're down so the interrupt handler does not

	 * reschedule our watchdog timer

 disable receives in the hardware */

 disable transmits in the hardware */

 flush both disables and wait for them to finish */

 record the stats before reset*/

/**

 * igbvf_sw_init - Initialize general software structures (struct igbvf_adapter)

 * @adapter: board private structure to initialize

 *

 * igbvf_sw_init initializes the Adapter private data structure.

 * Fields are initialized based on PCI device information and

 * OS network device settings (MTU size).

 Set various function pointers */

 Explicitly disable IRQ since the NIC can be in any state. */

/**

 * igbvf_open - Called when a network interface is made active

 * @netdev: network interface device structure

 *

 * Returns 0 on success, negative value on failure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP).  At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the watchdog timer is started,

 * and the stack is notified that the interface is ready.

 disallow open during test */

 allocate transmit descriptors */

 allocate receive descriptors */

	/* before we allocate an interrupt, we must be ready to handle it.

	 * Setting DEBUG_SHIRQ in the kernel makes it fire an interrupt

	 * as soon as we call pci_request_irq, so we have to setup our

	 * clean_rx handler before we do so.

 From here on the code is the same as igbvf_up() */

 clear any pending interrupts */

 start the watchdog */

/**

 * igbvf_close - Disables a network interface

 * @netdev: network interface device structure

 *

 * Returns 0, this is not allowed to fail

 *

 * The close entry point is called when an interface is de-activated

 * by the OS.  The hardware is still under the drivers control, but

 * needs to be disabled.  A global MAC reset is issued to stop the

 * hardware, and all transmit and receive resources are freed.

/**

 * igbvf_set_mac - Change the Ethernet Address of the NIC

 * @netdev: network interface device structure

 * @p: pointer to an address structure

 *

 * Returns 0 on success, negative on failure

/**

 * igbvf_update_stats - Update the board statistics counters

 * @adapter: board private structure

	/* Prevent stats update while adapter is being reset, link is down

	 * or if the pci connection is down.

 Fill out the OS statistics structure */

 If interface is down, stay link down */

 if check for link returns error we will need to reset */

/**

 * igbvf_watchdog - Timer Call-back

 * @t: timer list pointer containing private struct

 Do the rest outside of interrupt context */

			/* We've lost link, so the controller stops DMA,

			 * but we've got queued Tx work that's never going

			 * to get done, so reset controller to flush Tx.

			 * (Do the reset outside of interrupt context).

 Cause software interrupt to ensure Rx ring is cleaned */

 Reset the timer */

 set bits to identify this as an advanced context descriptor */

 ADV DTYP TUCMD MKRLOC/ISCSIHEDLEN */

 initialize outer IP header fields */

		/* IP header will have to cancel out any data that

		 * is not a part of the outer IP header

 determine offset of inner transport header */

 compute length of segmentation header */

 remove payload length from inner checksum */

 MSS L4LEN IDX */

 VLAN MACLEN IPLEN */

 validate that this is actually an SCTP request */

 there is enough descriptors then we don't need to worry  */

	/* Herbert's original patch had:

	 *  smp_mb__after_netif_stop_queue();

	 * but since that doesn't exist yet, just open code it.

 We need to check again just in case room has been made available */

 set time_stamp *before* dma to help avoid a possible race */

 clear timestamp and dma mappings for failed buffer_info mapping */

 clear timestamp and dma mappings for remaining portion of packet */

 insert tcp checksum */

 insert ip checksum */

	/* Force memory writes to complete before letting h/w

	 * know there are new descriptors to fetch.  (Only

	 * applicable for weak-ordered memory model archs,

	 * such as IA-64).

	/* need: count + 4 desc gap to keep tail from touching

	 *       + 2 desc gap to keep tail from touching head,

	 *       + 1 desc for skb->data,

	 *       + 1 desc for context descriptor,

	 * head, otherwise try next time

 this is a hard error */

	/* count reflects descriptors mapped, if 0 then mapping error

	 * has occurred and we need to rewind the descriptor queue

 Make sure there is space in the ring for the next send. */

/**

 * igbvf_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: queue timing out (unused)

 Do the reset outside of interrupt context */

/**

 * igbvf_change_mtu - Change the Maximum Transfer Unit

 * @netdev: network interface device structure

 * @new_mtu: new value for maximum frame size

 *

 * Returns 0 on success, negative on failure

 igbvf_down has a dependency on max_frame_size */

	/* NOTE: netdev_alloc_skb reserves 16 bytes, and typically NET_IP_ALIGN

	 * means we reserve 2 more, this pushes us to allocate from the next

	 * larger slab size.

	 * i.e. RXBUFFER_2048 --> size-4096 slab

	 * However with the new *_jumbo_rx* routines, jumbo receives will use

	 * fragmented skbs

 adjust allocation if LPE protects us, and we aren't using SBP */

/* Polling 'interrupt' - used by things like netconsole to send skbs

 * without having to re-enable interrupts. It's not called while

 * the interrupt routine is executing.

/**

 * igbvf_io_error_detected - called when PCI error is detected

 * @pdev: Pointer to PCI device

 * @state: The current pci connection state

 *

 * This function is called after a PCI bus error affecting

 * this device has been detected.

 Request a slot slot reset. */

/**

 * igbvf_io_slot_reset - called after the pci bus has been reset.

 * @pdev: Pointer to PCI device

 *

 * Restart the card from scratch, as if from a cold-boot. Implementation

 * resembles the first-half of the igbvf_resume routine.

/**

 * igbvf_io_resume - called when traffic can start flowing again.

 * @pdev: Pointer to PCI device

 *

 * This callback is called when the error recovery driver tells us that

 * its OK to resume normal operation. Implementation resembles the

 * second-half of the igbvf_resume routine.

 Make certain the headers can be described by a context descriptor */

	/* We can only support IPV4 TSO in tunnels if we can mangle the

	 * inner IP ID field, so strip TSO if MANGLEID is not supported.

/**

 * igbvf_probe - Device Initialization Routine

 * @pdev: PCI device information struct

 * @ent: entry in igbvf_pci_tbl

 *

 * Returns 0 on success, negative on failure

 *

 * igbvf_probe initializes an adapter identified by a pci_dev structure.

 * The OS initialization, configuring of the adapter private structure,

 * and a hardware reset occur.

 PCI config space info */

 setup adapter struct */

 construct the net_device struct */

 set this bit last since it cannot be part of vlan_features */

 MTU range: 68 - 9216 */

reset the controller to put the device in a known good state */

 ring size defaults */

 reset the hardware with the new settings */

 set hardware-specific flags */

 tell the stack to leave us alone until igbvf_open() is called */

/**

 * igbvf_remove - Device Removal Routine

 * @pdev: PCI device information struct

 *

 * igbvf_remove is called by the PCI subsystem to alert the driver

 * that it should release a PCI device.  The could be caused by a

 * Hot-Plug event, or because the driver is going to be removed from

 * memory.

	/* The watchdog timer may be rescheduled, so explicitly

	 * disable it from being rescheduled.

	/* it is important to delete the NAPI struct prior to freeing the

	 * Rx ring so that you do not end up with null pointer refs

 PCI Error Recovery (ERS) */

 terminate list */

 PCI Device API Driver */

/**

 * igbvf_init_module - Driver Registration Routine

 *

 * igbvf_init_module is the first routine called when the driver is

 * loaded. All it does is register with the PCI subsystem.

/**

 * igbvf_exit_module - Driver Exit Cleanup Routine

 *

 * igbvf_exit_module is called just before the driver is removed

 * from memory.

 netdev.c */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2007 - 2018 Intel Corporation. */

/**

 *  igb_get_bus_info_pcie - Get PCIe bus information

 *  @hw: pointer to the HW structure

 *

 *  Determines and stores the system bus information for a particular

 *  network interface.  The following bus information is determined and stored:

 *  bus speed, bus width, type (PCIe), and PCIe function.

/**

 *  igb_clear_vfta - Clear VLAN filter table

 *  @hw: pointer to the HW structure

 *

 *  Clears the register array which contains the VLAN filter table by

 *  setting all the values to 0.

/**

 *  igb_write_vfta - Write value to VLAN filter table

 *  @hw: pointer to the HW structure

 *  @offset: register offset in VLAN filter table

 *  @value: register value written to VLAN filter table

 *

 *  Writes value at the given offset in the register array which stores

 *  the VLAN filter table.

/**

 *  igb_init_rx_addrs - Initialize receive address's

 *  @hw: pointer to the HW structure

 *  @rar_count: receive address registers

 *

 *  Setups the receive address registers by setting the base receive address

 *  register to the devices MAC address and clearing all the other receive

 *  address registers to 0.

 Setup the receive address */

 Zero out the other (rar_entry_count - 1) receive addresses */

/**

 *  igb_find_vlvf_slot - find the VLAN id or the first empty slot

 *  @hw: pointer to hardware structure

 *  @vlan: VLAN id to write to VLAN filter

 *  @vlvf_bypass: skip VLVF if no match is found

 *

 *  return the VLVF index where this VLAN id should be placed

 *

 short cut the special case */

	/* if vlvf_bypass is set we don't want to use an empty slot, we

	 * will simply bypass the VLVF if there are no entries present in the

	 * VLVF that contain our VLAN

	/* Search for the VLAN id in the VLVF entries. Save off the first empty

	 * slot found along the way.

	 *

	 * pre-decrement loop covering (IXGBE_VLVF_ENTRIES - 1) .. 1

/**

 *  igb_vfta_set - enable or disable vlan in VLAN filter table

 *  @hw: pointer to the HW structure

 *  @vlan: VLAN id to add or remove

 *  @vind: VMDq output index that maps queue to VLAN id

 *  @vlan_on: if true add filter, if false remove

 *  @vlvf_bypass: skip VLVF if no match is found

 *

 *  Sets or clears a bit in the VLAN filter table array based on VLAN id

 *  and if we are adding or removing the filter

	/* this is a 2 part operation - first the VFTA, then the

	 * VLVF and VLVFB if VT Mode is set

	 * We don't write the VFTA until we know the VLVF part succeeded.

	/* Part 1

	 * The VFTA is a bitstring made up of 128 32-bit registers

	 * that enable the particular VLAN id, much like the MTA:

	 *    bits[11-5]: which register

	 *    bits[4-0]:  which bit in the register

	/* vfta_delta represents the difference between the current value

	 * of vfta and the value we want in the register.  Since the diff

	 * is an XOR mask we can just update vfta using an XOR.

	/* Part 2

	 * If VT Mode is set

	 *   Either vlan_on

	 *     make sure the VLAN is in VLVF

	 *     set the vind bit in the matching VLVFB

	 *   Or !vlan_on

	 *     clear the pool bit and possibly the vind

 set the pool bit */

 clear the pool bit */

		/* Clear VFTA first, then disable VLVF.  Otherwise

		 * we run the risk of stray packets leaking into

		 * the PF via the default pool

 disable VLVF and clear remaining bit from pool */

	/* If there are still bits set in the VLVFB registers

	 * for the VLAN ID indicated we need to see if the

	 * caller is requesting that we clear the VFTA entry bit.

	 * If the caller has requested that we clear the VFTA

	 * entry bit but there are still pools/VFs using this VLAN

	 * ID entry then ignore the request.  We're not worried

	 * about the case where we're turning the VFTA VLAN ID

	 * entry bit on, only when requested to turn it off as

	 * there may be multiple pools and/or VFs using the

	 * VLAN ID entry.  In that case we cannot clear the

	 * VFTA bit until all pools/VFs using that VLAN ID have also

	 * been cleared.  This will be indicated by "bits" being

	 * zero.

 record pool change and enable VLAN ID if not already enabled */

 bit was set/cleared before we started */

/**

 *  igb_check_alt_mac_addr - Check for alternate MAC addr

 *  @hw: pointer to the HW structure

 *

 *  Checks the nvm for an alternate MAC address.  An alternate MAC address

 *  can be setup by pre-boot software and must be treated like a permanent

 *  address and must override the actual permanent MAC address.  If an

 *  alternate MAC address is found it is saved in the hw struct and

 *  programmed into RAR0 and the function returns success, otherwise the

 *  function returns an error.

	/* Alternate MAC address is handled by the option ROM for 82580

	 * and newer. SW support not required.

 There is no Alternate MAC Address */

 if multicast bit is set, the alternate address will not be used */

	/* We have a valid alternate MAC address, and we want to treat it the

	 * same as the normal permanent MAC address stored by the HW into the

	 * RAR. Do this by mapping this address into RAR0.

/**

 *  igb_rar_set - Set receive address register

 *  @hw: pointer to the HW structure

 *  @addr: pointer to the receive address

 *  @index: receive address array register

 *

 *  Sets the receive address array register at index to the address passed

 *  in by addr.

	/* HW expects these in little endian so we reverse the byte order

	 * from network order (big endian) to little endian

 If MAC address zero, no need to set the AV bit */

	/* Some bridges will combine consecutive 32-bit writes into

	 * a single burst write, which will malfunction on some parts.

	 * The flushes avoid this.

/**

 *  igb_mta_set - Set multicast filter table address

 *  @hw: pointer to the HW structure

 *  @hash_value: determines the MTA register and bit to set

 *

 *  The multicast table address is a register array of 32-bit registers.

 *  The hash_value is used to determine what register the bit is in, the

 *  current value is read, the new bit is OR'd in and the new value is

 *  written back into the register.

	/* The MTA is a register array of 32-bit registers. It is

	 * treated like an array of (32*mta_reg_count) bits.  We want to

	 * set bit BitArray[hash_value]. So we figure out what register

	 * the bit is in, read it, OR in the new bit, then write

	 * back the new value.  The (hw->mac.mta_reg_count - 1) serves as a

	 * mask to bits 31:5 of the hash value which gives us the

	 * register we're modifying.  The hash bit within that register

	 * is determined by the lower 5 bits of the hash value.

/**

 *  igb_hash_mc_addr - Generate a multicast hash value

 *  @hw: pointer to the HW structure

 *  @mc_addr: pointer to a multicast address

 *

 *  Generates a multicast address hash value which is used to determine

 *  the multicast filter table array address and new table value.  See

 *  igb_mta_set()

 Register count multiplied by bits per register */

	/* For a mc_filter_type of 0, bit_shift is the number of left-shifts

	 * where 0xFF would still fall within the hash mask.

	/* The portion of the address that is used for the hash table

	 * is determined by the mc_filter_type setting.

	 * The algorithm is such that there is a total of 8 bits of shifting.

	 * The bit_shift for a mc_filter_type of 0 represents the number of

	 * left-shifts where the MSB of mc_addr[5] would still fall within

	 * the hash_mask.  Case 0 does this exactly.  Since there are a total

	 * of 8 bits of shifting, then mc_addr[4] will shift right the

	 * remaining number of bits. Thus 8 - bit_shift.  The rest of the

	 * cases are a variation of this algorithm...essentially raising the

	 * number of bits to shift mc_addr[5] left, while still keeping the

	 * 8-bit shifting total.

	 *

	 * For example, given the following Destination MAC Address and an

	 * mta register count of 128 (thus a 4096-bit vector and 0xFFF mask),

	 * we can see that the bit_shift for case 0 is 4.  These are the hash

	 * values resulting from each mc_filter_type...

	 * [0] [1] [2] [3] [4] [5]

	 * 01  AA  00  12  34  56

	 * LSB                 MSB

	 *

	 * case 0: hash_value = ((0x34 >> 4) | (0x56 << 4)) & 0xFFF = 0x563

	 * case 1: hash_value = ((0x34 >> 3) | (0x56 << 5)) & 0xFFF = 0xAC6

	 * case 2: hash_value = ((0x34 >> 2) | (0x56 << 6)) & 0xFFF = 0x163

	 * case 3: hash_value = ((0x34 >> 0) | (0x56 << 8)) & 0xFFF = 0x634

/**

 * igb_i21x_hw_doublecheck - double checks potential HW issue in i21X

 * @hw: pointer to the HW structure

 *

 * Checks if multicast array is wrote correctly

 * If not then rewrites again to register

/**

 *  igb_update_mc_addr_list - Update Multicast addresses

 *  @hw: pointer to the HW structure

 *  @mc_addr_list: array of multicast addresses to program

 *  @mc_addr_count: number of multicast addresses to program

 *

 *  Updates entire Multicast Table Array.

 *  The caller must have a packed mc_addr_list of multicast addresses.

 clear mta_shadow */

 update mta_shadow from mc_addr_list */

 replace the entire MTA table */

/**

 *  igb_clear_hw_cntrs_base - Clear base hardware counters

 *  @hw: pointer to the HW structure

 *

 *  Clears the base hardware counters by reading the counter registers.

/**

 *  igb_check_for_copper_link - Check for link (Copper)

 *  @hw: pointer to the HW structure

 *

 *  Checks to see of the link status of the hardware has changed.  If a

 *  change in link status has been detected, then we read the PHY registers

 *  to get the current speed/duplex if link exists.

	/* We only want to go out to the PHY registers to see if Auto-Neg

	 * has completed and/or if our link status has changed.  The

	 * get_link_status flag is set upon receiving a Link Status

	 * Change or Rx Sequence Error interrupt.

	/* First we want to see if the MII Status Register reports

	 * link.  If so, then we want to get the current speed/duplex

	 * of the PHY.

 No link detected */

	/* Check if there was DownShift, must be checked

	 * immediately after link-up

	/* If we are forcing speed/duplex, then we simply return since

	 * we have already determined whether we have link or not.

	/* Auto-Neg is enabled.  Auto Speed Detection takes care

	 * of MAC speed/duplex configuration.  So we only need to

	 * configure Collision Distance in the MAC.

	/* Configure Flow Control now that Auto-Neg has completed.

	 * First, we need to restore the desired flow control

	 * settings because we may have had to re-autoneg with a

	 * different link partner.

/**

 *  igb_setup_link - Setup flow control and link settings

 *  @hw: pointer to the HW structure

 *

 *  Determines which flow control settings to use, then configures flow

 *  control.  Calls the appropriate media-specific link configuration

 *  function.  Assuming the adapter has a valid link partner, a valid link

 *  should be established.  Assumes the hardware has previously been reset

 *  and the transmitter and receiver are not enabled.

	/* In the case of the phy reset being blocked, we already have a link.

	 * We do not need to set it up again.

	/* If requested flow control is set to default, set flow control

	 * based on the EEPROM flow control settings.

	/* We want to save off the original Flow Control configuration just

	 * in case we get disconnected and then reconnected into a different

	 * hub or switch with different Flow Control capabilities.

 Call the necessary media_type subroutine to configure the link. */

	/* Initialize the flow control address, type, and PAUSE timer

	 * registers to their default values.  This is done even if flow

	 * control is disabled, because it does not hurt anything to

	 * initialize these registers.

/**

 *  igb_config_collision_dist - Configure collision distance

 *  @hw: pointer to the HW structure

 *

 *  Configures the collision distance to the default value and is used

 *  during link setup. Currently no func pointer exists and all

 *  implementations are handled in the generic version of this function.

/**

 *  igb_set_fc_watermarks - Set flow control high/low watermarks

 *  @hw: pointer to the HW structure

 *

 *  Sets the flow control high/low threshold (watermark) registers.  If

 *  flow control XON frame transmission is enabled, then set XON frame

 *  tansmission as well.

	/* Set the flow control receive threshold registers.  Normally,

	 * these registers will be set to a default threshold that may be

	 * adjusted later by the driver's runtime code.  However, if the

	 * ability to transmit pause frames is not enabled, then these

	 * registers will be set to 0.

		/* We need to set up the Receive Threshold high and low water

		 * marks as well as (optionally) enabling the transmission of

		 * XON frames.

/**

 *  igb_set_default_fc - Set flow control default values

 *  @hw: pointer to the HW structure

 *

 *  Read the EEPROM for the default values for flow control and store the

 *  values.

	/* Read and store word 0x0F of the EEPROM. This word contains bits

	 * that determine the hardware's default PAUSE (flow control) mode,

	 * a bit that determines whether the HW defaults to enabling or

	 * disabling auto-negotiation, and the direction of the

	 * SW defined pins. If there is no SW over-ride of the flow

	 * control setting, then the variable hw->fc will

	 * be initialized based on a value in the EEPROM.

/**

 *  igb_force_mac_fc - Force the MAC's flow control settings

 *  @hw: pointer to the HW structure

 *

 *  Force the MAC's flow control settings.  Sets the TFCE and RFCE bits in the

 *  device control register to reflect the adapter settings.  TFCE and RFCE

 *  need to be explicitly set by software when a copper PHY is used because

 *  autonegotiation is managed by the PHY rather than the MAC.  Software must

 *  also configure these bits when link is forced on a fiber connection.

	/* Because we didn't get link via the internal auto-negotiation

	 * mechanism (we either forced link or we got link via PHY

	 * auto-neg), we have to manually enable/disable transmit an

	 * receive flow control.

	 *

	 * The "Case" statement below enables/disable flow control

	 * according to the "hw->fc.current_mode" parameter.

	 *

	 * The possible values of the "fc" parameter are:

	 *      0:  Flow control is completely disabled

	 *      1:  Rx flow control is enabled (we can receive pause

	 *          frames but not send pause frames).

	 *      2:  Tx flow control is enabled (we can send pause frames

	 *          frames but we do not receive pause frames).

	 *      3:  Both Rx and TX flow control (symmetric) is enabled.

	 *  other:  No other values should be possible at this point.

/**

 *  igb_config_fc_after_link_up - Configures flow control after link

 *  @hw: pointer to the HW structure

 *

 *  Checks the status of auto-negotiation after link up to ensure that the

 *  speed and duplex were not forced.  If the link needed to be forced, then

 *  flow control needs to be forced also.  If auto-negotiation is enabled

 *  and did not fail, then we configure flow control based on our link

 *  partner.

	/* Check for the case where we have fiber media and auto-neg failed

	 * so we had to force link.  In this case, we need to force the

	 * configuration of the MAC to match the "fc" parameter.

	/* Check for the case where we have copper media and auto-neg is

	 * enabled.  In this case, we need to check and see if Auto-Neg

	 * has completed, and if so, how the PHY and link partner has

	 * flow control configured.

		/* Read the MII Status Register and check to see if AutoNeg

		 * has completed.  We read this twice because this reg has

		 * some "sticky" (latched) bits.

		/* The AutoNeg process has completed, so we now need to

		 * read both the Auto Negotiation Advertisement

		 * Register (Address 4) and the Auto_Negotiation Base

		 * Page Ability Register (Address 5) to determine how

		 * flow control was negotiated.

		/* Two bits in the Auto Negotiation Advertisement Register

		 * (Address 4) and two bits in the Auto Negotiation Base

		 * Page Ability Register (Address 5) determine flow control

		 * for both the PHY and the link partner.  The following

		 * table, taken out of the IEEE 802.3ab/D6.0 dated March 25,

		 * 1999, describes these PAUSE resolution bits and how flow

		 * control is determined based upon these settings.

		 * NOTE:  DC = Don't Care

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | NIC Resolution

		 *-------|---------|-------|---------|--------------------

		 *   0   |    0    |  DC   |   DC    | e1000_fc_none

		 *   0   |    1    |   0   |   DC    | e1000_fc_none

		 *   0   |    1    |   1   |    0    | e1000_fc_none

		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause

		 *   1   |    0    |   0   |   DC    | e1000_fc_none

		 *   1   |   DC    |   1   |   DC    | e1000_fc_full

		 *   1   |    1    |   0   |    0    | e1000_fc_none

		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause

		 *

		 * Are both PAUSE bits set to 1?  If so, this implies

		 * Symmetric Flow Control is enabled at both ends.  The

		 * ASM_DIR bits are irrelevant per the spec.

		 *

		 * For Symmetric Flow Control:

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   1   |   DC    |   1   |   DC    | E1000_fc_full

		 *

			/* Now we need to check if the user selected RX ONLY

			 * of pause frames.  In this case, we had to advertise

			 * FULL flow control because we could not advertise RX

			 * ONLY. Hence, we must now check to see if we need to

			 * turn OFF  the TRANSMISSION of PAUSE frames.

		/* For receiving PAUSE frames ONLY.

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause

		/* For transmitting PAUSE frames ONLY.

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause

		/* Per the IEEE spec, at this point flow control should be

		 * disabled.  However, we want to consider that we could

		 * be connected to a legacy switch that doesn't advertise

		 * desired flow control, but can be forced on the link

		 * partner.  So if we advertised no flow control, that is

		 * what we will resolve to.  If we advertised some kind of

		 * receive capability (Rx Pause Only or Full Flow Control)

		 * and the link partner advertised none, we will configure

		 * ourselves to enable Rx Flow Control only.  We can do

		 * this safely for two reasons:  If the link partner really

		 * didn't want flow control enabled, and we enable Rx, no

		 * harm done since we won't be receiving any PAUSE frames

		 * anyway.  If the intent on the link partner was to have

		 * flow control enabled, then by us enabling RX only, we

		 * can at least receive pause frames and process them.

		 * This is a good idea because in most cases, since we are

		 * predominantly a server NIC, more times than not we will

		 * be asked to delay transmission of packets than asking

		 * our link partner to pause transmission of frames.

		/* Now we need to do one last check...  If we auto-

		 * negotiated to HALF DUPLEX, flow control should not be

		 * enabled per IEEE 802.3 spec.

		/* Now we call a subroutine to actually force the MAC

		 * controller to use the correct flow control settings.

	/* Check for the case where we have SerDes media and auto-neg is

	 * enabled.  In this case, we need to check and see if Auto-Neg

	 * has completed, and if so, how the PHY and link partner has

	 * flow control configured.

		/* Read the PCS_LSTS and check to see if AutoNeg

		 * has completed.

		/* The AutoNeg process has completed, so we now need to

		 * read both the Auto Negotiation Advertisement

		 * Register (PCS_ANADV) and the Auto_Negotiation Base

		 * Page Ability Register (PCS_LPAB) to determine how

		 * flow control was negotiated.

		/* Two bits in the Auto Negotiation Advertisement Register

		 * (PCS_ANADV) and two bits in the Auto Negotiation Base

		 * Page Ability Register (PCS_LPAB) determine flow control

		 * for both the PHY and the link partner.  The following

		 * table, taken out of the IEEE 802.3ab/D6.0 dated March 25,

		 * 1999, describes these PAUSE resolution bits and how flow

		 * control is determined based upon these settings.

		 * NOTE:  DC = Don't Care

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | NIC Resolution

		 *-------|---------|-------|---------|--------------------

		 *   0   |    0    |  DC   |   DC    | e1000_fc_none

		 *   0   |    1    |   0   |   DC    | e1000_fc_none

		 *   0   |    1    |   1   |    0    | e1000_fc_none

		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause

		 *   1   |    0    |   0   |   DC    | e1000_fc_none

		 *   1   |   DC    |   1   |   DC    | e1000_fc_full

		 *   1   |    1    |   0   |    0    | e1000_fc_none

		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause

		 *

		 * Are both PAUSE bits set to 1?  If so, this implies

		 * Symmetric Flow Control is enabled at both ends.  The

		 * ASM_DIR bits are irrelevant per the spec.

		 *

		 * For Symmetric Flow Control:

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   1   |   DC    |   1   |   DC    | e1000_fc_full

		 *

			/* Now we need to check if the user selected Rx ONLY

			 * of pause frames.  In this case, we had to advertise

			 * FULL flow control because we could not advertise Rx

			 * ONLY. Hence, we must now check to see if we need to

			 * turn OFF the TRANSMISSION of PAUSE frames.

		/* For receiving PAUSE frames ONLY.

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause

		/* For transmitting PAUSE frames ONLY.

		 *

		 *   LOCAL DEVICE  |   LINK PARTNER

		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

		 *-------|---------|-------|---------|--------------------

		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause

			/* Per the IEEE spec, at this point flow control

			 * should be disabled.

		/* Now we call a subroutine to actually force the MAC

		 * controller to use the correct flow control settings.

/**

 *  igb_get_speed_and_duplex_copper - Retrieve current speed/duplex

 *  @hw: pointer to the HW structure

 *  @speed: stores the current speed

 *  @duplex: stores the current duplex

 *

 *  Read the status register for the current speed/duplex and store the current

 *  speed and duplex for copper connections.

/**

 *  igb_get_hw_semaphore - Acquire hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Acquire the HW semaphore to access the PHY or NVM

 Get the SW semaphore */

 Get the FW semaphore. */

 Semaphore acquired if bit latched */

 Release semaphores */

/**

 *  igb_put_hw_semaphore - Release hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Release hardware semaphore used to access the PHY or NVM

/**

 *  igb_get_auto_rd_done - Check for auto read completion

 *  @hw: pointer to the HW structure

 *

 *  Check EEPROM for Auto Read done bit.

/**

 *  igb_valid_led_default - Verify a valid default LED config

 *  @hw: pointer to the HW structure

 *  @data: pointer to the NVM (EEPROM)

 *

 *  Read the EEPROM for the current default LED configuration.  If the

 *  LED configuration is not valid, set to a valid LED configuration.

/**

 *  igb_id_led_init -

 *  @hw: pointer to the HW structure

 *

 i210 and i211 devices have different LED mechanism */

 Do nothing */

 Do nothing */

/**

 *  igb_cleanup_led - Set LED config to default operation

 *  @hw: pointer to the HW structure

 *

 *  Remove the current LED configuration and set the LED configuration

 *  to the default value, saved from the EEPROM.

/**

 *  igb_blink_led - Blink LED

 *  @hw: pointer to the HW structure

 *

 *  Blink the led's which are set to be on.

 always blink LED0 for PCI-E fiber */

		/* Set the blink bit for each LED that's "on" (0x0E)

		 * (or "off" if inverted) in ledctl_mode2.  The blink

		 * logic in hardware only works when mode is set to "on"

		 * so it must be changed accordingly when the mode is

		 * "off" and inverted.

/**

 *  igb_led_off - Turn LED off

 *  @hw: pointer to the HW structure

 *

 *  Turn LED off.

/**

 *  igb_disable_pcie_master - Disables PCI-express master access

 *  @hw: pointer to the HW structure

 *

 *  Returns 0 (0) if successful, else returns -10

 *  (-E1000_ERR_MASTER_REQUESTS_PENDING) if master disable bit has not caused

 *  the master requests to be disabled.

 *

 *  Disables PCI-Express master access and verifies there are no pending

 *  requests.

/**

 *  igb_validate_mdi_setting - Verify MDI/MDIx settings

 *  @hw: pointer to the HW structure

 *

 *  Verify that when not using auto-negotitation that MDI/MDIx is correctly

 *  set, which is forced to MDI mode only.

 All MDI settings are supported on 82580 and newer. */

/**

 *  igb_write_8bit_ctrl_reg - Write a 8bit CTRL register

 *  @hw: pointer to the HW structure

 *  @reg: 32bit register offset such as E1000_SCTL

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Writes an address/data control type register.  There are several of these

 *  and they all have the format address << 8 | data and bit 31 is polled for

 *  completion.

 Set up the address and data */

 Poll the ready bit to see if the MDI read completed */

/**

 *  igb_enable_mng_pass_thru - Enable processing of ARP's

 *  @hw: pointer to the HW structure

 *

 *  Verifies the hardware needs to leave interface enabled so that frames can

 *  be directed to and from the management interface.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2007 - 2018 Intel Corporation. */

/**

 *  igb_raise_eec_clk - Raise EEPROM clock

 *  @hw: pointer to the HW structure

 *  @eecd: pointer to the EEPROM

 *

 *  Enable/Raise the EEPROM clock bit.

/**

 *  igb_lower_eec_clk - Lower EEPROM clock

 *  @hw: pointer to the HW structure

 *  @eecd: pointer to the EEPROM

 *

 *  Clear/Lower the EEPROM clock bit.

/**

 *  igb_shift_out_eec_bits - Shift data bits our to the EEPROM

 *  @hw: pointer to the HW structure

 *  @data: data to send to the EEPROM

 *  @count: number of bits to shift out

 *

 *  We need to shift 'count' bits out to the EEPROM.  So, the value in the

 *  "data" parameter will be shifted out to the EEPROM one bit at a time.

 *  In order to do this, "data" must be broken down into bits.

/**

 *  igb_shift_in_eec_bits - Shift data bits in from the EEPROM

 *  @hw: pointer to the HW structure

 *  @count: number of bits to shift in

 *

 *  In order to read a register from the EEPROM, we need to shift 'count' bits

 *  in from the EEPROM.  Bits are "shifted in" by raising the clock input to

 *  the EEPROM (setting the SK bit), and then reading the value of the data out

 *  "DO" bit.  During this "shifting in" process the data in "DI" bit should

 *  always be clear.

/**

 *  igb_poll_eerd_eewr_done - Poll for EEPROM read/write completion

 *  @hw: pointer to the HW structure

 *  @ee_reg: EEPROM flag for polling

 *

 *  Polls the EEPROM status bit for either read or write completion based

 *  upon the value of 'ee_reg'.

/**

 *  igb_acquire_nvm - Generic request for access to EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Set the EEPROM access request bit and wait for EEPROM access grant bit.

 *  Return successful if access grant bit set, else clear the request for

 *  EEPROM access and return -E1000_ERR_NVM (-1).

/**

 *  igb_standby_nvm - Return EEPROM to standby state

 *  @hw: pointer to the HW structure

 *

 *  Return the EEPROM to a standby state.

 Toggle CS to flush commands */

/**

 *  e1000_stop_nvm - Terminate EEPROM command

 *  @hw: pointer to the HW structure

 *

 *  Terminates the current command by inverting the EEPROM's chip select pin.

 Pull CS high */

/**

 *  igb_release_nvm - Release exclusive access to EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Stop any current commands to the EEPROM and clear the EEPROM request bit.

/**

 *  igb_ready_nvm_eeprom - Prepares EEPROM for read/write

 *  @hw: pointer to the HW structure

 *

 *  Setups the EEPROM for reading and writing.

 Clear SK and CS */

		/* Read "Status Register" repeatedly until the LSB is cleared.

		 * The EEPROM will signal that the command has been completed

		 * by clearing bit 0 of the internal status register.  If it's

		 * not cleared within 'timeout', then error out.

/**

 *  igb_read_nvm_spi - Read EEPROM's using SPI

 *  @hw: pointer to the HW structure

 *  @offset: offset of word in the EEPROM to read

 *  @words: number of words to read

 *  @data: word read from the EEPROM

 *

 *  Reads a 16 bit word from the EEPROM.

	/* A check for invalid values:  offset too large, too many words,

	 * and not enough words.

 Send the READ command (opcode + addr) */

	/* Read the data.  SPI NVMs increment the address with each byte

	 * read and will roll over if reading beyond the end.  This allows

	 * us to read the whole NVM from any offset

/**

 *  igb_read_nvm_eerd - Reads EEPROM using EERD register

 *  @hw: pointer to the HW structure

 *  @offset: offset of word in the EEPROM to read

 *  @words: number of words to read

 *  @data: word read from the EEPROM

 *

 *  Reads a 16 bit word from the EEPROM using the EERD register.

	/* A check for invalid values:  offset too large, too many words,

	 * and not enough words.

/**

 *  igb_write_nvm_spi - Write to EEPROM using SPI

 *  @hw: pointer to the HW structure

 *  @offset: offset within the EEPROM to be written to

 *  @words: number of words to write

 *  @data: 16 bit word(s) to be written to the EEPROM

 *

 *  Writes data to EEPROM at offset using SPI interface.

 *

 *  If e1000_update_nvm_checksum is not called after this function , the

 *  EEPROM will most likley contain an invalid checksum.

	/* A check for invalid values:  offset too large, too many words,

	 * and not enough words.

 Send the WRITE ENABLE command (8 bit opcode) */

		/* Some SPI eeproms use the 8th address bit embedded in the

		 * opcode

 Send the Write command (8-bit opcode + addr) */

 Loop to allow for up to whole page write of eeprom */

/**

 *  igb_read_part_string - Read device part number

 *  @hw: pointer to the HW structure

 *  @part_num: pointer to device part number

 *  @part_num_size: size of part number buffer

 *

 *  Reads the product board assembly (PBA) number from the EEPROM and stores

 *  the value in part_num.

	/* if nvm_data is not ptr guard the PBA must be in legacy format which

	 * means pointer is actually our second data word for the PBA number

	 * and we can decode it into an ascii string

 we will need 11 characters to store the PBA */

 extract hex string from data and pointer */

 put a null character on the end of our string */

 switch all the data but the '-' to hex char */

 check if part_num buffer is big enough */

 trim pba length from start of string */

/**

 *  igb_read_mac_addr - Read device MAC address

 *  @hw: pointer to the HW structure

 *

 *  Reads the device MAC address from the EEPROM and stores the value.

 *  Since devices with two ports use the same EEPROM, we increment the

 *  last bit in the MAC address for the second port.

/**

 *  igb_validate_nvm_checksum - Validate EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Calculates the EEPROM checksum by reading/adding each word of the EEPROM

 *  and then verifies that the sum of the EEPROM is equal to 0xBABA.

/**

 *  igb_update_nvm_checksum - Update EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Updates the EEPROM checksum by reading/adding each word of the EEPROM

 *  up to the checksum.  Then calculates the EEPROM checksum and writes the

 *  value to the EEPROM.

/**

 *  igb_get_fw_version - Get firmware version information

 *  @hw: pointer to the HW structure

 *  @fw_vers: pointer to output structure

 *

 *  unsupported MAC types will return all 0 version structure

	/* basic eeprom version numbers and bits used vary by part and by tool

	 * used to create the nvm images. Check which data format we have.

		/* Use this format, unless EETRACK ID exists,

		 * then use alternate format

 find combo image version */

 get Option Rom version if it exists and is valid */

 check for old style version format in newer images*/

	/* Convert minor value to hex before assigning to output struct

	 * Val to be converted will not be higher than 99, per tool output

 SPDX-License-Identifier: GPL-2.0+

 Copyright (C) 2011 Richard Cochran <richardcochran@gmail.com> */

/* The 82580 timesync updates the system timer every 8ns by 8ns,

 * and this update value cannot be reprogrammed.

 *

 * Neither the 82576 nor the 82580 offer registers wide enough to hold

 * nanoseconds time values for very long. For the 82580, SYSTIM always

 * counts nanoseconds, but the upper 24 bits are not available. The

 * frequency is adjusted by changing the 32 bit fractional nanoseconds

 * register, TIMINCA.

 *

 * For the 82576, the SYSTIM register time unit is affect by the

 * choice of the 24 bit TININCA:IV (incvalue) field. Five bits of this

 * field are needed to provide the nominal 16 nanosecond period,

 * leaving 19 bits for fractional nanoseconds.

 *

 * We scale the NIC clock cycle by a large factor so that relatively

 * small clock corrections can be added or subtracted at each clock

 * tick. The drawbacks of a large factor are a) that the clock

 * register overflows more quickly (not such a big deal) and b) that

 * the increment per tick has to fit into 24 bits.  As a result we

 * need to use a shift of 19 so we can fit a value of 16 into the

 * TIMINCA register.

 *

 *

 *             SYSTIMH            SYSTIML

 *        +--------------+   +---+---+------+

 *  82576 |      32      |   | 8 | 5 |  19  |

 *        +--------------+   +---+---+------+

 *         \________ 45 bits _______/  fract

 *

 *        +----------+---+   +--------------+

 *  82580 |    24    | 8 |   |      32      |

 *        +----------+---+   +--------------+

 *          reserved  \______ 40 bits _____/

 *

 *

 * The 45 bit 82576 SYSTIM overflows every

 *   2^45 * 10^-9 / 3600 = 9.77 hours.

 *

 * The 40 bit 82580 SYSTIM overflows every

 *   2^40 * 10^-9 /  60  = 18.3 minutes.

 *

 * SYSTIM is converted to real time using a timecounter. As

 * timecounter_cyc2time() allows old timestamps, the timecounter needs

 * to be updated at least once per half of the SYSTIM interval.

 * Scheduling of delayed work is not very accurate, and also the NIC

 * clock can be adjusted to run up to 6% faster and the system clock

 * up to 10% slower, so we aim for 6 minutes to be sure the actual

 * interval in the NIC time is shorter than 9.16 minutes.

 SYSTIM read access for the 82576 */

 SYSTIM read access for the 82580 */

	/* The timestamp latches on lowest register read. For the 82580

	 * the lowest register is SYSTIMR instead of SYSTIML.  However we only

	 * need to provide nanosecond resolution, so we just ignore it.

 SYSTIM read access for I210/I211 */

	/* The timestamp latches on lowest register read. For I210/I211, the

	 * lowest register is SYSTIMR. Since we only need to provide nanosecond

	 * resolution, we can ignore it.

	/* Writing the SYSTIMR register is not necessary as it only provides

	 * sub-nanosecond resolution.

/**

 * igb_ptp_systim_to_hwtstamp - convert system time value to hw timestamp

 * @adapter: board private structure

 * @hwtstamps: timestamp structure to update

 * @systim: unsigned 64bit system time value.

 *

 * We need to convert the system time value stored in the RX/TXSTMP registers

 * into a hwtstamp which can be used by the upper level timestamping functions.

 *

 * The 'tmreg_lock' spinlock is used to protect the consistency of the

 * system time value. This is needed because reading the 64 bit time

 * value involves reading two (or three) 32 bit registers. The first

 * read latches the value. Ditto for writing.

 *

 * In addition, here have extended the system time with an overflow

 * counter in software.

 Upper 32 bits contain s, lower 32 bits contain ns. */

 PTP clock operations */

 Make sure this pin is not enabled as an output. */

 Make sure this pin is not enabled as an input. */

 Reject requests with unsupported flags */

 Reject requests failing to enable both edges. */

 Reject requests with unsupported flags */

/**

 * igb_ptp_tx_work

 * @work: pointer to work struct

 *

 * This work function polls the TSYNCTXCTL valid bit to determine when a

 * timestamp has been taken for the current stored skb.

		/* Clear the tx valid bit in TSYNCTXCTL register to enable

		 * interrupt

 reschedule to check later */

 Update the timecounter */

/**

 * igb_ptp_rx_hang - detect error case when Rx timestamp registers latched

 * @adapter: private network adapter structure

 *

 * This watchdog task is scheduled to detect error case where hardware has

 * dropped an Rx packet that was timestamped when the ring is full. The

 * particular error is rare but leaves the device in a state unable to timestamp

 * any future packets.

 Other hardware uses per-packet timestamps */

	/* If we don't have a valid timestamp in the registers, just update the

	 * timeout counter and exit

 Determine the most recent watchdog or rx_timestamp event */

 Only need to read the high RXSTMP register to clear the lock */

/**

 * igb_ptp_tx_hang - detect error case where Tx timestamp never finishes

 * @adapter: private network adapter structure

	/* If we haven't received a timestamp within the timeout, it is

	 * reasonable to assume that it will never occur, so we can unlock the

	 * timestamp bit when this occurs.

		/* Clear the tx valid bit in TSYNCTXCTL register to enable

		 * interrupt

/**

 * igb_ptp_tx_hwtstamp - utility function which checks for TX time stamp

 * @adapter: Board private structure.

 *

 * If we were asked to do hardware stamping and such a time stamp is

 * available, then it must have been for this skb here because we only

 * allow only one such packet into the queue.

 adjust timestamp for the TX latency based on link speed */

	/* Clear the lock early before calling skb_tstamp_tx so that

	 * applications are not woken up before the lock bit is clear. We use

	 * a copy of the skb pointer to ensure other threads can't change it

	 * while we're notifying the stack.

 Notify the stack and free the skb after we've unlocked */

/**

 * igb_ptp_rx_pktstamp - retrieve Rx per packet timestamp

 * @q_vector: Pointer to interrupt specific structure

 * @va: Pointer to address containing Rx buffer

 * @timestamp: Pointer where timestamp will be stored

 *

 * This function is meant to retrieve a timestamp from the first buffer of an

 * incoming frame.  The value is stored in little endian format starting on

 * byte 8

 *

 * Returns: The timestamp header length or 0 if not available

	/* The timestamp is recorded in little endian format.

	 * DWORD: 0        1        2        3

	 * Field: Reserved Reserved SYSTIML  SYSTIMH

 check reserved dwords are zero, be/le doesn't matter for zero */

 adjust timestamp for the RX latency based on link speed */

/**

 * igb_ptp_rx_rgtstamp - retrieve Rx timestamp stored in register

 * @q_vector: Pointer to interrupt specific structure

 * @skb: Buffer containing timestamp and packet

 *

 * This function is meant to retrieve a timestamp from the internal registers

 * of the adapter and store it in the skb.

	/* If this bit is set, then the RX registers contain the time stamp. No

	 * other packet will be time stamped until we read these registers, so

	 * read the registers to make them available again. Because only one

	 * packet can be time stamped at a time, we know that the register

	 * values must belong to this one here and therefore we don't need to

	 * compare any of the additional attributes stored for it.

	 *

	 * If nothing went wrong, then it should have a shared tx_flags that we

	 * can turn into a skb_shared_hwtstamps.

 adjust timestamp for the RX latency based on link speed */

	/* Update the last_rx_timestamp timer in order to enable watchdog check

	 * for error case of latched timestamp on a dropped packet.

/**

 * igb_ptp_get_ts_config - get hardware time stamping config

 * @netdev: netdev struct

 * @ifr: interface struct

 *

 * Get the hwtstamp_config settings to return to the user. Rather than attempt

 * to deconstruct the settings from the registers, just return a shadow copy

 * of the last known settings.

/**

 * igb_ptp_set_timestamp_mode - setup hardware for timestamping

 * @adapter: networking device structure

 * @config: hwtstamp configuration

 *

 * Outgoing time stamping can be enabled and disabled. Play nice and

 * disable it when requested, although it shouldn't case any overhead

 * when no packet needs it. At most one packet in the queue may be

 * marked for time stamping, otherwise it would be impossible to tell

 * for sure to which packet the hardware time stamp belongs.

 *

 * Incoming time stamping has to be configured via the hardware

 * filters. Not all combinations are supported, in particular event

 * type has to be specified. Matching the kind of event packet is

 * not supported, with the exception of "all V2 events regardless of

 * level 2 or 4".

 reserved for future extensions */

		/* 82576 cannot timestamp all packets, which it needs to do to

		 * support both V1 Sync and Delay_Req messages

	/* Per-packet timestamping only works if all packets are

	 * timestamped, so enable timestamping in all packets as

	 * long as one Rx filter was configured.

 enable/disable TX */

 enable/disable RX */

 define which PTP packets are time stamped */

 define ethertype filter for timestamped packets */

 enable filter */

 enable timestamping */

 1588 eth protocol type */

 L4 Queue Filter[3]: filter by destination port and protocol */

 UDP */

 VF not compared */

 Enable Timestamping */

 mask all inputs */

 enable protocol check */

 enable source port check */

 clear TX/RX time stamp registers, just to be sure */

/**

 * igb_ptp_set_ts_config - set hardware time stamping config

 * @netdev: netdev struct

 * @ifr: interface struct

 *

 save these settings for future reference */

/**

 * igb_ptp_init - Initialize PTP functionality

 * @adapter: Board private structure

 *

 * This function is called at device probe to initialize the PTP

 * functionality.

/**

 * igb_ptp_suspend - Disable PTP work items and prepare for suspend

 * @adapter: Board private structure

 *

 * This function stops the overflow check work and PTP Tx timestamp work, and

 * will prepare the device for OS suspend.

/**

 * igb_ptp_stop - Disable PTP device and stop the overflow check.

 * @adapter: Board private structure.

 *

 * This function stops the PTP support and cancels the delayed work.

/**

 * igb_ptp_reset - Re-enable the adapter for PTP following a reset.

 * @adapter: Board private structure.

 *

 * This function handles the reset work required to re-enable the PTP device.

 reset the tstamp_config */

 Dial the nominal frequency. */

 No work to do. */

 Re-initialize the timer. */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2007 - 2018 Intel Corporation. */

/**

 *  igb_read_mbx - Reads a message from the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @mbx_id: id of mailbox to read

 *  @unlock: skip locking or not

 *

 *  returns SUCCESS if it successfully read message from buffer

 limit read to size of mailbox */

/**

 *  igb_write_mbx - Write a message to the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully copied message into the buffer

/**

 *  igb_check_for_msg - checks to see if someone sent us mail

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to check

 *

 *  returns SUCCESS if the Status bit was found or else ERR_MBX

/**

 *  igb_check_for_ack - checks to see if someone sent us ACK

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to check

 *

 *  returns SUCCESS if the Status bit was found or else ERR_MBX

/**

 *  igb_check_for_rst - checks to see if other side has reset

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to check

 *

 *  returns SUCCESS if the Status bit was found or else ERR_MBX

/**

 *  igb_unlock_mbx - unlock the mailbox

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to check

 *

 *  returns SUCCESS if the mailbox was unlocked or else ERR_MBX

/**

 *  igb_poll_for_msg - Wait for message notification

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully received a message notification

 if we failed, all future posted messages fail until reset */

/**

 *  igb_poll_for_ack - Wait for message acknowledgement

 *  @hw: pointer to the HW structure

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully received a message acknowledgement

 if we failed, all future posted messages fail until reset */

/**

 *  igb_read_posted_mbx - Wait for message notification and receive message

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully received a message notification and

 *  copied it into the receive buffer.

/**

 *  igb_write_posted_mbx - Write a message to the mailbox, wait for ack

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @mbx_id: id of mailbox to write

 *

 *  returns SUCCESS if it successfully copied message into the buffer and

 *  received an ack to that message within delay * timeout period

 exit if either we can't write or there isn't a defined timeout */

 send msg */

 if msg sent wait until we receive an ack */

/**

 *  igb_check_for_msg_pf - checks to see if the VF has sent mail

 *  @hw: pointer to the HW structure

 *  @vf_number: the VF index

 *

 *  returns SUCCESS if the VF has set the Status bit or else ERR_MBX

/**

 *  igb_check_for_ack_pf - checks to see if the VF has ACKed

 *  @hw: pointer to the HW structure

 *  @vf_number: the VF index

 *

 *  returns SUCCESS if the VF has set the Status bit or else ERR_MBX

/**

 *  igb_check_for_rst_pf - checks to see if the VF has reset

 *  @hw: pointer to the HW structure

 *  @vf_number: the VF index

 *

 *  returns SUCCESS if the VF has set the Status bit or else ERR_MBX

/**

 *  igb_obtain_mbx_lock_pf - obtain mailbox lock

 *  @hw: pointer to the HW structure

 *  @vf_number: the VF index

 *

 *  return SUCCESS if we obtained the mailbox lock

 Take ownership of the buffer */

 reserve mailbox for vf use */

/**

 *  igb_release_mbx_lock_pf - release mailbox lock

 *  @hw: pointer to the HW structure

 *  @vf_number: the VF index

 *

 *  return SUCCESS if we released the mailbox lock

 drop PF lock of mailbox, if set */

/**

 *  igb_write_mbx_pf - Places a message in the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @vf_number: the VF index

 *

 *  returns SUCCESS if it successfully copied message into the buffer

 lock the mailbox to prevent pf/vf race condition */

 flush msg and acks as we are overwriting the message buffer */

 copy the caller specified message to the mailbox memory buffer */

 Interrupt VF to tell it a message has been sent and release buffer*/

 update stats */

/**

 *  igb_read_mbx_pf - Read a message from the mailbox

 *  @hw: pointer to the HW structure

 *  @msg: The message buffer

 *  @size: Length of buffer

 *  @vf_number: the VF index

 *  @unlock: unlock the mailbox when done?

 *

 *  This function copies a message from the mailbox buffer to the caller's

 *  memory buffer.  The presumption is that the caller knows that there was

 *  a message due to a VF request so no polling for message is needed.

 lock the mailbox to prevent pf/vf race condition */

 copy the message to the mailbox memory buffer */

 Acknowledge the message and release mailbox lock (or not) */

 update stats */

/**

 *  igb_init_mbx_params_pf - set initial values for pf mailbox

 *  @hw: pointer to the HW structure

 *

 *  Initializes the hw->mbx struct to correct values for pf mailbox

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2007 - 2018 Intel Corporation. */

/* e1000_82575

 * e1000_82576

/* Due to a hw errata, if the host tries to  configure the VFTA register

 * while performing queries from the BMC or DMA, then the VFTA in some

 * cases won't be written.

/**

 *  igb_write_vfta_i350 - Write value to VLAN filter table

 *  @hw: pointer to the HW structure

 *  @offset: register offset in VLAN filter table

 *  @value: register value written to VLAN filter table

 *

 *  Writes value at the given offset in the register array which stores

 *  the VLAN filter table.

/**

 *  igb_sgmii_uses_mdio_82575 - Determine if I2C pins are for external MDIO

 *  @hw: pointer to the HW structure

 *

 *  Called to determine if the I2C pins are being used for I2C or as an

 *  external MDIO interface since the two options are mutually exclusive.

/**

 *  igb_check_for_link_media_swap - Check which M88E1112 interface linked

 *  @hw: pointer to the HW structure

 *

 *  Poll the M88E1112 interfaces to see which interface achieved link.

 Check the copper medium. */

 Check the other medium. */

 Determine if a swap needs to happen. */

 reset page to 0 */

 reset page to 0 */

/**

 *  igb_init_phy_params_82575 - Init PHY func ptrs.

 *  @hw: pointer to the HW structure

 set lan id */

 Set phy->phy_addr and phy->id. */

 Verify phy id and set remaining function pointers */

 Check if this PHY is configured for media swap. */

/**

 *  igb_init_nvm_params_82575 - Init NVM func ptrs.

 *  @hw: pointer to the HW structure

	/* Added to a constant, "size" becomes the left-shift value

	 * for setting word_size.

	/* Just in case size is out of range, cap it to the largest

	 * EEPROM size supported

 NVM Function Pointers */

 override generic family function pointers for specific descendants */

/**

 *  igb_init_mac_params_82575 - Init MAC func ptrs.

 *  @hw: pointer to the HW structure

 Set mta register count */

 Set uta register count */

 Set rar entry count */

 reset */

 Set if part includes ASF firmware */

 Set if manageability features are enabled. */

 enable EEE on i350 parts and later parts */

 Allow a single clear of the SW semaphore on I210 and newer */

 physical interface link setup */

 feature not supported on these id's */

/**

 *  igb_set_sfp_media_type_82575 - derives SFP module media type.

 *  @hw: pointer to the HW structure

 *

 *  The media type is chosen based on SFP module.

 *  compatibility flags retrieved from SFP ID EEPROM.

 Turn I2C interface ON and power on sfp cage */

 Read SFP module data */

 Check if there is some SFP module plugged and powered */

 Restore I2C interface setting */

 Set media type */

	/* The 82575 uses bits 22:23 for link mode. The mode can be changed

	 * based on the EEPROM. We cannot rely upon device ID. There

	 * is no distinguishable difference between fiber and internal

	 * SerDes mode on the 82575. There can be an external PHY attached

	 * on the SGMII interface. For this, we'll set sgmii_active to true.

 Get phy control interface type set (MDIO vs. I2C)*/

 for I2C based SGMII */

 read media type from SFP EEPROM */

			/* If media type was not identified then return media

			 * type defined by the CTRL_EXT settings.

 change current link mode setting */

 mac initialization and operations */

 NVM initialization */

 if part supports SR-IOV then initialize mailbox parameters */

 setup PHY parameters */

/**

 *  igb_acquire_phy_82575 - Acquire rights to access PHY

 *  @hw: pointer to the HW structure

 *

 *  Acquire access rights to the correct PHY.  This is a

 *  function pointer entry point called by the api module.

/**

 *  igb_release_phy_82575 - Release rights to access PHY

 *  @hw: pointer to the HW structure

 *

 *  A wrapper to release access rights to the correct PHY.  This is a

 *  function pointer entry point called by the api module.

/**

 *  igb_read_phy_reg_sgmii_82575 - Read PHY register using sgmii

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Reads the PHY register at offset using the serial gigabit media independent

 *  interface and stores the retrieved information in data.

/**

 *  igb_write_phy_reg_sgmii_82575 - Write PHY register using sgmii

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Writes the data to PHY register at the offset using the serial gigabit

 *  media independent interface.

/**

 *  igb_get_phy_id_82575 - Retrieve PHY addr and id

 *  @hw: pointer to the HW structure

 *

 *  Retrieves the PHY address and ID for both PHY's which do and do not use

 *  sgmi interface.

 Extra read required for some PHY's on i354 */

	/* For SGMII PHYs, we try the list of possible addresses until

	 * we find one that works.  For non-SGMII PHYs

	 * (e.g. integrated copper PHYs), an address of 1 should

	 * work.  The result of this function should mean phy->phy_addr

	 * and phy->id are set correctly.

 Power on sgmii phy if it is disabled */

	/* The address field in the I2CCMD register is 3 bits and 0 is invalid.

	 * Therefore, we need to test 1-7

			/* At the time of this writing, The M88 part is

			 * the only supported SGMII PHY product.

 A valid PHY type couldn't be found. */

 restore previous sfp cage power state */

/**

 *  igb_phy_hw_reset_sgmii_82575 - Performs a PHY reset

 *  @hw: pointer to the HW structure

 *

 *  Resets the PHY using the serial gigabit media independent interface.

	/* This isn't a true "hard" reset, but is the only reset

	 * available to us at this time.

	/* SFP documentation requires the following to configure the SPF module

	 * to work on SGMII.  No further documentation is given.

/**

 *  igb_set_d0_lplu_state_82575 - Set Low Power Linkup D0 state

 *  @hw: pointer to the HW structure

 *  @active: true to enable LPLU, false to disable

 *

 *  Sets the LPLU D0 state according to the active flag.  When

 *  activating LPLU this function also disables smart speed

 *  and vice versa.  LPLU will not be activated unless the

 *  device autonegotiation advertisement meets standards of

 *  either 10 or 10/100 or 10/100/1000 at all duplexes.

 *  This is a function pointer entry point only called by

 *  PHY setup routines.

 When LPLU is enabled, we should disable SmartSpeed */

		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used

		 * during Dx states where the power conservation is most

		 * important.  During driver activity we should enable

		 * SmartSpeed, so performance is maintained.

/**

 *  igb_set_d0_lplu_state_82580 - Set Low Power Linkup D0 state

 *  @hw: pointer to the HW structure

 *  @active: true to enable LPLU, false to disable

 *

 *  Sets the LPLU D0 state according to the active flag.  When

 *  activating LPLU this function also disables smart speed

 *  and vice versa.  LPLU will not be activated unless the

 *  device autonegotiation advertisement meets standards of

 *  either 10 or 10/100 or 10/100/1000 at all duplexes.

 *  This is a function pointer entry point only called by

 *  PHY setup routines.

 When LPLU is enabled, we should disable SmartSpeed */

		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used

		 * during Dx states where the power conservation is most

		 * important.  During driver activity we should enable

		 * SmartSpeed, so performance is maintained.

/**

 *  igb_set_d3_lplu_state_82580 - Sets low power link up state for D3

 *  @hw: pointer to the HW structure

 *  @active: boolean used to enable/disable lplu

 *

 *  Success returns 0, Failure returns 1

 *

 *  The low power link up (lplu) state is set to the power management level D3

 *  and SmartSpeed is disabled when active is true, else clear lplu for D3

 *  and enable Smartspeed.  LPLU and Smartspeed are mutually exclusive.  LPLU

 *  is used during Dx states where the power conservation is most important.

 *  During driver activity, SmartSpeed should be enabled so performance is

 *  maintained.

		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used

		 * during Dx states where the power conservation is most

		 * important.  During driver activity we should enable

		 * SmartSpeed, so performance is maintained.

 When LPLU is enabled, we should disable SmartSpeed */

/**

 *  igb_acquire_nvm_82575 - Request for access to EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Acquire the necessary semaphores for exclusive access to the EEPROM.

 *  Set the EEPROM access request bit and wait for EEPROM access grant bit.

 *  Return successful if access grant bit set, else clear the request for

 *  EEPROM access and return -E1000_ERR_NVM (-1).

/**

 *  igb_release_nvm_82575 - Release exclusive access to EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Stop any current commands to the EEPROM and clear the EEPROM request bit,

 *  then release the semaphores acquired.

/**

 *  igb_acquire_swfw_sync_82575 - Acquire SW/FW semaphore

 *  @hw: pointer to the HW structure

 *  @mask: specifies which semaphore to acquire

 *

 *  Acquire the SW/FW semaphore to access the PHY or NVM.  The mask

 *  will also specify which port we're acquiring the lock for.

		/* Firmware currently using resource (fwmask)

		 * or other software thread using resource (swmask)

/**

 *  igb_release_swfw_sync_82575 - Release SW/FW semaphore

 *  @hw: pointer to the HW structure

 *  @mask: specifies which semaphore to acquire

 *

 *  Release the SW/FW semaphore used to access the PHY or NVM.  The mask

 *  will also specify which port we're releasing the lock for.

 Empty */

/**

 *  igb_get_cfg_done_82575 - Read config done bit

 *  @hw: pointer to the HW structure

 *

 *  Read the management control register for the config done bit for

 *  completion status.  NOTE: silicon which is EEPROM-less will fail trying

 *  to read the config done bit, so an error is *ONLY* logged and returns

 *  0.  If we were to return with error, EEPROM-less silicon

 *  would not be able to be reset or change link.

 If EEPROM is not marked present, init the PHY manually */

/**

 *  igb_get_link_up_info_82575 - Get link speed/duplex info

 *  @hw: pointer to the HW structure

 *  @speed: stores the current speed

 *  @duplex: stores the current duplex

 *

 *  This is a wrapper function, if using the serial gigabit media independent

 *  interface, use PCS to retrieve the link speed and duplex information.

 *  Otherwise, use the generic function to get the link speed and duplex info.

/**

 *  igb_check_for_link_82575 - Check for link

 *  @hw: pointer to the HW structure

 *

 *  If sgmii is enabled, then use the pcs register to determine link, otherwise

 *  use the generic interface for determining link.

		/* Use this flag to determine if link needs to be checked or

		 * not.  If  we have link clear the flag so that we do not

		 * continue to check for link.

		/* Configure Flow Control now that Auto-Neg has completed.

		 * First, we need to restore the desired flow control

		 * settings because we may have had to re-autoneg with a

		 * different link partner.

/**

 *  igb_power_up_serdes_link_82575 - Power up the serdes link after shutdown

 *  @hw: pointer to the HW structure

 Enable PCS to turn on link */

 Power up the laser */

 flush the write to verify completion */

/**

 *  igb_get_pcs_speed_and_duplex_82575 - Retrieve current speed/duplex

 *  @hw: pointer to the HW structure

 *  @speed: stores the current speed

 *  @duplex: stores the current duplex

 *

 *  Using the physical coding sub-layer (PCS), retrieve the current speed and

 *  duplex, then store the values in the pointers provided.

 Set up defaults for the return values of this function */

	/* Read the PCS Status register for link state. For non-copper mode,

	 * the status register is not accurate. The PCS status register is

	 * used instead.

	/* The link up bit determines when link is up on autoneg. The sync ok

	 * gets set once both sides sync up and agree upon link. Stable link

	 * can be determined by checking for both link up and link sync ok

 Detect and store PCS speed */

 Detect and store PCS duplex */

 Check if it is an I354 2.5Gb backplane connection. */

/**

 *  igb_shutdown_serdes_link_82575 - Remove link during power down

 *  @hw: pointer to the HW structure

 *

 *  In the case of fiber serdes, shut down optics and PCS on driver unload

 *  when management pass thru is not enabled.

 Disable PCS to turn off link */

 shutdown the laser */

 flush the write to verify completion */

/**

 *  igb_reset_hw_82575 - Reset hardware

 *  @hw: pointer to the HW structure

 *

 *  This resets the hardware into a known state.  This is a

 *  function pointer entry point called by the api module.

	/* Prevent the PCI-E bus from sticking if there is no TLP connection

	 * on the last TLP read/write transaction when MAC is reset.

 set the completion timeout for interface */

		/* When auto config read does not complete, do not

		 * return with an error. This can happen in situations

		 * where there is no eeprom and prevents getting link.

 If EEPROM is not present, run manual init scripts */

 Clear any pending interrupt events. */

 Install any alternate MAC address into RAR0 */

/**

 *  igb_init_hw_82575 - Initialize hardware

 *  @hw: pointer to the HW structure

 *

 *  This inits the hardware readying it for operation.

 Initialize identification LED */

 This is not fatal and we should not stop init due to this */

 Disabling VLAN filtering */

 Setup the receive address */

 Zero out the Multicast HASH table */

 Zero out the Unicast HASH table */

 Setup link and flow control */

	/* Clear all of the statistics registers (clear on read).  It is

	 * important that we do this after we have tried to establish link

	 * because the symbol error count will increment wildly if there

	 * is no link.

/**

 *  igb_setup_copper_link_82575 - Configure copper link settings

 *  @hw: pointer to the HW structure

 *

 *  Configures the link for auto-neg or forced speed and duplex.  Then we check

 *  for link, once link is established calls to configure collision distance

 *  and flow control are called.

 Clear Go Link Disconnect bit on supported devices */

 allow time for SFP cage time to power up phy */

/**

 *  igb_setup_serdes_link_82575 - Setup link for serdes

 *  @hw: pointer to the HW structure

 *

 *  Configure the physical coding sub-layer (PCS) link.  The PCS link is

 *  used on copper connections where the serialized gigabit media independent

 *  interface (sgmii), or serdes fiber is being used.  Configures the link

 *  for auto-negotiation or forces speed/duplex.

	/* On the 82575, SerDes loopback mode persists until it is

	 * explicitly turned off or a power cycle is performed.  A read to

	 * the register does not indicate its status.  Therefore, we ensure

	 * loopback mode is disabled during initialization.

 power on the sfp cage if present and turn on I2C */

 set both sw defined pins */

 Set switch control to serdes energy detect */

 default pcs_autoneg to the same setting as mac autoneg */

 sgmii mode lets the phy handle forcing speed/duplex */

 autoneg time out should be disabled for SGMII mode */

 disable PCS autoneg and support parallel detect only */

		/* non-SGMII modes only supports a speed of 1000/Full for the

		 * link so it is best to just force the MAC and let the pcs

		 * link either autoneg or be forced to 1000/Full

 set speed of 1000/Full if speed/duplex is forced */

	/* New SerDes mode allows for forcing speed or autonegotiating speed

	 * at 1gb. Autoneg should be default set by most drivers. This is the

	 * mode that will be compatible with older link partners and switches.

	 * However, both are supported by the hardware and some drivers/tools.

 Set PCS register for autoneg */

 Enable Autoneg */

 Restart autoneg */

 Disable force flow control for autoneg */

 Configure flow control advertisement for autoneg */

 Set PCS register for forced link */

 Force Speed */

 Force flow control for forced link */

/**

 *  igb_sgmii_active_82575 - Return sgmii state

 *  @hw: pointer to the HW structure

 *

 *  82575 silicon has a serialized gigabit media independent interface (sgmii)

 *  which can be enabled for use in the embedded applications.  Simply

 *  return the current state of the sgmii interface.

/**

 *  igb_reset_init_script_82575 - Inits HW defaults after reset

 *  @hw: pointer to the HW structure

 *

 *  Inits recommended HW defaults after a reset when there is no EEPROM

 *  detected. This is only for the 82575.

 SerDes configuration via SERDESCTRL */

 CCM configuration via CCMCTL register */

 PCIe lanes configuration */

 PCIe PLL Configuration */

/**

 *  igb_read_mac_addr_82575 - Read device MAC address

 *  @hw: pointer to the HW structure

	/* If there's an alternate MAC address place it in RAR0

	 * so that it will override the Si installed default perm

	 * address.

/**

 * igb_power_down_phy_copper_82575 - Remove link during PHY power down

 * @hw: pointer to the HW structure

 *

 * In the case of a PHY power down to save power, or to turn off link during a

 * driver unload, or wake on lan is not enabled, remove the link.

 If the management interface is not enabled, then power down */

/**

 *  igb_clear_hw_cntrs_82575 - Clear device specific hardware counters

 *  @hw: pointer to the HW structure

 *

 *  Clears the hardware counters by reading the counter registers.

 This register should not be read in copper configurations */

/**

 *  igb_rx_fifo_flush_82575 - Clean rx fifo after RX enable

 *  @hw: pointer to the HW structure

 *

 *  After rx enable if manageability is enabled then there is likely some

 *  bad data at the start of the fifo and possibly in the DMA fifo. This

 *  function clears the fifos and flushes any packets that came in as rx was

 *  being enabled.

 disable IPv6 options as per hardware errata */

 Disable all RX queues */

 Poll all queues to verify they have shut down */

	/* Clear RLPML, RCTL.SBP, RFCTL.LEF, and set RCTL.LPE so that all

	 * incoming packets are rejected.  Set enable and wait 2ms so that

	 * any packet that was coming in as RCTL.EN was set is flushed

	/* Enable RX queues that were previously enabled and restore our

	 * previous state

 Flush receive errors generated by workaround */

/**

 *  igb_set_pcie_completion_timeout - set pci-e completion timeout

 *  @hw: pointer to the HW structure

 *

 *  The defaults for 82575 and 82576 should be in the range of 50us to 50ms,

 *  however the hardware default for these parts is 500us to 1ms which is less

 *  than the 10ms recommended by the pci-e spec.  To address this we need to

 *  increase the value to either 10ms to 200ms for capability version 1 config,

 *  or 16ms to 55ms for version 2.

 only take action if timeout value is defaulted to 0 */

	/* if capabilities version is type 1 we can write the

	 * timeout of 10ms to 200ms through the GCR register

	/* for version 2 capabilities we need to write the config space

	 * directly in order to set the completion timeout value for

	 * 16ms to 55ms

 disable completion timeout resend */

/**

 *  igb_vmdq_set_anti_spoofing_pf - enable or disable anti-spoofing

 *  @hw: pointer to the hardware struct

 *  @enable: state to enter, either enabled or disabled

 *  @pf: Physical Function pool - do not set anti-spoofing for the PF

 *

 *  enables/disables L2 switch anti-spoofing functionality.

		/* The PF can spoof - it has to in order to

		 * support emulation mode NICs

/**

 *  igb_vmdq_set_loopback_pf - enable or disable vmdq loopback

 *  @hw: pointer to the hardware struct

 *  @enable: state to enter, either enabled or disabled

 *

 *  enables/disables L2 switch loopback functionality.

 Currently no other hardware supports loopback */

/**

 *  igb_vmdq_set_replication_pf - enable or disable vmdq replication

 *  @hw: pointer to the hardware struct

 *  @enable: state to enter, either enabled or disabled

 *

 *  enables/disables replication of packets across multiple pools.

/**

 *  igb_read_phy_reg_82580 - Read 82580 MDI control register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Reads the MDI control register in the PHY at offset and stores the

 *  information read to data.

/**

 *  igb_write_phy_reg_82580 - Write 82580 MDI control register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write to register at offset

 *

 *  Writes data to MDI control register in the PHY at offset.

/**

 *  igb_reset_mdicnfg_82580 - Reset MDICNFG destination and com_mdio bits

 *  @hw: pointer to the HW structure

 *

 *  This resets the the MDICNFG.Destination and MDICNFG.Com_MDIO bits based on

 *  the values found in the EEPROM.  This addresses an issue in which these

 *  bits are not restored from EEPROM after reset.

/**

 *  igb_reset_hw_82580 - Reset hardware

 *  @hw: pointer to the HW structure

 *

 *  This resets function or entire device (all ports, etc.)

 *  to a known state.

 BH SW mailbox bit in SW_FW_SYNC */

	/* due to hw errata, global device reset doesn't always

	 * work on 82580

 Get current control state. */

	/* Prevent the PCI-E bus from sticking if there is no TLP connection

	 * on the last TLP read/write transaction when MAC is reset.

 Determine whether or not a global dev reset is requested */

 Add delay to insure DEV_RST has time to complete */

		/* When auto config read does not complete, do not

		 * return with an error. This can happen in situations

		 * where there is no eeprom and prevents getting link.

 clear global device reset status bit */

 Clear any pending interrupt events. */

 Install any alternate MAC address into RAR0 */

 Release semaphore */

/**

 *  igb_rxpbs_adjust_82580 - adjust RXPBS value to reflect actual RX PBA size

 *  @data: data received by reading RXPBS register

 *

 *  The 82580 uses a table based approach for packet buffer allocation sizes.

 *  This function converts the retrieved value into the correct table value

 *     0x0 0x1 0x2 0x3 0x4 0x5 0x6 0x7

 *  0x0 36  72 144   1   2   4   8  16

 *  0x8 35  70 140 rsv rsv rsv rsv rsv

/**

 *  igb_validate_nvm_checksum_with_offset - Validate EEPROM

 *  checksum

 *  @hw: pointer to the HW structure

 *  @offset: offset in words of the checksum protected region

 *

 *  Calculates the EEPROM checksum by reading/adding each word of the EEPROM

 *  and then verifies that the sum of the EEPROM is equal to 0xBABA.

/**

 *  igb_update_nvm_checksum_with_offset - Update EEPROM

 *  checksum

 *  @hw: pointer to the HW structure

 *  @offset: offset in words of the checksum protected region

 *

 *  Updates the EEPROM checksum by reading/adding each word of the EEPROM

 *  up to the checksum.  Then calculates the EEPROM checksum and writes the

 *  value to the EEPROM.

/**

 *  igb_validate_nvm_checksum_82580 - Validate EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Calculates the EEPROM section checksum by reading/adding each word of

 *  the EEPROM and then verifies that the sum of the EEPROM is

 *  equal to 0xBABA.

		/* if checksums compatibility bit is set validate checksums

		 * for all 4 ports.

/**

 *  igb_update_nvm_checksum_82580 - Update EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Updates the EEPROM section checksums for all 4 ports by reading/adding

 *  each word of the EEPROM up to the checksum.  Then calculates the EEPROM

 *  checksum and writes the value to the EEPROM.

 set compatibility bit to validate checksums appropriately */

/**

 *  igb_validate_nvm_checksum_i350 - Validate EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Calculates the EEPROM section checksum by reading/adding each word of

 *  the EEPROM and then verifies that the sum of the EEPROM is

 *  equal to 0xBABA.

/**

 *  igb_update_nvm_checksum_i350 - Update EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Updates the EEPROM section checksums for all 4 ports by reading/adding

 *  each word of the EEPROM up to the checksum.  Then calculates the EEPROM

 *  checksum and writes the value to the EEPROM.

/**

 *  __igb_access_emi_reg - Read/write EMI register

 *  @hw: pointer to the HW structure

 *  @address: EMI address to program

 *  @data: pointer to value to read/write from/to the EMI address

 *  @read: boolean flag to indicate read or write

/**

 *  igb_read_emi_reg - Read Extended Management Interface register

 *  @hw: pointer to the HW structure

 *  @addr: EMI address to program

 *  @data: value to be read from the EMI address

/**

 *  igb_set_eee_i350 - Enable/disable EEE support

 *  @hw: pointer to the HW structure

 *  @adv1G: boolean flag enabling 1G EEE advertisement

 *  @adv100M: boolean flag enabling 100M EEE advertisement

 *

 *  Enable/disable EEE based on setting in dev_spec structure.

 *

 enable or disable per user setting */

 This bit should not be set in normal operation. */

/**

 *  igb_set_eee_i354 - Enable/disable EEE support

 *  @hw: pointer to the HW structure

 *  @adv1G: boolean flag enabling 1G EEE advertisement

 *  @adv100M: boolean flag enabling 100M EEE advertisement

 *

 *  Enable/disable EEE legacy mode based on setting in dev_spec structure.

 *

 Switch to PHY page 18. */

 Return the PHY to page 0. */

 Turn on EEE advertisement. */

 Turn off EEE advertisement. */

/**

 *  igb_get_eee_status_i354 - Get EEE status

 *  @hw: pointer to the HW structure

 *  @status: EEE status

 *

 *  Get EEE status by guessing based on whether Tx or Rx LPI indications have

 *  been received.

 Check if EEE is supported on this device. */

/**

 *  igb_get_thermal_sensor_data_generic - Gathers thermal sensor data

 *  @hw: pointer to hardware structure

 *

 *  Updates the temperatures in mac.thermal_sensor_data

 Return the internal sensor only if ETS is unsupported */

/**

 *  igb_init_thermal_sensor_thresh_generic - Sets thermal sensor thresholds

 *  @hw: pointer to hardware structure

 *

 *  Sets the thermal sensor thresholds according to the NVM map

 *  and save off the threshold and location values into mac.thermal_sensor_data

 Return the internal sensor only if ETS is unsupported */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2007 - 2018 Intel Corporation. */

 Cable length tables */

/**

 *  igb_check_reset_block - Check if PHY reset is blocked

 *  @hw: pointer to the HW structure

 *

 *  Read the PHY management control register and check whether a PHY reset

 *  is blocked.  If a reset is not blocked return 0, otherwise

 *  return E1000_BLK_PHY_RESET (12).

/**

 *  igb_get_phy_id - Retrieve the PHY ID and revision

 *  @hw: pointer to the HW structure

 *

 *  Reads the PHY registers and stores the PHY ID and possibly the PHY

 *  revision in the hardware structure.

 ensure PHY page selection to fix misconfigured i210 */

/**

 *  igb_phy_reset_dsp - Reset PHY DSP

 *  @hw: pointer to the HW structure

 *

 *  Reset the digital signal processor.

/**

 *  igb_read_phy_reg_mdic - Read MDI control register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Reads the MDI control register in the PHY at offset and stores the

 *  information read to data.

	/* Set up Op-code, Phy Address, and register offset in the MDI

	 * Control register.  The MAC will take care of interfacing with the

	 * PHY to retrieve the desired data.

	/* Poll the ready bit to see if the MDI read completed

	 * Increasing the time out as testing showed failures with

	 * the lower time out

/**

 *  igb_write_phy_reg_mdic - Write MDI control register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write to register at offset

 *

 *  Writes data to MDI control register in the PHY at offset.

	/* Set up Op-code, Phy Address, and register offset in the MDI

	 * Control register.  The MAC will take care of interfacing with the

	 * PHY to retrieve the desired data.

	/* Poll the ready bit to see if the MDI read completed

	 * Increasing the time out as testing showed failures with

	 * the lower time out

/**

 *  igb_read_phy_reg_i2c - Read PHY register using i2c

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Reads the PHY register at offset using the i2c interface and stores the

 *  retrieved information in data.

	/* Set up Op-code, Phy Address, and register address in the I2CCMD

	 * register.  The MAC will take care of interfacing with the

	 * PHY to retrieve the desired data.

 Poll the ready bit to see if the I2C read completed */

 Need to byte-swap the 16-bit value. */

/**

 *  igb_write_phy_reg_i2c - Write PHY register using i2c

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Writes the data to PHY register at the offset using the i2c interface.

 Prevent overwriting SFP I2C EEPROM which is at A0 address.*/

 Swap the data bytes for the I2C interface */

	/* Set up Op-code, Phy Address, and register address in the I2CCMD

	 * register.  The MAC will take care of interfacing with the

	 * PHY to retrieve the desired data.

 Poll the ready bit to see if the I2C read completed */

/**

 *  igb_read_sfp_data_byte - Reads SFP module data.

 *  @hw: pointer to the HW structure

 *  @offset: byte location offset to be read

 *  @data: read data buffer pointer

 *

 *  Reads one byte from SFP module data stored

 *  in SFP resided EEPROM memory or SFP diagnostic area.

 *  Function should be called with

 *  E1000_I2CCMD_SFP_DATA_ADDR(<byte offset>) for SFP module database access

 *  E1000_I2CCMD_SFP_DIAG_ADDR(<byte offset>) for SFP diagnostics parameters

 *  access

	/* Set up Op-code, EEPROM Address,in the I2CCMD

	 * register. The MAC will take care of interfacing with the

	 * EEPROM to retrieve the desired data.

 Poll the ready bit to see if the I2C read completed */

/**

 *  igb_read_phy_reg_igp - Read igp PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to be read

 *  @data: pointer to the read data

 *

 *  Acquires semaphore, if necessary, then reads the PHY register at offset

 *  and storing the retrieved information in data.  Release any acquired

 *  semaphores before exiting.

/**

 *  igb_write_phy_reg_igp - Write igp PHY register

 *  @hw: pointer to the HW structure

 *  @offset: register offset to write to

 *  @data: data to write at register offset

 *

 *  Acquires semaphore, if necessary, then writes the data to PHY register

 *  at the offset.  Release any acquired semaphores before exiting.

/**

 *  igb_copper_link_setup_82580 - Setup 82580 PHY for copper link

 *  @hw: pointer to the HW structure

 *

 *  Sets up Carrier-sense on Transmit and downshift values.

 Enable CRS on TX. This must be set for half-duplex operation. */

 Enable downshift */

 Set MDI/MDIX mode */

	/* Options:

	 *   0 - Auto (default)

	 *   1 - MDI mode

	 *   2 - MDI-X mode

/**

 *  igb_copper_link_setup_m88 - Setup m88 PHY's for copper link

 *  @hw: pointer to the HW structure

 *

 *  Sets up MDI/MDI-X and polarity for m88 PHY's.  If necessary, transmit clock

 *  and downshift values are set also.

 Enable CRS on TX. This must be set for half-duplex operation. */

	/* Options:

	 *   MDI/MDI-X = 0 (default)

	 *   0 - Auto for all speeds

	 *   1 - MDI mode

	 *   2 - MDI-X mode

	 *   3 - Auto for 1000Base-T only (MDI-X for 10/100Base-T modes)

	/* Options:

	 *   disable_polarity_correction = 0 (default)

	 *       Automatic Correction for Reversed Cable Polarity

	 *   0 - Disabled

	 *   1 - Enabled

		/* Force TX_CLK in the Extended PHY Specific Control Register

		 * to 25MHz clock.

 82573L PHY - set the downshift counter to 5x. */

 Configure Master and Slave downshift values */

 Commit the changes. */

/**

 *  igb_copper_link_setup_m88_gen2 - Setup m88 PHY's for copper link

 *  @hw: pointer to the HW structure

 *

 *  Sets up MDI/MDI-X and polarity for i347-AT4, m88e1322 and m88e1112 PHY's.

 *  Also enables and sets the downshift parameters.

 Enable CRS on Tx. This must be set for half-duplex operation. */

	/* Options:

	 *   MDI/MDI-X = 0 (default)

	 *   0 - Auto for all speeds

	 *   1 - MDI mode

	 *   2 - MDI-X mode

	 *   3 - Auto for 1000Base-T only (MDI-X for 10/100Base-T modes)

 M88E1112 does not support this mode) */

	/* Options:

	 *   disable_polarity_correction = 0 (default)

	 *       Automatic Correction for Reversed Cable Polarity

	 *   0 - Disabled

	 *   1 - Enabled

 Enable downshift and setting it to X6 */

 Commit the changes. */

/**

 *  igb_copper_link_setup_igp - Setup igp PHY's for copper link

 *  @hw: pointer to the HW structure

 *

 *  Sets up LPLU, MDI/MDI-X, polarity, Smartspeed and Master/Slave config for

 *  igp PHY's.

	/* Wait 100ms for MAC to configure PHY from NVM settings, to avoid

	 * timeout issues when LFS is enabled.

	/* The NVM settings will configure LPLU in D3 for

	 * non-IGP1 PHYs.

 disable lplu d3 during driver init */

 disable lplu d0 during driver init */

 Configure mdi-mdix settings */

 set auto-master slave resolution settings */

		/* when autonegotiation advertisement is only 1000Mbps then we

		 * should disable SmartSpeed and enable Auto MasterSlave

		 * resolution as hardware default.

 Disable SmartSpeed */

 Set auto Master/Slave resolution process */

 load defaults for future use */

/**

 *  igb_copper_link_autoneg - Setup/Enable autoneg for copper link

 *  @hw: pointer to the HW structure

 *

 *  Performs initial bounds checking on autoneg advertisement parameter, then

 *  configure to advertise the full capability.  Setup the PHY to autoneg

 *  and restart the negotiation process between the link partner.  If

 *  autoneg_wait_to_complete, then wait for autoneg to complete before exiting.

	/* Perform some bounds checking on the autoneg advertisement

	 * parameter.

	/* If autoneg_advertised is zero, we assume it was not defaulted

	 * by the calling code so we set to advertise full capability.

	/* Restart auto-negotiation by setting the Auto Neg Enable bit and

	 * the Auto Neg Restart bit in the PHY control register.

	/* Does the user want to wait for Auto-Neg to complete here, or

	 * check at a later time (for example, callback routine).

/**

 *  igb_phy_setup_autoneg - Configure PHY for auto-negotiation

 *  @hw: pointer to the HW structure

 *

 *  Reads the MII auto-neg advertisement register and/or the 1000T control

 *  register and if the PHY is already setup for auto-negotiation, then

 *  return successful.  Otherwise, setup advertisement and flow control to

 *  the appropriate values for the wanted auto-negotiation.

 Read the MII Auto-Neg Advertisement Register (Address 4). */

 Read the MII 1000Base-T Control Register (Address 9). */

	/* Need to parse both autoneg_advertised and fc and set up

	 * the appropriate PHY registers.  First we will parse for

	 * autoneg_advertised software override.  Since we can advertise

	 * a plethora of combinations, we need to check each bit

	 * individually.

	/* First we clear all the 10/100 mb speed bits in the Auto-Neg

	 * Advertisement Register (Address 4) and the 1000 mb speed bits in

	 * the  1000Base-T Control Register (Address 9).

 Do we want to advertise 10 Mb Half Duplex? */

 Do we want to advertise 10 Mb Full Duplex? */

 Do we want to advertise 100 Mb Half Duplex? */

 Do we want to advertise 100 Mb Full Duplex? */

 We do not allow the Phy to advertise 1000 Mb Half Duplex */

 Do we want to advertise 1000 Mb Full Duplex? */

	/* Check for a software override of the flow control settings, and

	 * setup the PHY advertisement registers accordingly.  If

	 * auto-negotiation is enabled, then software will have to set the

	 * "PAUSE" bits to the correct value in the Auto-Negotiation

	 * Advertisement Register (PHY_AUTONEG_ADV) and re-start auto-

	 * negotiation.

	 *

	 * The possible values of the "fc" parameter are:

	 *      0:  Flow control is completely disabled

	 *      1:  Rx flow control is enabled (we can receive pause frames

	 *          but not send pause frames).

	 *      2:  Tx flow control is enabled (we can send pause frames

	 *          but we do not support receiving pause frames).

	 *      3:  Both Rx and TX flow control (symmetric) are enabled.

	 *  other:  No software override.  The flow control configuration

	 *          in the EEPROM is used.

		/* Flow control (RX & TX) is completely disabled by a

		 * software over-ride.

		/* RX Flow control is enabled, and TX Flow control is

		 * disabled, by a software over-ride.

		 *

		 * Since there really isn't a way to advertise that we are

		 * capable of RX Pause ONLY, we will advertise that we

		 * support both symmetric and asymmetric RX PAUSE.  Later

		 * (in e1000_config_fc_after_link_up) we will disable the

		 * hw's ability to send PAUSE frames.

		/* TX Flow control is enabled, and RX Flow control is

		 * disabled, by a software over-ride.

		/* Flow control (both RX and TX) is enabled by a software

		 * over-ride.

/**

 *  igb_setup_copper_link - Configure copper link settings

 *  @hw: pointer to the HW structure

 *

 *  Calls the appropriate function to configure the link for auto-neg or forced

 *  speed and duplex.  Then we check for link, once link is established calls

 *  to configure collision distance and flow control are called.  If link is

 *  not established, we return -E1000_ERR_PHY (-2).

		/* Setup autoneg and flow control advertisement and perform

		 * autonegotiation.

		/* PHY will be set to 10H, 10F, 100H or 100F

		 * depending on user settings.

	/* Check link status. Wait up to 100 microseconds for link to become

	 * valid.

/**

 *  igb_phy_force_speed_duplex_igp - Force speed/duplex for igp PHY

 *  @hw: pointer to the HW structure

 *

 *  Calls the PHY setup function to force speed and duplex.  Clears the

 *  auto-crossover to force MDI manually.  Waits for link and returns

 *  successful if link up is successful, else -E1000_ERR_PHY (-2).

	/* Clear Auto-Crossover to force MDI manually.  IGP requires MDI

	 * forced whenever speed and duplex are forced.

 Try once more */

/**

 *  igb_phy_force_speed_duplex_m88 - Force speed/duplex for m88 PHY

 *  @hw: pointer to the HW structure

 *

 *  Calls the PHY setup function to force speed and duplex.  Clears the

 *  auto-crossover to force MDI manually.  Resets the PHY to commit the

 *  changes.  If time expires while waiting for link up, we reset the DSP.

 *  After reset, TX_CLK and CRS on TX must be set.  Return successful upon

 *  successful completion, else return corresponding error code.

 I210 and I211 devices support Auto-Crossover in forced operation. */

		/* Clear Auto-Crossover to force MDI manually.  M88E1000

		 * requires MDI forced whenever speed and duplex are forced.

 Reset the phy to commit changes. */

				/* We didn't get link.

				 * Reset the DSP and cross our fingers.

 Try once more */

	/* Resetting the phy means we need to re-force TX_CLK in the

	 * Extended PHY Specific Control Register to 25MHz clock from

	 * the reset value of 2.5MHz.

	/* In addition, we must re-enable CRS on Tx for both half and full

	 * duplex.

/**

 *  igb_phy_force_speed_duplex_setup - Configure forced PHY speed/duplex

 *  @hw: pointer to the HW structure

 *  @phy_ctrl: pointer to current value of PHY_CONTROL

 *

 *  Forces speed and duplex on the PHY by doing the following: disable flow

 *  control, force speed/duplex on the MAC, disable auto speed detection,

 *  disable auto-negotiation, configure duplex, configure speed, configure

 *  the collision distance, write configuration to CTRL register.  The

 *  caller must write to the PHY_CONTROL register for these settings to

 *  take affect.

 Turn off flow control when forcing speed/duplex */

 Force speed/duplex on the mac */

 Disable Auto Speed Detection */

 Disable autoneg on the phy */

 Forcing Full or Half Duplex? */

 Forcing 10mb or 100mb? */

/**

 *  igb_set_d3_lplu_state - Sets low power link up state for D3

 *  @hw: pointer to the HW structure

 *  @active: boolean used to enable/disable lplu

 *

 *  Success returns 0, Failure returns 1

 *

 *  The low power link up (lplu) state is set to the power management level D3

 *  and SmartSpeed is disabled when active is true, else clear lplu for D3

 *  and enable Smartspeed.  LPLU and Smartspeed are mutually exclusive.  LPLU

 *  is used during Dx states where the power conservation is most important.

 *  During driver activity, SmartSpeed should be enabled so performance is

 *  maintained.

		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used

		 * during Dx states where the power conservation is most

		 * important.  During driver activity we should enable

		 * SmartSpeed, so performance is maintained.

 When LPLU is enabled, we should disable SmartSpeed */

/**

 *  igb_check_downshift - Checks whether a downshift in speed occurred

 *  @hw: pointer to the HW structure

 *

 *  Success returns 0, Failure returns 1

 *

 *  A downshift is detected by querying the PHY link health.

 speed downshift not supported */

/**

 *  igb_check_polarity_m88 - Checks the polarity.

 *  @hw: pointer to the HW structure

 *

 *  Success returns 0, Failure returns -E1000_ERR_PHY (-2)

 *

 *  Polarity is determined based on the PHY specific status register.

/**

 *  igb_check_polarity_igp - Checks the polarity.

 *  @hw: pointer to the HW structure

 *

 *  Success returns 0, Failure returns -E1000_ERR_PHY (-2)

 *

 *  Polarity is determined based on the PHY port status register, and the

 *  current speed (since there is no polarity at 100Mbps).

	/* Polarity is determined based on the speed of

	 * our connection.

		/* This really only applies to 10Mbps since

		 * there is no polarity for 100Mbps (always 0).

/**

 *  igb_wait_autoneg - Wait for auto-neg completion

 *  @hw: pointer to the HW structure

 *

 *  Waits for auto-negotiation to complete or for the auto-negotiation time

 *  limit to expire, which ever happens first.

 Break after autoneg completes or PHY_AUTO_NEG_LIMIT expires. */

	/* PHY_AUTO_NEG_TIME expiration doesn't guarantee auto-negotiation

	 * has completed.

/**

 *  igb_phy_has_link - Polls PHY for link

 *  @hw: pointer to the HW structure

 *  @iterations: number of times to poll for link

 *  @usec_interval: delay between polling attempts

 *  @success: pointer to whether polling was successful or not

 *

 *  Polls the PHY status register for link, 'iterations' number of times.

		/* Some PHYs require the PHY_STATUS register to be read

		 * twice due to the link bit being sticky.  No harm doing

		 * it across the board.

			/* If the first read fails, another entity may have

			 * ownership of the resources, wait and try again to

			 * see if they have relinquished the resources yet.

/**

 *  igb_get_cable_length_m88 - Determine cable length for m88 PHY

 *  @hw: pointer to the HW structure

 *

 *  Reads the PHY specific status register to retrieve the cable length

 *  information.  The cable length is determined by averaging the minimum and

 *  maximum values to get the "average" cable length.  The m88 PHY has four

 *  possible cable length values, which are:

 *	Register Value		Cable Length

 *	0			< 50 meters

 *	1			50 - 80 meters

 *	2			80 - 110 meters

 *	3			110 - 140 meters

 *	4			> 140 meters

 Remember the original page select and set it to 7 */

 Check if the unit of cable length is meters or cm */

 Get cable length from Pair 0 length Regs */

 Get cable length from Pair 1 length Regs */

 Get cable length from Pair 2 length Regs */

 Get cable length from Pair 3 length Regs */

 Populate the phy structure with cable length in meters */

 Reset the page selec to its original value */

 Remember the original page select and set it to 5 */

 Reset the page select to its original value */

/**

 *  igb_get_cable_length_igp_2 - Determine cable length for igp2 PHY

 *  @hw: pointer to the HW structure

 *

 *  The automatic gain control (agc) normalizes the amplitude of the

 *  received signal, adjusting for the attenuation produced by the

 *  cable.  By reading the AGC registers, which represent the

 *  combination of coarse and fine gain value, the value can be put

 *  into a lookup table to obtain the approximate cable length

 *  for each channel.

 Read the AGC registers for all channels */

		/* Getting bits 15:9, which represent the combination of

		 * coarse and fine gain values.  The result is a number

		 * that can be put into the lookup table to obtain the

		 * approximate cable length.

 Array index bound check. */

 Remove min & max AGC values from calculation. */

 Calculate cable length with the error range of +/- 10 meters. */

/**

 *  igb_get_phy_info_m88 - Retrieve PHY information

 *  @hw: pointer to the HW structure

 *

 *  Valid for only copper links.  Read the PHY status register (sticky read)

 *  to verify that link is up.  Read the PHY special control register to

 *  determine the polarity and 10base-T extended distance.  Read the PHY

 *  special status register to determine MDI/MDIx and current speed.  If

 *  speed is 1000, then determine cable length, local and remote receiver.

 Set values to "undefined" */

/**

 *  igb_get_phy_info_igp - Retrieve igp PHY information

 *  @hw: pointer to the HW structure

 *

 *  Read PHY status to determine if link is up.  If link is up, then

 *  set/determine 10base-T extended distance and polarity correction.  Read

 *  PHY port status to determine MDI/MDIx and speed.  Based on the speed,

 *  determine on the cable length, local and remote receiver.

/**

 *  igb_phy_sw_reset - PHY software reset

 *  @hw: pointer to the HW structure

 *

 *  Does a software reset of the PHY by reading the PHY control register and

 *  setting/write the control register reset bit to the PHY.

/**

 *  igb_phy_hw_reset - PHY hardware reset

 *  @hw: pointer to the HW structure

 *

 *  Verify the reset block is not blocking us from resetting.  Acquire

 *  semaphore (if necessary) and read/set/write the device control reset

 *  bit in the PHY.  Wait the appropriate delay time for the device to

 *  reset and release the semaphore (if necessary).

/**

 *  igb_phy_init_script_igp3 - Inits the IGP3 PHY

 *  @hw: pointer to the HW structure

 *

 *  Initializes a Intel Gigabit PHY3 when an EEPROM is not present.

 PHY init IGP 3 */

 Enable rise/fall, 10-mode work in class-A */

 Remove all caps from Replica path filter */

 Bias trimming for ADC, AFE and Driver (Default) */

 Increase Hybrid poly bias */

 Add 4% to TX amplitude in Giga mode */

 Disable trimming (TTT) */

 Poly DC correction to 94.6% + 2% for all channels */

 ABS DC correction to 95.9% */

 BG temp curve trim */

 Increasing ADC OPAMP stage 1 currents to max */

 Force 1000 ( required for enabling PHY regs configuration) */

 Set upd_freq to 6 */

 Disable NPDFE */

 Disable adaptive fixed FFE (Default) */

 Enable FFE hysteresis */

 Fixed FFE for short cable lengths */

 Fixed FFE for medium cable lengths */

 Fixed FFE for long cable lengths */

 Enable Adaptive Clip Threshold */

 AHT reset limit to 1 */

 Set AHT master delay to 127 msec */

 Set scan bits for AHT */

 Set AHT Preset bits */

 Change integ_factor of channel A to 3 */

 Change prop_factor of channels BCD to 8 */

 Change cg_icount + enable integbp for channels BCD */

	/* Change cg_icount + enable integbp + change prop_factor_master

	 * to 8 for channel A

 Disable AHT in Slave mode on channel A */

	/* Enable LPLU and disable AN to 1000 in non-D0a states,

	 * Enable SPD+B2B

 Enable restart AN on an1000_dis change */

 Enable wh_fifo read clock in 10/100 modes */

 Restart AN, Speed selection is 1000 */

/**

 *  igb_initialize_M88E1512_phy - Initialize M88E1512 PHY

 *  @hw: pointer to the HW structure

 *

 *  Initialize Marvel 1512 to work correctly with Avoton.

 Switch to PHY page 0xFF. */

 Switch to PHY page 0xFB. */

 Switch to PHY page 0x12. */

 Change mode to SGMII-to-Copper */

 Return the PHY to page 0. */

 msec_delay(1000); */

/**

 *  igb_initialize_M88E1543_phy - Initialize M88E1512 PHY

 *  @hw: pointer to the HW structure

 *

 *  Initialize Marvell 1543 to work correctly with Avoton.

 Switch to PHY page 0xFF. */

 Switch to PHY page 0xFB. */

 Switch to PHY page 0x12. */

 Change mode to SGMII-to-Copper */

 Switch to PHY page 1. */

 Change mode to 1000BASE-X/SGMII and autoneg enable */

 Return the PHY to page 0. */

 msec_delay(1000); */

/**

 * igb_power_up_phy_copper - Restore copper link in case of PHY power down

 * @hw: pointer to the HW structure

 *

 * In the case of a PHY power down to save power, or to turn off link during a

 * driver unload, restore the link to previous settings.

 The PHY will retain its settings across a power down/up cycle */

/**

 * igb_power_down_phy_copper - Power down copper PHY

 * @hw: pointer to the HW structure

 *

 * Power down PHY to save power when interface is down and wake on lan

 * is not enabled.

 The PHY will retain its settings across a power down/up cycle */

/**

 *  igb_check_polarity_82580 - Checks the polarity.

 *  @hw: pointer to the HW structure

 *

 *  Success returns 0, Failure returns -E1000_ERR_PHY (-2)

 *

 *  Polarity is determined based on the PHY specific status register.

/**

 *  igb_phy_force_speed_duplex_82580 - Force speed/duplex for I82580 PHY

 *  @hw: pointer to the HW structure

 *

 *  Calls the PHY setup function to force speed and duplex.  Clears the

 *  auto-crossover to force MDI manually.  Waits for link and returns

 *  successful if link up is successful, else -E1000_ERR_PHY (-2).

	/* Clear Auto-Crossover to force MDI manually.  82580 requires MDI

	 * forced whenever speed and duplex are forced.

 Try once more */

/**

 *  igb_get_phy_info_82580 - Retrieve I82580 PHY information

 *  @hw: pointer to the HW structure

 *

 *  Read PHY status to determine if link is up.  If link is up, then

 *  set/determine 10base-T extended distance and polarity correction.  Read

 *  PHY port status to determine MDI/MDIx and speed.  Based on the speed,

 *  determine on the cable length, local and remote receiver.

/**

 *  igb_get_cable_length_82580 - Determine cable length for 82580 PHY

 *  @hw: pointer to the HW structure

 *

 * Reads the diagnostic status register and verifies result is valid before

 * placing it in the phy_cable_length field.

/**

 *  igb_set_master_slave_mode - Setup PHY for Master/slave mode

 *  @hw: pointer to the HW structure

 *

 *  Sets up Master/slave mode

 Resolve Master/Slave mode */

 load defaults for future use */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2007 - 2018 Intel Corporation. */

 ethtool support for igb */

 packets, bytes, restart_queue */

 the e1000 autoneg seems to match ethtool nicely */

 MDI-X => 2; MDI =>1; Invalid =>0 */

	/* When SoL/IDER sessions are active, autoneg/speed/duplex

	 * cannot be changed

	/* MDI setting is only allowed when autoneg enabled because

	 * some hardware doesn't allow MDI setting when speed or

	 * duplex is forced.

 calling this overrides forced MDI setting */

 MDI-X => 2; MDI => 1; Auto => 3 */

		/* fix up the value for auto (3 => 0) as zero is mapped

		 * internally to auto

 reset the link */

	/* If the link is not reported up to netdev, interrupts are disabled,

	 * and so the physical link state may have changed since we last

	 * looked. Set get_link_status to make sure that the true link

	 * state is interrogated, rather than pulling a cached and possibly

	 * stale link state from the driver.

 100basefx does not support setting link flow control */

 Make sure SRRCTL considers new fc settings for each ring */

 General Registers */

 NVM Register */

 Interrupt */

	/* Reading EICS for EICR because they read the

	 * same but EICS does not clear on read

	/* Reading ICS for ICR because they read the

	 * same but ICS does not clear on read

 Flow Control */

 Receive */

 Transmit */

 Wake Up */

 MAC */

 Statistics */

 Device's eeprom is always little-endian, word addressable */

		/* need read/modify/write of first changed EEPROM word

		 * only the second byte of the word is being modified

		/* need read/modify/write of last changed EEPROM word

		 * only the first byte of the word is being modified

 Device's eeprom is always little-endian, word addressable */

 Update the checksum if nvm write succeeded */

	/* EEPROM image version # is reported as firmware version # for

	 * 82575 controllers

 nothing to do */

	/* We can't just free everything and then setup again,

	 * because the ISRs in MSI-X mode get passed pointers

	 * to the Tx and Rx ring structs.

 Clear copied XDP RX-queue info */

 ethtool register test data */

/* In the hardware, registers are laid out either singly, in arrays

 * spaced 0x100 bytes apart, or in contiguous tables.  We assume

 * most tests take place on arrays or single registers (handled

 * as a single-element array) and special-case the tables.

 * Table tests are always pattern tests.

 *

 * We also make provision for some required setup steps by specifying

 * registers to be written without any read-back testing.

 i210 reg test */

 RDH is read-only for i210, only test RDT. */

 i350 reg test */

 RDH is read-only for i350, only test RDT. */

 82580 reg test */

 RDH is read-only for 82580, only test RDT. */

 82576 reg test */

 Enable all RX queues before testing. */

 RDH is read-only for 82576, only test RDT. */

 82575 register test */

 Enable all four RX queues before testing. */

 RDH is read-only for 82575, only test RDT. */

	/* Because the status register is such a special case,

	 * we handle it separately from the rest of the register

	 * tests.  Some bits are read-only, some toggle, and some

	 * are writable on newer MACs.

 restore previous status */

	/* Perform the remainder of the register test, looping through

	 * the test table until we either fail or reach the null entry.

 Validate eeprom on all parts but flashless */

 Hook up test interrupt handler just for this test */

 Disable all the interrupts */

 Define all writable bits for ICS */

 Test each interrupt */

 Interrupt to test */

			/* Disable the interrupt to be reported in

			 * the cause register and then force the same

			 * interrupt and see if one gets posted.  If

			 * an interrupt was posted to the bus, the

			 * test failed.

 Flush any pending interrupts */

		/* Enable the interrupt to be reported in

		 * the cause register and then force the same

		 * interrupt and see if one gets posted.  If

		 * an interrupt was not posted to the bus, the

		 * test failed.

 Flush any pending interrupts */

			/* Disable the other interrupts to be reported in

			 * the cause register and then force the other

			 * interrupts and see if any get posted.  If

			 * an interrupt was posted to the bus, the

			 * test failed.

 Flush any pending interrupts */

 Disable all the interrupts */

 Unhook test interrupt handler */

 Setup Tx descriptor ring and Tx buffers */

 Setup Rx descriptor ring and Rx buffers */

 set the default queue to queue 0 of PF */

 enable receive ring */

 Write out to PHY registers 29 and 30 to disable the Receiver. */

 Auto-MDI/MDIX Off */

 reset to update Auto-MDI/MDIX */

 autoneg off */

 force 1000, set loopback  */

 enable MII loopback */

 add small delay to avoid loopback test failure */

 force 1000, set loopback */

 Now set up the MAC to the same speed/duplex as the PHY. */

 Clear the speed sel bits */

 Set the Force Speed Bit */

 Set the Force Duplex Bit */

 Force Speed to 1000 */

 Force Duplex to FULL */

 Set link up enable bit */

 Invert Loss of Signal */

	/* Disable the receiver on the PHY so when a cable is plugged in, the

	 * PHY does not begin to autoneg when a cable is reconnected to the NIC.

 use CTRL_EXT to identify link type as SGMII can appear as copper */

 Enable DH89xxCC MPHY for near end loopback */

 Unset switch control to serdes energy detect */

		/* Unset sigdetect for SERDES loopback on

		 * 82580 and newer devices.

 Set PCS register for forced speed */

 Disable Autoneg*/

 Force link up */

 Force 1000    */

 SerDes Full duplex */

 Force Speed */

 Force Link */

 Disable near end loopback on DH89xxCC */

 initialize next to clean and descriptor values */

 check Rx buffer */

 sync Rx buffer for CPU read */

 verify contents of skb */

 sync Rx buffer for device write */

 unmap buffer on Tx side */

 Free all the Tx ring sk_buffs */

 unmap skb header data */

 increment Rx/Tx next to clean counters */

 fetch next descriptor */

 re-map buffers to ring, store next to clean values */

 allocate test skb */

 place data into test skb */

	/* Calculate the loop count based on the largest descriptor ring

	 * The idea is to wrap the largest ring a number of times using 64

	 * send/receive pairs during each loop

 loop count loop */

 reset count of good packets */

 place 64 packets on the transmit queue*/

 allow 200 milliseconds for packets to go from Tx to Rx */

 end loop count loop */

 free the original skb */

	/* PHY loopback cannot be performed if SoL/IDER

	 * sessions are active

		/* On some blade server designs, link establishment

		 * could take as long as 2-3 minutes

 can't do offline tests on media switching devices */

 Offline tests */

 save speed, duplex, autoneg settings */

 power up link for link test */

		/* Link test performed before hardware reset so autoneg doesn't

		 * interfere with test result

 indicate we're in test mode */

 power up link for loopback test */

 restore speed, duplex, autoneg settings */

 force this routine to wait until autoneg complete/timeout */

 PHY is powered down when interface is down */

 Online tests aren't run; pass by default */

 apply any specific unsupported masks here */

 these settings will always override what we currently have */

 bit defines for adapter->led_status */

 If ITR is disabled, disable DMAC */

 convert to rate of irq's per second */

 convert to rate of irq's per second */

 BUG_ON(p - data != IGB_STATS_LEN * ETH_GSTRING_LEN); */

 82576 does not support timestamping all packets. */

 report total rule count */

			/* As we only support matching by the full

			 * mask, return the mask to userspace

			/* As we only support matching by the full

			 * mask, return the mask to userspace

 report total rule count */

 Report default options for RSS on igb */

	/* RSS does not support anything other than hashing

	 * to queues on src and dst IPs and ports

 if we changed something we need to update flags */

 Perform hash on these packet types */

 find an empty etype filter register */

 check whether this vlan prio is already set */

 hash found, or no matching entry */

 if there is an old rule occupying our place remove it */

	/* If no input this was a delete, err should be 0 if a rule was

	 * successfully found and removed from the list else -EINVAL

 initialize node */

 add filter to the list */

 update counts */

	/* Don't allow programming if the action is a queue greater than

	 * the number of online Rx queues.

 Don't allow indexes to exist outside of available space */

 Only support matching addresses by the full mask */

 Only support matching addresses by the full mask */

 The IPCNFG and EEER registers are not supported on I354. */

 EEE status on negotiated link */

 EEE Link Partner Advertised */

	/* Report correct negotiated EEE status for devices that

	 * wrongly report EEE at half-duplex

 Tx LPI timer is not implemented currently */

 reset link */

 Check whether we support SFF-8472 or not */

 addressing mode is not supported */

 addressing mode is not supported */

 We have an SFP, but it does not support SFF-8472 */

 We have an SFP which supports a revision of SFF-8472 */

 Read EEPROM block, SFF-8079/SFF-8472, word at a time */

 Error occurred while reading module */

 82576 supports 2 RSS queues for SR-IOV */

 We do not allow change in unsupported parameters */

 82576 supports 2 RSS queues for SR-IOV */

 Verify user input. */

 Report maximum channels */

 Report info for other vector */

 Verify they are not requesting separate vectors */

 Verify other_count is valid and has not been changed */

 Verify the number of channels doesn't exceed hw limits */

		/* Hardware has to reinitialize queues and interrupts to

		 * match the new configuration.

 reset interface to repopulate queues */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2007 - 2018 Intel Corporation. */

 required last entry */

 CONFIG_IGB_DCA */

 CONFIG_PCI_IOV */

 General Registers */

 Interrupt Registers */

 RX Registers */

 TX Registers */

 List Terminator */

 igb_regdump - register printout routine */

 igb_dump - Print registers, Tx-rings and Rx-rings */

 Print netdevice Info */

 Print Registers */

 Print TX Ring Summary */

 Print TX Rings */

	/* Transmit Descriptor Formats

	 *

	 * Advanced Transmit Descriptor

	 *   +--------------------------------------------------------------+

	 * 0 |         Buffer Address [63:0]                                |

	 *   +--------------------------------------------------------------+

	 * 8 | PAYLEN  | PORTS  |CC|IDX | STA | DCMD  |DTYP|MAC|RSV| DTALEN |

	 *   +--------------------------------------------------------------+

	 *   63      46 45    40 39 38 36 35 32 31   24             15       0

 Print RX Rings Summary */

 Print RX Rings */

	/* Advanced Receive Descriptor (Read) Format

	 *    63                                           1        0

	 *    +-----------------------------------------------------+

	 *  0 |       Packet Buffer Address [63:1]           |A0/NSE|

	 *    +----------------------------------------------+------+

	 *  8 |       Header Buffer Address [63:1]           |  DD  |

	 *    +-----------------------------------------------------+

	 *

	 *

	 * Advanced Receive Descriptor (Write-Back) Format

	 *

	 *   63       48 47    32 31  30      21 20 17 16   4 3     0

	 *   +------------------------------------------------------+

	 * 0 | Packet     IP     |SPH| HDR_LEN   | RSV|Packet|  RSS |

	 *   | Checksum   Ident  |   |           |    | Type | Type |

	 *   +------------------------------------------------------+

	 * 8 | VLAN Tag | Length | Extended Error | Extended Status |

	 *   +------------------------------------------------------+

	 *   63       48 47    32 31            20 19               0

 Descriptor Done */

/**

 *  igb_get_i2c_data - Reads the I2C SDA data bit

 *  @data: opaque pointer to adapter struct

 *

 *  Returns the I2C data bit value

/**

 *  igb_set_i2c_data - Sets the I2C data bit

 *  @data: pointer to hardware structure

 *  @state: I2C data value (0 or 1) to set

 *

 *  Sets the I2C data bit

/**

 *  igb_set_i2c_clk - Sets the I2C SCL clock

 *  @data: pointer to hardware structure

 *  @state: state to set clock

 *

 *  Sets the I2C clock line to state

/**

 *  igb_get_i2c_clk - Gets the I2C SCL clock state

 *  @data: pointer to hardware structure

 *

 *  Gets the I2C clock state

/**

 *  igb_get_hw_dev - return device

 *  @hw: pointer to hardware structure

 *

 *  used by hardware layer to print debugging information

/**

 *  igb_init_module - Driver Registration Routine

 *

 *  igb_init_module is the first routine called when the driver is

 *  loaded. All it does is register with the PCI subsystem.

/**

 *  igb_exit_module - Driver Exit Cleanup Routine

 *

 *  igb_exit_module is called just before the driver is removed

 *  from memory.

/**

 *  igb_cache_ring_register - Descriptor ring to register mapping

 *  @adapter: board private structure to initialize

 *

 *  Once we know the feature-set enabled for the device, we'll cache

 *  the register offset the descriptor ring is assigned to.

		/* The queues are allocated for virtualization such that VF 0

		 * is allocated queues 0 and 8, VF 1 queues 1 and 9, etc.

		 * In order to avoid collision we start at the first free queue

		 * and continue consuming queues in the same sequence

 reads should not return all F's */

/**

 *  igb_write_ivar - configure ivar for given MSI-X vector

 *  @hw: pointer to the HW structure

 *  @msix_vector: vector number we are allocating to a given ring

 *  @index: row index of IVAR register to write within IVAR table

 *  @offset: column offset of in IVAR, should be multiple of 8

 *

 *  This function is intended to handle the writing of the IVAR register

 *  for adapters 82576 and newer.  The IVAR table consists of 2 columns,

 *  each containing an cause allocation for an Rx and Tx ring, and a

 *  variable number of rows depending on the number of queues supported.

 clear any bits that are currently set */

 write vector and valid bit */

		/* The 82575 assigns vectors using a bitmask, which matches the

		 * bitmask for the EICR/EIMS/EIMC registers.  To assign one

		 * or more queues to a vector, we write the appropriate bits

		 * into the MSIXBM register for that vector.

		/* 82576 uses a table that essentially consists of 2 columns

		 * with 8 rows.  The ordering is column-major so we use the

		 * lower 3 bits as the row index, and the 4th bit as the

		 * column offset.

		/* On 82580 and newer adapters the scheme is similar to 82576

		 * however instead of ordering column-major we have things

		 * ordered row-major.  So we traverse the table by using

		 * bit 0 as the column offset, and the remaining bits as the

		 * row index.

 add q_vector eims value to global eims_enable_mask */

 configure q_vector to set itr on first interrupt */

/**

 *  igb_configure_msix - Configure MSI-X hardware

 *  @adapter: board private structure to initialize

 *

 *  igb_configure_msix sets up the hardware to properly

 *  generate MSI-X interrupts.

 set vector for other causes, i.e. link changes */

 enable MSI-X PBA support*/

 Auto-Mask interrupts upon ICR read. */

 enable msix_other interrupt */

		/* Turn on MSI-X capability first, or our settings

		 * won't stick.  And it will take days to debug.

 enable msix_other interrupt */

 do nothing, since nothing else supports MSI-X */

 switch (hw->mac.type) */

/**

 *  igb_request_msix - Initialize MSI-X interrupts

 *  @adapter: board private structure to initialize

 *

 *  igb_request_msix allocates MSI-X vectors and requests interrupts from the

 *  kernel.

 free already assigned IRQs */

/**

 *  igb_free_q_vector - Free memory allocated for specific interrupt vector

 *  @adapter: board private structure to initialize

 *  @v_idx: Index of vector to be freed

 *

 *  This function frees the memory allocated to the q_vector.

	/* igb_get_stats64() might access the rings on this vector,

	 * we must wait a grace period before freeing it.

/**

 *  igb_reset_q_vector - Reset config for interrupt vector

 *  @adapter: board private structure to initialize

 *  @v_idx: Index of vector to be reset

 *

 *  If NAPI is enabled it will delete any references to the

 *  NAPI struct. This is preparation for igb_free_q_vector.

	/* Coming from igb_set_interrupt_capability, the vectors are not yet

	 * allocated. So, q_vector is NULL so we should stop here.

/**

 *  igb_free_q_vectors - Free memory allocated for interrupt vectors

 *  @adapter: board private structure to initialize

 *

 *  This function frees the memory allocated to the q_vectors.  In addition if

 *  NAPI is enabled it will delete any references to the NAPI struct prior

 *  to freeing the q_vector.

/**

 *  igb_clear_interrupt_scheme - reset the device to a state of no interrupts

 *  @adapter: board private structure to initialize

 *

 *  This function resets the device so that it has 0 Rx queues, Tx queues, and

 *  MSI-X interrupts allocated.

/**

 *  igb_set_interrupt_capability - set MSI or MSI-X if supported

 *  @adapter: board private structure to initialize

 *  @msix: boolean value of MSIX capability

 *

 *  Attempt to configure interrupts using the best available

 *  capabilities of the hardware and kernel.

 Number of supported queues. */

 start with one vector for every Rx queue */

 if Tx handler is separate add 1 for every Tx queue */

 store the number of vectors reserved for queues */

 add 1 vector for link status interrupts */

 If we can't do MSI-X, try MSI */

 disable SR-IOV for non MSI-X configurations */

 disable iov and allow time for transactions to clear */

/**

 *  igb_alloc_q_vector - Allocate memory for a single interrupt vector

 *  @adapter: board private structure to initialize

 *  @v_count: q_vectors allocated on adapter, used for ring interleaving

 *  @v_idx: index of vector in adapter struct

 *  @txr_count: total number of Tx rings to allocate

 *  @txr_idx: index of first Tx ring to allocate

 *  @rxr_count: total number of Rx rings to allocate

 *  @rxr_idx: index of first Rx ring to allocate

 *

 *  We allocate one q_vector.  If allocation fails we return -ENOMEM.

 igb only supports 1 Tx and/or 1 Rx queue per vector */

 allocate q_vector and rings */

 initialize NAPI */

 tie q_vector and adapter together */

 initialize work limits */

 initialize ITR configuration */

 initialize pointer to rings */

 intialize ITR */

 rx or rx/tx vector */

 tx only vector */

 assign generic ring traits */

 configure backlink on ring */

 update q_vector Tx values */

 For 82575, context index must be unique per ring. */

 apply Tx specific ring traits */

 assign ring to adapter */

 push pointer to next ring */

 assign generic ring traits */

 configure backlink on ring */

 update q_vector Rx values */

 set flag indicating ring supports SCTP checksum offload */

		/* On i350, i354, i210, and i211, loopback VLAN packets

		 * have the tag byte-swapped.

 apply Rx specific ring traits */

 assign ring to adapter */

/**

 *  igb_alloc_q_vectors - Allocate memory for interrupt vectors

 *  @adapter: board private structure to initialize

 *

 *  We allocate one q_vector per queue interrupt.  If allocation fails we

 *  return -ENOMEM.

 update counts and index */

 update counts and index */

/**

 *  igb_init_interrupt_scheme - initialize interrupts, allocate queues/vectors

 *  @adapter: board private structure to initialize

 *  @msix: boolean value of MSIX capability

 *

 *  This function initializes the interrupts and allocates all of the queues.

/**

 *  igb_request_irq - initialize interrupts

 *  @adapter: board private structure to initialize

 *

 *  Attempts to configure interrupts using the best available

 *  capabilities of the hardware and kernel.

 fall back to MSI */

 fall back to legacy interrupts */

/**

 *  igb_irq_disable - Mask off interrupt generation on the NIC

 *  @adapter: board private structure

	/* we need to be careful when disabling interrupts.  The VFs are also

	 * mapped into these registers and so clearing the bits can cause

	 * issues on the VF drivers so we only need to clear what we set

/**

 *  igb_irq_enable - Enable default interrupt generation settings

 *  @adapter: board private structure

 add VID to filter table */

 remove VID from filter table */

/**

 *  igb_release_hw_control - release control of the h/w to f/w

 *  @adapter: address of board private structure

 *

 *  igb_release_hw_control resets CTRL_EXT:DRV_LOAD bit.

 *  For ASF and Pass Through versions of f/w this means that the

 *  driver is no longer loaded.

 Let firmware take over control of h/w */

/**

 *  igb_get_hw_control - get control of the h/w from f/w

 *  @adapter: address of board private structure

 *

 *  igb_get_hw_control sets CTRL_EXT:DRV_LOAD bit.

 *  For ASF and Pass Through versions of f/w this means that

 *  the driver is loaded.

 Let firmware know the driver has taken over */

/**

 *  igb_config_tx_modes - Configure "Qav Tx mode" features on igb

 *  @adapter: pointer to adapter struct

 *  @queue: queue number

 *

 *  Configure CBS and Launchtime for a given hardware queue.

 *  Parameters are retrieved from the correct Tx ring, so

 *  igb_save_cbs_params() and igb_save_txtime_params() should be used

 *  for setting those correctly prior to this function being called.

	/* If any of the Qav features is enabled, configure queues as SR and

	 * with HIGH PRIO. If none is, then configure them with LOW PRIO and

	 * as SP.

 If CBS is enabled, set DataTranARB and config its parameters. */

		/* i210 does not allow the queue 0 to be in the Strict

		 * Priority mode while the Qav mode is enabled, so,

		 * instead of disabling strict priority mode, we give

		 * queue 0 the maximum of credits possible.

		 *

		 * See section 8.12.19 of the i210 datasheet, "Note:

		 * Queue0 QueueMode must be set to 1b when

		 * TransmitMode is set to Qav."

 max "linkspeed" idleslope in kbps */

		/* Always set data transfer arbitration to credit-based

		 * shaper algorithm on TQAVCTRL if CBS is enabled for any of

		 * the queues.

		/* According to i210 datasheet section 7.2.7.7, we should set

		 * the 'idleSlope' field from TQAVCC register following the

		 * equation:

		 *

		 * For 100 Mbps link speed:

		 *

		 *     value = BW * 0x7735 * 0.2                          (E1)

		 *

		 * For 1000Mbps link speed:

		 *

		 *     value = BW * 0x7735 * 2                            (E2)

		 *

		 * E1 and E2 can be merged into one equation as shown below.

		 * Note that 'link-speed' is in Mbps.

		 *

		 *     value = BW * 0x7735 * 2 * link-speed

		 *                           --------------               (E3)

		 *                                1000

		 *

		 * 'BW' is the percentage bandwidth out of full link speed

		 * which can be found with the following equation. Note that

		 * idleSlope here is the parameter from this function which

		 * is in kbps.

		 *

		 *     BW =     idleSlope

		 *          -----------------                             (E4)

		 *          link-speed * 1000

		 *

		 * That said, we can come up with a generic equation to

		 * calculate the value we should set it TQAVCC register by

		 * replacing 'BW' in E3 by E4. The resulting equation is:

		 *

		 * value =     idleSlope     * 0x7735 * 2 * link-speed

		 *         -----------------            --------------    (E5)

		 *         link-speed * 1000                 1000

		 *

		 * 'link-speed' is present in both sides of the fraction so

		 * it is canceled out. The final equation is the following:

		 *

		 *     value = idleSlope * 61034

		 *             -----------------                          (E6)

		 *                  1000000

		 *

		 * NOTE: For i210, given the above, we can see that idleslope

		 *       is represented in 16.38431 kbps units by the value at

		 *       the TQAVCC register (1Gbps / 61034), which reduces

		 *       the granularity for idleslope increments.

		 *       For instance, if you want to configure a 2576kbps

		 *       idleslope, the value to be written on the register

		 *       would have to be 157.23. If rounded down, you end

		 *       up with less bandwidth available than originally

		 *       required (~2572 kbps). If rounded up, you end up

		 *       with a higher bandwidth (~2589 kbps). Below the

		 *       approach we take is to always round up the

		 *       calculated value, so the resulting bandwidth might

		 *       be slightly higher for some configurations.

 Set idleSlope to zero. */

 Set hiCredit to zero. */

		/* If CBS is not enabled for any queues anymore, then return to

		 * the default state of Data Transmission Arbitration on

		 * TQAVCTRL.

 If LaunchTime is enabled, set DataTranTIM. */

		/* Always set DataTranTIM on TQAVCTRL if LaunchTime is enabled

		 * for any of the SR queues, and configure fetchtime delta.

		 * XXX NOTE:

		 *     - LaunchTime will be enabled for all SR queues.

		 *     - A fixed offset can be added relative to the launch

		 *       time of all packets if configured at reg LAUNCH_OS0.

		 *       We are keeping it as 0 for now (default value).

		/* If Launchtime is not enabled for any SR queues anymore,

		 * then clear DataTranTIM on TQAVCTRL and clear fetchtime delta,

		 * effectively disabling Launchtime.

	/* XXX: In i210 controller the sendSlope and loCredit parameters from

	 * CBS are not configurable by software so we don't do any 'controller

	 * configuration' in respect to these parameters.

/**

 *  igb_setup_tx_mode - Switch to/from Qav Tx mode when applicable

 *  @adapter: pointer to adapter struct

 *

 *  Configure TQAVCTRL register switching the controller's Tx mode

 *  if FQTSS mode is enabled or disabled. Additionally, will issue

 *  a call to igb_config_tx_modes() per queue so any previously saved

 *  Tx parameters are applied.

 Only i210 controller supports changing the transmission mode. */

		/* Configure TQAVCTRL register: set transmit mode to 'Qav',

		 * set data fetch arbitration to 'round robin', set SP_WAIT_SR

		 * so SP queues wait for SR ones.

		/* Configure Tx and Rx packet buffers sizes as described in

		 * i210 datasheet section 7.2.7.7.

		/* Section 8.12.9 states that MAX_TPKT_SIZE from DTXMXPKTSZ

		 * register should not exceed the buffer size programmed in

		 * TXPBS. The smallest buffer size programmed in TXPBS is 4kB

		 * so according to the datasheet we should set MAX_TPKT_SIZE to

		 * 4kB / 64.

		 *

		 * However, when we do so, no frame from queue 2 and 3 are

		 * transmitted.  It seems the MAX_TPKT_SIZE should not be great

		 * or _equal_ to the buffer size programmed in TXPBS. For this

		 * reason, we set set MAX_ TPKT_SIZE to (4kB - 1) / 64.

		/* Since FQTSS mode is enabled, apply any CBS configuration

		 * previously set. If no previous CBS configuration has been

		 * done, then the initial configuration is applied, which means

		 * CBS is disabled.

		/* According to Section 8.12.21, the other flags we've set when

		 * enabling FQTSS are not relevant when disabling FQTSS so we

		 * don't set they here.

/**

 *  igb_configure - configure the hardware for RX and TX

 *  @adapter: private board structure

	/* call igb_desc_unused which always leaves

	 * at least 1 descriptor unused to make sure

	 * next_to_use != next_to_clean

/**

 *  igb_power_up_link - Power up the phy/serdes link

 *  @adapter: address of board private structure

/**

 *  igb_power_down_link - Power down the phy/serdes link

 *  @adapter: address of board private structure

/**

 * igb_check_swap_media -  Detect and switch function for Media Auto Sense

 * @adapter: address of the board private structure

	/* need to live swap if current media is copper and we have fiber/serdes

	 * to go to.

 copper signal takes time to appear */

 shouldn't get here during regular operation */

/**

 *  igb_up - Open the interface and prepare it to handle traffic

 *  @adapter: board private structure

 hardware has been reset, we need to reload some things */

 Clear any pending interrupts. */

 notify VFs that reset has been completed */

 start the watchdog. */

	/* signal that we're down so the interrupt handler does not

	 * reschedule our watchdog timer

 disable receives in the hardware */

 flush and sleep below */

 disable transmits in the hardware */

 flush both disables and wait for them to finish */

 record the stats before reset*/

 clear VLAN promisc flag so VFTA will be updated if necessary */

 since we reset the hardware DCA settings were cleared */

/** igb_enable_mas - Media Autosense re-enable after swap

 *

 * @adapter: adapter struct

 configure for SerDes media detect */

	/* Repartition Pba for greater than 9k mtu

	 * To take effect CTRL.RST is required.

 write Rx PBA so that hardware can report correct Tx PBA */

		/* To maintain wire speed transmits, the Tx FIFO should be

		 * large enough to accommodate two full transmit packets,

		 * rounded up to the next 1KB and expressed in KB.  Likewise,

		 * the Rx FIFO should be large enough to accommodate at least

		 * one full receive packet and is similarly rounded up and

		 * expressed in KB.

		/* The Tx FIFO also stores 16 bytes of information about the Tx

		 * but don't include Ethernet FCS because hardware appends it.

		 * We only need to round down to the nearest 512 byte block

		 * count since the value we care about is 2 frames, not 1.

 upper 16 bits has Tx packet buffer allocation size in KB */

		/* If current Tx allocation is less than the min Tx FIFO size,

		 * and the min Tx FIFO size is less than the current Rx FIFO

		 * allocation, take space away from current Rx allocation.

			/* if short on Rx space, Rx wins and must trump Tx

			 * adjustment

 adjust PBA for jumbo frames */

	/* flow control settings

	 * The high water mark must be low enough to fit one full frame

	 * after transmitting the pause frame.  As such we must have enough

	 * space to allow for us to complete our current transmit and then

	 * receive the frame that is in progress from the link partner.

	 * Set it to:

	 * - the full Rx FIFO size minus one full Tx plus one full Rx frame

 16-byte granularity */

 disable receive for all VFs and wait one second */

 ping all the active vfs to let them know we are going down */

 disable transmits and receives */

 Allow time for pending master requests to run */

 need to resetup here after media swap */

 RAR registers were cleared during init_hw, clear mac table */

 Recover default RAR entry */

	/* Flow control settings reset on hardware reset, so guarantee flow

	 * control is off when forcing speed.

 Re-initialize the thermal sensor on i350 devices. */

			/* If present, re-initialize the external thermal sensor

			 * interface.

 Re-establish EEE setting */

 Enable h/w to recognize an 802.1Q VLAN Ethernet packet */

 Re-enable PTP, where applicable. */

	/* Since there is no support for separate Rx/Tx vlan accel

	 * enable/disable make sure Tx flag is always in same state as Rx.

 guarantee we can provide a unique filter for the unicast address */

 Make certain the headers can be described by a context descriptor */

	/* We can only support IPV4 TSO in tunnels if we can mangle the

	 * inner IP ID field, so strip TSO if MANGLEID is not supported.

 CBS offloading is only supported by i210 controller. */

 CBS offloading is only supported by queue 0 and queue 1. */

 Launchtime offloading is only supported by i210 controller. */

 Launchtime offloading is only supported by queues 0 and 1. */

 verify igb ring attributes are sufficient for XDP */

 device is up and bpf is added/removed, must setup the RX queues */

 bpf is just replaced, RXQ and MTU are already setup */

	/* Force memory writes to complete before letting h/w know there

	 * are new descriptors to fetch.

	/* During program transitions its possible adapter->xdp_prog is assigned

	 * but ring has not been configured yet. In this case simply abort xmit.

 Avoid transmit queue timeout since we share it with the slow path */

	/* During program transitions its possible adapter->xdp_prog is assigned

	 * but ring has not been configured yet. In this case simply abort xmit.

 Avoid transmit queue timeout since we share it with the slow path */

/**

 * igb_set_fw_version - Configure version string for ethtool

 * @adapter: adapter struct

 if option is rom valid, display its version too */

 no option rom */

/**

 * igb_init_mas - init Media Autosense feature if enabled in the NVM

 *

 * @adapter: adapter struct

 Shouldn't get here */

/**

 *  igb_init_i2c - Init I2C interface

 *  @adapter: pointer to adapter structure

 I2C interface supported on i350 devices */

	/* Initialize the i2c bus which is controlled by the registers.

	 * This bus will use the i2c_algo_bit structure that implements

	 * the protocol through toggling of the 4 bits in the register.

/**

 *  igb_probe - Device Initialization Routine

 *  @pdev: PCI device information struct

 *  @ent: entry in igb_pci_tbl

 *

 *  Returns 0 on success, negative on failure

 *

 *  igb_probe initializes an adapter identified by a pci_dev structure.

 *  The OS initialization, configuring of the adapter private structure,

 *  and a hardware reset occur.

 global quad port a indication */

	/* Catch broken hardware that put the wrong VF device ID in

	 * the PCIe SR-IOV capability.

 hw->hw_addr can be altered, we'll use adapter->io_addr for unmap */

 PCI config space info */

 Copy the default MAC, PHY and NVM function pointers */

 Initialize skew-specific constants */

 setup the private structure */

 Copper options */

	/* features is initialized to 0 in allocation, it might have bits

	 * set by igb_sw_init so we should use an or instead of an

	 * assignment.

 copy netdev features into list of user selectable features */

 set this bit last since it cannot be part of vlan_features */

 MTU range: 68 - 9216 */

	/* before reading the NVM, reset the controller to put the device in a

	 * known good starting state

	/* make sure the NVM is good , i211/i210 parts can have special NVM

	 * that doesn't contain a checksum

 copy the MAC address out of the NVM */

 get firmware version for ethtool -i */

 configure RXPBSIZE and TXPBSIZE */

 Initialize link properties that are user-changeable */

 By default, support wake on port A */

 Check the NVM for wake support on non-port A ports */

	/* now that we have the eeprom settings, apply the special cases where

	 * the eeprom may be wrong or the board simply won't support wake on

	 * lan on a particular port

		/* Wake events only supported on port A for dual fiber

		 * regardless of eeprom setting

 if quad port adapter, disable WoL on all but port A */

 Reset for multiple quad port adapters */

 If the device can't wake, don't set software support */

 initialize the wol settings based on the eeprom settings */

 Some vendors want WoL disabled by default, but still supported */

	/* Some vendors want the ability to Use the EEPROM setting as

	 * enable/disable only, and not for capability

 reset the hardware with the new settings */

 Init the I2C interface */

	/* let the f/w know that the h/w is now under the control of the

	 * driver.

 carrier off reporting is important to ethtool even BEFORE open */

 Initialize the thermal sensor on i350 devices. */

		/* Read the NVM to determine if this i350 device supports an

		 * external thermal sensor.

 Check if Media Autosense is enabled */

 do hw tstamp init after resetting */

 print bus type/speed/width info, not applicable to i354 */

 Enable EEE for internal copper PHY devices */

 reclaim resources allocated to VFs */

 disable iov and allow time for transactions to clear */

 Re-enable DMA Coalescing flag since IOV is turned off */

 if allocation failed then we do not support SR-IOV */

	/* Due to the limited number of RAR entries calculate potential

	 * number of MAC filters available for the VFs. Reserve entries

	 * for PF default MAC, PF MAC filters and at least one RAR entry

	 * for each VF for VF MAC.

 Initialize list of VF MAC filters */

		/* If we could not allocate memory for the VF MAC filters

		 * we can continue without this feature but warn user.

 only call pci_enable_sriov() if no VFs are allocated already */

 DMA Coalescing is not supported in IOV mode. */

/**

 *  igb_remove_i2c - Cleanup  I2C interface

 *  @adapter: pointer to adapter structure

 free the adapter bus structure */

/**

 *  igb_remove - Device Removal Routine

 *  @pdev: PCI device information struct

 *

 *  igb_remove is called by the PCI subsystem to alert the driver

 *  that it should release a PCI device.  The could be caused by a

 *  Hot-Plug event, or because the driver is going to be removed from

 *  memory.

	/* The watchdog timer may be rescheduled, so explicitly

	 * disable watchdog from being rescheduled.

	/* Release control of h/w to f/w.  If f/w is AMT enabled, this

	 * would have already happened in close and is redundant.

/**

 *  igb_probe_vfs - Initialize vf data storage and add VFs to pci config space

 *  @adapter: board private structure to initialize

 *

 *  This function initializes the vf specific data storage and then attempts to

 *  allocate the VFs.  The reason for ordering it this way is because it is much

 *  mor expensive time wise to disable SR-IOV than it is to allocate and free

 *  the memory for the VFs.

 Virtualization features not supported on i210 family. */

	/* Of the below we really only want the effect of getting

	 * IGB_FLAG_HAS_MSIX set (if available), without which

	 * igb_enable_sriov() has no effect.

 CONFIG_PCI_IOV */

 Determine the maximum number of RSS queues supported. */

 I350 cannot do RSS and SR-IOV at the same time */

 Determine if we need to pair queues. */

 Device supports enough interrupts without queue pairing. */

		/* If rss_queues > half of max_rss_queues, pair the queues in

		 * order to conserve interrupts due to limited supply.

/**

 *  igb_sw_init - Initialize general software structures (struct igb_adapter)

 *  @adapter: board private structure to initialize

 *

 *  igb_sw_init initializes the Adapter private data structure.

 *  Fields are initialized based on PCI device information and

 *  OS network device settings (MTU size).

 set default ring sizes */

 set default ITR values */

 set default work limits */

 CONFIG_PCI_IOV */

 Assume MSI-X interrupts, will be checked during IRQ allocation */

 Setup and initialize a copy of the hw vlan table array */

 This call may decrease the number of queues */

 Explicitly disable IRQ since the NIC can be in any state. */

/**

 *  __igb_open - Called when a network interface is made active

 *  @netdev: network interface device structure

 *  @resuming: indicates whether we are in a resume call

 *

 *  Returns 0 on success, negative value on failure

 *

 *  The open entry point is called when a network interface is made

 *  active by the system (IFF_UP).  At this point all resources needed

 *  for transmit and receive operations are allocated, the interrupt

 *  handler is registered with the OS, the watchdog timer is started,

 *  and the stack is notified that the interface is ready.

 disallow open during test */

 allocate transmit descriptors */

 allocate receive descriptors */

	/* before we allocate an interrupt, we must be ready to handle it.

	 * Setting DEBUG_SHIRQ in the kernel makes it fire an interrupt

	 * as soon as we call pci_request_irq, so we have to setup our

	 * clean_rx handler before we do so.

 Notify the stack of the actual queue counts. */

 From here on the code is the same as igb_up() */

 Clear any pending interrupts. */

 notify VFs that reset has been completed */

 start the watchdog. */

/**

 *  __igb_close - Disables a network interface

 *  @netdev: network interface device structure

 *  @suspending: indicates we are in a suspend call

 *

 *  Returns 0, this is not allowed to fail

 *

 *  The close entry point is called when an interface is de-activated

 *  by the OS.  The hardware is still under the driver's control, but

 *  needs to be disabled.  A global MAC reset is issued to stop the

 *  hardware, and all transmit and receive resources are freed.

/**

 *  igb_setup_tx_resources - allocate Tx resources (Descriptors)

 *  @tx_ring: tx descriptor ring (for a specific queue) to setup

 *

 *  Return 0 on success, negative on failure

 round up to nearest 4K */

/**

 *  igb_setup_all_tx_resources - wrapper to allocate Tx resources

 *				 (Descriptors) for all queues

 *  @adapter: board private structure

 *

 *  Return 0 on success, negative on failure

/**

 *  igb_setup_tctl - configure the transmit control registers

 *  @adapter: Board private structure

 disable queue 0 which is enabled by default on 82575 and 82576 */

 Program the Transmit Control Register */

 Enable transmits */

/**

 *  igb_configure_tx_ring - Configure transmit ring after Reset

 *  @adapter: board private structure

 *  @ring: tx ring to configure

 *

 *  Configure a transmit ring after a reset.

 reinitialize tx_buffer_info */

/**

 *  igb_configure_tx - Configure transmit Unit after Reset

 *  @adapter: board private structure

 *

 *  Configure the Tx unit of the MAC after a reset.

 disable the queues */

/**

 *  igb_setup_rx_resources - allocate Rx resources (Descriptors)

 *  @rx_ring: Rx descriptor ring (for a specific queue) to setup

 *

 *  Returns 0 on success, negative on failure

 Round up to nearest 4K */

 XDP RX-queue info */

/**

 *  igb_setup_all_rx_resources - wrapper to allocate Rx resources

 *				 (Descriptors) for all queues

 *  @adapter: board private structure

 *

 *  Return 0 on success, negative on failure

/**

 *  igb_setup_mrqc - configure the multiple receive queue control registers

 *  @adapter: Board private structure

 82576 supports 2 RSS queues for SR-IOV */

	/* Disable raw packet checksumming so that RSS hash is placed in

	 * descriptor on writeback.  No need to enable TCP/UDP/IP checksum

	 * offloads as they are enabled by default

 Enable Receive Checksum Offload for SCTP */

 Don't need to set TUOFL or IPOFL, they default to 1 */

	/* Generate RSS hash based on packet types, TCP/UDP

	 * port numbers and/or IPv4/v6 src and dst addresses

	/* If VMDq is enabled then we set the appropriate mode for that, else

	 * we default to RSS so that an RSS hash is calculated per packet even

	 * if we are only using one queue

 Set the default pool for the PF's first queue */

/**

 *  igb_setup_rctl - configure the receive control registers

 *  @adapter: Board private structure

	/* enable stripping of CRC. It's unlikely this will break BMC

	 * redirection as it did with e1000. Newer features require

	 * that the HW strips the CRC.

 disable store bad packets and clear size bits. */

 enable LPE to allow for reception of jumbo frames */

 disable queue 0 to prevent tail write w/o re-config */

	/* Attention!!!  For SR-IOV PF driver operations you must enable

	 * queue drop for all VF and PF queues to prevent head of line blocking

	 * if an un-trusted VF does not provide descriptors to hardware.

 set all queue drop enable bits */

 This is useful for sniffing bad packets. */

		/* UPE and MPE will be handled by normal PROMISC logic

		 * in e1000e_set_rx_mode

 Receive bad packets */

 RX All Bcast Pkts */

 RX All MAC Ctrl Pkts */

 Allow filtered pause */

 Dis VLAN CFIEN Filter */

		/* Do not mess with E1000_CTRL_VME, it affects transmit as well,

		 * and that breaks VLANs.

	/* This register exists only on 82576 and newer so if we are older then

	 * we should exit and do nothing

 Accept untagged packets */

 Tagged packets ONLY */

 clear all bits that might not be set */

 enable RSS */

	/* for VMDq only allow the VFs and pool 0 to accept broadcast and

	 * multicast packets

 Accept broadcast */

/**

 *  igb_setup_srrctl - configure the split and replication receive control

 *                     registers

 *  @adapter: Board private structure

 *  @ring: receive ring to be configured

	/* Only set Drop Enable if VFs allocated, or we are supporting multiple

	 * queues and rx flow control is disabled

/**

 *  igb_configure_rx_ring - Configure a receive ring after Reset

 *  @adapter: board private structure

 *  @ring: receive ring to be configured

 *

 *  Configure the Rx unit of the MAC after a reset.

 disable the queue */

 Set DMA base address registers */

 initialize head and tail */

 set descriptor configuration */

 set filtering for VMDQ pools */

 initialize rx_buffer_info */

 initialize Rx descriptor 0 */

 enable receive descriptor fetching */

 set build_skb and buffer size flags */

/**

 *  igb_configure_rx - Configure receive Unit after Reset

 *  @adapter: board private structure

 *

 *  Configure the Rx unit of the MAC after a reset.

 set the correct pool for the PF default MAC address in entry 0 */

	/* Setup the HW Rx Head and Tail Descriptor Pointers and

	 * the Base and Length of the Rx Descriptor Ring

/**

 *  igb_free_tx_resources - Free Tx Resources per Queue

 *  @tx_ring: Tx descriptor ring for a specific queue

 *

 *  Free all transmit software resources

 if not set, then don't free */

/**

 *  igb_free_all_tx_resources - Free Tx Resources for All Queues

 *  @adapter: board private structure

 *

 *  Free all transmit software resources

/**

 *  igb_clean_tx_ring - Free Tx Buffers

 *  @tx_ring: ring to be cleaned

 Free all the Tx ring sk_buffs */

 unmap skb header data */

 check for eop_desc to determine the end of the packet */

 unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 reset BQL for queue */

 reset next_to_use and next_to_clean */

/**

 *  igb_clean_all_tx_rings - Free Tx Buffers for all queues

 *  @adapter: board private structure

/**

 *  igb_free_rx_resources - Free Rx Resources

 *  @rx_ring: ring to clean the resources from

 *

 *  Free all receive software resources

 if not set, then don't free */

/**

 *  igb_free_all_rx_resources - Free Rx Resources for All Queues

 *  @adapter: board private structure

 *

 *  Free all receive software resources

/**

 *  igb_clean_rx_ring - Free Rx Buffers per Queue

 *  @rx_ring: ring to free buffers from

 Free all the Rx ring sk_buffs */

		/* Invalidate cache lines that may have been written to by

		 * device so that we avoid corrupting memory.

 free resources associated with mapping */

/**

 *  igb_clean_all_rx_rings - Free Rx Buffers for all queues

 *  @adapter: board private structure

/**

 *  igb_set_mac - Change the Ethernet Address of the NIC

 *  @netdev: network interface device structure

 *  @p: pointer to an address structure

 *

 *  Returns 0 on success, negative on failure

 set the correct pool for the new PF MAC address in entry 0 */

/**

 *  igb_write_mc_addr_list - write multicast addresses to MTA

 *  @netdev: network interface device structure

 *

 *  Writes multicast address list to the MTA hash table.

 *  Returns: -ENOMEM on failure

 *           0 on no addresses written

 *           X on writing X addresses to MTA

 nothing to program, so clear mc list */

 The shared function expects a packed array of only addresses. */

 VLAN filtering needed for VLAN prio filter */

 VLAN filtering needed for pool filtering */

 We are already in VLAN promisc, nothing to do */

 Add PF to all active pools */

 Set all bits in the VLAN filter table array */

 Set flag so we don't redo unnecessary work */

 guarantee that we don't scrub out management VLAN */

 pull VLAN ID from VLVF */

 only concern ourselves with a certain range */

 record VLAN ID in VFTA */

 if PF is part of this then continue */

 remove PF from the pool */

 extract values from active_vlans and write back to VFTA */

 We are not in VLAN promisc, nothing to do */

 Set flag so we don't redo unnecessary work */

/**

 *  igb_set_rx_mode - Secondary Unicast, Multicast and Promiscuous mode set

 *  @netdev: network interface device structure

 *

 *  The set_rx_mode entry point is called whenever the unicast or multicast

 *  address lists or the network interface flags are updated.  This routine is

 *  responsible for configuring the hardware for proper unicast, multicast,

 *  promiscuous mode, and all-multi behavior.

 Check for Promiscuous and All Multicast modes */

 enable use of UTA filter to force packets to default pool */

			/* Write addresses to the MTA, if the attempt fails

			 * then we should just turn on promiscuous mode so

			 * that we can at least receive multicast traffic

	/* Write addresses to available RAR registers, if there is not

	 * sufficient space to store all the addresses then enable

	 * unicast promiscuous mode

 enable VLAN filtering by default */

 disable VLAN filtering for modes that require it */

 if we fail to set all rules then just clear VFE */

 update state of unicast, multicast, and VLAN filtering modes */

	/* In order to support SR-IOV and eventually VMDq it is necessary to set

	 * the VMOLR to enable the appropriate modes.  Without this workaround

	 * we will have issues with VLAN tag stripping not being done for frames

	 * that are only arriving because we are the default pool

 set UTA to appropriate mode */

 enable Rx jumbo frames, restrict as needed to support build_skb */

/* Need to wait a few seconds after link up to get diagnostic information from

 * the phy

/**

 *  igb_has_link - check shared code for link and determine up/down

 *  @adapter: pointer to driver private info

	/* get_link_status is set on LSC (link status) interrupt or

	 * rx sequence error interrupt.  get_link_status will stay

	 * false until the e1000_check_for_link establishes link

	 * for copper adapters ONLY

 check for thermal sensor event on i350 copper only */

/**

 *  igb_check_lvmmc - check for malformed packets received

 *  and indicated in LVMMC register

 *  @adapter: pointer to adapter

/**

 *  igb_watchdog - Timer Call-back

 *  @t: pointer to timer_list containing our private info pointer

 Do the rest outside of interrupt context */

 Force link down if we have fiber to swap to */

 Perform a reset if the media type changed. */

 Cancel scheduled suspend requests. */

 Links status message must follow this format */

 disable EEE if enabled */

 check if SmartSpeed worked */

 check for thermal sensor event */

 adjust timeout factor according to speed/duplex */

 maybe add some timeout factor ? */

 wait for Remote receiver status OK */

 link state has changed, schedule phy info update */

 check for thermal sensor event */

 Links status message must follow this format */

 link state has changed, schedule phy info update */

 link is down, time to check for alternate media */

 return immediately */

 also check for alternate media here */

 return immediately */

			/* We've lost link, so the controller stops DMA,

			 * but we've got queued Tx work that's never going

			 * to get done, so reset controller to flush Tx.

			 * (Do the reset outside of interrupt context).

 return immediately since reset is imminent */

 Force detection of hung controller every watchdog period */

 Cause software interrupt to ensure Rx ring is cleaned */

 Check LVMMC register on i350/i354 only */

 Reset the timer */

/**

 *  igb_update_ring_itr - update the dynamic ITR value based on packet size

 *  @q_vector: pointer to q_vector

 *

 *  Stores a new ITR value based on strictly on packet size.  This

 *  algorithm is less sophisticated than that used in igb_update_itr,

 *  due to the difficulty of synchronizing statistics across multiple

 *  receive rings.  The divisors and thresholds used by this function

 *  were determined based on theoretical maximum wire speed and testing

 *  data, in order to minimize response time while increasing bulk

 *  throughput.

 *  This functionality is controlled by ethtool's coalescing settings.

 *  NOTE:  This function is called only when operating in a multiqueue

 *         receive environment.

	/* For non-gigabit speeds, just fix the interrupt rate at 4000

	 * ints/sec - ITR timer value of 120 ticks.

 if avg_wire_size isn't set no work was done */

 Add 24 bytes to size to account for CRC, preamble, and gap */

 Don't starve jumbo frames */

 Give a little boost to mid-size frames */

 conservative mode (itr 3) eliminates the lowest_latency setting */

/**

 *  igb_update_itr - update the dynamic ITR value based on statistics

 *  @q_vector: pointer to q_vector

 *  @ring_container: ring info to update the itr for

 *

 *  Stores a new ITR value based on packets and byte

 *  counts during the last interrupt.  The advantage of per interrupt

 *  computation is faster updates and more accurate ITR for the current

 *  traffic pattern.  Constants in this function were computed

 *  based on theoretical maximum wire speed and thresholds were set based

 *  on testing data as well as attempting to minimize response time

 *  while increasing bulk throughput.

 *  This functionality is controlled by ethtool's coalescing settings.

 *  NOTE:  These calculations are only valid when operating in a single-

 *         queue environment.

 no packets, exit with status unchanged */

 handle TSO and jumbo frames */

 50 usec aka 20000 ints/s */

 this if handles the TSO accounting */

 250 usec aka 4000 ints/s */

 clear work counters since we have the values we need */

 write updated itr to ring container */

 for non-gigabit speeds, just fix the interrupt rate at 4000 */

 conservative mode (itr 3) eliminates the lowest_latency setting */

 counts and packets in update_itr are dependent on these numbers */

 70,000 ints/sec */

 20,000 ints/sec */

 4,000 ints/sec */

		/* this attempts to bias the interrupt rate towards Bulk

		 * by adding intermediate steps when interrupt rate is

		 * increasing

		/* Don't write the value here; it resets the adapter's

		 * internal timer, and causes us to delay far longer than

		 * we should between interrupts.  Instead, we write the ITR

		 * value at the beginning of the next interrupt so the timing

		 * ends up being correct.

 set bits to identify this as an advanced context descriptor */

 For 82575, context index must be unique per ring. */

	/* We assume there is always a valid tx time available. Invalid times

	 * should have been handled by the upper layers.

 ADV DTYP TUCMD MKRLOC/ISCSIHEDLEN */

 initialize outer IP header fields */

		/* IP header will have to cancel out any data that

		 * is not a part of the outer IP header

 determine offset of inner transport header */

 remove payload length from inner checksum */

 compute length of segmentation header */

 compute length of segmentation header */

 update gso size and bytecount with header size */

 MSS L4LEN IDX */

 VLAN MACLEN IPLEN */

 validate that this is actually an SCTP request */

 update TX checksum flag */

 set type for advanced descriptor with frame checksum insertion */

 set HW vlan bit if vlan is present */

 set segmentation bits for TSO */

 set timestamp bit if present */

 insert frame checksum */

 82575 requires a unique index per ring */

 insert L4 checksum */

 insert IPv4 checksum */

	/* Herbert's original patch had:

	 *  smp_mb__after_netif_stop_queue();

	 * but since that doesn't exist yet, just open code it.

	/* We need to check again in a case another CPU has just

	 * made room available.

 A reprieve! */

 record length, and DMA address */

 write last descriptor with RS and EOP bits */

 set the timestamp */

	/* Force memory writes to complete before letting h/w know there

	 * are new descriptors to fetch.  (Only applicable for weak-ordered

	 * memory model archs, such as IA-64).

	 *

	 * We also need this memory barrier to make certain all of the

	 * status bits have been updated before next_to_watch is written.

 set next_to_watch value indicating a packet is present */

 Make sure there is space in the ring for the next send. */

 clear dma mappings for failed tx_buffer_info map */

 record the location of the first descriptor for this packet */

 put descriptor type bits */

 82575 requires a unique index per ring */

 set the timestamp */

 Avoid any potential race with xdp_xmit and cleanup */

 set next_to_watch value indicating a packet is present */

 Make sure there is space in the ring for the next send. */

	/* need: 1 descriptor per page * PAGE_SIZE/IGB_MAX_DATA_PER_TXD,

	 *       + 1 desc for skb_headlen/IGB_MAX_DATA_PER_TXD,

	 *       + 2 desc gap to keep tail from touching head,

	 *       + 1 desc for context descriptor,

	 * otherwise try next time

 this is a hard error */

 record the location of the first descriptor for this packet */

 record initial flags and protocol */

	/* The minimum packet size with TCTL.PSP set is 17 so pad the skb

	 * in order to meet this minimum size requirement.

/**

 *  igb_tx_timeout - Respond to a Tx Hang

 *  @netdev: network interface device structure

 *  @txqueue: number of the Tx queue that hung (unused)

 Do the reset outside of interrupt context */

 If we're already down or resetting, just bail */

/**

 *  igb_get_stats64 - Get System Network Statistics

 *  @netdev: network interface device structure

 *  @stats: rtnl_link_stats64 pointer

/**

 *  igb_change_mtu - Change the Maximum Transfer Unit

 *  @netdev: network interface device structure

 *  @new_mtu: new value for maximum frame size

 *

 *  Returns 0 on success, negative on failure

 adjust max frame to be at least the size of a standard frame */

 igb_down has a dependency on max_frame_size */

/**

 *  igb_update_stats - Update the board statistics counters

 *  @adapter: board private structure

	/* Prevent stats update while adapter is being reset, or if the pci

	 * connection is down.

 read stats registers */

 clear GORCL */

 clear GOTCL */

 read internal phy specific stats */

 this stat has invalid values on i210/i211 */

 Fill out the OS statistics structure */

 Rx Errors */

	/* RLEC on some newer hardware can be incorrect so build

	 * our own version based on RUC and ROC

 Tx Errors */

 Tx Dropped needs to be maintained elsewhere */

 Management Stats */

 OS2BMC Stats */

 retrieve hardware timestamp */

 u32 conversion of tv_sec is safe until y2106 */

 acknowledge the interrupts */

 reading ICR causes bit 31 of EICR to be cleared */

 HW is reporting DMA is out of sync */

		/* The DMA Out of Sync is also indication of a spoof event

		 * in IOV mode. Check the Wrong VM Behavior register to

		 * see if it is really a spoof event.

 Check for a mailbox event */

 guard against interrupt when we're going down */

 Write the ITR value calculated from the previous interrupt. */

	/* We can enable relaxed ordering for reads, but not writes when

	 * DCA is enabled.  This is due to a known issue in some chipsets

	 * which will cause the DCA tag to be cleared.

	/* We can enable relaxed ordering for reads, but not writes when

	 * DCA is enabled.  This is due to a known issue in some chipsets

	 * which will cause the DCA tag to be cleared.

 Always use CB2 mode, difference is masked in the CB driver. */

 if already enabled, don't do it again */

 since DCA is disabled. */

			/* without this a class_device is left

			 * hanging around in the sysfs model

 CONFIG_IGB_DCA */

 By default spoof check is enabled for all VFs */

 By default VFs are not trusted */

		/* if we have hashes and we are clearing a multicast promisc

		 * flag we need to write the hashes to the MTA as this step

		 * was previously skipped

 there are flags left unprocessed, likely not supported */

	/* salt away the number of multicast addresses assigned

	 * to this VF for later use to restore when the PF multi cast

	 * list changes

 only up to 30 hash values supported */

 store the hashes for later use */

 Flush and reset the mta with the new values */

 create mask for VF and other pools */

 drop PF from pool bits */

 Find the vlan filter for this id */

 remove the vf from the pool */

 clear out bit from VLVF */

 if other pools are present, just remove ourselves */

 if PF is present, leave VFTA */

 clear bit from VFTA */

 clear pool selection enable */

 clear pool bits */

 short cut the special case */

 Search for the VLAN id in the VLVF entries */

	/* See if any other pools are set for this VLAN filter

	 * entry other than the PF.

 Disable the filter so this falls into the default pool. */

	/* If VLAN overlaps with one the PF is currently monitoring make

	 * sure that we are able to allocate a VLVF entry.  This may be

	 * redundant but it guarantees PF will maintain visibility to

	 * the VLAN.

	/* If we failed to add the VF VLAN or we are removing the VF VLAN

	 * we may need to drop the PF pool bit in order to allow us to free

	 * up the VLVF resources.

 revoke access to previous VLAN */

 Restore tagless access via VLAN 0 */

 Remove any PF assigned VLAN */

 VLAN 0 is a special case, don't allow it to be removed */

 clear flags - except flag that indicates PF has set the MAC */

 reset vlans for device */

 reset multicast table array for vf */

 Flush and reset the mta with the new values */

 clear mac address as we were hotplug removed/added */

 process remaining reset events */

 process all the same items cleared in a function level reset */

 set vf mac address */

 enable transmit and receive for vf */

 reply to reset with ack and vf mac address */

 do not count rar entries reserved for VFs MAC addresses */

 do not count default entries */

 do not count "in use" entries for different queues */

 Set default MAC address for the PF in the first RAR entry */

/* If the filter to be added and an already existing filter express

 * the same address and address type, it should be possible to only

 * override the other configurations, for example the queue to steer

 * traffic.

/* Add a MAC filter for 'addr' directing matching traffic to 'queue',

 * 'flags' is used to indicate what kind of match is made, match is by

 * default for the destination address, if matching by source address

 * is desired the flag IGB_MAC_STATE_SRC_ADDR can be used.

	/* Search for the first empty entry in the MAC table.

	 * Do not touch entries at the end of the table reserved for the VF MAC

	 * addresses.

/* Remove a MAC filter for 'addr' directing matching traffic to

 * 'queue', 'flags' is used to indicate what kind of match need to be

 * removed, match is by default for the destination address, if

 * matching by source address is to be removed the flag

 * IGB_MAC_STATE_SRC_ADDR can be used.

	/* Search for matching entry in the MAC table based on given address

	 * and queue. Do not touch entries at the end of the table reserved

	 * for the VF MAC addresses.

		/* When a filter for the default address is "deleted",

		 * we return it to its initial configuration

	/* In theory, this should be supported on 82575 as well, but

	 * that part wasn't easily accessible during development.

 remove all unicast MAC filters related to the current VF */

 try to find empty slot in the list */

	/* The VF MAC Address is stored in a packed array of bytes

	 * starting at the second 32 bit word of the msg array

 if device isn't clear to send it shouldn't be reading either */

 if receive failed revoke VF CTS stats and restart init */

 this is a message we already processed, do nothing */

	/* until the vf completes a reset it should not be

	 * allowed to start any configuration.

 unlocks mailbox */

 notify the VF of the results of what it sent us */

 unlocks mailbox */

 process any reset requests */

 process any messages pending */

 process any acks */

/**

 *  igb_set_uta - Set unicast filter table address

 *  @adapter: board private structure

 *  @set: boolean indicating if we are setting or clearing bits

 *

 *  The unicast table address is a register array of 32-bit registers.

 *  The table is meant to be used in a way similar to how the MTA is used

 *  however due to certain limitations in the hardware it is necessary to

 *  set all the hash bits to 1 and use the VMOLR ROPE bit as a promiscuous

 *  enable bit to allow vlan tag stripping when promiscuous mode is enabled

 we only need to do this if VMDq is enabled */

/**

 *  igb_intr_msi - Interrupt Handler

 *  @irq: interrupt number

 *  @data: pointer to a network interface device structure

 read ICR disables interrupts using IAM */

 HW is reporting DMA is out of sync */

/**

 *  igb_intr - Legacy Interrupt Handler

 *  @irq: interrupt number

 *  @data: pointer to a network interface device structure

	/* Interrupt Auto-Mask...upon reading ICR, interrupts are masked.  No

	 * need for the IMC write

	/* IMS will not auto-mask if INT_ASSERTED is not set, and if it is

	 * not set, then the adapter didn't send an interrupt

 HW is reporting DMA is out of sync */

 guard against interrupt when we're going down */

/**

 *  igb_poll - NAPI Rx polling callback

 *  @napi: napi polling structure

 *  @budget: count of how many packets we should handle

 If all work not completed, return budget and keep polling */

	/* Exit the polling mode, but don't re-enable interrupts if stack might

	 * poll us due to busy-polling

/**

 *  igb_clean_tx_irq - Reclaim resources after transmit completes

 *  @q_vector: pointer to q_vector containing needed info

 *  @napi_budget: Used to determine if we are in netpoll

 *

 *  returns true if ring is completely cleaned

 if next_to_watch is not set then there is no work pending */

 prevent any other reads prior to eop_desc */

 if DD is not set pending work has not been completed */

 clear next_to_watch to prevent false hangs */

 update the statistics for this packet */

 free the skb */

 unmap skb header data */

 clear tx_buffer data */

 clear last DMA location and unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 issue prefetch for next Tx descriptor */

 update budget accounting */

		/* Detect a transmit hang in hardware, this serializes the

		 * check with the clearing of time_stamp and movement of i

 detected Tx unit hang */

 we are about to reset, no point in enabling stuff */

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

/**

 *  igb_reuse_rx_page - page flip buffer and store it back on the ring

 *  @rx_ring: rx descriptor ring to store buffers on

 *  @old_buff: donor buffer to have page reused

 *

 *  Synchronizes page for reuse by the adapter

 update, and store next to alloc */

	/* Transfer page from old buffer to new buffer.

	 * Move each member individually to avoid possible store

	 * forwarding stalls.

 avoid re-using remote and pfmemalloc pages */

 if we are only owner of page we can reuse it */

	/* If we have drained the page fragment pool we need to update

	 * the pagecnt_bias and page count so that we fully restock the

	 * number of references the driver holds.

/**

 *  igb_add_rx_frag - Add contents of Rx buffer to sk_buff

 *  @rx_ring: rx descriptor ring to transact packets on

 *  @rx_buffer: buffer containing page to add

 *  @skb: sk_buff to place the data into

 *  @size: size of buffer to be added

 *

 *  This function will add the data contained in rx_buffer->page to the skb.

 prefetch first cache line of first page */

 allocate a skb to store the frags */

 Determine available headroom for copy */

 align pull length to size of long to optimize memcpy performance */

 update all of the pointers */

 prefetch first cache line of first page */

 build an skb around the page buffer */

 update pointers within the skb to store the data */

 update buffer offset */

 xdp_frame write */

 Must be power-of-2 */

 Ignore Checksum bit is set */

 Rx checksum disabled via ethtool */

 TCP/UDP checksum error bit is set */

		/* work around errata with sctp packets where the TCPE aka

		 * L4E bit is set incorrectly on 64 byte (60 byte w/o crc)

		 * packets, (aka let the stack check the crc32c)

 let the stack verify checksum errors */

 It must be a TCP or UDP packet with a valid checksum */

/**

 *  igb_is_non_eop - process handling of non-EOP buffers

 *  @rx_ring: Rx ring being processed

 *  @rx_desc: Rx descriptor for current buffer

 *

 *  This function updates next to clean.  If the buffer is an EOP buffer

 *  this function exits returning false, otherwise it will place the

 *  sk_buff in the next buffer to be chained and return true indicating

 *  that this is in fact a non-EOP buffer.

 fetch, update, and store next to clean */

/**

 *  igb_cleanup_headers - Correct corrupted or empty headers

 *  @rx_ring: rx descriptor ring packet is being transacted on

 *  @rx_desc: pointer to the EOP Rx descriptor

 *  @skb: pointer to current skb being fixed

 *

 *  Address the case where we are pulling data in on pages only

 *  and as such no data is present in the skb header.

 *

 *  In addition if skb is not at least 60 bytes we need to pad it so that

 *  it is large enough to qualify as a valid Ethernet frame.

 *

 *  Returns true if an error was encountered and skb was freed.

 XDP packets use error pointer so abort at this point */

 if eth_skb_pad returns an error the skb was freed */

/**

 *  igb_process_skb_fields - Populate skb header fields from Rx descriptor

 *  @rx_ring: rx descriptor ring packet is being transacted on

 *  @rx_desc: pointer to the EOP Rx descriptor

 *  @skb: pointer to current skb being populated

 *

 *  This function checks the ring, descriptor, and packet information in

 *  order to populate the hash, checksum, VLAN, timestamp, protocol, and

 *  other fields within the skb.

 we are reusing so sync this buffer for CPU use */

 hand second half of page back to the ring */

		/* We are not reusing the buffer so unmap it and free

		 * any references we are holding to it

 clear contents of rx_buffer */

 Frame size depend on rx_ring setup when PAGE_SIZE=4K */

 return some buffers to hardware, one at a time is too slow */

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we know the

		 * descriptor has been written back

 pull rx packet timestamp if available and valid */

 retrieve a buffer from the ring */

 At larger PAGE_SIZE, frame_sz depend on len size */

 exit if we failed to retrieve a buffer */

 fetch next buffer in frame if non-eop */

 verify the packet layout is correct */

 probably a little skewed due to removing CRC */

 populate checksum, timestamp, VLAN, and protocol */

 reset skb pointer */

 update budget accounting */

 place incomplete frames back on ring for completion */

 since we are recycling buffers we should seldom need to alloc */

 alloc new page for storage */

 map page for use */

	/* if mapping failed free memory back to system since

	 * there isn't much point in holding memory we can't use

/**

 *  igb_alloc_rx_buffers - Replace used receive buffers

 *  @rx_ring: rx descriptor ring to allocate new receive buffers

 *  @cleaned_count: count of buffers to allocate

 nothing to do */

 sync the buffer for use by the device */

		/* Refresh the desc even if buffer_addrs didn't change

		 * because each write-back erases this info.

 clear the length for the next_to_use descriptor */

 record the next descriptor to use */

 update next to alloc since we have filled the ring */

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

/**

 * igb_mii_ioctl -

 * @netdev: pointer to netdev struct

 * @ifr: interface structure

 * @cmd: ioctl command to execute

/**

 * igb_ioctl -

 * @netdev: pointer to netdev struct

 * @ifr: interface structure

 * @cmd: ioctl command to execute

 enable VLAN tag insert/strip */

 Disable CFI check */

 disable VLAN tag insert/strip */

 add the filter since PF can receive vlans w/o entry in vlvf */

 remove VID from filter table */

	/* Make sure dplx is at most 1 bit and lsb of speed is not set

	 * for the switch() below to work

	/* Fiber NIC's only allow 1000 gbps Full duplex

	 * and 100Mbps Full duplex for 100baseFx sfp

 not supported */

 clear MDI, MDI(-X) override is only allowed when autoneg enabled */

 turn on all-multi mode if wake on multicast is enabled */

 Allow time for pending master requests to run */

	/* Release control of h/w to f/w.  If f/w is AMT enabled, this

	 * would have already happened in close and is redundant.

	/* WUPM stores only the first 128 bytes of the wake packet.

	 * Read the packet only if we have the whole thing.

 Ensure reads are 32-bit aligned */

	/* let the f/w know that the h/w is now under the control of the

	 * driver.

/**

 *  igb_io_error_detected - called when PCI error is detected

 *  @pdev: Pointer to PCI device

 *  @state: The current pci connection state

 *

 *  This function is called after a PCI bus error affecting

 *  this device has been detected.

 Request a slot slot reset. */

/**

 *  igb_io_slot_reset - called after the pci bus has been reset.

 *  @pdev: Pointer to PCI device

 *

 *  Restart the card from scratch, as if from a cold-boot. Implementation

 *  resembles the first-half of the igb_resume routine.

		/* In case of PCI error, adapter lose its HW address

		 * so we should re-assign it here.

/**

 *  igb_io_resume - called when traffic can start flowing again.

 *  @pdev: Pointer to PCI device

 *

 *  This callback is called when the error recovery driver tells us that

 *  its OK to resume normal operation. Implementation resembles the

 *  second-half of the igb_resume routine.

	/* let the f/w know that the h/w is now under the control of the

	 * driver.

/**

 *  igb_rar_set_index - Sync RAL[index] and RAH[index] registers with MAC table

 *  @adapter: Pointer to adapter structure

 *  @index: Index of the RAR entry which need to be synced with MAC table

	/* HW expects these to be in network order when they are plugged

	 * into the registers which are little endian.  In order to guarantee

	 * that ordering we need to do an leXX_to_cpup here in order to be

	 * ready for the byteswap that occurs with writel

 Indicate to hardware the Address is Valid. */

	/* VF MAC addresses start at end of receive addresses and moves

	 * towards the first, as a result a collision should not be possible

	/* Setting the VF MAC to 0 reverts the IGB_VF_FLAG_PF_SET_MAC

	 * flag and allows to overwrite the MAC via VF netdev.  This

	 * is necessary to allow libvirt a way to restore the original

	 * MAC after unbinding vfio-pci and reloading igbvf after shutting

	 * down a VM.

 Generate additional warning if PF is down */

 Calculate the rate factor values to set */

 vf X uses queue X */

	/* Set global transmit compensation time to the MMW_SIZE in RTTBCNRM

	 * register. MMW_SIZE=0x014 if 9728-byte jumbo is supported.

 VF TX rate limit was not set or not supported */

 replication is not supported for 82575 */

 notify HW that the MAC is adding vlan tags */

 enable replication vlan tag stripping */

 none of the above registers are supported by i350 */

 force threshold to 0. */

			/* DMA Coalescing high water mark needs to be greater

			 * than the Rx threshold. Set hwm to PBA - max frame

			 * size in 16B units, capping it at PBA - 6KB.

			/* Set the DMA Coalescing Rx threshold to PBA - 2 * max

			 * frame size, capping it at PBA - 10KB.

 transition to L0x or L1 if available..*/

 watchdog timer= +-1000 usec in 32usec intervals */

 Disable BMC-to-OS Watchdog Enable */

			/* no lower threshold to disable

			 * coalescing(smart fifb)-UTRESH=0

			/* free space in tx packet buffer to wake from

			 * DMA coal

			/* make low power state decision controlled

			 * by DMA coal

 endif adapter->dmac is not disabled */

/**

 *  igb_read_i2c_byte - Reads 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to read

 *  @dev_addr: device address

 *  @data: value read

 *

 *  Performs byte read operation over I2C interface at

 *  a specified device address.

/**

 *  igb_write_i2c_byte - Writes 8 bit word over I2C

 *  @hw: pointer to hardware structure

 *  @byte_offset: byte offset to write

 *  @dev_addr: device address

 *  @data: value to write

 *

 *  Performs byte write operation over I2C interface at

 *  a specified device address.

 igb_main.c */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2007 - 2018 Intel Corporation. */

/* e1000_i210

 * e1000_i211

/**

 * igb_get_hw_semaphore_i210 - Acquire hardware semaphore

 *  @hw: pointer to the HW structure

 *

 *  Acquire the HW semaphore to access the PHY or NVM

 Get the SW semaphore */

		/* In rare circumstances, the SW semaphore may already be held

		 * unintentionally. Clear the semaphore once before giving up.

 If we do not have the semaphore here, we have to give up. */

 Get the FW semaphore. */

 Semaphore acquired if bit latched */

 Release semaphores */

/**

 *  igb_acquire_nvm_i210 - Request for access to EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Acquire the necessary semaphores for exclusive access to the EEPROM.

 *  Set the EEPROM access request bit and wait for EEPROM access grant bit.

 *  Return successful if access grant bit set, else clear the request for

 *  EEPROM access and return -E1000_ERR_NVM (-1).

/**

 *  igb_release_nvm_i210 - Release exclusive access to EEPROM

 *  @hw: pointer to the HW structure

 *

 *  Stop any current commands to the EEPROM and clear the EEPROM request bit,

 *  then release the semaphores acquired.

/**

 *  igb_acquire_swfw_sync_i210 - Acquire SW/FW semaphore

 *  @hw: pointer to the HW structure

 *  @mask: specifies which semaphore to acquire

 *

 *  Acquire the SW/FW semaphore to access the PHY or NVM.  The mask

 *  will also specify which port we're acquiring the lock for.

 FIXME: find real value to use here */

 Firmware currently using resource (fwmask) */

/**

 *  igb_release_swfw_sync_i210 - Release SW/FW semaphore

 *  @hw: pointer to the HW structure

 *  @mask: specifies which semaphore to acquire

 *

 *  Release the SW/FW semaphore used to access the PHY or NVM.  The mask

 *  will also specify which port we're releasing the lock for.

 Empty */

/**

 *  igb_read_nvm_srrd_i210 - Reads Shadow Ram using EERD register

 *  @hw: pointer to the HW structure

 *  @offset: offset of word in the Shadow Ram to read

 *  @words: number of words to read

 *  @data: word read from the Shadow Ram

 *

 *  Reads a 16 bit word from the Shadow Ram using the EERD register.

 *  Uses necessary synchronization semaphores.

	/* We cannot hold synchronization semaphores for too long,

	 * because of forceful takeover procedure. However it is more efficient

	 * to read in bursts than synchronizing access for each word.

/**

 *  igb_write_nvm_srwr - Write to Shadow Ram using EEWR

 *  @hw: pointer to the HW structure

 *  @offset: offset within the Shadow Ram to be written to

 *  @words: number of words to write

 *  @data: 16 bit word(s) to be written to the Shadow Ram

 *

 *  Writes data to Shadow Ram at offset using EEWR register.

 *

 *  If igb_update_nvm_checksum is not called after this function , the

 *  Shadow Ram will most likely contain an invalid checksum.

	/* A check for invalid values:  offset too large, too many words,

	 * too many words for the offset, and not enough words.

/**

 *  igb_write_nvm_srwr_i210 - Write to Shadow RAM using EEWR

 *  @hw: pointer to the HW structure

 *  @offset: offset within the Shadow RAM to be written to

 *  @words: number of words to write

 *  @data: 16 bit word(s) to be written to the Shadow RAM

 *

 *  Writes data to Shadow RAM at offset using EEWR register.

 *

 *  If e1000_update_nvm_checksum is not called after this function , the

 *  data will not be committed to FLASH and also Shadow RAM will most likely

 *  contain an invalid checksum.

 *

 *  If error code is returned, data and Shadow RAM may be inconsistent - buffer

 *  partially written.

	/* We cannot hold synchronization semaphores for too long,

	 * because of forceful takeover procedure. However it is more efficient

	 * to write in bursts than synchronizing access for each word.

/**

 *  igb_read_invm_word_i210 - Reads OTP

 *  @hw: pointer to the HW structure

 *  @address: the word address (aka eeprom offset) to read

 *  @data: pointer to the data read

 *

 *  Reads 16-bit words from the OTP. Return error when the word is not

 *  stored in OTP.

 Get record type */

/**

 * igb_read_invm_i210 - Read invm wrapper function for I210/I211

 *  @hw: pointer to the HW structure

 *  @offset: offset to read from

 *  @words: number of words to read (unused)

 *  @data: pointer to the data read

 *

 *  Wrapper function to return data formerly found in the NVM.

 Only the MAC addr is required to be present in the iNVM */

/**

 *  igb_read_invm_version - Reads iNVM version and image type

 *  @hw: pointer to the HW structure

 *  @invm_ver: version structure for the version read

 *

 *  Reads iNVM version and image type.

 Read iNVM memory */

 Read version number */

 Check if we have first version location used */

 Check if we have second version location used */

		/* Check if we have odd version location

		 * used and it is the last one used

		/* Check if we have even version location

		 * used and it is the last one used

 Read Image Type */

 Check if we have image type in first location used */

 Check if we have image type in first location used */

/**

 *  igb_validate_nvm_checksum_i210 - Validate EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Calculates the EEPROM checksum by reading/adding each word of the EEPROM

 *  and then verifies that the sum of the EEPROM is equal to 0xBABA.

		/* Replace the read function with semaphore grabbing with

		 * the one that skips this for a while.

		 * We have semaphore taken already here.

 Revert original read operation. */

/**

 *  igb_update_nvm_checksum_i210 - Update EEPROM checksum

 *  @hw: pointer to the HW structure

 *

 *  Updates the EEPROM checksum by reading/adding each word of the EEPROM

 *  up to the checksum.  Then calculates the EEPROM checksum and writes the

 *  value to the EEPROM. Next commit EEPROM data onto the Flash.

	/* Read the first word from the EEPROM. If this times out or fails, do

	 * not continue or we could be in for a very long wait while every

	 * EEPROM read fails

		/* Do not use hw->nvm.ops.write, hw->nvm.ops.read

		 * because we do not want to take the synchronization

		 * semaphores twice here.

/**

 *  igb_pool_flash_update_done_i210 - Pool FLUDONE status.

 *  @hw: pointer to the HW structure

 *

/**

 *  igb_get_flash_presence_i210 - Check if flash device is detected.

 *  @hw: pointer to the HW structure

 *

/**

 *  igb_update_flash_i210 - Commit EEPROM to the flash

 *  @hw: pointer to the HW structure

 *

/**

 *  igb_valid_led_default_i210 - Verify a valid default LED config

 *  @hw: pointer to the HW structure

 *  @data: pointer to the NVM (EEPROM)

 *

 *  Read the EEPROM for the current default LED configuration.  If the

 *  LED configuration is not valid, set to a valid LED configuration.

/**

 *  __igb_access_xmdio_reg - Read/write XMDIO register

 *  @hw: pointer to the HW structure

 *  @address: XMDIO address to program

 *  @dev_addr: device address to program

 *  @data: pointer to value to read/write from/to the XMDIO address

 *  @read: boolean flag to indicate read or write

 Recalibrate the device back to 0 */

/**

 *  igb_read_xmdio_reg - Read XMDIO register

 *  @hw: pointer to the HW structure

 *  @addr: XMDIO address to program

 *  @dev_addr: device address to program

 *  @data: value to be read from the EMI address

/**

 *  igb_write_xmdio_reg - Write XMDIO register

 *  @hw: pointer to the HW structure

 *  @addr: XMDIO address to program

 *  @dev_addr: device address to program

 *  @data: value to be written to the XMDIO address

/**

 *  igb_init_nvm_params_i210 - Init NVM func ptrs.

 *  @hw: pointer to the HW structure

 NVM Function Pointers */

/**

 * igb_pll_workaround_i210

 * @hw: pointer to the HW structure

 *

 * Works around an errata in the PLL circuit where it occasionally

 * provides the wrong clock frequency after power up.

 Get and set needed register values */

 Get data from NVM, or set default */

 check current state directly from internal PHY */

 directly reset the internal PHY */

 restore WUC register */

 restore MDICNFG setting */

/**

 *  igb_get_cfg_done_i210 - Read config done bit

 *  @hw: pointer to the HW structure

 *

 *  Read the management control register for the config done bit for

 *  completion status.  NOTE: silicon which is EEPROM-less will fail trying

 *  to read the config done bit, so an error is *ONLY* logged and returns

 *  0.  If we were to return with error, EEPROM-less silicon

 *  would not be able to be reset or change link.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2007 - 2018 Intel Corporation. */

 hwmon callback functions */

 reset the temp field */

 display millidegree */

 display millidegree */

 display millidegree */

/* igb_add_hwmon_attr - Create hwmon attr table for a hwmon sysfs file.

 * @ adapter: pointer to the adapter structure

 * @ offset: offset in the eeprom sensor data table

 * @ type: type of sensor data to display

 *

 * For each file we want in hwmon's sysfs interface we need a device_attribute

 * This is included in our hwmon_attr struct that contains the references to

 * the data structures we need to get the data to display.

 These always the same regardless of type */

 called from igb_main.c */

 called from igb_main.c */

 If this method isn't defined we don't support thermals */

 Don't create thermal hwmon interface if no sensors present */

		/* Only create hwmon sysfs entries for sensors that have

		 * meaningful data.

 Bail if any hwmon attr struct fails to initialize */

 init i2c_client */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

/**

 *  fm10k_tlv_msg_init - Initialize message block for TLV data storage

 *  @msg: Pointer to message block

 *  @msg_id: Message ID indicating message type

 *

 *  This function return success if provided with a valid message pointer

 verify pointer is not NULL */

/**

 *  fm10k_tlv_attr_put_null_string - Place null terminated string on message

 *  @msg: Pointer to message block

 *  @attr_id: Attribute ID

 *  @string: Pointer to string to be stored in attribute

 *

 *  This function will reorder a string to be CPU endian and store it in

 *  the attribute buffer.  It will return success if provided with a valid

 *  pointers.

 verify pointers are not NULL */

 copy string into local variable and then write to msg */

 write data to message */

 record character to offset location */

 test for NULL and then increment */

 write last piece of data to message */

 record attribute header, update message length */

 add header length to length */

/**

 *  fm10k_tlv_attr_get_null_string - Get null terminated string from attribute

 *  @attr: Pointer to attribute

 *  @string: Pointer to location of destination string

 *

 *  This function pulls the string back out of the attribute and will place

 *  it in the array pointed by by string.  It will return success if provided

 *  with a valid pointers.

 verify pointers are not NULL */

/**

 *  fm10k_tlv_attr_put_mac_vlan - Store MAC/VLAN attribute in message

 *  @msg: Pointer to message block

 *  @attr_id: Attribute ID

 *  @mac_addr: MAC address to be stored

 *  @vlan: VLAN to be stored

 *

 *  This function will reorder a MAC address to be CPU endian and store it

 *  in the attribute buffer.  It will return success if provided with a

 *  valid pointers.

 verify pointers are not NULL */

 record attribute header, update message length */

 copy value into local variable and then write to msg */

 add header length to length */

/**

 *  fm10k_tlv_attr_get_mac_vlan - Get MAC/VLAN stored in attribute

 *  @attr: Pointer to attribute

 *  @mac_addr: location of buffer to store MAC address

 *  @vlan: location of buffer to store VLAN

 *

 *  This function pulls the MAC address back out of the attribute and will

 *  place it in the array pointed by by mac_addr.  It will return success

 *  if provided with a valid pointers.

 verify pointers are not NULL */

/**

 *  fm10k_tlv_attr_put_bool - Add header indicating value "true"

 *  @msg: Pointer to message block

 *  @attr_id: Attribute ID

 *

 *  This function will simply add an attribute header, the fact

 *  that the header is here means the attribute value is true, else

 *  it is false.  The function will return success if provided with a

 *  valid pointers.

 verify pointers are not NULL */

 record attribute header */

 add header length to length */

/**

 *  fm10k_tlv_attr_put_value - Store integer value attribute in message

 *  @msg: Pointer to message block

 *  @attr_id: Attribute ID

 *  @value: Value to be written

 *  @len: Size of value

 *

 *  This function will place an integer value of up to 8 bytes in size

 *  in a message attribute.  The function will return success provided

 *  that msg is a valid pointer, and len is 1, 2, 4, or 8.

 verify non-null msg and len is 1, 2, 4, or 8 */

 record attribute header, update message length */

 add header length to length */

/**

 *  fm10k_tlv_attr_get_value - Get integer value stored in attribute

 *  @attr: Pointer to attribute

 *  @value: Pointer to destination buffer

 *  @len: Size of value

 *

 *  This function will place an integer value of up to 8 bytes in size

 *  in the offset pointed to by value.  The function will return success

 *  provided that pointers are valid and the len value matches the

 *  attribute length.

 verify pointers are not NULL */

/**

 *  fm10k_tlv_attr_put_le_struct - Store little endian structure in message

 *  @msg: Pointer to message block

 *  @attr_id: Attribute ID

 *  @le_struct: Pointer to structure to be written

 *  @len: Size of le_struct

 *

 *  This function will place a little endian structure value in a message

 *  attribute.  The function will return success provided that all pointers

 *  are valid and length is a non-zero multiple of 4.

 verify non-null msg and len is in 32 bit words */

 copy le32 structure into host byte order at 32b boundaries */

 record attribute header, update message length */

 add header length to length */

/**

 *  fm10k_tlv_attr_get_le_struct - Get little endian struct form attribute

 *  @attr: Pointer to attribute

 *  @le_struct: Pointer to structure to be written

 *  @len: Size of structure

 *

 *  This function will place a little endian structure in the buffer

 *  pointed to by le_struct.  The function will return success

 *  provided that pointers are valid and the len value matches the

 *  attribute length.

 verify pointers are not NULL */

/**

 *  fm10k_tlv_attr_nest_start - Start a set of nested attributes

 *  @msg: Pointer to message block

 *  @attr_id: Attribute ID

 *

 *  This function will mark off a new nested region for encapsulating

 *  a given set of attributes.  The idea is if you wish to place a secondary

 *  structure within the message this mechanism allows for that.  The

 *  function will return NULL on failure, and a pointer to the start

 *  of the nested attributes on success.

 verify pointer is not NULL */

 return pointer to nest header */

/**

 *  fm10k_tlv_attr_nest_stop - Stop a set of nested attributes

 *  @msg: Pointer to message block

 *

 *  This function closes off an existing set of nested attributes.  The

 *  message pointer should be pointing to the parent of the nest.  So in

 *  the case of a nest within the nest this would be the outer nest pointer.

 *  This function will return success provided all pointers are valid.

 verify pointer is not NULL */

 locate the nested header and retrieve its length */

 only include nest if data was added to it */

/**

 *  fm10k_tlv_attr_validate - Validate attribute metadata

 *  @attr: Pointer to attribute

 *  @tlv_attr: Type and length info for attribute

 *

 *  This function does some basic validation of the input TLV.  It

 *  verifies the length, and in the case of null terminated strings

 *  it verifies that the last byte is null.  The function will

 *  return FM10K_ERR_PARAM if any attribute is malformed, otherwise

 *  it returns 0.

 verify this is an attribute and not a message */

 search through the list of attributes to find a matching ID */

 if didn't find a match then we should exit */

 move to start of attribute data */

 struct must be 4 byte aligned */

 nested attributes must be 4 byte aligned */

 attribute id is mapped to bad value */

/**

 *  fm10k_tlv_attr_parse - Parses stream of attribute data

 *  @attr: Pointer to attribute list

 *  @results: Pointer array to store pointers to attributes

 *  @tlv_attr: Type and length info for attributes

 *

 *  This function validates a stream of attributes and parses them

 *  up into an array of pointers stored in results.  The function will

 *  return FM10K_ERR_PARAM on any input or message error,

 *  FM10K_NOT_IMPLEMENTED for any attribute that is outside of the array

 *  and 0 on success. Any attributes not found in tlv_attr will be silently

 *  ignored.

 verify pointers are not NULL */

 initialize results to NULL */

 pull length from the message header */

 no attributes to parse if there is no length */

 no attributes to parse, just raw data, message becomes attribute */

 move to start of attribute data */

 run through list parsing all attributes */

 silently ignore non-implemented attributes */

 update offset */

 move to next attribute */

 we should find ourselves at the end of the list */

/**

 *  fm10k_tlv_msg_parse - Parses message header and calls function handler

 *  @hw: Pointer to hardware structure

 *  @msg: Pointer to message

 *  @mbx: Pointer to mailbox information structure

 *  @data: Pointer to message handler data structure

 *

 *  This function should be the first function called upon receiving a

 *  message.  The handler will identify the message type and call the correct

 *  handler for the given message.  It will return the value from the function

 *  call on a recognized message type, otherwise it will return

 *  FM10K_NOT_IMPLEMENTED on an unrecognized type.

 verify pointer is not NULL */

 verify this is a message and not an attribute */

 grab message ID */

 if we didn't find it then pass it up as an error */

 parse the attributes into the results list */

/**

 *  fm10k_tlv_msg_error - Default handler for unrecognized TLV message IDs

 *  @hw: Pointer to hardware structure

 *  @results: Pointer array to message, results[0] is pointer to message

 *  @mbx: Unused mailbox pointer

 *

 *  This function is a default handler for unrecognized messages.  At a

 *  a minimum it just indicates that the message requested was

 *  unimplemented.

/* The message below is meant to be used as a test message to demonstrate

 * how to use the TLV interface and to test the types.  Normally this code

 * be compiled out by stripping the code wrapped in FM10K_TLV_TEST_MSG

/**

 *  fm10k_tlv_msg_test_generate_data - Stuff message with data

 *  @msg: Pointer to message

 *  @attr_flags: List of flags indicating what attributes to add

 *

 *  This function is meant to load a message buffer with attribute data

/**

 *  fm10k_tlv_msg_test_create - Create a test message testing all attributes

 *  @msg: Pointer to message

 *  @attr_flags: List of flags indicating what attributes to add

 *

 *  This function is meant to load a message buffer with all attribute types

 *  including a nested attribute.

 check for nested attributes */

/**

 *  fm10k_tlv_msg_test - Validate all results on test message receive

 *  @hw: Pointer to hardware structure

 *  @results: Pointer array to attributes in the message

 *  @mbx: Pointer to mailbox information structure

 *

 *  This function does a check to verify all attributes match what the test

 *  message placed in the message buffer.  It is the default handler

 *  for TLV test messages.

 retrieve results of a previous test */

 clear any pointers */

 parse the nested attributes into the nest results list */

 loop back through to the start */

 generate reply with test result */

 load onto outgoing mailbox */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

/**

 *  fm10k_stop_hw_vf - Stop Tx/Rx units

 *  @hw: pointer to hardware structure

 *

 we need to disable the queues before taking further steps */

 If permanent address is set then we need to restore it */

 restore default itr_scale for next VF initialization */

	/* The queues have already been disabled so we just need to

	 * update their base address registers

		/* Restore ITR scale in software-defined mechanism in TDLEN

		 * for next VF initialization. See definition of

		 * FM10K_TDLEN_ITR_SCALE_SHIFT for more details on the use of

		 * TDLEN here.

/**

 *  fm10k_reset_hw_vf - VF hardware reset

 *  @hw: pointer to hardware structure

 *

 *  This function should return the hardware to a state similar to the

 *  one it is in after just being initialized.

 shut down queues we own and reset DMA configuration */

 Inititate VF reset */

 Flush write and allow 100us for reset to complete */

 Clear reset bit and verify it was cleared */

/**

 *  fm10k_init_hw_vf - VF hardware initialization

 *  @hw: pointer to hardware structure

 *

 verify we have at least 1 queue */

 determine how many queues we have */

 verify the Descriptor cache offsets are increasing */

 check to verify the PF doesn't own any of our queues */

 shut down queues we own and reset DMA configuration */

 record maximum queue count */

 fetch default VLAN and ITR scale */

	/* Read the ITR scale from TDLEN. See the definition of

	 * FM10K_TDLEN_ITR_SCALE_SHIFT for more information about how TDLEN is

	 * used here.

 This structure defines the attibutes to be parsed below */

/**

 *  fm10k_update_vlan_vf - Update status of VLAN ID in VLAN filter table

 *  @hw: pointer to hardware structure

 *  @vid: VLAN ID to add to table

 *  @vsi: Reserved, should always be 0

 *  @set: Indicates if this is a set or clear operation

 *

 *  This function adds or removes the corresponding VLAN ID from the VLAN

 *  filter table for this VF.

 verify the index is not set */

 clever trick to verify reserved bits in both vid and length */

 encode set bit into the VLAN ID */

 generate VLAN request */

 load onto outgoing mailbox */

/**

 *  fm10k_msg_mac_vlan_vf - Read device MAC address from mailbox message

 *  @hw: pointer to the HW structure

 *  @results: Attributes for message

 *  @mbx: unused mailbox data

 *

 *  This function should determine the MAC address for the VF

 record MAC address requested */

/**

 *  fm10k_read_mac_addr_vf - Read device MAC address

 *  @hw: pointer to the HW structure

 *

 *  This function should determine the MAC address for the VF

 last byte should be 0 */

 first byte should be all 1's */

/**

 *  fm10k_update_uc_addr_vf - Update device unicast addresses

 *  @hw: pointer to the HW structure

 *  @glort: unused

 *  @mac: MAC address to add/remove from table

 *  @vid: VLAN ID to add/remove from table

 *  @add: Indicates if this is an add or remove operation

 *  @flags: flags field to indicate add and secure - unused

 *

 *  This function is used to add or remove unicast MAC addresses for

 *  the VF.

 verify VLAN ID is valid */

 verify MAC address is valid */

 verify we are not locked down on the MAC address */

 add bit to notify us if this is a set or clear operation */

 generate VLAN request */

 load onto outgoing mailbox */

/**

 *  fm10k_update_mc_addr_vf - Update device multicast addresses

 *  @hw: pointer to the HW structure

 *  @glort: unused

 *  @mac: MAC address to add/remove from table

 *  @vid: VLAN ID to add/remove from table

 *  @add: Indicates if this is an add or remove operation

 *

 *  This function is used to add or remove multicast MAC addresses for

 *  the VF.

 verify VLAN ID is valid */

 verify multicast address is valid */

 add bit to notify us if this is a set or clear operation */

 generate VLAN request */

 load onto outgoing mailbox */

/**

 *  fm10k_update_int_moderator_vf - Request update of interrupt moderator list

 *  @hw: pointer to hardware structure

 *

 *  This function will issue a request to the PF to rescan our MSI-X table

 *  and to update the interrupt moderator linked list.

 generate MSI-X request */

 load onto outgoing mailbox */

 This structure defines the attibutes to be parsed below */

/**

 *  fm10k_msg_lport_state_vf - Message handler for lport_state message from PF

 *  @hw: Pointer to hardware structure

 *  @results: pointer array containing parsed data

 *  @mbx: Pointer to mailbox information structure

 *

 *  This handler is meant to capture the indication from the PF that we

 *  are ready to bring up the interface.

/**

 *  fm10k_update_lport_state_vf - Update device state in lower device

 *  @hw: pointer to the HW structure

 *  @glort: unused

 *  @count: number of logical ports to enable - unused (always 1)

 *  @enable: boolean value indicating if this is an enable or disable request

 *

 *  Notify the lower device of a state change.  If the lower device is

 *  enabled we can add filters, if it is disabled all filters for this

 *  logical port are flushed.

 reset glort mask 0 as we have to wait to be enabled */

 generate port state request */

 load onto outgoing mailbox */

/**

 *  fm10k_update_xcast_mode_vf - Request update of multicast mode

 *  @hw: pointer to hardware structure

 *  @glort: unused

 *  @mode: integer value indicating mode being requested

 *

 *  This function will attempt to request a higher mode for the port

 *  so that it can enable either multicast, multicast promiscuous, or

 *  promiscuous mode of operation.

 generate message requesting to change xcast mode */

 load onto outgoing mailbox */

/**

 *  fm10k_update_hw_stats_vf - Updates hardware related statistics of VF

 *  @hw: pointer to hardware structure

 *  @stats: pointer to statistics structure

 *

 *  This function collects and aggregates per queue hardware statistics.

/**

 *  fm10k_rebind_hw_stats_vf - Resets base for hardware statistics of VF

 *  @hw: pointer to hardware structure

 *  @stats: pointer to the stats structure to update

 *

 *  This function resets the base for queue hardware statistics.

 Unbind Queue Statistics */

 Reinitialize bases for all stats */

/**

 *  fm10k_configure_dglort_map_vf - Configures GLORT entry and queues

 *  @hw: pointer to hardware structure

 *  @dglort: pointer to dglort configuration structure

 *

 *  Reads the configuration structure contained in dglort_cfg and uses

 *  that information to then populate a DGLORTMAP/DEC entry and the queues

 *  to which it has been assigned.

 verify the dglort pointer */

 stub for now until we determine correct message for this */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

/**

 *  fm10k_fifo_init - Initialize a message FIFO

 *  @fifo: pointer to FIFO

 *  @buffer: pointer to memory to be used to store FIFO

 *  @size: maximum message size to store in FIFO, must be 2^n - 1

/**

 *  fm10k_fifo_used - Retrieve used space in FIFO

 *  @fifo: pointer to FIFO

 *

 *  This function returns the number of DWORDs used in the FIFO

/**

 *  fm10k_fifo_unused - Retrieve unused space in FIFO

 *  @fifo: pointer to FIFO

 *

 *  This function returns the number of unused DWORDs in the FIFO

/**

 *  fm10k_fifo_empty - Test to verify if FIFO is empty

 *  @fifo: pointer to FIFO

 *

 *  This function returns true if the FIFO is empty, else false

/**

 *  fm10k_fifo_head_offset - returns indices of head with given offset

 *  @fifo: pointer to FIFO

 *  @offset: offset to add to head

 *

 *  This function returns the indices into the FIFO based on head + offset

/**

 *  fm10k_fifo_tail_offset - returns indices of tail with given offset

 *  @fifo: pointer to FIFO

 *  @offset: offset to add to tail

 *

 *  This function returns the indices into the FIFO based on tail + offset

/**

 *  fm10k_fifo_head_len - Retrieve length of first message in FIFO

 *  @fifo: pointer to FIFO

 *

 *  This function returns the size of the first message in the FIFO

 verify there is at least 1 DWORD in the fifo so *head is valid */

 retieve the message length */

/**

 *  fm10k_fifo_head_drop - Drop the first message in FIFO

 *  @fifo: pointer to FIFO

 *

 *  This function returns the size of the message dropped from the FIFO

 update head so it is at the start of next frame */

/**

 *  fm10k_fifo_drop_all - Drop all messages in FIFO

 *  @fifo: pointer to FIFO

 *

 *  This function resets the head pointer to drop all messages in the FIFO and

 *  ensure the FIFO is empty.

/**

 *  fm10k_mbx_index_len - Convert a head/tail index into a length value

 *  @mbx: pointer to mailbox

 *  @head: head index

 *  @tail: head index

 *

 *  This function takes the head and tail index and determines the length

 *  of the data indicated by this pair.

 we wrapped so subtract 2, one for index 0, one for all 1s index */

/**

 *  fm10k_mbx_tail_add - Determine new tail value with added offset

 *  @mbx: pointer to mailbox

 *  @offset: length to add to tail offset

 *

 *  This function takes the local tail index and recomputes it for

 *  a given length added as an offset.

 add/sub 1 because we cannot have offset 0 or all 1s */

/**

 *  fm10k_mbx_tail_sub - Determine new tail value with subtracted offset

 *  @mbx: pointer to mailbox

 *  @offset: length to add to tail offset

 *

 *  This function takes the local tail index and recomputes it for

 *  a given length added as an offset.

 sub/add 1 because we cannot have offset 0 or all 1s */

/**

 *  fm10k_mbx_head_add - Determine new head value with added offset

 *  @mbx: pointer to mailbox

 *  @offset: length to add to head offset

 *

 *  This function takes the local head index and recomputes it for

 *  a given length added as an offset.

 add/sub 1 because we cannot have offset 0 or all 1s */

/**

 *  fm10k_mbx_head_sub - Determine new head value with subtracted offset

 *  @mbx: pointer to mailbox

 *  @offset: length to add to head offset

 *

 *  This function takes the local head index and recomputes it for

 *  a given length added as an offset.

 sub/add 1 because we cannot have offset 0 or all 1s */

/**

 *  fm10k_mbx_pushed_tail_len - Retrieve the length of message being pushed

 *  @mbx: pointer to mailbox

 *

 *  This function will return the length of the message currently being

 *  pushed onto the tail of the Rx queue.

 pushed tail is only valid if pushed is set */

/**

 *  fm10k_fifo_write_copy - pulls data off of msg and places it in FIFO

 *  @fifo: pointer to FIFO

 *  @msg: message array to populate

 *  @tail_offset: additional offset to add to tail pointer

 *  @len: length of FIFO to copy into message header

 *

 *  This function will take a message and copy it into a section of the

 *  FIFO.  In order to get something into a location other than just

 *  the tail you can use tail_offset to adjust the pointer.

 track when we should cross the end of the FIFO */

 copy end of message before start of message */

 Copy remaining message into Tx FIFO */

/**

 *  fm10k_fifo_enqueue - Enqueues the message to the tail of the FIFO

 *  @fifo: pointer to FIFO

 *  @msg: message array to read

 *

 *  This function enqueues a message up to the size specified by the length

 *  contained in the first DWORD of the message and will place at the tail

 *  of the FIFO.  It will return 0 on success, or a negative value on error.

 verify parameters */

 verify there is room for the message */

 Copy message into FIFO */

 memory barrier to guarantee FIFO is written before tail update */

 Update Tx FIFO tail */

/**

 *  fm10k_mbx_validate_msg_size - Validate incoming message based on size

 *  @mbx: pointer to mailbox

 *  @len: length of data pushed onto buffer

 *

 *  This function analyzes the frame and will return a non-zero value when

 *  the start of a message larger than the mailbox is detected.

 length should include previous amounts pushed */

 offset in message is based off of current message size */

 message extends out of pushed section, but fits in FIFO */

 return length of invalid section */

/**

 *  fm10k_mbx_write_copy - pulls data off of Tx FIFO and places it in mbmem

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will take a section of the Tx FIFO and copy it into the

 *  mailbox memory.  The offset in mbmem is based on the lower bits of the

 *  tail and len determines the length to copy.

 determine data length and mbmem tail index */

 determine offset in the ring */

 memory barrier to guarantee data is ready to be read */

 Copy message from Tx FIFO */

 adjust tail to match offset for FIFO */

 write message to hardware FIFO */

/**

 *  fm10k_mbx_pull_head - Pulls data off of head of Tx FIFO

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *  @head: acknowledgement number last received

 *

 *  This function will push the tail index forward based on the remote

 *  head index.  It will then pull up to mbmem_len DWORDs off of the

 *  head of the FIFO and will place it in the MBMEM registers

 *  associated with the mailbox.

 update number of bytes pulled and update bytes in transit */

 determine length of data to pull, reserve space for mbmem header */

 update tail and record number of bytes in transit */

 drop pulled messages from the FIFO */

 Copy message out from the Tx FIFO */

/**

 *  fm10k_mbx_read_copy - pulls data off of mbmem and places it in Rx FIFO

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will take a section of the mailbox memory and copy it

 *  into the Rx FIFO.  The offset is based on the lower bits of the

 *  head and len determines the length to copy.

 determine data length and mbmem head index */

 determine offset in the ring */

 Copy message into Rx FIFO */

 adjust head to match offset for FIFO */

 read message from hardware FIFO */

 memory barrier to guarantee FIFO is written before tail update */

/**

 *  fm10k_mbx_push_tail - Pushes up to 15 DWORDs on to tail of FIFO

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *  @tail: tail index of message

 *

 *  This function will first validate the tail index and size for the

 *  incoming message.  It then updates the acknowledgment number and

 *  copies the data into the FIFO.  It will return the number of messages

 *  dequeued on success and a negative value on error.

 determine length of data to push */

 update head and record bytes received */

 nothing to do if there is no data */

 Copy msg into Rx FIFO */

 determine if there are any invalid lengths in message */

 Update pushed */

 flush any completed messages */

 pre-generated data for generating the CRC based on the poly 0xAC9A. */

/**

 *  fm10k_crc_16b - Generate a 16 bit CRC for a region of 16 bit data

 *  @data: pointer to data to process

 *  @seed: seed value for CRC

 *  @len: length measured in 16 bits words

 *

 *  This function will generate a CRC based on the polynomial 0xAC9A and

 *  whatever value is stored in the seed variable.  Note that this

 *  value inverts the local seed and the result in order to capture all

 *  leading and trailing zeros.

/**

 *  fm10k_fifo_crc - generate a CRC based off of FIFO data

 *  @fifo: pointer to FIFO

 *  @offset: offset point for start of FIFO

 *  @len: number of DWORDS words to process

 *  @seed: seed value for CRC

 *

 *  This function generates a CRC for some region of the FIFO

 track when we should cross the end of the FIFO */

 if we are in 2 blocks process the end of the FIFO first */

 process any remaining bits */

/**

 *  fm10k_mbx_update_local_crc - Update the local CRC for outgoing data

 *  @mbx: pointer to mailbox

 *  @head: head index provided by remote mailbox

 *

 *  This function will generate the CRC for all data from the end of the

 *  last head update to the current one.  It uses the result of the

 *  previous CRC as the seed for this update.  The result is stored in

 *  mbx->local.

 determine the offset for the start of the region to be pulled */

 update local CRC to include all of the pulled data */

/**

 *  fm10k_mbx_verify_remote_crc - Verify the CRC is correct for current data

 *  @mbx: pointer to mailbox

 *

 *  This function will take all data that has been provided from the remote

 *  end and generate a CRC for it.  This is stored in mbx->remote.  The

 *  CRC for the header is then computed and if the result is non-zero this

 *  is an error and we signal an error dropping all data and resetting the

 *  connection.

 update the remote CRC if new data has been received */

 process the full header as we have to validate the CRC */

 notify other end if we have a problem */

/**

 *  fm10k_mbx_rx_ready - Indicates that a message is ready in the Rx FIFO

 *  @mbx: pointer to mailbox

 *

 *  This function returns true if there is a message in the Rx FIFO to dequeue.

/**

 *  fm10k_mbx_tx_ready - Indicates that the mailbox is in state ready for Tx

 *  @mbx: pointer to mailbox

 *  @len: verify free space is >= this value

 *

 *  This function returns true if the mailbox is in a state ready to transmit.

/**

 *  fm10k_mbx_tx_complete - Indicates that the Tx FIFO has been emptied

 *  @mbx: pointer to mailbox

 *

 *  This function returns true if the Tx FIFO is empty.

/**

 *  fm10k_mbx_dequeue_rx - Dequeues the message from the head in the Rx FIFO

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function dequeues messages and hands them off to the TLV parser.

 *  It will return the number of messages processed when called.

 parse Rx messages out of the Rx FIFO to empty it */

 shift remaining bytes back to start of FIFO */

 shift head and tail based on the memory we moved */

/**

 *  fm10k_mbx_enqueue_tx - Enqueues the message to the tail of the Tx FIFO

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *  @msg: message array to read

 *

 *  This function enqueues a message up to the size specified by the length

 *  contained in the first DWORD of the message and will place at the tail

 *  of the FIFO.  It will return 0 on success, or a negative value on error.

 enqueue the message on the Tx FIFO */

 if it failed give the FIFO a chance to drain */

 if we failed treat the error */

	/* begin processing message, ignore errors as this is just meant

	 * to start the mailbox flow so we are not concerned if there

	 * is a bad error, or the mailbox is already busy with a request

/**

 *  fm10k_mbx_read - Copies the mbmem to local message buffer

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function copies the message from the mbmem to the message array

 only allow one reader in here at a time */

 read to capture initial interrupt bits */

 write back interrupt bits to clear */

 read remote header */

/**

 *  fm10k_mbx_write - Copies the local message buffer to mbmem

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function copies the message from the the message array to mbmem

 write new msg header to notify recipient of change */

 write mailbox to send interrupt */

 we no longer are using the header so free it */

/**

 *  fm10k_mbx_create_connect_hdr - Generate a connect mailbox header

 *  @mbx: pointer to mailbox

 *

 *  This function returns a connection mailbox header

/**

 *  fm10k_mbx_create_data_hdr - Generate a data mailbox header

 *  @mbx: pointer to mailbox

 *

 *  This function returns a data mailbox header

 generate CRC for data in flight and header */

 load header to memory to be written */

/**

 *  fm10k_mbx_create_disconnect_hdr - Generate a disconnect mailbox header

 *  @mbx: pointer to mailbox

 *

 *  This function returns a disconnect mailbox header

 load header to memory to be written */

/**

 *  fm10k_mbx_create_fake_disconnect_hdr - Generate a false disconnect mbox hdr

 *  @mbx: pointer to mailbox

 *

 *  This function creates a fake disconnect header for loading into remote

 *  mailbox header. The primary purpose is to prevent errors on immediate

 *  start up after mbx->connect.

 load header to memory to be written */

/**

 *  fm10k_mbx_create_error_msg - Generate an error message

 *  @mbx: pointer to mailbox

 *  @err: local error encountered

 *

 *  This function will interpret the error provided by err, and based on

 *  that it may shift the message by 1 DWORD and then place an error header

 *  at the start of the message.

 only generate an error message for these types */

/**

 *  fm10k_mbx_validate_msg_hdr - Validate common fields in the message header

 *  @mbx: pointer to mailbox

 *

 *  This function will parse up the fields in the mailbox header and return

 *  an error if the header contains any of a number of invalid configurations

 *  including unrecognized type, invalid route, or a malformed message.

 validate that all data has been received */

 validate that head is moving correctly */

 validate that tail is moving correctly */

 validate size is in range and is power of 2 mask */

 neither create nor error include a tail offset */

/**

 *  fm10k_mbx_create_reply - Generate reply based on state and remote head

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *  @head: acknowledgement number

 *

 *  This function will generate an outgoing message based on the current

 *  mailbox state and the remote FIFO head.  It will return the length

 *  of the outgoing message excluding header on success, and a negative value

 *  on error.

 update our checksum for the outgoing data */

 as long as other end recognizes us keep sending data */

 generate new header based on data */

 send disconnect even if we aren't connected */

 generate new header based on data */

/**

 *  fm10k_mbx_reset_work- Reset internal pointers for any pending work

 *  @mbx: pointer to mailbox

 *

 *  This function will reset all internal pointers so any work in progress

 *  is dropped.  This call should occur every time we transition from the

 *  open state to the connect state.

 reset our outgoing max size back to Rx limits */

 update mbx->pulled to account for tail_len and ack */

 now drop any messages which have started or finished transmitting */

 just do a quick resysnc to start of message */

/**

 *  fm10k_mbx_update_max_size - Update the max_size and drop any large messages

 *  @mbx: pointer to mailbox

 *  @size: new value for max_size

 *

 *  This function updates the max_size value and drops any outgoing messages

 *  at the head of the Tx FIFO if they are larger than max_size. It does not

 *  drop all messages, as this is too difficult to parse and remove them from

 *  the FIFO. Instead, rely on the checking to ensure that messages larger

 *  than max_size aren't pushed into the memory buffer.

 flush any oversized messages from the queue */

/**

 *  fm10k_mbx_connect_reset - Reset following request for reset

 *  @mbx: pointer to mailbox

 *

 *  This function resets the mailbox to either a disconnected state

 *  or a connect state depending on the current mailbox state

 just do a quick resysnc to start of frame */

 reset CRC seeds */

 we cannot exit connect until the size is good */

/**

 *  fm10k_mbx_process_connect - Process connect header

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will read an incoming connect header and reply with the

 *  appropriate message.  It will return a value indicating the number of

 *  data DWORDs on success, or will return a negative value on failure.

 we will need to pull all of the fields for verification */

 reset any in-progress work */

 we cannot exit connect until the size is good */

 record the remote system requesting connection */

 align our tail index to remote head index */

/**

 *  fm10k_mbx_process_data - Process data header

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will read an incoming data header and reply with the

 *  appropriate message.  It will return a value indicating the number of

 *  data DWORDs on success, or will return a negative value on failure.

 we will need to pull all of the fields for verification */

 if we are in connect just update our data and go */

 abort on message size errors */

 verify the checksum on the incoming data */

 process messages if we have received any */

/**

 *  fm10k_mbx_process_disconnect - Process disconnect header

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will read an incoming disconnect header and reply with the

 *  appropriate message.  It will return a value indicating the number of

 *  data DWORDs on success, or will return a negative value on failure.

 we will need to pull the header field for verification */

 We should not be receiving disconnect if Rx is incomplete */

 we have already verified mbx->head == tail so we know this is 0 */

 verify the checksum on the incoming header is correct */

 state doesn't change if we still have work to do */

 verify the head indicates we completed all transmits */

 reset any in-progress work */

/**

 *  fm10k_mbx_process_error - Process error header

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will read an incoming error header and reply with the

 *  appropriate message.  It will return a value indicating the number of

 *  data DWORDs on success, or will return a negative value on failure.

 we will need to pull all of the fields for verification */

 flush any uncompleted work */

 reset CRC seeds */

 reset tail index and size to prepare for reconnect */

 if open then reset max_size and go back to connect */

 send a connect message to get data flowing again */

/**

 *  fm10k_mbx_process - Process mailbox interrupt

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will process incoming mailbox events and generate mailbox

 *  replies.  It will return a value indicating the number of DWORDs

 *  transmitted excluding header on success or a negative value on error.

 we do not read mailbox if closed */

 copy data from mailbox */

 validate type, source, and destination */

 notify partner of errors on our end */

 copy data from mailbox */

/**

 *  fm10k_mbx_disconnect - Shutdown mailbox connection

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will shut down the mailbox.  It places the mailbox first

 *  in the disconnect state, it then allows up to a predefined timeout for

 *  the mailbox to transition to close on its own.  If this does not occur

 *  then the mailbox will be forced into the closed state.

 *

 *  Any mailbox transactions not completed before calling this function

 *  are not guaranteed to complete and may be dropped.

 Place mbx in ready to disconnect state */

 trigger interrupt to start shutdown process */

	/* in case we didn't close, just force the mailbox into shutdown and

	 * drop all left over messages in the FIFO.

/**

 *  fm10k_mbx_connect - Start mailbox connection

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will initiate a mailbox connection.  It will populate the

 *  mailbox with a broadcast connect message and then initialize the lock.

 *  This is safe since the connect message is a single DWORD so the mailbox

 *  transaction is guaranteed to be atomic.

 *

 *  This function will return an error if the mailbox has not been initiated

 *  or is currently in use.

 we cannot connect an uninitialized mailbox */

 we cannot connect an already connected mailbox */

 mailbox timeout can now become active */

 Place mbx in ready to connect state */

 initialize header of remote mailbox */

 enable interrupt and notify other party of new message */

 generate and load connect header into mailbox */

/**

 *  fm10k_mbx_validate_handlers - Validate layout of message parsing data

 *  @msg_data: handlers for mailbox events

 *

 *  This function validates the layout of the message parsing data.  This

 *  should be mostly static, but it is important to catch any errors that

 *  are made when constructing the parsers.

 Allow NULL mailboxes that transmit but don't receive */

 all messages should have a function handler */

 parser is optional */

 ID should always be increasing */

 ID should fit in results array */

 verify terminator is in the list */

 ID should always be increasing */

 verify terminator is in the list */

/**

 *  fm10k_mbx_register_handlers - Register a set of handler ops for mailbox

 *  @mbx: pointer to mailbox

 *  @msg_data: handlers for mailbox events

 *

 *  This function associates a set of message handling ops with a mailbox.

 validate layout of handlers before assigning them */

 initialize the message handlers */

/**

 *  fm10k_pfvf_mbx_init - Initialize mailbox memory for PF/VF mailbox

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *  @msg_data: handlers for mailbox events

 *  @id: ID reference for PF as it supports up to 64 PF/VF mailboxes

 *

 *  This function initializes the mailbox for use.  It will split the

 *  buffer provided and use that to populate both the Tx and Rx FIFO by

 *  evenly splitting it.  In order to allow for easy masking of head/tail

 *  the value reported in size must be a power of 2 and is reported in

 *  DWORDs, not bytes.  Any invalid values will cause the mailbox to return

 *  error.

 initialize registers */

 there are only 64 VF <-> PF mailboxes */

 start out in closed state */

 validate layout of handlers before assigning them */

 initialize the message handlers */

	/* start mailbox as timed out and let the reset_hw call

	 * set the timeout value to begin communications

 initialize tail and head */

 initialize CRC seeds */

 Split buffer for use by Tx/Rx FIFOs */

 initialize the FIFOs, sizes are in 4 byte increments */

 initialize function pointers */

/**

 *  fm10k_sm_mbx_create_data_hdr - Generate a mailbox header for local FIFO

 *  @mbx: pointer to mailbox

 *

 *  This function returns a data mailbox header

/**

 *  fm10k_sm_mbx_create_connect_hdr - Generate a mailbox header for local FIFO

 *  @mbx: pointer to mailbox

 *  @err: error flags to report if any

 *

 *  This function returns a connection mailbox header

/**

 *  fm10k_sm_mbx_connect_reset - Reset following request for reset

 *  @mbx: pointer to mailbox

 *

 *  This function resets the mailbox to a just connected state

 flush any uncompleted work */

 set local version to max and remote version to 0 */

 initialize tail and head */

 reset state back to connect */

/**

 *  fm10k_sm_mbx_connect - Start switch manager mailbox connection

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will initiate a mailbox connection with the switch

 *  manager.  To do this it will first disconnect the mailbox, and then

 *  reconnect it in order to complete a reset of the mailbox.

 *

 *  This function will return an error if the mailbox has not been initiated

 *  or is currently in use.

 we cannot connect an uninitialized mailbox */

 we cannot connect an already connected mailbox */

 mailbox timeout can now become active */

 Place mbx in ready to connect state */

 reset interface back to connect */

 enable interrupt and notify other party of new message */

 generate and load connect header into mailbox */

/**

 *  fm10k_sm_mbx_disconnect - Shutdown mailbox connection

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will shut down the mailbox.  It places the mailbox first

 *  in the disconnect state, it then allows up to a predefined timeout for

 *  the mailbox to transition to close on its own.  If this does not occur

 *  then the mailbox will be forced into the closed state.

 *

 *  Any mailbox transactions not completed before calling this function

 *  are not guaranteed to complete and may be dropped.

 Place mbx in ready to disconnect state */

 trigger interrupt to start shutdown process */

 in case we didn't close just force the mailbox into shutdown */

/**

 *  fm10k_sm_mbx_validate_fifo_hdr - Validate fields in the remote FIFO header

 *  @mbx: pointer to mailbox

 *

 *  This function will parse up the fields in the mailbox header and return

 *  an error if the header contains any of a number of invalid configurations

 *  including unrecognized offsets or version numbers.

/**

 *  fm10k_sm_mbx_process_error - Process header with error flag set

 *  @mbx: pointer to mailbox

 *

 *  This function is meant to respond to a request where the error flag

 *  is set.  As a result we will terminate a connection if one is present

 *  and fall back into the reset state with a connection header of version

 *  0 (RESET).

 if there is an error just disconnect */

 flush any uncompleted work */

 try connnecting at lower version */

/**

 *  fm10k_sm_mbx_create_error_msg - Process an error in FIFO header

 *  @mbx: pointer to mailbox

 *  @err: local error encountered

 *

 *  This function will interpret the error provided by err, and based on

 *  that it may set the error bit in the local message header

 only generate an error message for these types */

 process it as though we received an error, and send error reply */

/**

 *  fm10k_sm_mbx_receive - Take message from Rx mailbox FIFO and put it in Rx

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *  @tail: tail index of message

 *

 *  This function will dequeue one message from the Rx switch manager mailbox

 *  FIFO and place it in the Rx mailbox FIFO for processing by software.

 reduce length by 1 to convert to a mask */

 push tail in front of head */

 copy data to the Rx FIFO */

 process messages if we have received any */

 guarantee head aligns with the end of the last message */

 clear any extra bits left over since index adds 1 extra bit */

/**

 *  fm10k_sm_mbx_transmit - Take message from Tx and put it in Tx mailbox FIFO

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *  @head: head index of message

 *

 *  This function will dequeue one message from the Tx mailbox FIFO and place

 *  it in the Tx switch manager mailbox FIFO for processing by hardware.

 reduce length by 1 to convert to a mask */

 push head behind tail */

 determine msg aligned offset for end of buffer */

 guarantee we stop on a message boundary */

 clear any extra bits left over since index adds 1 extra bit */

/**

 *  fm10k_sm_mbx_create_reply - Generate reply based on state and remote head

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *  @head: acknowledgement number

 *

 *  This function will generate an outgoing message based on the current

 *  mailbox state and the remote FIFO head.  It will return the length

 *  of the outgoing message excluding header on success, and a negative value

 *  on error.

 flush out Tx data */

 generate new header based on data */

/**

 *  fm10k_sm_mbx_process_reset - Process header with version == 0 (RESET)

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function is meant to respond to a request where the version data

 *  is set to 0.  As such we will either terminate the connection or go

 *  into the connect state in order to re-establish the connection.  This

 *  function can also be used to respond to an error as the connection

 *  resetting would also be a means of dealing with errors.

 drop remote connections and disconnect */

 flush any incomplete work */

 Update remote value to match local value */

/**

 *  fm10k_sm_mbx_process_version_1 - Process header with version == 1

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function is meant to process messages received when the remote

 *  mailbox is active.

 pull all fields needed for verification */

 if we are in connect and wanting version 1 then start up and go */

 abort on message size errors */

 continue until we have flushed the Rx FIFO */

/**

 *  fm10k_sm_mbx_process - Process switch manager mailbox interrupt

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *

 *  This function will process incoming mailbox events and generate mailbox

 *  replies.  It will return a value indicating the number of DWORDs

 *  transmitted excluding header on success or a negative value on error.

 we do not read mailbox if closed */

 retrieve data from switch manager */

 report data to switch manager */

/**

 *  fm10k_sm_mbx_init - Initialize mailbox memory for PF/SM mailbox

 *  @hw: pointer to hardware structure

 *  @mbx: pointer to mailbox

 *  @msg_data: handlers for mailbox events

 *

 *  This function initializes the PF/SM mailbox for use.  It will split the

 *  buffer provided and use that to populate both the Tx and Rx FIFO by

 *  evenly splitting it.  In order to allow for easy masking of head/tail

 *  the value reported in size must be a power of 2 and is reported in

 *  DWORDs, not bytes.  Any invalid values will cause the mailbox to return

 *  error.

 start out in closed state */

 validate layout of handlers before assigning them */

 initialize the message handlers */

	/* start mailbox as timed out and let the reset_hw call

	 * set the timeout value to begin communications

 Split buffer for use by Tx/Rx FIFOs */

 initialize the FIFOs, sizes are in 4 byte increments */

 initialize function pointers */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

/**

 *  fm10k_iov_msg_queue_mac_vlan - Message handler for MAC/VLAN request from VF

 *  @hw: Pointer to hardware structure

 *  @results: Pointer array to message, results[0] is pointer to message

 *  @mbx: Pointer to mailbox information structure

 *

 *  This function is a custom handler for MAC/VLAN requests from the VF. The

 *  assumption is that it is acceptable to directly hand off the message from

 *  the VF to the PF's switch manager. However, we use a MAC/VLAN message

 *  queue to avoid overloading the mailbox when a large number of requests

 *  come in.

 we shouldn't be updating rules on a disabled interface */

 record VLAN id requested */

		/* if the length field has been set, this is a multi-bit

		 * update request. For multi-bit requests, simply disallow

		 * them when the pf_vid has been set. In this case, the PF

		 * should have already cleared the VLAN_TABLE, and if we

		 * allowed them, it could allow a rogue VF to receive traffic

		 * on a VLAN it was not assigned. In the single-bit case, we

		 * need to modify requests for VLAN 0 to use the default PF or

		 * SW vid when assigned.

			/* prevent multi-bit requests when PF has

			 * administratively set the VLAN for this VF

 update VSI info for VF in regards to VLAN table */

 record unicast MAC address requested */

 block attempts to set MAC for a locked device */

 Add this request to the MAC/VLAN queue */

 record multicast MAC address requested */

 verify that the VF is allowed to request multicast */

 Add this request to the MAC/VLAN queue */

 if there is no iov_data then there is no mailbox to process */

 check again now that we are in the RCU block */

 read VFLRE to determine if any VFs have been reset */

 if there is no iov_data then there is no mailbox to process */

 check again now that we are in the RCU block */

 lock the mailbox for transmit and receive */

	/* Most VF messages sent to the PF cause the PF to respond by

	 * requesting from the SM mailbox. This means that too many VF

	 * messages processed at once could cause a mailbox timeout on the PF.

	 * To prevent this, store a pointer to the next VF mbx to process. Use

	 * that as the start of the loop so that we don't starve whichever VF

	 * got ignored on the previous run.

 process the SM mailbox first to drain outgoing messages */

 verify port mapping is valid, if not reset port */

 reset VFs that have mailbox timed out */

 guarantee we have free space in the SM mailbox */

 keep track of how many times this occurs */

 make sure we try again momentarily */

 cleanup mailbox and process received messages */

	/* if we stopped processing mailboxes early, update next_vf_mbx.

	 * Otherwise, reset next_vf_mbx, and restart loop so that we process

	 * the remaining mailboxes we skipped at the start.

 free the lock */

 pull out num_vfs from iov_data */

 shut down queue mapping for VFs */

 Stop any active VFs and reset their resources */

	/* Mask the completion abort bit in the ERR_UNCOR_MASK register,

	 * preventing the device from reporting these errors to the upstream

	 * PCIe root device. This avoids bringing down platforms which upgrade

	 * non-fatal completer aborts into machine check exceptions. Completer

	 * aborts can occur whenever a VF reads a queue it doesn't own.

 pull out num_vfs from iov_data */

 return error if iov_data is not already populated */

	/* Lower severity of completer abort error reporting as

	 * the VFs can trigger this any time they read a queue

	 * that they don't own.

 allocate hardware resources for the VFs */

 configure DGLORT mapping for RSS */

 assign resources to the device */

 allocate all but the last GLORT to the VFs */

 assign GLORT to VF, and restrict it to multicast */

 mailbox is disconnected so we don't send a message */

 now we are ready so we can connect */

 no IOV support, not our message to process */

 glort outside our range, not our message to process */

 determine if an update has occurred and if so notify the VF */

 reclaim hardware resources */

 drop iov_data from interface */

 return error if iov_data is already populated */

 The PF should always be able to assign resources */

 nothing to do if no VFs are requested */

 allocate memory for VF storage */

 record number of VFs */

 loop through vf_info structures initializing each entry */

 Record VF VSI value */

 initialize mailbox memory */

 assign iov_data to interface */

 allocate hardware resources for the VFs */

 allocate resources for the VFs */

 allocate VFs if not already allocated */

/**

 * fm10k_iov_update_stats - Update stats for all VFs

 * @interface: device private structure

 *

 * Updates the VF statistics for all enabled VFs. Expects to be called by

 * fm10k_update_stats and assumes that locking via the __FM10K_UPDATING_STATS

 * bit is already handled.

 assigning the MAC address will send a mailbox message */

 disable LPORT for this VF which clears switch rules */

 assign new MAC+VLAN for this VF */

 re-enable the LPORT for this VF */

 verify SR-IOV is active and that vf idx is valid */

 verify MAC addr is valid */

 record new MAC address */

 verify SR-IOV is active and that vf idx is valid */

 QOS is unsupported and VLAN IDs accepted range 0-4094 */

 VF VLAN Protocol part to default is unsupported */

 exit if there is nothing to do */

 record default VLAN ID for VF */

 Clear the VLAN table for the VF */

 verify SR-IOV is active and that vf idx is valid */

 rate limit cannot be less than 10Mbs or greater than link speed */

 store values */

 update hardware configuration */

 verify SR-IOV is active and that vf idx is valid */

 verify SR-IOV is active and that vf idx is valid */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

/**

 * fm10k_dcbnl_ieee_getets - get the ETS configuration for the device

 * @dev: netdev interface for the device

 * @ets: ETS structure to push configuration to

 we support 8 TCs in all modes */

 we only support strict priority and cannot do traffic shaping */

 populate the prio map based on the netdev */

/**

 * fm10k_dcbnl_ieee_setets - set the ETS configuration for the device

 * @dev: netdev interface for the device

 * @ets: ETS structure to pull configuration from

 verify type and determine num_tcs needed */

 if requested TC is greater than 0 then num_tcs is max + 1 */

 update TC hardware mapping if necessary */

 update priority mapping */

/**

 * fm10k_dcbnl_ieee_getpfc - get the PFC configuration for the device

 * @dev: netdev interface for the device

 * @pfc: PFC structure to push configuration to

 record flow control max count and state of TCs */

/**

 * fm10k_dcbnl_ieee_setpfc - set the PFC configuration for the device

 * @dev: netdev interface for the device

 * @pfc: PFC structure to pull configuration from

 record PFC configuration to interface */

 if we are running update the drop_en state for all queues */

/**

 * fm10k_dcbnl_getdcbx - get the DCBX configuration for the device

 * @dev: netdev interface for the device

 *

 * Returns that we support only IEEE DCB for this interface

/**

 * fm10k_dcbnl_setdcbx - get the DCBX configuration for the device

 * @dev: netdev interface for the device

 * @mode: new mode for this device

 *

 * Returns error on attempt to enable anything but IEEE DCB for this interface

/**

 * fm10k_dcbnl_set_ops - Configures dcbnl ops pointer for netdev

 * @dev: netdev interface for the device

 *

 * Enables PF for DCB by assigning DCBNL ops pointer.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 *  fm10k_get_bus_info_generic - Generic set PCI bus info

 *  @hw: pointer to hardware structure

 *

 *  Gets the PCI bus info (speed, width, type) then calls helper function to

 *  store this data within the fm10k_hw structure.

 Get the maximum link width and speed from PCIe config space */

 Get the PCIe maximum payload size for the PCIe function */

 Get the negotiated link width and speed from PCIe config space */

 Get the negotiated PCIe maximum payload size for the PCIe function */

 read in value from MSI-X capability register */

 MSI-X count is zero-based in HW */

/**

 *  fm10k_get_invariants_generic - Inits constant values

 *  @hw: pointer to the hardware structure

 *

 *  Initialize the common invariants for the device.

 initialize GLORT state to avoid any false hits */

 record maximum number of MSI-X vectors */

/**

 *  fm10k_start_hw_generic - Prepare hardware for Tx/Rx

 *  @hw: pointer to hardware structure

 *

 *  This function sets the Tx ready flag to indicate that the Tx path has

 *  been initialized.

 set flag indicating we are beginning Tx */

/**

 *  fm10k_disable_queues_generic - Stop Tx/Rx queues

 *  @hw: pointer to hardware structure

 *  @q_cnt: number of queues to be disabled

 *

 clear tx_ready to prevent any false hits for reset */

 clear the enable bit for all rings */

 loop through all queues to verify that they are all disabled */

 if we are at end of rings all rings are disabled */

 if queue enables cleared, then move to next ring pair */

 decrement time and wait 1 usec */

/**

 *  fm10k_stop_hw_generic - Stop Tx/Rx units

 *  @hw: pointer to hardware structure

 *

/**

 *  fm10k_read_hw_stats_32b - Reads value of 32-bit registers

 *  @hw: pointer to the hardware structure

 *  @addr: address of register containing a 32-bit value

 *  @stat: pointer to structure holding hw stat information

 *

 *  Function reads the content of the register and returns the delta

 *  between the base and the current value.

/**

 *  fm10k_read_hw_stats_48b - Reads value of 48-bit registers

 *  @hw: pointer to the hardware structure

 *  @addr: address of register containing the lower 32-bit value

 *  @stat: pointer to structure holding hw stat information

 *

 *  Function reads the content of 2 registers, combined to represent a 48-bit

 *  statistical value. Extra processing is required to handle overflowing.

 *  Finally, a delta value is returned representing the difference between the

 *  values stored in registers and values stored in the statistic counters.

 Check for overflow */

/**

 *  fm10k_update_hw_base_48b - Updates 48-bit statistic base value

 *  @stat: pointer to the hardware statistic structure

 *  @delta: value to be updated into the hardware statistic structure

 *

 *  Function receives a value and determines if an update is required based on

 *  a delta calculation. Only the base value will be updated.

 update lower 32 bits */

 update upper 32 bits */

/**

 *  fm10k_update_hw_stats_tx_q - Updates TX queue statistics counters

 *  @hw: pointer to the hardware structure

 *  @q: pointer to the ring of hardware statistics queue

 *  @idx: index pointing to the start of the ring iteration

 *

 *  Function updates the TX queue statistics counters that are related to the

 *  hardware.

 Retrieve TX Owner Data */

 Process TX Ring */

 Re-Check Owner Data */

 drop non-ID bits and set VALID ID bit */

 update packet counts */

 update bases and record ID */

/**

 *  fm10k_update_hw_stats_rx_q - Updates RX queue statistics counters

 *  @hw: pointer to the hardware structure

 *  @q: pointer to the ring of hardware statistics queue

 *  @idx: index pointing to the start of the ring iteration

 *

 *  Function updates the RX queue statistics counters that are related to the

 *  hardware.

 Retrieve RX Owner Data */

 Process RX Ring */

 Re-Check Owner Data */

 drop non-ID bits and set VALID ID bit */

 update packet counts */

 update bases and record ID */

/**

 *  fm10k_update_hw_stats_q - Updates queue statistics counters

 *  @hw: pointer to the hardware structure

 *  @q: pointer to the ring of hardware statistics queue

 *  @idx: index pointing to the start of the ring iteration

 *  @count: number of queues to iterate over

 *

 *  Function updates the queue statistics counters that are related to the

 *  hardware.

/**

 *  fm10k_unbind_hw_stats_q - Unbind the queue counters from their queues

 *  @q: pointer to the ring of hardware statistics queue

 *  @idx: index pointing to the start of the ring iteration

 *  @count: number of queues to iterate over

 *

 *  Function invalidates the index values for the queues so any updates that

 *  may have happened are ignored and the base for the queue stats is reset.

/**

 *  fm10k_get_host_state_generic - Returns the state of the host

 *  @hw: pointer to hardware structure

 *  @host_ready: pointer to boolean value that will record host state

 *

 *  This function will check the health of the mailbox and Tx queue 0

 *  in order to determine if we should report that the link is up or not.

 process upstream mailbox in case interrupts were disabled */

 If Tx is no longer enabled link should come down */

 exit if not checking for link, or link cannot be changed */

 if we somehow dropped the Tx enable we should reset */

 if Mailbox timed out we should request reset */

 verify Mailbox is still open */

 interface cannot receive traffic without logical ports */

	/* if we passed all the tests above then the switch is ready and we no

	 * longer need to check for link

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

 Descriptor Seq Functions */

 Do nothing. */

 Generate header */

 Validate descriptor allocation */

 Generate header */

 Validate descriptor allocation */

/**

 * fm10k_dbg_q_vector_init - setup debugfs for the q_vectors

 * @q_vector: q_vector to allocate directories for

 *

 * A folder is created for each q_vector found. In each q_vector

 * folder, a debugfs file is created for each tx and rx ring

 * allocated to the q_vector.

 Generate a folder for each q_vector */

 Generate a file for each rx ring in the q_vector */

 Generate a file for each rx ring in the q_vector */

/**

 * fm10k_dbg_q_vector_exit - setup debugfs for the q_vectors

 * @q_vector: q_vector to allocate directories for

/**

 * fm10k_dbg_intfc_init - setup the debugfs directory for the intferface

 * @interface: the interface that is starting up

/**

 * fm10k_dbg_intfc_exit - clean out the interface's debugfs entries

 * @interface: the interface that is stopping

/**

 * fm10k_dbg_init - start up debugfs for the driver

/**

 * fm10k_dbg_exit - clean out the driver's debugfs entries

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

/**

 * fm10k_setup_tx_resources - allocate Tx resources (Descriptors)

 * @tx_ring:    tx descriptor ring (for a specific queue) to setup

 *

 * Return 0 on success, negative on failure

 round up to nearest 4K */

/**

 * fm10k_setup_all_tx_resources - allocate all queues Tx resources

 * @interface: board private structure

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

 rewind the index freeing the rings as we go */

/**

 * fm10k_setup_rx_resources - allocate Rx resources (Descriptors)

 * @rx_ring:    rx descriptor ring (for a specific queue) to setup

 *

 * Returns 0 on success, negative on failure

 Round up to nearest 4K */

/**

 * fm10k_setup_all_rx_resources - allocate all queues Rx resources

 * @interface: board private structure

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

 rewind the index freeing the rings as we go */

 tx_buffer must be completely set up in the transmit path */

/**

 * fm10k_clean_tx_ring - Free Tx Buffers

 * @tx_ring: ring to be cleaned

 ring already cleared, nothing to do */

 Free all the Tx ring sk_buffs */

 reset BQL values */

 Zero out the descriptor ring */

/**

 * fm10k_free_tx_resources - Free Tx Resources per Queue

 * @tx_ring: Tx descriptor ring for a specific queue

 *

 * Free all transmit software resources

 if not set, then don't free */

/**

 * fm10k_clean_all_tx_rings - Free Tx Buffers for all queues

 * @interface: board private structure

/**

 * fm10k_free_all_tx_resources - Free Tx Resources for All Queues

 * @interface: board private structure

 *

 * Free all transmit software resources

/**

 * fm10k_clean_rx_ring - Free Rx Buffers per Queue

 * @rx_ring: ring to free buffers from

 Free all the Rx ring sk_buffs */

 clean-up will only set page pointer to NULL */

 Zero out the descriptor ring */

/**

 * fm10k_free_rx_resources - Free Rx Resources

 * @rx_ring: ring to clean the resources from

 *

 * Free all receive software resources

 if not set, then don't free */

/**

 * fm10k_clean_all_rx_rings - Free Rx Buffers for all queues

 * @interface: board private structure

/**

 * fm10k_free_all_rx_resources - Free Rx Resources for All Queues

 * @interface: board private structure

 *

 * Free all receive software resources

/**

 * fm10k_request_glort_range - Request GLORTs for use in configuring rules

 * @interface: board private structure

 *

 * This function allocates a range of glorts for this interface to use.

 establish GLORT base */

 nothing we can do until mask is allocated */

	/* we support 3 possible GLORT configurations.

	 * 1: VFs consume all but the last 1

	 * 2: VFs and PF split glorts with possible gap between

	 * 3: VFs allocated first 64, all others belong to PF

/**

 * fm10k_restore_udp_port_info

 * @interface: board private structure

 *

 * This function restores the value in the tunnel_cfg register(s) after reset

 only the PF supports configuring tunnels */

 restore tunnel configuration register */

 restore Geneve tunnel configuration register */

/**

 * fm10k_udp_tunnel_sync - Called when UDP tunnel ports change

 * @dev: network interface device structure

 * @table: Tunnel table (according to tables of @fm10k_udp_tunnels)

 *

 * This function is called when a new UDP tunnel port is added or deleted.

 * Due to hardware restrictions, only one port per type can be offloaded at

 * once. Core will send to the driver a port of its choice.

/**

 * fm10k_open - Called when a network interface is made active

 * @netdev: network interface device structure

 *

 * Returns 0 on success, negative value on failure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP).  At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the watchdog timer is started,

 * and the stack is notified that the interface is ready.

 allocate transmit descriptors */

 allocate receive descriptors */

 allocate interrupt resources */

 setup GLORT assignment for this port */

 Notify the stack of the actual queue counts */

/**

 * fm10k_close - Disables a network interface

 * @netdev: network interface device structure

 *

 * Returns 0, this is not allowed to fail

 *

 * The close entry point is called when an interface is de-activated

 * by the OS.  The hardware is still under the drivers control, but

 * needs to be disabled.  A global MAC reset is issued to stop the

 * hardware, and all transmit and receive resources are freed.

		/* FM10K only supports hardware tagging, any tags in frame

		 * are considered 2nd level or "outer" tags

 make sure skb is not shared */

 make sure there is enough room to move the ethernet header */

 verify the skb head is not shared */

 locate VLAN header */

 pull the 2 key pieces of data out of it */

 squash it by moving the ethernet addresses up 4 bytes */

	/* The minimum packet size for a single buffer is 17B so pad the skb

	 * in order to meet this minimum size requirement.

/**

 * fm10k_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: the index of the Tx queue that timed out

 fake Tx hang - increase the kernel timeout */

/**

 * fm10k_host_mbx_ready - Check PF interface's mailbox readiness

 * @interface: board private structure

 *

 * This function checks if the PF interface's mailbox is ready before queueing

 * mailbox messages for transmission. This will prevent filling the TX mailbox

 * queue when the receiver is not ready. VF interfaces are exempt from this

 * check since it will block all PF-VF mailbox messages from being sent from

 * the VF to the PF at initialization.

/**

 * fm10k_queue_vlan_request - Queue a VLAN update request

 * @interface: the fm10k interface structure

 * @vid: the VLAN vid

 * @vsi: VSI index number

 * @set: whether to set or clear

 *

 * This function queues up a VLAN update. For VFs, this must be sent to the

 * managing PF over the mailbox. For PFs, we'll use the same handling so that

 * it's similar to the VF. This avoids storming the PF<->VF mailbox with too

 * many VLAN updates during reset.

	/* This must be atomic since we may be called while the netdev

	 * addr_list_lock is held

/**

 * fm10k_queue_mac_request - Queue a MAC update request

 * @interface: the fm10k interface structure

 * @glort: the target glort for this update

 * @addr: the address to update

 * @vid: the vid to update

 * @set: whether to add or remove

 *

 * This function queues up a MAC request for sending to the switch manager.

 * A separate thread monitors the queue and sends updates to the switch

 * manager. Return 0 on success, and negative error code on failure.

	/* This must be atomic since we may be called while the netdev

	 * addr_list_lock is held

/**

 * fm10k_clear_macvlan_queue - Cancel pending updates for a given glort

 * @interface: the fm10k interface structure

 * @glort: the target glort to clear

 * @vlans: true to clear VLAN messages, false to ignore them

 *

 * Cancel any outstanding MAC/VLAN requests for a given glort. This is

 * expected to be called when a logical port goes down.

 Free any outstanding MAC/VLAN requests for this interface */

 Don't free requests for other interfaces */

 drop any leading bits on the VLAN ID */

 return non-zero value as we are only doing a partial sync/unsync */

 drop any leading bits on the VLAN ID */

 return non-zero value as we are only doing a partial sync/unsync */

 updates do not apply to VLAN 0 */

	/* Verify that we have permission to add VLANs. If this is a request

	 * to remove a VLAN, we still want to allow the user to remove the

	 * VLAN device. In that case, we need to clear the bit in the

	 * active_vlans bitmask.

 update active_vlans bitmask */

 disable the default VLAN ID on ring if we have an active VLAN */

	/* If our VLAN has been overridden, there is no reason to send VLAN

	 * removal requests as they will be silently ignored.

	/* Do not remove default VLAN ID related entries from VLAN and MAC

	 * tables

	/* Do not throw an error if the interface is down. We will sync once

	 * we come up

 only need to update the VLAN if not in promiscuous mode */

 Update our base MAC address */

 Update L2 accelerated macvlan addresses */

 set VLAN ID prior to syncing/unsyncing the VLAN */

 Update the unicast and multicast address list to add/drop VLAN */

 update VLAN and address table based on changes */

 update VLAN and address table based on changes */

 loop through and find any gaps in the table */

 send request to clear multiple bits at a time */

 setting MAC address requires mailbox */

 if we had a mailbox error suggest trying again */

 no need to update the harwdare if we are not running */

 determine new mode based on flags */

 update xcast mode first, but only if it changed */

 update VLAN table when entering promiscuous mode */

 clear VLAN table when exiting promiscuous mode */

 update xcast mode if host's mailbox is ready */

 record updated xcast mode state */

 synchronize all of the addresses */

 record glort for this interface */

 convert interface flags to xcast mode */

 Enable logical port if host's mailbox is ready */

 update VLAN table */

 update table with current entries */

 synchronize macvlan addresses */

	/* update xcast mode before synchronizing addresses if host's mailbox

	 * is ready

 synchronize all of the addresses */

 synchronize macvlan addresses */

 record updated xcast mode state */

 Restore tunnel configuration */

 Wait for MAC/VLAN work to finish */

 Cancel pending MAC/VLAN requests */

	/* clear the logical port state on lower device if host's mailbox is

	 * ready

 reset flags to default state */

 clear the sync flag since the lport has been dropped */

/**

 * fm10k_get_stats64 - Get System Network Statistics

 * @netdev: network interface device structure

 * @stats: storage space for 64bit statistics

 *

 * Obtain 64bit statistics in a way that is safe for both 32bit and 64bit

 * architectures.

 following stats updated by fm10k_service_task() */

 Currently only the PF supports priority classes */

 Hardware supports up to 8 traffic classes */

	/* Hardware has to reinitialize queues to match packet

	 * buffer alignment. Unfortunately, the hardware is not

	 * flexible enough to do this dynamically.

 we expect the prio_tc map to be repopulated later */

 flag to indicate SWPRI has yet to be updated */

	/* The hardware supported by fm10k only filters on the destination MAC

	 * address. In order to avoid issues we only support offloading modes

	 * where the hardware can actually provide the functionality.

 allocate l2 accel structure if it is not available */

 verify there is enough free GLORTs to support l2_accel */

 update pointers */

 do not expand if we are at our limit */

 expand if we have hit the size limit */

 update pointers */

 add macvlan to accel table, and record GLORT for position */

 record station */

 configure default DGLORT mapping for RSS/DCB */

 Add rules for this specific dglort to the switch */

 search table for matching interface */

 exit if macvlan not found */

 Remove any rules specific to this dglort */

 record removal */

 configure default DGLORT mapping for RSS/DCB */

 If table is empty remove it */

 set net device and ethtool ops */

 configure default debug level */

 configure default features */

 Only the PF can support VXLAN and NVGRE tunnel offloads */

 all features defined to this point should be changeable */

 allow user to enable L2 forwarding acceleration */

 configure VLAN features */

	/* we want to leave these both on as we cannot disable VLAN tag

	 * insertion or stripping on the hardware since it is contained

	 * in the FTAG and not in the frame itself.

 MTU range: 68 - 15342 */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

/**

 *  fm10k_reset_hw_pf - PF hardware reset

 *  @hw: pointer to hardware structure

 *

 *  This function should return the hardware to a state similar to the

 *  one it is in after being powered on.

 Disable interrupts */

 Lock ITR2 reg 0 into itself and disable interrupt moderation */

 We assume here Tx and Rx queue 0 are owned by the PF */

 Shut off VF access to their queues forcing them to queue 0 */

 shut down all rings */

 Verify that DMA is no longer active */

 Inititate data path reset */

 Flush write and allow 100us for reset to complete */

 Verify we made it out of reset */

/**

 *  fm10k_is_ari_hierarchy_pf - Indicate ARI hierarchy support

 *  @hw: pointer to hardware structure

 *

 *  Looks at the ARI hierarchy bit to determine whether ARI is supported or not.

/**

 *  fm10k_init_hw_pf - PF hardware initialization

 *  @hw: pointer to hardware structure

 *

 Establish default VSI as valid */

 Invalidate all other GLORT entries */

 reset ITR2(0) to point to itself */

 reset VF ITR2(0) to point to 0 avoid PF registers */

 loop through all PF ITR2 registers pointing them to the previous */

 Enable interrupt moderator if not already enabled */

 compute the default txqctl configuration */

 configure rings for 256 Queue / 32 Descriptor cache mode */

 configure rings to provide TPH processing hints */

	/* set max hold interval to align with 1.024 usec in all modes and

	 * store ITR scale

 just in case, assume Gen3 ITR scale */

 Configure TSO flags */

	/* Enable DMA engine

	 * Set Rx Descriptor size to 32

	 * Set Minimum MSS to 64

	 * Set Maximum number of Rx queues to 256 / 32 Descriptor

 record maximum queue count, we limit ourselves to 128 */

 We support either 64 VFs or 7 VFs depending on if we have ARI */

/**

 *  fm10k_update_vlan_pf - Update status of VLAN ID in VLAN filter table

 *  @hw: pointer to hardware structure

 *  @vid: VLAN ID to add to table

 *  @vsi: Index indicating VF ID or PF ID in table

 *  @set: Indicates if this is a set or clear operation

 *

 *  This function adds or removes the corresponding VLAN ID from the VLAN

 *  filter table for the corresponding function.  In addition to the

 *  standard set/clear that supports one bit a multi-bit write is

 *  supported to set 64 bits at a time.

 verify the VSI index is valid */

	/* VLAN multi-bit write:

	 * The multi-bit write has several parts to it.

	 *               24              16               8               0

	 *  7 6 5 4 3 2 1 0 7 6 5 4 3 2 1 0 7 6 5 4 3 2 1 0 7 6 5 4 3 2 1 0

	 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

	 * | RSVD0 |         Length        |C|RSVD0|        VLAN ID        |

	 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

	 *

	 * VLAN ID: Vlan Starting value

	 * RSVD0: Reserved section, must be 0

	 * C: Flag field, 0 is set, 1 is clear (Used in VF VLAN message)

	 * Length: Number of times to repeat the bit being set

 verify the reserved 0 fields are 0 */

 Loop through the table updating all required VLANs */

 record the initial state of the register */

 truncate mask if we are at the start or end of the run */

 make necessary modifications to the register */

/**

 *  fm10k_read_mac_addr_pf - Read device MAC address

 *  @hw: pointer to the HW structure

 *

 *  Reads the device MAC address from the SM_AREA and stores the value.

 last byte should be all 1's */

 first byte should be all 1's */

/**

 *  fm10k_glort_valid_pf - Validate that the provided glort is valid

 *  @hw: pointer to the HW structure

 *  @glort: base glort to be validated

 *

 *  This function will return an error if the provided glort is invalid

/**

 *  fm10k_update_xc_addr_pf - Update device addresses

 *  @hw: pointer to the HW structure

 *  @glort: base resource tag for this request

 *  @mac: MAC address to add/remove from table

 *  @vid: VLAN ID to add/remove from table

 *  @add: Indicates if this is an add or remove operation

 *  @flags: flags field to indicate add and secure

 *

 *  This function generates a message to the Switch API requesting

 *  that the given logical port add/remove the given L2 MAC/VLAN address.

 clear set bit from VLAN ID */

 if glort or VLAN are not valid return error */

 record fields */

 populate mac_update fields */

 load onto outgoing mailbox */

/**

 *  fm10k_update_uc_addr_pf - Update device unicast addresses

 *  @hw: pointer to the HW structure

 *  @glort: base resource tag for this request

 *  @mac: MAC address to add/remove from table

 *  @vid: VLAN ID to add/remove from table

 *  @add: Indicates if this is an add or remove operation

 *  @flags: flags field to indicate add and secure

 *

 *  This function is used to add or remove unicast addresses for

 *  the PF.

 verify MAC address is valid */

/**

 *  fm10k_update_mc_addr_pf - Update device multicast addresses

 *  @hw: pointer to the HW structure

 *  @glort: base resource tag for this request

 *  @mac: MAC address to add/remove from table

 *  @vid: VLAN ID to add/remove from table

 *  @add: Indicates if this is an add or remove operation

 *

 *  This function is used to add or remove multicast MAC addresses for

 *  the PF.

 verify multicast address is valid */

/**

 *  fm10k_update_xcast_mode_pf - Request update of multicast mode

 *  @hw: pointer to hardware structure

 *  @glort: base resource tag for this request

 *  @mode: integer value indicating mode being requested

 *

 *  This function will attempt to request a higher mode for the port

 *  so that it can enable either multicast, multicast promiscuous, or

 *  promiscuous mode of operation.

 if glort is not valid return error */

	/* write xcast mode as a single u32 value,

	 * lower 16 bits: glort

	 * upper 16 bits: mode

 generate message requesting to change xcast mode */

 load onto outgoing mailbox */

/**

 *  fm10k_update_int_moderator_pf - Update interrupt moderator linked list

 *  @hw: pointer to hardware structure

 *

 *  This function walks through the MSI-X vector table to determine the

 *  number of active interrupts and based on that information updates the

 *  interrupt moderator linked list.

 Disable interrupt moderator */

 loop through PF from last to first looking enabled vectors */

 always reset VFITR2[0] to point to last enabled PF vector */

 reset ITR2[0] to point to last enabled PF vector */

 Enable interrupt moderator */

/**

 *  fm10k_update_lport_state_pf - Notify the switch of a change in port state

 *  @hw: pointer to the HW structure

 *  @glort: base resource tag for this request

 *  @count: number of logical ports being updated

 *  @enable: boolean value indicating enable or disable

 *

 *  This function is used to add/remove a logical port from the switch.

 do nothing if we are being asked to create or destroy 0 ports */

 if glort is not valid return error */

 reset multicast mode if deleting lport */

 construct the lport message from the 2 pieces of data we have */

 generate lport create/delete message */

 load onto outgoing mailbox */

/**

 *  fm10k_configure_dglort_map_pf - Configures GLORT entry and queues

 *  @hw: pointer to hardware structure

 *  @dglort: pointer to dglort configuration structure

 *

 *  Reads the configuration structure contained in dglort_cfg and uses

 *  that information to then populate a DGLORTMAP/DEC entry and the queues

 *  to which it has been assigned.

 verify the dglort pointer */

 verify the dglort values */

 determine count of VSIs and queues */

 configure SGLORT for queues */

 determine count of PCs and queues */

 configure PC for Tx queues */

 configure DGLORTDEC */

 configure DGLORTMAP */

 write values to hardware */

/**

 *  fm10k_iov_assign_resources_pf - Assign pool resources for virtualization

 *  @hw: pointer to the HW structure

 *  @num_vfs: number of VFs to be allocated

 *  @num_pools: number of virtualization pools to be allocated

 *

 *  Allocates queues and traffic classes to virtualization entities to prepare

 *  the PF for SR-IOV and VMDq

 hardware only supports up to 64 pools */

 the number of VFs cannot exceed the number of pools */

 record number of virtualization entities */

 determine qmap offsets and counts */

 calculate starting index for queues */

 establish TCs with -1 credits and no quanta to prevent transmit */

 zero out all mbmem registers */

 clear event notification of VF FLR */

 loop through unallocated rings assigning them back to PF */

 PF should have already updated VFITR2[0] */

 update all ITR registers to flow to VFITR2[0] */

 update PF ITR2[0] to reference the last vector */

 loop through rings populating rings and TCs */

 record index for VF queue 0 for use in end of loop */

 assign VF and locked TC to queues */

 map queue pair to VF */

 repeat the first ring for all of the remaining VF rings */

 loop through remaining indexes assigning all to queue 0 */

/**

 *  fm10k_iov_configure_tc_pf - Configure the shaping group for VF

 *  @hw: pointer to the HW structure

 *  @vf_idx: index of VF receiving GLORT

 *  @rate: Rate indicated in Mb/s

 *

 *  Configured the TC for a given VF to allow only up to a given number

 *  of Mb/s of outgoing Tx throughput.

 configure defaults */

 verify vf is in range */

 set interval to align with 4.096 usec in all modes */

		/* The quanta is measured in Bytes per 4.096 or 8.192 usec

		 * The rate is provided in Mbits per second

		 * To tralslate from rate to quanta we need to multiply the

		 * rate by 8.192 usec and divide by 8 bits/byte.  To avoid

		 * dealing with floating point we can round the values up

		 * to the nearest whole number ratio which gives us 128 / 125.

		/* try to keep the rate limiting accurate by increasing

		 * the number of credits and interval for rates less than 4Gb/s

 update rate limiter with new values */

/**

 *  fm10k_iov_assign_int_moderator_pf - Add VF interrupts to moderator list

 *  @hw: pointer to the HW structure

 *  @vf_idx: index of VF receiving GLORT

 *

 *  Update the interrupt moderator linked list to include any MSI-X

 *  interrupts which the VF has enabled in the MSI-X vector table.

 verify vf is in range */

 determine vector offset and count */

 search for first vector that is not masked */

 reset linked list so it now includes our active vectors */

/**

 *  fm10k_iov_assign_default_mac_vlan_pf - Assign a MAC and VLAN to VF

 *  @hw: pointer to the HW structure

 *  @vf_info: pointer to VF information structure

 *

 *  Assign a MAC address and default VLAN to a VF and notify it of the update

 verify vf is in range */

 determine qmap offsets and counts */

 calculate starting index for queues */

	/* Determine correct default VLAN ID. The FM10K_VLAN_OVERRIDE bit is

	 * used here to indicate to the VF that it will not have privilege to

	 * write VLAN_TABLE. All policy is enforced on the PF but this allows

	 * the VF to correctly report errors to userspace requests.

 generate MAC_ADDR request */

	/* Configure Queue control register with new VLAN ID. The TXQCTL

	 * register is RO from the VF, so the PF must do this even in the

	 * case of notifying the VF of a new VID via the mailbox.

 try loading a message onto outgoing mailbox first */

	/* If we aren't connected to a mailbox, this is most likely because

	 * the VF driver is not running. It should thus be safe to re-map

	 * queues and use the registers to pass the MAC address so that the VF

	 * driver gets correct information during its initialization.

 MAP Tx queue back to 0 temporarily, and disable it */

 verify ring has disabled before modifying base address registers */

 limit ourselves to a 1ms timeout */

 Update base address registers to contain MAC address */

 Record the base address into queue 0 */

	/* Provide the VF the ITR scale, using software-defined fields in TDLEN

	 * to pass the information during VF initialization. See definition of

	 * FM10K_TDLEN_ITR_SCALE_SHIFT for more details.

 restore the queue back to VF ownership */

/**

 *  fm10k_iov_reset_resources_pf - Reassign queues and interrupts to a VF

 *  @hw: pointer to the HW structure

 *  @vf_info: pointer to VF information structure

 *

 *  Reassign the interrupts and queues to a VF following an FLR

 verify vf is in range */

 clear event notification of VF FLR */

 force timeout and then disconnect the mailbox */

 determine vector offset and count */

 determine qmap offsets and counts */

 make all the queues inaccessible to the VF */

 calculate starting index for queues */

 determine correct default VLAN ID */

 configure Queue control register */

 stop further DMA and reset queue ownership back to VF */

 reset TC with -1 credits and no quanta to prevent transmit */

 update our first entry in the table based on previous VF */

 reset linked list so it now includes our active vectors */

 link remaining vectors so that next points to previous */

 zero out MBMEM, VLAN_TABLE, RETA, RSSRK, and MRQC registers */

 Update base address registers to contain MAC address */

 map queue pairs back to VF from last to first */

		/* See definition of FM10K_TDLEN_ITR_SCALE_SHIFT for an

		 * explanation of how TDLEN is used.

 repeat the first ring for all the remaining VF rings */

/**

 *  fm10k_iov_set_lport_pf - Assign and enable a logical port for a given VF

 *  @hw: pointer to hardware structure

 *  @vf_info: pointer to VF information structure

 *  @lport_idx: Logical port offset from the hardware glort

 *  @flags: Set of capability flags to extend port beyond basic functionality

 *

 *  This function allows enabling a VF port by assigning it a GLORT and

 *  setting the flags so that it can enable an Rx mode.

 if glort is not valid return error */

/**

 *  fm10k_iov_reset_lport_pf - Disable a logical port for a given VF

 *  @hw: pointer to hardware structure

 *  @vf_info: pointer to VF information structure

 *

 *  This function disables a VF port by stripping it of a GLORT and

 *  setting the flags so that it cannot enable any Rx mode.

 need to disable the port if it is already enabled */

 notify switch that this port has been disabled */

 generate port state response to notify VF it is not ready */

 clear flags and glort if it exists */

/**

 *  fm10k_iov_update_stats_pf - Updates hardware related statistics for VFs

 *  @hw: pointer to hardware structure

 *  @q: stats for all queues of a VF

 *  @vf_idx: index of VF

 *

 *  This function collects queue stats for VFs.

 get stats for all of the queues */

/**

 *  fm10k_iov_msg_msix_pf - Message handler for MSI-X request from VF

 *  @hw: Pointer to hardware structure

 *  @results: Pointer array to message, results[0] is pointer to message

 *  @mbx: Pointer to mailbox information structure

 *

 *  This function is a default handler for MSI-X requests from the VF. The

 *  assumption is that in this case it is acceptable to just directly

 *  hand off the message from the VF to the underlying shared code.

/**

 * fm10k_iov_select_vid - Select correct default VLAN ID

 * @vf_info: pointer to VF information structure

 * @vid: VLAN ID to correct

 *

 * Will report an error if the VLAN ID is out of range. For VID = 0, it will

 * return either the pf_vid or sw_vid depending on which one is set.

/**

 *  fm10k_iov_msg_mac_vlan_pf - Message handler for MAC/VLAN request from VF

 *  @hw: Pointer to hardware structure

 *  @results: Pointer array to message, results[0] is pointer to message

 *  @mbx: Pointer to mailbox information structure

 *

 *  This function is a default handler for MAC/VLAN requests from the VF.

 *  The assumption is that in this case it is acceptable to just directly

 *  hand off the message from the VF to the underlying shared code.

 we shouldn't be updating rules on a disabled interface */

 record VLAN id requested */

		/* if the length field has been set, this is a multi-bit

		 * update request. For multi-bit requests, simply disallow

		 * them when the pf_vid has been set. In this case, the PF

		 * should have already cleared the VLAN_TABLE, and if we

		 * allowed them, it could allow a rogue VF to receive traffic

		 * on a VLAN it was not assigned. In the single-bit case, we

		 * need to modify requests for VLAN 0 to use the default PF or

		 * SW vid when assigned.

			/* prevent multi-bit requests when PF has

			 * administratively set the VLAN for this VF

 update VSI info for VF in regards to VLAN table */

 record unicast MAC address requested */

 block attempts to set MAC for a locked device */

 notify switch of request for new unicast address */

 record multicast MAC address requested */

 verify that the VF is allowed to request multicast */

 notify switch of request for new multicast address */

/**

 *  fm10k_iov_supported_xcast_mode_pf - Determine best match for xcast mode

 *  @vf_info: VF info structure containing capability flags

 *  @mode: Requested xcast mode

 *

 *  This function outputs the mode that most closely matches the requested

 *  mode.  If not modes match it will request we disable the port

 match up mode to capabilities as best as possible */

 disable interface as it should not be able to request any */

/**

 *  fm10k_iov_msg_lport_state_pf - Message handler for port state requests

 *  @hw: Pointer to hardware structure

 *  @results: Pointer array to message, results[0] is pointer to message

 *  @mbx: Pointer to mailbox information structure

 *

 *  This function is a default handler for port state requests.  The port

 *  state requests for now are basic and consist of enabling or disabling

 *  the port.

 verify VF is allowed to enable even minimal mode */

 XCAST mode update requested */

 prep for possible demotion depending on capabilities */

 if mode is not currently enabled, enable it */

 swap mode back to a bit flag */

 need to disable the port if it is already enabled */

		/* we need to clear VF_FLAG_ENABLED flags in order to ensure

		 * that we actually re-enable the LPORT state below. Note that

		 * this has no impact if the VF is already disabled, as the

		 * flags are already cleared.

 when enabling the port we should reset the rate limiters */

 set mode for minimal functionality */

 generate port state response to notify VF it is ready */

 if enable state toggled note the update */

 if state change succeeded, then update our stored state */

/**

 *  fm10k_update_hw_stats_pf - Updates hardware related statistics of PF

 *  @hw: pointer to hardware structure

 *  @stats: pointer to the stats structure to update

 *

 *  This function collects and aggregates global and per queue hardware

 *  statistics.

 Use Tx queue 0 as a canary to detect a reset */

 Read Global Statistics */

 if value has not changed then we have consistent data */

 drop non-ID bits and set VALID ID bit */

 Update Global Statistics */

 Update bases and record current PF id */

 Update Queue Statistics */

/**

 *  fm10k_rebind_hw_stats_pf - Resets base for hardware statistics of PF

 *  @hw: pointer to hardware structure

 *  @stats: pointer to the stats structure to update

 *

 *  This function resets the base for global and per queue hardware

 *  statistics.

 Unbind Global Statistics */

 Unbind Queue Statistics */

 Reinitialize bases for all stats */

/**

 *  fm10k_set_dma_mask_pf - Configures PhyAddrSpace to limit DMA to system

 *  @hw: pointer to hardware structure

 *  @dma_mask: 64 bit DMA mask required for platform

 *

 *  This function sets the PHYADDR.PhyAddrSpace bits for the endpoint in order

 *  to limit the access to memory beyond what is physically in the system.

 we need to write the upper 32 bits of DMA mask to PhyAddrSpace */

/**

 *  fm10k_get_fault_pf - Record a fault in one of the interface units

 *  @hw: pointer to hardware structure

 *  @type: pointer to fault type register offset

 *  @fault: pointer to memory location to record the fault

 *

 *  Record the fault register contents to the fault data structure and

 *  clear the entry from the register.

 *

 *  Returns ERR_PARAM if invalid register is specified or no error is present.

 verify the fault register is in range and is aligned */

 only service faults that are valid */

 read remaining fields */

 clear valid bit to allow for next error */

 Record which function triggered the error */

 record fault type */

/**

 *  fm10k_request_lport_map_pf - Request LPORT map from the switch API

 *  @hw: pointer to hardware structure

 *

 issue request asking for LPORT map */

 load onto outgoing mailbox */

/**

 *  fm10k_get_host_state_pf - Returns the state of the switch and mailbox

 *  @hw: pointer to hardware structure

 *  @switch_ready: pointer to boolean value that will record switch state

 *

 *  This function will check the DMA_CTRL2 register and mailbox in order

 *  to determine if the switch is ready for the PF to begin requesting

 *  addresses and mapping traffic to the local interface.

 verify the switch is ready for interaction */

 retrieve generic host state info */

 This structure defines the attibutes to be parsed below */

/**

 *  fm10k_msg_lport_map_pf - Message handler for lport_map message from SM

 *  @hw: Pointer to hardware structure

 *  @results: pointer array containing parsed data

 *  @mbx: Pointer to mailbox information structure

 *

 *  This handler configures the lport mapping based on the reply from the

 *  switch API.

 extract values out of the header */

 verify mask is set and none of the masked bits in glort are set */

 verify the mask is contiguous, and that it is 1's followed by 0's */

 record the glort, mask, and port count */

/**

 *  fm10k_msg_update_pvid_pf - Message handler for port VLAN message from SM

 *  @hw: Pointer to hardware structure

 *  @results: pointer array containing parsed data

 *  @mbx: Pointer to mailbox information structure

 *

 *  This handler configures the default VLAN for the PF

 extract values from the pvid update */

 if glort is not valid return error */

 verify VLAN ID is valid */

 record the port VLAN ID value */

/**

 *  fm10k_record_global_table_data - Move global table data to swapi table info

 *  @from: pointer to source table data structure

 *  @to: pointer to destination table info structure

 *

 *  This function is will copy table_data to the table_info contained in

 *  the hw struct.

 convert from le32 struct to CPU byte ordered values */

/**

 *  fm10k_msg_err_pf - Message handler for error reply

 *  @hw: Pointer to hardware structure

 *  @results: pointer array containing parsed data

 *  @mbx: Pointer to mailbox information structure

 *

 *  This handler will capture the data for any error replies to previous

 *  messages that the PF has sent.

 extract structure from message */

 record table status */

 record SW API status value */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

/*

 * fm10k_pci_tbl - PCI Device ID Table

 *

 * Wildcard entries (PCI_ANY_ID) should come last

 * Last entry must be all 0s

 *

 * { Vendor ID, Device ID, SubVendor ID, SubDevice ID,

 *   Class, Class Mask, private data (not used) }

 required last entry */

/**

 * fm10k_macvlan_schedule - Schedule MAC/VLAN queue task

 * @interface: fm10k private interface structure

 *

 * Schedule the MAC/VLAN queue monitor task. If the MAC/VLAN task cannot be

 * started immediately, request that it be restarted when possible.

	/* Avoid processing the MAC/VLAN queue when the service task is

	 * disabled, or when we're resetting the device.

		/* We delay the actual start of execution in order to allow

		 * multiple MAC/VLAN updates to accumulate before handling

		 * them, and to allow some time to let the mailbox drain

		 * between runs.

/**

 * fm10k_stop_macvlan_task - Stop the MAC/VLAN queue monitor

 * @interface: fm10k private interface structure

 *

 * Wait until the MAC/VLAN queue task has stopped, and cancel any future

 * requests.

 Disable the MAC/VLAN work item */

 Make sure we waited until any current invocations have stopped */

	/* We set the __FM10K_MACVLAN_SCHED bit when we schedule the task.

	 * However, it may not be unset of the MAC/VLAN task never actually

	 * got a chance to run. Since we've canceled the task here, and it

	 * cannot be rescheuled right now, we need to ensure the scheduled bit

	 * gets unset.

/**

 * fm10k_resume_macvlan_task - Restart the MAC/VLAN queue monitor

 * @interface: fm10k private interface structure

 *

 * Clear the __FM10K_MACVLAN_DISABLE bit and, if a request occurred, schedule

 * the MAC/VLAN work monitor.

 Re-enable the MAC/VLAN work item */

	/* We might have received a MAC/VLAN request while disabled. If so,

	 * kick off the queue now.

 flush memory to make sure state is correct before next watchog */

	/* If a service event was requested since we started, immediately

	 * re-schedule now. This ensures we don't drop a request until the

	 * next timer event.

	/* It's possible that cancel_work_sync stopped the service task from

	 * running before it could actually start. In this case the

	 * __FM10K_SERVICE_SCHED bit will never be cleared. Since we know that

	 * the service task cannot be running at this point, we need to clear

	 * the scheduled bit, as otherwise the service task may never be

	 * restarted.

/**

 * fm10k_service_timer - Timer Call-back

 * @t: pointer to timer data

 Reset the timer */

/**

 * fm10k_prepare_for_reset - Prepare the driver and device for a pending reset

 * @interface: fm10k private data structure

 *

 * This function prepares for a device reset by shutting as much down as we

 * can. It does nothing and returns false if __FM10K_RESETTING was already set

 * prior to calling this function. It returns true if it actually did work.

 put off any impending NetWatchDogTimeout */

 Nothing to do if a reset is already in progress */

	/* As the MAC/VLAN task will be accessing registers it must not be

	 * running while we reset. Although the task will not be scheduled

	 * once we start resetting it may already be running

 free interrupts */

 delay any future reset requests */

 reset and initialize the hardware so it is in a known state */

 re-associate interrupts */

 update hardware address for VFs if perm_addr has changed */

 do nothing if netdev is still present or hw_addr is set */

	/* We've lost the PCIe register space, and can no longer access the

	 * device. Shut everything except the detach subtask down and prepare

	 * to reset the device in case we recover. If we actually prepare for

	 * reset, indicate that we're detached.

 check the real address space to see if we've recovered */

		/* Make sure the reset was initiated because we detached,

		 * otherwise we might race with a different reset flow.

 Restore the hardware address */

		/* PCIe link has been restored, and the device is active

		 * again. Restore everything and reset the device.

 Re-attach the netdev */

	/* If another thread has already prepared to reset the device, we

	 * should not attempt to handle a reset here, since we'd race with

	 * that thread. This may happen if we suspend the device or if the

	 * PCIe link is lost. In this case, we'll just ignore the RESET

	 * request, as it will (eventually) be taken care of when the thread

	 * which actually started the reset is finished.

/**

 * fm10k_configure_swpri_map - Configure Receive SWPRI to PC mapping

 * @interface: board private structure

 *

 * Configure the SWPRI to PC mapping for the port.

 clear flag indicating update is needed */

 these registers are only available on the PF */

 configure SWPRI to PC map */

/**

 * fm10k_watchdog_update_host_state - Update the link status based on host.

 * @interface: board private structure

 lock the mailbox for transmit and receive */

 free the lock */

/**

 * fm10k_mbx_subtask - Process upstream and downstream mailboxes

 * @interface: board private structure

 *

 * This function will process both the upstream and downstream mailboxes.

 If we're resetting, bail out */

 process upstream mailbox and update device state */

 process downstream mailboxes */

/**

 * fm10k_watchdog_host_is_ready - Update netdev status based on host ready

 * @interface: board private structure

 only continue if link state is currently down */

/**

 * fm10k_watchdog_host_not_ready - Update netdev status based on host not ready

 * @interface: board private structure

 only continue if link state is currently up */

/**

 * fm10k_update_stats - Update the board statistics counters.

 * @interface: board private structure

 ensure only one thread updates stats at a time */

 do not allow stats update via service task for next second */

 gather some stats to the interface struct that are per queue */

 gather some stats to the interface struct that are per queue */

 Fill out the OS statistics structure */

 Update VF statistics */

/**

 * fm10k_watchdog_flush_tx - flush queues on host not ready

 * @interface: pointer to the device interface structure

 nothing to do if carrier is up */

	/* We've lost link, so the controller stops DMA, but we've got

	 * queued Tx work that's never going to get done, so reset

	 * controller to flush Tx.

/**

 * fm10k_watchdog_subtask - check and bring link up

 * @interface: pointer to the device interface structure

 if interface is down do nothing */

 update stats only once every second */

 flush any uncompleted work */

/**

 * fm10k_check_hang_subtask - check for hung queues and dropped interrupts

 * @interface: pointer to the device interface structure

 *

 * This function serves two purposes.  First it strobes the interrupt lines

 * in order to make certain interrupts are occurring.  Secondly it sets the

 * bits needed to check for TX hangs.  As a result we should immediately

 * determine if a hang has occurred.

 If we're down or resetting, just bail */

 rate limit tx hang checks to only once every 2 seconds */

 Force detection of hung controller */

 Rearm all in-use q_vectors for immediate firing */

/**

 * fm10k_service_task - manages and runs subtasks

 * @work: pointer to work_struct containing our data

 Check whether we're detached first */

 tasks run even when interface is down */

 tasks only run when interface is up */

 release lock on service events to allow scheduling next event */

/**

 * fm10k_macvlan_task - send queued MAC/VLAN requests to switch manager

 * @work: pointer to work_struct containing our data

 *

 * This work item handles sending MAC/VLAN updates to the switch manager. When

 * the interface is up, it will attempt to queue mailbox messages to the

 * switch manager requesting updates for MAC/VLAN pairs. If the Tx fifo of the

 * mailbox is full, it will reschedule itself to try again in a short while.

 * This ensures that the driver does not overload the switch mailbox with too

 * many simultaneous requests, causing an unnecessary reset.

 Pop the first item off the list */

 We have no more items to process */

		/* Check that we have plenty of space to send the message. We

		 * want to ensure that the mailbox stays low enough to avoid a

		 * change in the host state, otherwise we may see spurious

		 * link up / link down notifications.

 Put the request back on the list */

 Free the item now that we've sent the update */

 flush memory to make sure state is correct */

	/* If a MAC/VLAN request was scheduled since we started, we should

	 * re-schedule. However, there is no reason to re-schedule if there is

	 * no work to do.

/**

 * fm10k_configure_tx_ring - Configure Tx ring after Reset

 * @interface: board private structure

 * @ring: structure containing ring specific data

 *

 * Configure the Tx descriptor ring after a reset.

 disable queue to avoid issues while updating state */

 possible poll here to verify ring resources have been cleaned */

 set location and size for descriptor ring */

 reset head and tail pointers */

 store tail pointer */

 reset ntu and ntc to place SW in sync with hardware */

 Map interrupt */

 enable use of FTAG bit in Tx descriptor, register is RO for VF */

 Initialize XPS */

 enable queue */

/**

 * fm10k_enable_tx_ring - Verify Tx ring is enabled after configuration

 * @interface: board private structure

 * @ring: structure containing ring specific data

 *

 * Verify the Tx descriptor ring is ready for transmit.

 if we are already enabled just exit */

 poll to verify queue is enabled */

/**

 * fm10k_configure_tx - Configure Transmit Unit after Reset

 * @interface: board private structure

 *

 * Configure the Tx unit of the MAC after a reset.

 Setup the HW Tx Head and Tail descriptor pointers */

 poll here to verify that Tx rings are now enabled */

/**

 * fm10k_configure_rx_ring - Configure Rx ring after Reset

 * @interface: board private structure

 * @ring: structure containing ring specific data

 *

 * Configure the Rx descriptor ring after a reset.

 disable queue to avoid issues while updating state */

 possible poll here to verify ring resources have been cleaned */

 set location and size for descriptor ring */

 reset head and tail pointers */

 store tail pointer */

 reset ntu and ntc to place SW in sync with hardware */

 Configure the Rx buffer size for one buff without split */

 Configure the Rx ring to suppress loopback packets */

 Enable drop on empty */

 assign default VLAN to queue */

 if we have an active VLAN, disable default VLAN ID */

 Map interrupt */

 enable queue */

 place buffers on ring for receive data */

/**

 * fm10k_update_rx_drop_en - Configures the drop enable bits for Rx rings

 * @interface: board private structure

 *

 * Configure the drop enable bits for the Rx rings.

/**

 * fm10k_configure_dglort - Configure Receive DGLORT after reset

 * @interface: board private structure

 *

 * Configure the DGLORT description and RSS tables.

 Fill out hash function seeds */

 Write RETA table to hardware */

	/* Generate RSS hash based on packet types, TCP/UDP

	 * port numbers and/or IPv4/v6 src and dst addresses

 configure default DGLORT mapping for RSS/DCB */

 assign GLORT per queue for queue mapped testing */

 assign glort value for RSS/DCB specific to this interface */

 configure DGLORT mapping for RSS/DCB */

/**

 * fm10k_configure_rx - Configure Receive Unit after Reset

 * @interface: board private structure

 *

 * Configure the Rx unit of the MAC after a reset.

 Configure SWPRI to PC map */

 Configure RSS and DGLORT map */

 Setup the HW Rx Head and Tail descriptor pointers */

 possible poll here to verify that Rx rings are now enabled */

 re-enable mailbox interrupt and indicate 20us delay */

 service upstream mailbox */

	/* For VF faults, clear out the respective LPORT, reset the queue

	 * resources, and then reconnect to the mailbox. This allows the

	 * VF in question to resume behavior. For transient faults that are

	 * the result of non-malicious behavior this will log the fault and

	 * allow the VF to resume functionality. Obviously for malicious VFs

	 * they will be able to attempt malicious behavior again. In this

	 * case, the system administrator will need to step in and manually

	 * remove or disable the VF in question.

 reset_lport disables the VF, so re-enable it */

 reset_resources will disconnect from the mbx  */

 only check if there is an error reported */

 retrieve fault info */

 unmask any set bits related to this interrupt */

 report any faults found to the message log */

 reset any queues disabled due to receiver overrun */

 service mailboxes */

 handle VFLRE events */

 if switch toggled state we should reset GLORTs */

 force link down for at least 4 seconds */

 reset dglort_map back to no config */

 we should validate host state after interrupt event */

 validate host state, and handle VF mailboxes in the service task */

 re-enable mailbox interrupt and indicate 20us delay */

 no mailbox IRQ to free if MSI-X is not enabled */

 disconnect the mailbox */

 disable Mailbox cause */

 MAC was changed so we need reset */

 VLAN override was changed, or default VLAN changed */

 generic error handler for mailbox issues */

 Use timer0 for interrupt moderation on the mailbox */

 register mailbox handlers */

 request the IRQ */

 map all of the interrupt sources */

 enable interrupt */

 force link down for a reasonable delay */

 reset dglort_map back to no config */

 prevent overloading kernel message buffer */

 we need to reset if port count was just updated */

 extract values from the pvid update */

 if glort is not valid return error */

 verify VLAN ID is valid */

 check to see if this belongs to one of the VFs */

 we need to reset if default VLAN was just updated */

 Use timer0 for interrupt moderation on the mailbox */

 register mailbox handlers */

 request the IRQ */

 Enable interrupts w/ no moderation for "other" interrupts */

 Enable interrupts w/ moderation for mailbox */

 Enable individual interrupt causes */

 enable interrupt */

 enable Mailbox cause */

 connect mailbox */

 if the mailbox failed to connect, then free IRQ */

/**

 * fm10k_qv_free_irq - release interrupts associated with queue vectors

 * @interface: board private structure

 *

 * Release all interrupts associated with this interface

 clear the affinity_mask in the IRQ descriptor */

 disable interrupts */

/**

 * fm10k_qv_request_irq - initialize interrupts for queue vectors

 * @interface: board private structure

 *

 * Attempts to configure interrupts using the best available

 * capabilities of the hardware and kernel.

 name the vector */

 skip this unused q_vector */

 Assign ITR register to q_vector */

 request the IRQ */

 assign the mask for this irq */

 Enable q_vector */

 wind through the ring freeing all entries and vectors */

 clear the affinity_mask in the IRQ descriptor */

 disable interrupts */

 Enable Tx/Rx DMA */

 configure Tx descriptor rings */

 configure Rx descriptor rings */

 configure interrupts */

 enable statistics capture again */

 clear down bit to indicate we are ready to go */

 enable polling cleanups */

 re-establish Rx filters */

 enable transmits */

 kick off the service timer now */

 signal that we are down to the interrupt handler and service task */

 call carrier off first to avoid false dev_watchdog timeouts */

 disable transmits */

 reset Rx filters */

 disable polling routines */

 capture stats one last time before stopping interface */

 prevent updating statistics while we're down */

 skip waiting for TX DMA if we lost PCIe link */

	/* In some rare circumstances it can take a while for Tx queues to

	 * quiesce and be fully disabled. Attempt to .stop_hw() first, and

	 * then if we get ERR_REQUESTS_PENDING, go ahead and wait in a loop

	 * until the Tx queues have emptied, or until a number of retries. If

	 * we fail to clear within the retry loop, we will issue a warning

	 * indicating that Tx DMA is probably hung. Note this means we call

	 * .stop_hw() twice but this shouldn't cause any problems.

 start checking at the last ring to have pending Tx */

 if all the queues are drained, we can break now */

 Disable DMA engine for Tx/Rx */

 free any buffers still on the rings */

/**

 * fm10k_sw_init - Initialize general software structures

 * @interface: host interface private structure to initialize

 * @ent: PCI device ID entry

 *

 * fm10k_sw_init initializes the interface private data structure.

 * Fields are initialized based on PCI device information and

 * OS network device settings (MTU size).

 initialize back pointer */

 PCI config space info */

 Setup hw api */

 Setup IOV handlers */

 Set common capability flags and settings */

 pick up the PCIe bus settings for reporting later */

 limit the usable DMA range */

 update netdev with DMA restrictions */

 reset and initialize the hardware so it is in a known state */

 initialize hardware statistics */

 Set upper limit on IOV VFs that can be allocated */

 Start with random Ethernet address */

 Initialize MAC address from hardware */

 tag address assignment as random */

 initialize DCBNL interface */

 set default ring sizes */

 set default interrupt moderation */

 Initialize the MAC/VLAN queue */

 Initialize the mailbox lock */

 Start off interface as being down */

/**

 * fm10k_probe - Device Initialization Routine

 * @pdev: PCI device information struct

 * @ent: entry in fm10k_pci_tbl

 *

 * Returns 0 on success, negative on failure

 *

 * fm10k_probe initializes an interface identified by a pci_dev structure.

 * The OS initialization, configuring of the interface private structure,

 * and a hardware reset occur.

 enable debugfs support */

	/* the mbx interrupt might attempt to schedule the service task, so we

	 * must ensure it is disabled since we haven't yet requested the timer

	 * or work item.

 final check of hardware state before registering the interface */

 carrier off reporting is important to ethtool even BEFORE open */

 stop all the transmit queues from transmitting until link is up */

	/* Initialize service timer and service task late in order to avoid

	 * cleanup issues.

 Setup the MAC/VLAN queue */

 kick off service timer now, even when interface is down */

 print warning for non-optimal configurations */

 report MAC address for logging */

 enable SR-IOV after registering netdev to enforce PF/VF ordering */

 clear the service task disable bit and kick off service task */

/**

 * fm10k_remove - Device Removal Routine

 * @pdev: PCI device information struct

 *

 * fm10k_remove is called by the PCI subsystem to alert the driver

 * that it should release a PCI device.  The could be caused by a

 * Hot-Plug event, or because the driver is going to be removed from

 * memory.

 Remove all pending MAC/VLAN requests */

 free netdev, this may bounce the interrupts due to setup_tc */

 release VFs */

 disable mailbox interrupt */

 free interrupts */

 remove any debugfs interfaces */

	/* the watchdog task reads from registers, which might appear like

	 * a surprise remove if the PCIe device is disabled while we're

	 * stopped. We stop the watchdog task until after we resume software

	 * activity.

	 *

	 * Note that the MAC/VLAN task will be stopped as part of preparing

	 * for reset so we don't need to handle it here.

	/* Even if we didn't properly prepare for reset in

	 * fm10k_prepare_suspend, we'll attempt to resume anyways.

 reset statistics starting values */

	/* assume host is not ready, to prevent race with watchdog in case we

	 * actually don't have connection to the switch

 force link to stay down for a second to prevent link flutter */

 restart the service task */

 Restart the MAC/VLAN request queue in-case of outstanding events */

/**

 * fm10k_resume - Generic PM resume hook

 * @dev: generic device structure

 *

 * Generic PM hook used when waking the device from a low power state after

 * suspend or hibernation. This function does not need to handle lower PCIe

 * device state as the stack takes care of that for us.

 refresh hw_addr in case it was dropped */

/**

 * fm10k_suspend - Generic PM suspend hook

 * @dev: generic device structure

 *

 * Generic PM hook used when setting the device into a low power state for

 * system suspend or hibernation. This function does not need to handle lower

 * PCIe device state as the stack takes care of that for us.

/**

 * fm10k_io_error_detected - called when PCI error is detected

 * @pdev: Pointer to PCI device

 * @state: The current pci connection state

 *

 * This function is called after a PCI bus error affecting

 * this device has been detected.

 Request a slot reset. */

/**

 * fm10k_io_slot_reset - called after the pci bus has been reset.

 * @pdev: Pointer to PCI device

 *

 * Restart the card from scratch, as if from a cold-boot.

		/* After second error pci->state_saved is false, this

		 * resets it so EEH doesn't break.

/**

 * fm10k_io_resume - called when traffic can start flowing again.

 * @pdev: Pointer to PCI device

 *

 * This callback is called when the error recovery driver tells us that

 * its OK to resume normal operation.

/**

 * fm10k_io_reset_prepare - called when PCI function is about to be reset

 * @pdev: Pointer to PCI device

 *

 * This callback is called when the PCI function is about to be reset,

 * allowing the device driver to prepare for it.

 warn incase we have any active VF devices */

/**

 * fm10k_io_reset_done - called when PCI function has finished resetting

 * @pdev: Pointer to PCI device

 *

 * This callback is called just after the PCI function is reset, such as via

 * /sys/class/net/<enpX>/device/reset or similar.

/**

 * fm10k_register_pci_driver - register driver interface

 *

 * This function is called on module load in order to register the driver.

/**

 * fm10k_unregister_pci_driver - unregister driver interface

 *

 * This function is called on module unload in order to remove the driver.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

 single workqueue for entire fm10k driver */

/**

 * fm10k_init_module - Driver Registration Routine

 *

 * fm10k_init_module is the first routine called when the driver is

 * loaded.  All it does is register with the PCI subsystem.

 create driver workqueue */

/**

 * fm10k_exit_module - Driver Exit Cleanup Routine

 *

 * fm10k_exit_module is called just before the driver is removed

 * from memory.

 destroy driver workqueue */

 Only page will be NULL if buffer was consumed */

 alloc new page for storage */

 map page for use */

	/* if mapping failed free memory back to system since

	 * there isn't much point in holding memory we can't use

/**

 * fm10k_alloc_rx_buffers - Replace used receive buffers

 * @rx_ring: ring to place buffers on

 * @cleaned_count: number of buffers to replace

 nothing to do */

		/* Refresh the desc even if buffer_addrs didn't change

		 * because each write-back erases this info.

 clear the status bits for the next_to_use descriptor */

 record the next descriptor to use */

 update next to alloc since we have filled the ring */

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

 notify hardware of new descriptors */

/**

 * fm10k_reuse_rx_page - page flip buffer and store it back on the ring

 * @rx_ring: rx descriptor ring to store buffers on

 * @old_buff: donor buffer to have page reused

 *

 * Synchronizes page for reuse by the interface

 update, and store next to alloc */

 transfer page from old buffer to new buffer */

 sync the buffer for use by the device */

 avoid re-using remote and pfmemalloc pages */

 if we are only owner of page we can reuse it */

 flip page offset to other buffer */

 move offset up to the next cache line */

	/* Even if we own the page, we are not allowed to use atomic_set()

	 * This would break get_page_unless_zero() users.

/**

 * fm10k_add_rx_frag - Add contents of Rx buffer to sk_buff

 * @rx_buffer: buffer containing page to add

 * @size: packet size from rx_desc

 * @rx_desc: descriptor containing length of buffer written by hardware

 * @skb: sk_buff to place the data into

 *

 * This function will add the data contained in rx_buffer->page to the skb.

 * This is done either through a direct copy if the data in the buffer is

 * less than the skb header size, otherwise it will just attach the page as

 * a frag to the skb.

 *

 * The function will then update the page offset if necessary and return

 * true if the buffer can be reused by the interface.

 page is reusable, we can reuse buffer as-is */

 this page cannot be reused so discard it */

	/* we need the header to contain the greater of either ETH_HLEN or

	 * 60 bytes if the skb->len is less than 60 for skb_pad.

 align pull length to size of long to optimize memcpy performance */

 update all of the pointers */

 prefetch first cache line of first page */

 allocate a skb to store the frags */

		/* we will be copying header into skb->data in

		 * pskb_may_pull so it is in our interest to prefetch

		 * it now to avoid a possible cache miss

 we are reusing so sync this buffer for CPU use */

 pull page into skb */

 hand second half of page back to the ring */

 we are not reusing the buffer so unmap it */

 clear contents of rx_buffer */

 Rx checksum disabled via ethtool */

 TCP/UDP checksum error bit is set */

 It must be a TCP or UDP packet with a valid checksum */

 check to see if DGLORT belongs to a MACVLAN */

 Record Rx queue, or update macvlan statistics */

/**

 * fm10k_process_skb_fields - Populate skb header fields from Rx descriptor

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @rx_desc: pointer to the EOP Rx descriptor

 * @skb: pointer to current skb being populated

 *

 * This function checks the ring, descriptor, and packet information in

 * order to populate the hash, checksum, VLAN, timestamp, protocol, and

 * other fields within the skb.

/**

 * fm10k_is_non_eop - process handling of non-EOP buffers

 * @rx_ring: Rx ring being processed

 * @rx_desc: Rx descriptor for current buffer

 *

 * This function updates next to clean.  If the buffer is an EOP buffer

 * this function exits returning false, otherwise it will place the

 * sk_buff in the next buffer to be chained and return true indicating

 * that this is in fact a non-EOP buffer.

 fetch, update, and store next to clean */

/**

 * fm10k_cleanup_headers - Correct corrupted or empty headers

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @rx_desc: pointer to the EOP Rx descriptor

 * @skb: pointer to current skb being fixed

 *

 * Address the case where we are pulling data in on pages only

 * and as such no data is present in the skb header.

 *

 * In addition if skb is not at least 60 bytes we need to pad it so that

 * it is large enough to qualify as a valid Ethernet frame.

 *

 * Returns true if an error was encountered and skb was freed.

 if eth_skb_pad returns an error the skb was freed */

/**

 * fm10k_receive_skb - helper function to handle rx indications

 * @q_vector: structure containing interrupt and ring information

 * @skb: packet to send up

 return some buffers to hardware, one at a time is too slow */

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we know the

		 * descriptor has been written back

 retrieve a buffer from the ring */

 exit if we failed to retrieve a buffer */

 fetch next buffer in frame if non-eop */

 verify the packet layout is correct */

 populate checksum, timestamp, VLAN, and protocol */

 reset skb pointer */

 update budget accounting */

 place incomplete frames back on ring for completion */

 return offset of udp_hdr plus 8 bytes for VXLAN header */

 currently only IPv4 is supported due to hlen above */

 our transport header should be NVGRE */

 verify all reserved flags are 0 */

 report start of ethernet header */

	/* The hardware allows tunnel offloads only if the combined inner and

	 * outer header is 184 bytes or less

 compute header lengths */

 compute offset from SOF to transport header and add header len */

 update gso size and bytecount with header size */

 populate Tx descriptor header size and mss */

 update TX checksum flag */

 populate Tx descriptor header size and mss */

 set type for advanced descriptor with frame checksum insertion */

 set checksum offload bits */

 set RS and INT for last frame in a cache line */

 record values to descriptor */

 return true if we just wrapped the ring */

 Memory barrier before checking head and tail */

 Check again in a case another CPU has just made room available */

 A reprieve! - use start_queue because it doesn't call schedule */

 add HW VLAN tag */

 record length, and DMA address */

 write last descriptor with LAST bit set */

 record bytecount for BQL */

 record SW timestamp if HW timestamp is not available */

	/* Force memory writes to complete before letting h/w know there

	 * are new descriptors to fetch.  (Only applicable for weak-ordered

	 * memory model archs, such as IA-64).

	 *

	 * We also need this memory barrier to make certain all of the

	 * status bits have been updated before next_to_watch is written.

 set next_to_watch value indicating a packet is present */

 Make sure there is space in the ring for the next send. */

 notify HW of packet */

 clear dma mappings for failed tx_buffer map */

	/* need: 1 descriptor per page * PAGE_SIZE/FM10K_MAX_DATA_PER_TXD,

	 *       + 1 desc for skb_headlen/FM10K_MAX_DATA_PER_TXD,

	 *       + 2 desc gap to keep tail from touching head

	 * otherwise try next time

 record the location of the first descriptor for this packet */

 record initial flags and protocol */

/**

 * fm10k_get_tx_pending - how many Tx descriptors not processed

 * @ring: the ring structure

 * @in_sw: is tx_pending being checked in SW or in HW?

	/* Check for a hung queue, but be thorough. This verifies

	 * that a transmit has been completed since the previous

	 * check AND there is at least one packet pending. By

	 * requiring this to fail twice we avoid races with

	 * clearing the ARMED bit and conditions where we

	 * run the check_tx_hang logic with a transmit completion

	 * pending but without time to complete it yet.

 update completed stats and continue */

 reset the countdown */

 make sure it is true for two checks in a row */

/**

 * fm10k_tx_timeout_reset - initiate reset due to Tx timeout

 * @interface: driver private struct

 Do the reset outside of interrupt context */

/**

 * fm10k_clean_tx_irq - Reclaim resources after transmit completes

 * @q_vector: structure containing interrupt and ring information

 * @tx_ring: tx ring to clean

 * @napi_budget: Used to determine if we are in netpoll

 if next_to_watch is not set then there is no work pending */

 prevent any other reads prior to eop_desc */

 if DD is not set pending work has not been completed */

 clear next_to_watch to prevent false hangs */

 update the statistics for this packet */

 free the skb */

 unmap skb header data */

 clear tx_buffer data */

 unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 issue prefetch for next Tx descriptor */

 update budget accounting */

 schedule immediate reset if we believe we hung */

 the netdev is about to reset, no point in enabling stuff */

 notify netdev of completed buffers */

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

/**

 * fm10k_update_itr - update the dynamic ITR value based on packet size

 *

 *      Stores a new ITR value based on strictly on packet size.  The

 *      divisors and thresholds used by this function were determined based

 *      on theoretical maximum wire speed and testing data, in order to

 *      minimize response time while increasing bulk throughput.

 *

 * @ring_container: Container for rings to have ITR updated

 Only update ITR if we are using adaptive setting */

	/* The following is a crude approximation of:

	 *  wmem_default / (size + overhead) = desired_pkts_per_int

	 *  rate / bits_per_byte / (size + ethernet overhead) = pkt_rate

	 *  (desired_pkt_rate / pkt_rate) * usecs_per_sec = ITR value

	 *

	 * Assuming wmem_default is 212992 and overhead is 640 bytes per

	 * packet, (256 skb, 64 headroom, 320 shared info), we can reduce the

	 * formula down to

	 *

	 *  (34 * (size + 24)) / (size + 640) = ITR

	 *

	 * We first do some math on the packet size and then finally bitshift

	 * by 8 after rounding up. We also have to account for PCIe link speed

	 * difference as ITR scales based on this.

 Start at 250K ints/sec and gradually drop to 77K ints/sec */

 77K ints/sec to 45K ints/sec */

 45K ints/sec to 38K ints/sec */

 plateau at a limit of 38K ints/sec */

	/* Perform final bitshift for division after rounding up to ensure

	 * that the calculation will never get below a 1. The bit shift

	 * accounts for changes in the ITR due to PCIe link speed.

 write back value and retain adaptive flag */

 Enable auto-mask and clear the current mask */

 Update Tx ITR */

 Update Rx ITR */

 Store Tx itr in timer slot 0 */

 Shift Rx itr to timer slot 1 */

 Write the final value to the ITR register */

 Handle case where we are called by netpoll with a budget of 0 */

	/* attempt to distribute budget to each queue fairly, but don't

	 * allow the budget to go below 1 because we'll exit polling

 If all work not completed, return budget and keep polling */

	/* Exit the polling mode, but don't re-enable interrupts if stack might

	 * poll us due to busy-polling

/**

 * fm10k_set_qos_queues: Allocate queues for a QOS-enabled device

 * @interface: board private structure to initialize

 *

 * When QoS (Quality of Service) is enabled, allocate queues for

 * each traffic class.  If multiqueue isn't available,then abort QoS

 * initialization.

 *

 * This function handles all combinations of Qos and RSS.

 *

 Map queue offset and counts onto allocated tx queues */

 set QoS mask and indices */

 determine the upper limit for our current DCB mode */

 set RSS mask and indices */

 configure pause class to queue mapping */

/**

 * fm10k_set_rss_queues: Allocate queues for RSS

 * @interface: board private structure to initialize

 *

 * This is our "base" multiqueue mode.  RSS (Receive Side Scaling) will try

 * to allocate one Rx queue per CPU, and if available, one Tx queue per CPU.

 *

 record indices and power of 2 mask for RSS */

/**

 * fm10k_set_num_queues: Allocate queues for device, feature dependent

 * @interface: board private structure to initialize

 *

 * This is the top level queue allocation routine.  The order here is very

 * important, starting with the "most" number of features turned on at once,

 * and ending with the smallest set of features.  This way large combinations

 * can be allocated if they're turned on, and smaller combinations are the

 * fall through conditions.

 *

 Attempt to setup QoS and RSS first */

 If we don't have QoS, just fallback to only RSS. */

/**

 * fm10k_reset_num_queues - Reset the number of queues to zero

 * @interface: board private structure

 *

 * This function should be called whenever we need to reset the number of

 * queues after an error condition.

/**

 * fm10k_alloc_q_vector - Allocate memory for a single interrupt vector

 * @interface: board private structure to initialize

 * @v_count: q_vectors allocated on interface, used for ring interleaving

 * @v_idx: index of vector in interface struct

 * @txr_count: total number of Tx rings to allocate

 * @txr_idx: index of first Tx ring to allocate

 * @rxr_count: total number of Rx rings to allocate

 * @rxr_idx: index of first Rx ring to allocate

 *

 * We allocate one q_vector.  If allocation fails we return -ENOMEM.

 allocate q_vector and rings */

 initialize NAPI */

 tie q_vector and interface together */

 initialize pointer to rings */

 save Tx ring container info */

 assign generic ring traits */

 configure backlink on ring */

 apply Tx specific ring traits */

 assign ring to interface */

 update count and index */

 push pointer to next ring */

 save Rx ring container info */

 assign generic ring traits */

 configure backlink on ring */

 apply Rx specific ring traits */

 assign ring to interface */

 update count and index */

 push pointer to next ring */

/**

 * fm10k_free_q_vector - Free memory allocated for specific interrupt vector

 * @interface: board private structure to initialize

 * @v_idx: Index of vector to be freed

 *

 * This function frees the memory allocated to the q_vector.  In addition if

 * NAPI is enabled it will delete any references to the NAPI struct prior

 * to freeing the q_vector.

/**

 * fm10k_alloc_q_vectors - Allocate memory for interrupt vectors

 * @interface: board private structure to initialize

 *

 * We allocate one q_vector per queue interrupt.  If allocation fails we

 * return -ENOMEM.

 update counts and index */

 update counts and index */

/**

 * fm10k_free_q_vectors - Free memory allocated for interrupt vectors

 * @interface: board private structure to initialize

 *

 * This function frees the memory allocated to the q_vectors.  In addition if

 * NAPI is enabled it will delete any references to the NAPI struct prior

 * to freeing the q_vector.

/**

 * fm10k_reset_msix_capability - reset MSI-X capability

 * @interface: board private structure to initialize

 *

 * Reset the MSI-X capability back to its starting state

/**

 * fm10k_init_msix_capability - configure MSI-X capability

 * @interface: board private structure to initialize

 *

 * Attempt to configure the interrupts using the best available

 * capabilities of the hardware and the kernel.

	/* It's easy to be greedy for MSI-X vectors, but it really

	 * doesn't do us much good if we have a lot more vectors

	 * than CPU's.  So let's be conservative and only ask for

	 * (roughly) the same number of vectors as there are CPU's.

	 * the default is to use pairs of vectors

 account for vectors not related to queues */

	/* At the same time, hardware can only support a maximum of

	 * hw.mac->max_msix_vectors vectors.  With features

	 * such as RSS and VMDq, we can easily surpass the number of Rx and Tx

	 * descriptor queues supported by our device.  Thus, we cap it off in

	 * those rare cases where the cpu count also exceeds our vector limit.

 A failure in MSI-X entry allocation is fatal. */

 populate entry values */

 Attempt to enable MSI-X with requested value */

 record the number of queues available for q_vectors */

/**

 * fm10k_cache_ring_qos - Descriptor ring to register mapping for QoS

 * @interface: Interface structure continaining rings and devices

 *

 * Cache the descriptor ring offsets for Qos

/**

 * fm10k_cache_ring_rss - Descriptor ring to register mapping for RSS

 * @interface: Interface structure continaining rings and devices

 *

 * Cache the descriptor ring offsets for RSS

/**

 * fm10k_assign_rings - Map rings to network devices

 * @interface: Interface structure containing rings and devices

 *

 * This function is meant to go though and configure both the network

 * devices so that they contain rings, and configure the rings so that

 * they function with their network devices.

	/* If the Rx flow indirection table has been configured manually, we

	 * need to maintain it when possible.

 this should never happen */

 do nothing if all of the elements are in bounds */

/**

 * fm10k_init_queueing_scheme - Determine proper queueing scheme

 * @interface: board private structure to initialize

 *

 * We determine which queueing scheme to use based on...

 * - Hardware queue count (num_*_queues)

 *   - defined by miscellaneous hardware support/features (RSS, etc.)

 Number of supported queues */

 Configure MSI-X capability */

 Allocate memory for queues */

 Map rings to devices, and map devices to physical queues */

 Initialize RSS redirection table */

/**

 * fm10k_clear_queueing_scheme - Clear the current queueing scheme settings

 * @interface: board private structure to clear queueing scheme on

 *

 * We go through and clear queueing specific resources and reset the structure

 * to pre-load conditions

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2019 Intel Corporation. */

	/* The stat_string is expected to be a format string formatted using

	 * vsnprintf by fm10k_add_stat_strings. Every member of a stats array

	 * should use the same format specifiers as they will be formatted

	 * using the same variadic arguments.

 netdevice statistics */

 detailed Rx errors */

 General interface statistics */

 mailbox statistics */

 per-queue ring statistics */

 memory is not zero allocated so we have to clear it */

 If function below adds more registers this define needs to be updated */

 If function above adds more registers this define needs to be updated */

 General PF Registers */

 Interrupt Throttling Registers */

 General VF registers */

 Interrupt Throttling Registers */

 If function above adds more registers these define need to be updated */

 record fixed values for autoneg and tx pause */

 we can only support pause on the PF to avoid head-of-line blocking */

 nothing to do */

 allocate temporary buffer to store rings in */

	/* Setup new Tx resources and free the old Tx resources in that order.

	 * We can then assign the new resources to the rings via a memcpy.

	 * The advantage to this approach is that we are guaranteed to still

	 * have resources even in the case of an allocation failure.

 Repeat the process for the Rx rings if needed */

 verify limits */

 record settings */

 set initial values for adaptive ITR */

 update interface */

 update q_vectors */

 Report default options for RSS on fm10k */

	/* RSS does not support anything other than hashing

	 * to queues on src and dst IPs and ports

	/* If something changed we need to update the MRQC register. Note that

	 * test_bit() is guaranteed to return strictly 0 or 1, so testing for

	 * equality is safe.

 Perform hash on these packet types */

		/* If we enable UDP RSS display a warning that this may cause

		 * fragmented UDP packets to arrive out of order.

 For now this is a VF only feature */

 loop through both nested and unnested attribute types */

 generate message to be tested */

 wait up to 1 second for response */

 reporting errors */

 record entries to reta table */

 generate a new table if we weren't given one */

 Verify user input. */

 We do not allow change in unsupported parameters */

 For QoS report channels per traffic class */

 report maximum channels */

 report info for other vector */

 record RSS queues */

 verify they are not requesting separate vectors */

 verify other_count has not changed */

 verify the number of channels does not exceed hardware limits */

 use setup TC to update any traffic class queue mapping */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

 ethtool support for iavf */

 ethtool statistics helpers */

/**

 * struct iavf_stats - definition for an ethtool statistic

 * @stat_string: statistic name to display in ethtool -S output

 * @sizeof_stat: the sizeof() the stat, must be no greater than sizeof(u64)

 * @stat_offset: offsetof() the stat from a base pointer

 *

 * This structure defines a statistic to be added to the ethtool stats buffer.

 * It defines a statistic as offset from a common base pointer. Stats should

 * be defined in constant arrays using the IAVF_STAT macro, with every element

 * of the array using the same _type for calculating the sizeof_stat and

 * stat_offset.

 *

 * The @sizeof_stat is expected to be sizeof(u8), sizeof(u16), sizeof(u32) or

 * sizeof(u64). Other sizes are not expected and will produce a WARN_ONCE from

 * the iavf_add_ethtool_stat() helper function.

 *

 * The @stat_string is interpreted as a format string, allowing formatted

 * values to be inserted while looping over multiple structures for a given

 * statistics array. Thus, every statistic string in an array should have the

 * same type and number of format specifiers, to be formatted by variadic

 * arguments to the iavf_add_stat_string() helper function.

/* Helper macro to define an iavf_stat structure with proper size and type.

 * Use this when defining constant statistics arrays. Note that @_type expects

 * only a type name and is used multiple times.

 Helper macro for defining some statistics related to queues */

 Stats associated with a Tx or Rx ring */

/**

 * iavf_add_one_ethtool_stat - copy the stat into the supplied buffer

 * @data: location to store the stat value

 * @pointer: basis for where to copy from

 * @stat: the stat definition

 *

 * Copies the stat data defined by the pointer and stat structure pair into

 * the memory supplied as data. Used to implement iavf_add_ethtool_stats and

 * iavf_add_queue_stats. If the pointer is null, data will be zero'd.

		/* ensure that the ethtool data buffer is zero'd for any stats

		 * which don't have a valid pointer.

/**

 * __iavf_add_ethtool_stats - copy stats into the ethtool supplied buffer

 * @data: ethtool stats buffer

 * @pointer: location to copy stats from

 * @stats: array of stats to copy

 * @size: the size of the stats definition

 *

 * Copy the stats defined by the stats array using the pointer as a base into

 * the data buffer supplied by ethtool. Updates the data pointer to point to

 * the next empty location for successive calls to __iavf_add_ethtool_stats.

 * If pointer is null, set the data values to zero and update the pointer to

 * skip these stats.

/**

 * iavf_add_ethtool_stats - copy stats into ethtool supplied buffer

 * @data: ethtool stats buffer

 * @pointer: location where stats are stored

 * @stats: static const array of stat definitions

 *

 * Macro to ease the use of __iavf_add_ethtool_stats by taking a static

 * constant stats array and passing the ARRAY_SIZE(). This avoids typos by

 * ensuring that we pass the size associated with the given stats array.

 *

 * The parameter @stats is evaluated twice, so parameters with side effects

 * should be avoided.

/**

 * iavf_add_queue_stats - copy queue statistics into supplied buffer

 * @data: ethtool stats buffer

 * @ring: the ring to copy

 *

 * Queue statistics must be copied while protected by

 * u64_stats_fetch_begin_irq, so we can't directly use iavf_add_ethtool_stats.

 * Assumes that queue stats are defined in iavf_gstrings_queue_stats. If the

 * ring pointer is null, zero out the queue stat values and update the data

 * pointer. Otherwise safely copy the stats from the ring into the supplied

 * buffer and update the data pointer when finished.

 *

 * This function expects to be called while under rcu_read_lock().

	/* To avoid invalid statistics values, ensure that we keep retrying

	 * the copy until we get a consistent value according to

	 * u64_stats_fetch_retry_irq. But first, make sure our ring is

	 * non-null before attempting to access its syncp.

 Once we successfully copy the stats in, update the data pointer */

/**

 * __iavf_add_stat_strings - copy stat strings into ethtool buffer

 * @p: ethtool supplied buffer

 * @stats: stat definitions array

 * @size: size of the stats array

 *

 * Format and copy the strings described by stats into the buffer pointed at

 * by p.

/**

 * iavf_add_stat_strings - copy stat strings into ethtool buffer

 * @p: ethtool supplied buffer

 * @stats: stat definitions array

 *

 * Format and copy the strings described by the const static stats value into

 * the buffer pointed at by p.

 *

 * The parameter @stats is evaluated twice, so parameters with side effects

 * should be avoided. Additionally, stats must be an array such that

 * ARRAY_SIZE can be called on it.

/* For now we have one and only one private flag and it is only defined

 * when we have support for the SKIP_CPU_SYNC DMA attribute.  Instead

 * of leaving all this code sitting around empty we will strip it unless

 * our one private flag is actually available.

/**

 * iavf_get_link_ksettings - Get Link Speed and Duplex settings

 * @netdev: network interface device structure

 * @cmd: ethtool command

 *

 * Reports speed/duplex settings. Because this is a VF, we don't know what

 * kind of link we really have, so we fake it.

/**

 * iavf_get_sset_count - Get length of string set

 * @netdev: network interface device structure

 * @sset: id of string set

 *

 * Reports size of various string tables.

/**

 * iavf_get_ethtool_stats - report device statistics

 * @netdev: network interface device structure

 * @stats: ethtool statistics structure

 * @data: pointer to data buffer

 *

 * All statistics are added to the data buffer as an array of u64.

 Avoid accessing un-allocated queues */

 Avoid accessing un-allocated queues */

/**

 * iavf_get_priv_flag_strings - Get private flag strings

 * @netdev: network interface device structure

 * @data: buffer for string data

 *

 * Builds the private flags string table

/**

 * iavf_get_stat_strings - Get stat strings

 * @netdev: network interface device structure

 * @data: buffer for string data

 *

 * Builds the statistics string table

	/* Queues are always allocated in pairs, so we just use num_tx_queues

	 * for both Tx and Rx queues.

/**

 * iavf_get_strings - Get string set

 * @netdev: network interface device structure

 * @sset: id of string set

 * @data: buffer for string data

 *

 * Builds string tables for various string sets

/**

 * iavf_get_priv_flags - report device private flags

 * @netdev: network interface device structure

 *

 * The get string set count and the string set should be matched for each

 * flag returned.  Add new strings for each flag to the iavf_gstrings_priv_flags

 * array.

 *

 * Returns a u32 bitmap of flags.

/**

 * iavf_set_priv_flags - set private flags

 * @netdev: network interface device structure

 * @flags: bit flags to be set

	/* Before we finalize any flag changes, any checks which we need to

	 * perform to determine if the new flags will be supported should go

	 * here...

	/* Compare and exchange the new flags into place. If we failed, that

	 * is if cmpxchg returns anything but the old value, this means

	 * something else must have modified the flags variable since we

	 * copied it. We'll just punt with an error and log something in the

	 * message buffer.

	/* Process any additional changes needed as a result of flag changes.

	 * The changed_flags value reflects the list of bits that were changed

	 * in the code above.

 issue a reset to force legacy-rx change to take effect */

/**

 * iavf_get_msglevel - Get debug message level

 * @netdev: network interface device structure

 *

 * Returns current debug message level.

/**

 * iavf_set_msglevel - Set debug message level

 * @netdev: network interface device structure

 * @data: message level

 *

 * Set current debug message level. Higher values cause the driver to

 * be noisier.

/**

 * iavf_get_drvinfo - Get driver info

 * @netdev: network interface device structure

 * @drvinfo: ethool driver info structure

 *

 * Returns information about the driver and device for display to the user.

/**

 * iavf_get_ringparam - Get ring parameters

 * @netdev: network interface device structure

 * @ring: ethtool ringparam structure

 *

 * Returns current ring parameters. TX and RX rings are reported separately,

 * but the number of rings is not reported.

/**

 * iavf_set_ringparam - Set ring parameters

 * @netdev: network interface device structure

 * @ring: ethtool ringparam structure

 *

 * Sets ring parameters. TX and RX rings are controlled separately, but the

 * number of rings is not specified, so all rings get the same settings.

 if nothing to do return success */

/**

 * __iavf_get_coalesce - get per-queue coalesce settings

 * @netdev: the netdev to check

 * @ec: ethtool coalesce data structure

 * @queue: which queue to pick

 *

 * Gets the per-queue settings for coalescence. Specifically Rx and Tx usecs

 * are per queue. If queue is <0 then we default to queue 0 as the

 * representative value.

	/* Rx and Tx usecs per queue value. If user doesn't specify the

	 * queue, return queue 0's value to represent.

/**

 * iavf_get_coalesce - Get interrupt coalescing settings

 * @netdev: network interface device structure

 * @ec: ethtool coalesce structure

 * @kernel_coal: ethtool CQE mode setting structure

 * @extack: extack for reporting error messages

 *

 * Returns current coalescing settings. This is referred to elsewhere in the

 * driver as Interrupt Throttle Rate, as this is how the hardware describes

 * this functionality. Note that if per-queue settings have been modified this

 * only represents the settings of queue 0.

/**

 * iavf_get_per_queue_coalesce - get coalesce values for specific queue

 * @netdev: netdev to read

 * @ec: coalesce settings from ethtool

 * @queue: the queue to read

 *

 * Read specific queue's coalesce settings.

/**

 * iavf_set_itr_per_queue - set ITR values for specific queue

 * @adapter: the VF adapter struct to set values for

 * @ec: coalesce settings from ethtool

 * @queue: the queue to modify

 *

 * Change the ITR settings for a specific queue.

	/* The interrupt handler itself will take care of programming

	 * the Tx and Rx ITR values based on the values we have entered

	 * into the q_vector, no need to write the values now.

/**

 * __iavf_set_coalesce - set coalesce settings for particular queue

 * @netdev: the netdev to change

 * @ec: ethtool coalesce settings

 * @queue: the queue to change

 *

 * Sets the coalesce settings for a particular queue.

	/* Rx and Tx usecs has per queue value. If user doesn't specify the

	 * queue, apply to all queues.

/**

 * iavf_set_coalesce - Set interrupt coalescing settings

 * @netdev: network interface device structure

 * @ec: ethtool coalesce structure

 * @kernel_coal: ethtool CQE mode setting structure

 * @extack: extack for reporting error messages

 *

 * Change current coalescing settings for every queue.

/**

 * iavf_set_per_queue_coalesce - set specific queue's coalesce settings

 * @netdev: the netdev to change

 * @ec: ethtool's coalesce settings

 * @queue: the queue to modify

 *

 * Modifies a specific queue's coalesce settings.

/**

 * iavf_fltr_to_ethtool_flow - convert filter type values to ethtool

 * flow type values

 * @flow: filter type to be converted

 *

 * Returns the corresponding ethtool flow type.

 0 is undefined ethtool flow */

/**

 * iavf_ethtool_flow_to_fltr - convert ethtool flow type to filter enum

 * @eth: Ethtool flow type to be converted

 *

 * Returns flow enum

/**

 * iavf_is_mask_valid - check mask field set

 * @mask: full mask to check

 * @field: field for which mask should be valid

 *

 * If the mask is fully set return true. If it is not valid for field return

 * false.

/**

 * iavf_parse_rx_flow_user_data - deconstruct user-defined data

 * @fsp: pointer to ethtool Rx flow specification

 * @fltr: pointer to Flow Director filter for userdef data storage

 *

 * Returns 0 on success, negative error value on failure

		/* 504 is the maximum value for offsets, and offset is measured

		 * from the start of the MAC address.

/**

 * iavf_fill_rx_flow_ext_data - fill the additional data

 * @fsp: pointer to ethtool Rx flow specification

 * @fltr: pointer to Flow Director filter to get additional data

/**

 * iavf_get_ethtool_fdir_entry - fill ethtool structure with Flow Director filter data

 * @adapter: the VF adapter structure that contains filter list

 * @cmd: ethtool command data structure to receive the filter data

 *

 * Returns 0 as expected for success by ethtool

/**

 * iavf_get_fdir_fltr_ids - fill buffer with filter IDs of active filters

 * @adapter: the VF adapter structure containing the filter list

 * @cmd: ethtool command data structure

 * @rule_locs: ethtool array passed in from OS to receive filter IDs

 *

 * Returns 0 as expected for success by ethtool

/**

 * iavf_add_fdir_fltr_info - Set the input set for Flow Director filter

 * @adapter: pointer to the VF adapter structure

 * @fsp: pointer to ethtool Rx flow specification

 * @fltr: filter structure

 not doing un-parsed flow types */

/**

 * iavf_add_fdir_ethtool - add Flow Director filter

 * @adapter: pointer to the VF adapter structure

 * @cmd: command to add Flow Director filter

 *

 * Returns 0 on success and negative values for failure

/**

 * iavf_del_fdir_ethtool - delete Flow Director filter

 * @adapter: pointer to the VF adapter structure

 * @cmd: command to delete Flow Director filter

 *

 * Returns 0 on success and negative values for failure

/**

 * iavf_adv_rss_parse_hdrs - parses headers from RSS hash input

 * @cmd: ethtool rxnfc command

 *

 * This function parses the rxnfc command and returns intended

 * header types for RSS configuration

/**

 * iavf_adv_rss_parse_hash_flds - parses hash fields from RSS hash input

 * @cmd: ethtool rxnfc command

 *

 * This function parses the rxnfc command and returns intended hash fields for

 * RSS configuration

/**

 * iavf_set_adv_rss_hash_opt - Enable/Disable flow types for RSS hash

 * @adapter: pointer to the VF adapter structure

 * @cmd: ethtool rxnfc command

 *

 * Returns Success if the flow input set is supported.

/**

 * iavf_get_adv_rss_hash_opt - Retrieve hash fields for a given flow-type

 * @adapter: pointer to the VF adapter structure

 * @cmd: ethtool rxnfc command

 *

 * Returns Success if the flow input set is supported.

/**

 * iavf_set_rxnfc - command to set Rx flow rules.

 * @netdev: network interface device structure

 * @cmd: ethtool rxnfc command

 *

 * Returns 0 for success and negative values for errors

/**

 * iavf_get_rxnfc - command to get RX flow classification rules

 * @netdev: network interface device structure

 * @cmd: ethtool rxnfc command

 * @rule_locs: pointer to store rule locations

 *

 * Returns Success if the command is supported.

/**

 * iavf_get_channels: get the number of channels supported by the device

 * @netdev: network interface device structure

 * @ch: channel information structure

 *

 * For the purposes of our device, we only use combined channels, i.e. a tx/rx

 * queue pair. Report one extra channel to match our "other" MSI-X vector.

 Report maximum channels */

/**

 * iavf_set_channels: set the new channel count

 * @netdev: network interface device structure

 * @ch: channel information structure

 *

 * Negotiate a new number of channels with the PF then do a reset.  During

 * reset we'll realloc queues and fix the RSS table.  Returns 0 on success,

 * negative on failure.

	/* All of these should have already been checked by ethtool before this

	 * even gets to us, but just to be sure.

 wait for the reset is done */

/**

 * iavf_get_rxfh_key_size - get the RSS hash key size

 * @netdev: network interface device structure

 *

 * Returns the table size.

/**

 * iavf_get_rxfh_indir_size - get the rx flow hash indirection table size

 * @netdev: network interface device structure

 *

 * Returns the table size.

/**

 * iavf_get_rxfh - get the rx flow hash indirection table

 * @netdev: network interface device structure

 * @indir: indirection table

 * @key: hash key

 * @hfunc: hash function in use

 *

 * Reads the indirection table directly from the hardware. Always returns 0.

 Each 32 bits pointed by 'indir' is stored with a lut entry */

/**

 * iavf_set_rxfh - set the rx flow hash indirection table

 * @netdev: network interface device structure

 * @indir: indirection table

 * @key: hash key

 * @hfunc: hash function to use

 *

 * Returns -EINVAL if the table specifies an inavlid queue id, otherwise

 * returns 0 after programming the table.

 We do not allow change in unsupported parameters */

 Each 32 bits pointed by 'indir' is stored with a lut entry */

/**

 * iavf_set_ethtool_ops - Initialize ethtool ops struct

 * @netdev: network interface device structure

 *

 * Sets ethtool ops struct in our netdev so that ethtool can call

 * our functions.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 * iavf_unmap_and_free_tx_resource - Release a Tx buffer

 * @ring:      the ring that owns the buffer

 * @tx_buffer: the buffer to free

 tx_buffer must be completely set up in the transmit path */

/**

 * iavf_clean_tx_ring - Free any empty Tx buffers

 * @tx_ring: ring to be cleaned

 ring already cleared, nothing to do */

 Free all the Tx ring sk_buffs */

 Zero out the descriptor ring */

 cleanup Tx queue statistics */

/**

 * iavf_free_tx_resources - Free Tx resources per queue

 * @tx_ring: Tx descriptor ring for a specific queue

 *

 * Free all transmit software resources

/**

 * iavf_get_tx_pending - how many Tx descriptors not processed

 * @ring: the ring of descriptors

 * @in_sw: is tx_pending being checked in SW or HW

 *

 * Since there is no access to the ring head register

 * in XL710, we need to use our local copies

/**

 * iavf_detect_recover_hung - Function to detect and recover hung_queues

 * @vsi:  pointer to vsi struct with tx queues

 *

 * VSI has netdev and netdev has TX queues. This function is to check each of

 * those TX queues if they are hung, trigger recovery by issuing SW interrupt.

			/* If packet counter has not changed the queue is

			 * likely stalled, so force an interrupt for this

			 * queue.

			 *

			 * prev_pkt_ctr would be negative if there was no

			 * pending work.

			/* Memory barrier between read of packet count and call

			 * to iavf_get_tx_pending()

/**

 * iavf_clean_tx_irq - Reclaim resources after transmit completes

 * @vsi: the VSI we care about

 * @tx_ring: Tx ring to clean

 * @napi_budget: Used to determine if we are in netpoll

 *

 * Returns true if there's any budget left (e.g. the clean is finished)

 if next_to_watch is not set then there is no work pending */

 prevent any other reads prior to eop_desc */

 if the descriptor isn't done, no work yet to do */

 clear next_to_watch to prevent false hangs */

 update the statistics for this packet */

 free the skb */

 unmap skb header data */

 clear tx_buffer data */

 unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 update budget accounting */

		/* check to see if there are < 4 descriptors

		 * waiting to be written back, then kick the hardware to force

		 * them to be written back in case we stay in NAPI.

		 * In this mode on X722 we do not enable Interrupt.

 notify netdev of completed buffers */

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

/**

 * iavf_enable_wb_on_itr - Arm hardware to do a wb, interrupts are not enabled

 * @vsi: the VSI we care about

 * @q_vector: the vector on which to enable writeback

 *

 set noitr */

/**

 * iavf_force_wb - Issue SW Interrupt so HW does a wb

 * @vsi: the VSI we care about

 * @q_vector: the vector  on which to force writeback

 *

 set noitr */

 allow 00 to be written to the index */;

/**

 * iavf_update_itr - update the dynamic ITR value based on statistics

 * @q_vector: structure containing interrupt and ring information

 * @rc: structure containing ring performance data

 *

 * Stores a new ITR value based on packets and byte

 * counts during the last interrupt.  The advantage of per interrupt

 * computation is faster updates and more accurate ITR for the current

 * traffic pattern.  Constants in this function were computed

 * based on theoretical maximum wire speed and thresholds were set based

 * on testing data as well as attempting to minimize response time

 * while increasing bulk throughput.

	/* If we don't have any rings just leave ourselves set for maximum

	 * possible latency so we take ourselves out of the equation.

	/* For Rx we want to push the delay up and default to low latency.

	 * for Tx we want to pull the delay down and default to high latency.

	/* If we didn't update within up to 1 - 2 jiffies we can assume

	 * that either packets are coming in so slow there hasn't been

	 * any work, or that there is so much work that NAPI is dealing

	 * with interrupt moderation and we don't need to do anything.

	/* If itr_countdown is set it means we programmed an ITR within

	 * the last 4 interrupt cycles. This has a side effect of us

	 * potentially firing an early interrupt. In order to work around

	 * this we need to throw out any data received for a few

	 * interrupts following the update.

		/* If Rx there are 1 to 4 packets and bytes are less than

		 * 9000 assume insufficient data to use bulk rate limiting

		 * approach unless Tx is already in bulk rate limiting. We

		 * are likely latency driven.

		/* If we have Tx and Rx ITR maxed and Tx ITR is running in

		 * bulk mode and we are receiving 4 or fewer packets just

		 * reset the ITR_ADAPTIVE_LATENCY bit for latency mode so

		 * that the Rx can relax.

		/* If we have processed over 32 packets in a single interrupt

		 * for Tx assume we need to switch over to "bulk" mode.

	/* We have no packets to actually measure against. This means

	 * either one of the other queues on this vector is active or

	 * we are a Tx queue doing TSO with too high of an interrupt rate.

	 *

	 * Between 4 and 56 we can assume that our current interrupt delay

	 * is only slightly too low. As such we should increase it by a small

	 * fixed amount.

		/* Between 56 and 112 is our "goldilocks" zone where we are

		 * working out "just right". Just report that our current

		 * ITR is good for us.

		/* If packet count is 128 or greater we are likely looking

		 * at a slight overrun of the delay we want. Try halving

		 * our delay to see if that will cut the number of packets

		 * in half per interrupt.

	/* The paths below assume we are dealing with a bulk ITR since

	 * number of packets is greater than 256. We are just going to have

	 * to compute a value and try to bring the count under control,

	 * though for smaller packet sizes there isn't much we can do as

	 * NAPI polling will likely be kicking in sooner rather than later.

	/* If packet counts are 256 or greater we can assume we have a gross

	 * overestimation of what the rate should be. Instead of trying to fine

	 * tune it just use the formula below to try and dial in an exact value

	 * give the current packet size of the frame.

	/* The following is a crude approximation of:

	 *  wmem_default / (size + overhead) = desired_pkts_per_int

	 *  rate / bits_per_byte / (size + ethernet overhead) = pkt_rate

	 *  (desired_pkt_rate / pkt_rate) * usecs_per_sec = ITR value

	 *

	 * Assuming wmem_default is 212992 and overhead is 640 bytes per

	 * packet, (256 skb, 64 headroom, 320 shared info), we can reduce the

	 * formula down to

	 *

	 *  (170 * (size + 24)) / (size + 640) = ITR

	 *

	 * We first do some math on the packet size and then finally bitshift

	 * by 8 after rounding up. We also have to account for PCIe link speed

	 * difference as ITR scales based on this.

 Start at 250k ints/sec */

 250K ints/sec to 60K ints/sec */

 60K ints/sec to 36K ints/sec */

 36K ints/sec to 30K ints/sec */

 plateau at a limit of 30K ints/sec */

	/* If we are in low latency mode halve our delay which doubles the

	 * rate to somewhere between 100K to 16K ints/sec

	/* Resultant value is 256 times larger than it needs to be. This

	 * gives us room to adjust the value as needed to either increase

	 * or decrease the value based on link speeds of 10G, 2.5G, 1G, etc.

	 *

	 * Use addition as we have already recorded the new latency flag

	 * for the ITR value.

 write back value */

 next update should occur within next jiffy */

/**

 * iavf_setup_tx_descriptors - Allocate the Tx descriptors

 * @tx_ring: the tx ring to set up

 *

 * Return 0 on success, negative on error

 warn if we are about to overwrite the pointer */

 round up to nearest 4K */

/**

 * iavf_clean_rx_ring - Free Rx buffers

 * @rx_ring: ring to be cleaned

 ring already cleared, nothing to do */

 Free all the Rx ring sk_buffs */

		/* Invalidate cache lines that may have been written to by

		 * device so that we avoid corrupting memory.

 free resources associated with mapping */

 Zero out the descriptor ring */

/**

 * iavf_free_rx_resources - Free Rx resources

 * @rx_ring: ring to clean the resources from

 *

 * Free all receive software resources

/**

 * iavf_setup_rx_descriptors - Allocate Rx descriptors

 * @rx_ring: Rx descriptor ring (for a specific queue) to setup

 *

 * Returns 0 on success, negative on failure

 warn if we are about to overwrite the pointer */

 Round up to nearest 4K */

/**

 * iavf_release_rx_desc - Store the new tail and head values

 * @rx_ring: ring to bump

 * @val: new head index

 update next to alloc since we have filled the ring */

	/* Force memory writes to complete before letting h/w

	 * know there are new descriptors to fetch.  (Only

	 * applicable for weak-ordered memory model archs,

	 * such as IA-64).

/**

 * iavf_rx_offset - Return expected offset into page to access data

 * @rx_ring: Ring we are requesting offset of

 *

 * Returns the offset value for ring into the data buffer.

/**

 * iavf_alloc_mapped_page - recycle or make a new page

 * @rx_ring: ring to use

 * @bi: rx_buffer struct to modify

 *

 * Returns true if the page was successfully allocated or

 * reused.

 since we are recycling buffers we should seldom need to alloc */

 alloc new page for storage */

 map page for use */

	/* if mapping failed free memory back to system since

	 * there isn't much point in holding memory we can't use

 initialize pagecnt_bias to 1 representing we fully own page */

/**

 * iavf_receive_skb - Send a completed packet up the stack

 * @rx_ring:  rx ring in play

 * @skb: packet to send up

 * @vlan_tag: vlan tag for packet

/**

 * iavf_alloc_rx_buffers - Replace used receive buffers

 * @rx_ring: ring to place buffers on

 * @cleaned_count: number of buffers to replace

 *

 * Returns false if all allocations were successful, true if any fail

 do nothing if no valid netdev defined */

 sync the buffer for use by the device */

		/* Refresh the desc even if buffer_addrs didn't change

		 * because each write-back erases this info.

 clear the status bits for the next_to_use descriptor */

	/* make sure to come back via polling to try again after

	 * allocation failure

/**

 * iavf_rx_checksum - Indicate in skb if hw indicated a good cksum

 * @vsi: the VSI we care about

 * @skb: skb currently being received and modified

 * @rx_desc: the receive descriptor

 Rx csum enabled and ip headers found? */

 did the hardware decode the packet and checksum? */

 both known and outer_ip must be set for the below code to work */

 likely incorrect csum if alternate IP extension headers found */

 don't increment checksum err here, non-fatal err */

 there was some L4 error, count error and punt packet to the stack */

	/* handle packets that were not able to be checksummed due

	 * to arrival speed, in this case the stack can compute

	 * the csum.

 Only report checksum unnecessary for TCP, UDP, or SCTP */

/**

 * iavf_ptype_to_htype - get a hash type

 * @ptype: the ptype value from the descriptor

 *

 * Returns a hash type to be used by skb_set_hash

/**

 * iavf_rx_hash - set the hash value in the skb

 * @ring: descriptor ring

 * @rx_desc: specific descriptor

 * @skb: skb currently being received and modified

 * @rx_ptype: Rx packet type

/**

 * iavf_process_skb_fields - Populate skb header fields from Rx descriptor

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @rx_desc: pointer to the EOP Rx descriptor

 * @skb: pointer to current skb being populated

 * @rx_ptype: the packet type decoded by hardware

 *

 * This function checks the ring, descriptor, and packet information in

 * order to populate the hash, checksum, VLAN, protocol, and

 * other fields within the skb.

 modifies the skb - consumes the enet header */

/**

 * iavf_cleanup_headers - Correct empty headers

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @skb: pointer to current skb being fixed

 *

 * Also address the case where we are pulling data in on pages only

 * and as such no data is present in the skb header.

 *

 * In addition if skb is not at least 60 bytes we need to pad it so that

 * it is large enough to qualify as a valid Ethernet frame.

 *

 * Returns true if an error was encountered and skb was freed.

 if eth_skb_pad returns an error the skb was freed */

/**

 * iavf_reuse_rx_page - page flip buffer and store it back on the ring

 * @rx_ring: rx descriptor ring to store buffers on

 * @old_buff: donor buffer to have page reused

 *

 * Synchronizes page for reuse by the adapter

 update, and store next to alloc */

 transfer page from old buffer to new buffer */

/**

 * iavf_can_reuse_rx_page - Determine if this page can be reused by

 * the adapter for another receive

 *

 * @rx_buffer: buffer containing the page

 *

 * If page is reusable, rx_buffer->page_offset is adjusted to point to

 * an unused region in the page.

 *

 * For small pages, @truesize will be a constant value, half the size

 * of the memory at page.  We'll attempt to alternate between high and

 * low halves of the page, with one half ready for use by the hardware

 * and the other half being consumed by the stack.  We use the page

 * ref count to determine whether the stack has finished consuming the

 * portion of this page that was passed up with a previous packet.  If

 * the page ref count is >1, we'll assume the "other" half page is

 * still busy, and this page cannot be reused.

 *

 * For larger pages, @truesize will be the actual space used by the

 * received packet (adjusted upward to an even multiple of the cache

 * line size).  This will advance through the page by the amount

 * actually consumed by the received packets while there is still

 * space for a buffer.  Each region of larger pages will be used at

 * most once, after which the page will not be reused.

 *

 * In either case, if the page is reusable its refcount is increased.

 Is any reuse possible? */

 if we are only owner of page we can reuse it */

	/* If we have drained the page fragment pool we need to update

	 * the pagecnt_bias and page count so that we fully restock the

	 * number of references the driver holds.

/**

 * iavf_add_rx_frag - Add contents of Rx buffer to sk_buff

 * @rx_ring: rx descriptor ring to transact packets on

 * @rx_buffer: buffer containing page to add

 * @skb: sk_buff to place the data into

 * @size: packet length from rx_desc

 *

 * This function will add the data contained in rx_buffer->page to the skb.

 * It will just attach the page as a frag to the skb.

 *

 * The function will then update the page offset.

 page is being used so we must update the page offset */

/**

 * iavf_get_rx_buffer - Fetch Rx buffer and synchronize data for use

 * @rx_ring: rx descriptor ring to transact packets on

 * @size: size of buffer to add to skb

 *

 * This function will pull an Rx buffer from the ring and synchronize it

 * for use by the CPU.

 we are reusing so sync this buffer for CPU use */

 We have pulled a buffer for use, so decrement pagecnt_bias */

/**

 * iavf_construct_skb - Allocate skb and populate it

 * @rx_ring: rx descriptor ring to transact packets on

 * @rx_buffer: rx buffer to pull data from

 * @size: size of buffer to add to skb

 *

 * This function allocates an skb.  It then populates it with the page

 * data from the current receive descriptor, taking care to set up the

 * skb correctly.

 prefetch first cache line of first page */

 allocate a skb to store the frags */

 Determine available headroom for copy */

 align pull length to size of long to optimize memcpy performance */

 update all of the pointers */

 buffer is used by skb, update page_offset */

 buffer is unused, reset bias back to rx_buffer */

/**

 * iavf_build_skb - Build skb around an existing buffer

 * @rx_ring: Rx descriptor ring to transact packets on

 * @rx_buffer: Rx buffer to pull data from

 * @size: size of buffer to add to skb

 *

 * This function builds an skb around an existing Rx buffer, taking care

 * to set up the skb correctly and avoid any memcpy overhead.

 prefetch first cache line of first page */

 build an skb around the page buffer */

 update pointers within the skb to store the data */

 buffer is used by skb, update page_offset */

/**

 * iavf_put_rx_buffer - Clean up used buffer and either recycle or free

 * @rx_ring: rx descriptor ring to transact packets on

 * @rx_buffer: rx buffer to pull data from

 *

 * This function will clean up the contents of the rx_buffer.  It will

 * either recycle the buffer or unmap it and free the associated resources.

 hand second half of page back to the ring */

 we are not reusing the buffer so unmap it */

 clear contents of buffer_info */

/**

 * iavf_is_non_eop - process handling of non-EOP buffers

 * @rx_ring: Rx ring being processed

 * @rx_desc: Rx descriptor for current buffer

 * @skb: Current socket buffer containing buffer in progress

 *

 * This function updates next to clean.  If the buffer is an EOP buffer

 * this function exits returning false, otherwise it will place the

 * sk_buff in the next buffer to be chained and return true indicating

 * that this is in fact a non-EOP buffer.

 fetch, update, and store next to clean */

 if we are the last buffer then there is nothing else to do */

/**

 * iavf_clean_rx_irq - Clean completed descriptors from Rx ring - bounce buf

 * @rx_ring: rx descriptor ring to transact packets on

 * @budget: Total limit on number of packets to process

 *

 * This function provides a "bounce buffer" approach to Rx interrupt

 * processing.  The advantage to this is that on systems that have

 * expensive overhead for IOMMU access this provides a means of avoiding

 * it by maintaining the mapping of the page to the system.

 *

 * Returns amount of work completed

 return some buffers to hardware, one at a time is too slow */

		/* status_error_len will always be zero for unused descriptors

		 * because it's cleared in cleanup, and overlaps with hdr_addr

		 * which is always zero because packet split isn't used, if the

		 * hardware wrote DD then the length will be non-zero

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we have

		 * verified the descriptor has been written back.

 retrieve a buffer from the ring */

 exit if we failed to retrieve a buffer */

		/* ERR_MASK will only have valid bits if EOP set, and

		 * what we are doing here is actually checking

		 * IAVF_RX_DESC_ERROR_RXE_SHIFT, since it is the zeroth bit in

		 * the error field

 probably a little skewed due to removing CRC */

 populate checksum, VLAN, and protocol */

 update budget accounting */

 guarantee a trip back through this routine if there was a failure */

	/* We don't bother with setting the CLEARPBA bit as the data sheet

	 * points out doing so is "meaningless since it was already

	 * auto-cleared". The auto-clearing happens when the interrupt is

	 * asserted.

	 *

	 * Hardware errata 28 for also indicates that writing to a

	 * xxINT_DYN_CTLx CSR with INTENA_MSK (bit 31) set to 0 will clear

	 * an event in the PBA anyway so we need to rely on the automask

	 * to hold pending events for us until the interrupt is re-enabled

	 *

	 * The itr value is reported in microseconds, and the register

	 * value is recorded in 2 microsecond units. For this reason we

	 * only need to shift by the interval shift - 1 instead of the

	 * full value.

 a small macro to shorten up some long lines */

/* The act of updating the ITR will cause it to immediately trigger. In order

 * to prevent this from throwing off adaptive update statistics we defer the

 * update so that it can only happen so often. So after either Tx or Rx are

 * updated we make the adaptive scheme wait until either the ITR completely

 * expires via the next_update expiration or we have been through at least

 * 3 interrupts.

/**

 * iavf_update_enable_itr - Update itr and re-enable MSIX interrupt

 * @vsi: the VSI we care about

 * @q_vector: q_vector for which itr is being updated and interrupt enabled

 *

 These will do nothing if dynamic updates are not enabled */

	/* This block of logic allows us to get away with only updating

	 * one ITR value with each interrupt. The idea is to perform a

	 * pseudo-lazy update with the following criteria.

	 *

	 * 1. Rx is given higher priority than Tx if both are in same state

	 * 2. If we must reduce an ITR that is given highest priority.

	 * 3. We then give priority to increasing ITR based on amount.

 Rx ITR needs to be reduced, this is highest priority */

		/* Tx ITR needs to be reduced, this is second priority

		 * Tx ITR needs to be increased more than Rx, fourth priority

 Rx ITR needs to be increased, third priority */

 No ITR update, lowest priority */

/**

 * iavf_napi_poll - NAPI polling Rx/Tx cleanup routine

 * @napi: napi struct with our devices info in it

 * @budget: amount of work driver is allowed to do this pass, in packets

 *

 * This function will clean all queues associated with a q_vector.

 *

 * Returns the amount of work done

	/* Since the actual Tx work is minimal, we can give the Tx a larger

	 * budget and be more aggressive about cleaning up the Tx descriptors.

 Handle case where we are called by netpoll with a budget of 0 */

	/* We attempt to distribute budget to each Rx queue fairly, but don't

	 * allow the budget to go below 1 because that would exit polling early.

 if we clean as many as budgeted, we must not be done */

 If work not completed, return budget and polling will return */

		/* It is possible that the interrupt affinity has changed but,

		 * if the cpu is pegged at 100%, polling will never exit while

		 * traffic continues and the interrupt will be stuck on this

		 * cpu.  We check to make sure affinity is correct before we

		 * continue to poll, otherwise we must stop polling so the

		 * interrupt can move to the correct cpu.

 Tell napi that we are done polling */

 Force an interrupt */

 Return budget-1 so that polling stops */

	/* Exit the polling mode, but don't re-enable interrupts if stack might

	 * poll us due to busy-polling

/**

 * iavf_tx_prepare_vlan_flags - prepare generic TX VLAN tagging flags for HW

 * @skb:     send buffer

 * @tx_ring: ring to send buffer on

 * @flags:   the tx flags to be set

 *

 * Checks the skb and set up correspondingly several generic transmit flags

 * related to VLAN tagging for the HW, such as VLAN, DCB, etc.

 *

 * Returns error code indicate the frame should be dropped upon error and the

 * otherwise  returns 0 to indicate the flags has been set properly.

		/* When HW VLAN acceleration is turned off by the user the

		 * stack sets the protocol to 8021q so that the driver

		 * can take any steps required to support the SW only

		 * VLAN handling.  In our case the driver doesn't need

		 * to take any further steps so just set the protocol

		 * to the encapsulated ethertype.

 if we have a HW VLAN tag being added, default to the HW one */

 else if it is a SW VLAN, check the next protocol and store the tag */

/**

 * iavf_tso - set up the tso context descriptor

 * @first:    pointer to first Tx buffer for xmit

 * @hdr_len:  ptr to the size of the packet header

 * @cd_type_cmd_tso_mss: Quad Word 1

 *

 * Returns 0 if no TSO can happen, 1 if tso is going, or error

 initialize outer IP header fields */

 determine offset of outer transport header */

 remove payload length from outer checksum */

 reset pointers to inner headers */

 initialize inner IP header fields */

 determine offset of inner transport header */

 remove payload length from inner checksum */

 compute length of UDP segmentation header */

 compute length of TCP segmentation header */

 pull values out of skb_shinfo */

 update GSO size and bytecount with header size */

 find the field values */

/**

 * iavf_tx_enable_csum - Enable Tx checksum offloads

 * @skb: send buffer

 * @tx_flags: pointer to Tx flags currently set

 * @td_cmd: Tx descriptor command bits to set

 * @td_offset: Tx descriptor header offsets to set

 * @tx_ring: Tx descriptor ring

 * @cd_tunneling: ptr to context desc bits

 compute outer L2 header size */

 define outer network header type */

 define outer transport */

 compute outer L3 header size */

 switch IP header pointer from outer to inner header */

 compute tunnel header size */

 indicate if we need to offload outer UDP header */

 record tunnel offload values */

 switch L4 header pointer from outer to inner */

 reset type as we transition from outer to inner headers */

 Enable IP checksum offloads */

		/* the stack computes the IP header already, the only time we

		 * need the hardware to recompute it is in the case of TSO.

 compute inner L3 header size */

 Enable L4 checksum offloads */

 enable checksum offloads */

 enable SCTP checksum offload */

 enable UDP checksum offload */

/**

 * iavf_create_tx_ctx - Build the Tx context descriptor

 * @tx_ring:  ring to create the descriptor on

 * @cd_type_cmd_tso_mss: Quad Word 1

 * @cd_tunneling: Quad Word 0 - bits 0-31

 * @cd_l2tag2: Quad Word 0 - bits 32-63

 grab the next descriptor */

 cpu_to_le32 and assign to struct fields */

/**

 * __iavf_chk_linearize - Check if there are more than 8 buffers per packet

 * @skb:      send buffer

 *

 * Note: Our HW can't DMA more than 8 buffers to build a packet on the wire

 * and so we need to figure out the cases where we need to linearize the skb.

 *

 * For TSO we need to count the TSO header and segment payload separately.

 * As such we need to check cases where we have 7 fragments or more as we

 * can potentially require 9 DMA transactions, 1 for the TSO header, 1 for

 * the segment payload in the first descriptor, and another 7 for the

 * fragments.

 no need to check if number of frags is less than 7 */

	/* We need to walk through the list and validate that each group

	 * of 6 fragments totals at least gso_size.

	/* Initialize size to the negative value of gso_size minus 1.  We

	 * use this as the worst case scenerio in which the frag ahead

	 * of us only provides one byte which is why we are limited to 6

	 * descriptors for a single transmit as the header and previous

	 * fragment are already consuming 2 descriptors.

 Add size of frags 0 through 4 to create our initial sum */

	/* Walk through fragments adding latest fragment, testing it, and

	 * then removing stale fragments from the sum.

		/* The stale fragment may present us with a smaller

		 * descriptor than the actual fragment size. To account

		 * for that we need to remove all the data on the front and

		 * figure out what the remainder would be in the last

		 * descriptor associated with the fragment.

 if sum is negative we failed to make sufficient progress */

/**

 * __iavf_maybe_stop_tx - 2nd level check for tx stop conditions

 * @tx_ring: the ring to be checked

 * @size:    the size buffer we want to assure is available

 *

 * Returns -EBUSY if a stop is needed, else 0

 Memory barrier before checking head and tail */

 Check again in a case another CPU has just made room available. */

 A reprieve! - use start_queue because it doesn't call schedule */

/**

 * iavf_tx_map - Build the Tx descriptor

 * @tx_ring:  ring to send buffer on

 * @skb:      send buffer

 * @first:    first buffer info buffer to use

 * @tx_flags: collected send information

 * @hdr_len:  size of the packet header

 * @td_cmd:   the command field in the descriptor

 * @td_offset: offset for checksum or crc

 record length, and DMA address */

 align size to end of page */

 write last descriptor with RS and EOP bits */

	/* Force memory writes to complete before letting h/w know there

	 * are new descriptors to fetch.

	 *

	 * We also use this memory barrier to make certain all of the

	 * status bits have been updated before next_to_watch is written.

 set next_to_watch value indicating a packet is present */

 notify HW of packet */

 clear dma mappings for failed tx_bi map */

/**

 * iavf_xmit_frame_ring - Sends buffer on Tx ring

 * @skb:     send buffer

 * @tx_ring: ring to send buffer on

 *

 * Returns NETDEV_TX_OK if sent, else an error code

 prefetch the data, we'll need it later */

	/* need: 1 descriptor per page * PAGE_SIZE/IAVF_MAX_DATA_PER_TXD,

	 *       + 1 desc for skb_head_len/IAVF_MAX_DATA_PER_TXD,

	 *       + 4 desc gap to avoid the cache line where head is,

	 *       + 1 desc for context descriptor,

	 * otherwise try next time

 record the location of the first descriptor for this packet */

 prepare the xmit flags */

 obtain protocol of skb */

 setup IPv4/IPv6 offloads */

 Always offload the checksum, since it's in the data descriptor */

 always enable CRC insertion offload */

/**

 * iavf_xmit_frame - Selects the correct VSI and Tx queue to send buffer

 * @skb:    send buffer

 * @netdev: network interface device structure

 *

 * Returns NETDEV_TX_OK if sent, else an error code

	/* hardware can't handle really short frames, hardware padding works

	 * beyond this point

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 * iavf_client_get_params - retrieve relevant client parameters

 * @vsi: VSI with parameters

 * @params: client param struct

/**

 * iavf_notify_client_message - call the client message receive callback

 * @vsi: the VSI associated with this client

 * @msg: message buffer

 * @len: length of message

 *

 * If there is a client to this VSI, call the client

/**

 * iavf_notify_client_l2_params - call the client notify callback

 * @vsi: the VSI with l2 param changes

 *

 * If there is a client to this VSI, call the client

/**

 * iavf_notify_client_open - call the client open callback

 * @vsi: the VSI with netdev opened

 *

 * If there is a client to this netdev, call the client with open

/**

 * iavf_client_release_qvlist - send a message to the PF to release iwarp qv map

 * @ldev: pointer to L2 context.

 *

 * Return 0 on success or < 0 on error

/**

 * iavf_notify_client_close - call the client close callback

 * @vsi: the VSI with netdev closed

 * @reset: true when close called due to reset pending

 *

 * If there is a client to this netdev, call the client with close

/**

 * iavf_client_add_instance - add a client instance to the instance list

 * @adapter: pointer to the board struct

 *

 * Returns cinst ptr on success, NULL on failure

/**

 * iavf_client_del_instance - removes a client instance from the list

 * @adapter: pointer to the board struct

 *

/**

 * iavf_client_subtask - client maintenance work

 * @adapter: board private structure

 first check client is registered */

 Add the client instance to the instance list */

 Send an Open request to the client */

 remove client instance */

/**

 * iavf_lan_add_device - add a lan device struct to the list of lan devices

 * @adapter: pointer to the board struct

 *

 * Returns 0 on success or none 0 on error

	/* Since in some cases register may have happened before a device gets

	 * added, we can schedule a subtask to go initiate the clients.

/**

 * iavf_lan_del_device - removes a lan device from the device list

 * @adapter: pointer to the board struct

 *

 * Returns 0 on success or non-0 on error

/**

 * iavf_client_release - release client specific resources

 * @client: pointer to the registered client

 *

 delete the client instance */

/**

 * iavf_client_prepare - prepare client specific resources

 * @client: pointer to the registered client

 *

 Signal the watchdog to service the client */

/**

 * iavf_client_virtchnl_send - send a message to the PF instance

 * @ldev: pointer to L2 context.

 * @client: Client pointer.

 * @msg: pointer to message buffer

 * @len: message length

 *

 * Return 0 on success or < 0 on error

/**

 * iavf_client_setup_qvlist - send a message to the PF to setup iwarp qv map

 * @ldev: pointer to L2 context.

 * @client: Client pointer.

 * @qvlist_info: queue and vector list

 *

 * Return 0 on success or < 0 on error

 A quick check on whether the vectors belong to the client */

/**

 * iavf_register_client - Register a iavf client driver with the L2 driver

 * @client: pointer to the iavf_client struct

 *

 * Returns 0 on success or non-0 on error

/**

 * iavf_unregister_client - Unregister a iavf client driver with the L2 driver

 * @client: pointer to the iavf_client struct

 *

 * Returns 0 on success or non-0 on error

	/* When a unregister request comes through we would have to send

	 * a close for each of the client instances that were opened.

	 * client_release function is called to handle this.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/* All iavf tracepoints are defined by the include below, which must

 * be included exactly once across the whole kernel with

 * CREATE_TRACE_POINTS defined

/* iavf_pci_tbl - PCI Device ID Table

 *

 * Wildcard entries (PCI_ANY_ID) should come last

 * Last entry must be all 0s

 *

 * { Vendor ID, Device ID, SubVendor ID, SubDevice ID,

 *   Class, Class Mask, private data (not used) }

 required last entry */

/**

 * iavf_pdev_to_adapter - go from pci_dev to adapter

 * @pdev: pci_dev pointer

/**

 * iavf_allocate_dma_mem_d - OS specific memory alloc for shared code

 * @hw:   pointer to the HW structure

 * @mem:  ptr to mem struct to fill out

 * @size: size of memory requested

 * @alignment: what to align the allocation to

/**

 * iavf_free_dma_mem_d - OS specific memory free for shared code

 * @hw:   pointer to the HW structure

 * @mem:  ptr to mem struct to free

/**

 * iavf_allocate_virt_mem_d - OS specific memory alloc for shared code

 * @hw:   pointer to the HW structure

 * @mem:  ptr to mem struct to fill out

 * @size: size of memory requested

/**

 * iavf_free_virt_mem_d - OS specific memory free for shared code

 * @hw:   pointer to the HW structure

 * @mem:  ptr to mem struct to free

 it's ok to kfree a NULL pointer */

/**

 * iavf_lock_timeout - try to lock mutex but give up after timeout

 * @lock: mutex that should be locked

 * @msecs: timeout in msecs

 *

 * Returns 0 on success, negative on failure

/**

 * iavf_schedule_reset - Set the flags and schedule a reset event

 * @adapter: board private structure

/**

 * iavf_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: queue number that is timing out

/**

 * iavf_misc_irq_disable - Mask off interrupt generation on the NIC

 * @adapter: board private structure

/**

 * iavf_misc_irq_enable - Enable default interrupt generation settings

 * @adapter: board private structure

/**

 * iavf_irq_disable - Mask off interrupt generation on the NIC

 * @adapter: board private structure

/**

 * iavf_irq_enable_queues - Enable interrupt for specified queues

 * @adapter: board private structure

 * @mask: bitmap of queues to enable

/**

 * iavf_irq_enable - Enable default interrupt generation settings

 * @adapter: board private structure

 * @flush: boolean value whether to run rd32()

/**

 * iavf_msix_aq - Interrupt handler for vector 0

 * @irq: interrupt number

 * @data: pointer to netdev

 handle non-queue interrupts, these reads clear the registers */

 schedule work on the private workqueue */

/**

 * iavf_msix_clean_rings - MSIX mode Interrupt Handler

 * @irq: interrupt number

 * @data: pointer to a q_vector

/**

 * iavf_map_vector_to_rxq - associate irqs with rx queues

 * @adapter: board private structure

 * @v_idx: interrupt number

 * @r_idx: queue number

/**

 * iavf_map_vector_to_txq - associate irqs with tx queues

 * @adapter: board private structure

 * @v_idx: interrupt number

 * @t_idx: queue number

/**

 * iavf_map_rings_to_vectors - Maps descriptor rings to vectors

 * @adapter: board private structure to initialize

 *

 * This function maps descriptor rings to the queue-specific vectors

 * we were allotted through the MSI-X enabling code.  Ideally, we'd have

 * one vector per ring/queue, but on a constrained vector budget, we

 * group the rings as "efficiently" as possible.  You would add new

 * mapping configurations in here.

		/* In the case where we have more queues than vectors, continue

		 * round-robin on vectors until all queues are mapped.

/**

 * iavf_irq_affinity_notify - Callback for affinity changes

 * @notify: context as to what irq was changed

 * @mask: the new affinity mask

 *

 * This is a callback function used by the irq_set_affinity_notifier function

 * so that we may register to receive changes to the irq affinity masks.

/**

 * iavf_irq_affinity_release - Callback for affinity notifier release

 * @ref: internal core kernel usage

 *

 * This is a callback function used by the irq_set_affinity_notifier function

 * to inform the current notification subscriber that they will no longer

 * receive notifications.

/**

 * iavf_request_traffic_irqs - Initialize MSI-X interrupts

 * @adapter: board private structure

 * @basename: device basename

 *

 * Allocates MSI-X vectors for tx and rx handling, and requests

 * interrupts from the kernel.

 Decrement for Other and TCP Timer vectors */

 skip this unused q_vector */

 register for affinity change notifications */

		/* Spread the IRQ affinity hints across online CPUs. Note that

		 * get_cpu_mask returns a mask with a permanent lifetime so

		 * it's safe to use as a hint for irq_set_affinity_hint.

/**

 * iavf_request_misc_irq - Initialize MSI-X interrupts

 * @adapter: board private structure

 *

 * Allocates MSI-X vector 0 and requests interrupts from the kernel. This

 * vector is only for the admin queue, and stays active even when the netdev

 * is closed.

/**

 * iavf_free_traffic_irqs - Free MSI-X interrupts

 * @adapter: board private structure

 *

 * Frees all MSI-X vectors other than 0.

/**

 * iavf_free_misc_irq - Free MSI-X miscellaneous vector

 * @adapter: board private structure

 *

 * Frees MSI-X vector 0.

/**

 * iavf_configure_tx - Configure Transmit Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Tx unit of the MAC after a reset.

/**

 * iavf_configure_rx - Configure Receive Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Rx unit of the MAC after a reset.

 Legacy Rx will always default to a 2048 buffer size. */

		/* For jumbo frames on systems with 4K pages we have to use

		 * an order 1 page, so we might as well increase the size

		 * of our Rx buffer to make better use of the available space

		/* We use a 1536 buffer size for configurations with

		 * standard Ethernet mtu.  On x86 this gives us enough room

		 * for shared info and 192 bytes of padding.

/**

 * iavf_find_vlan - Search filter list for specific vlan filter

 * @adapter: board private structure

 * @vlan: vlan tag

 *

 * Returns ptr to the filter object or NULL. Must be called while holding the

 * mac_vlan_list_lock.

/**

 * iavf_add_vlan - Add a vlan filter to the list

 * @adapter: board private structure

 * @vlan: VLAN tag

 *

 * Returns ptr to the filter object or NULL when no memory available.

/**

 * iavf_del_vlan - Remove a vlan filter from the list

 * @adapter: board private structure

 * @vlan: VLAN tag

/**

 * iavf_restore_filters

 * @adapter: board private structure

 *

 * Restore existing non MAC filters when VF netdev comes back up

 re-add all VLAN filters */

/**

 * iavf_vlan_rx_add_vid - Add a VLAN filter to a device

 * @netdev: network device struct

 * @proto: unused protocol data

 * @vid: VLAN tag

/**

 * iavf_vlan_rx_kill_vid - Remove a VLAN filter from a device

 * @netdev: network device struct

 * @proto: unused protocol data

 * @vid: VLAN tag

/**

 * iavf_find_filter - Search filter list for specific mac filter

 * @adapter: board private structure

 * @macaddr: the MAC address

 *

 * Returns ptr to the filter object or NULL. Must be called while holding the

 * mac_vlan_list_lock.

/**

 * iavf_add_filter - Add a mac filter to the filter list

 * @adapter: board private structure

 * @macaddr: the MAC address

 *

 * Returns ptr to the filter object or NULL when no memory available.

/**

 * iavf_set_mac - NDO callback to set port mac address

 * @netdev: network interface device structure

 * @p: pointer to an address structure

 *

 * Returns 0 on success, negative on failure

/**

 * iavf_addr_sync - Callback for dev_(mc|uc)_sync to add address

 * @netdev: the netdevice

 * @addr: address to add

 *

 * Called by __dev_(mc|uc)_sync when an address needs to be added. We call

 * __dev_(uc|mc)_sync from .set_rx_mode and guarantee to hold the hash lock.

/**

 * iavf_addr_unsync - Callback for dev_(mc|uc)_sync to remove address

 * @netdev: the netdevice

 * @addr: address to add

 *

 * Called by __dev_(mc|uc)_sync when an address needs to be removed. We call

 * __dev_(uc|mc)_sync from .set_rx_mode and guarantee to hold the hash lock.

	/* Under some circumstances, we might receive a request to delete

	 * our own device address from our uc list. Because we store the

	 * device address in the VSI's MAC/VLAN filter list, we need to ignore

	 * such requests and not delete our device address from this list.

/**

 * iavf_set_rx_mode - NDO callback to set the netdev filters

 * @netdev: network interface device structure

/**

 * iavf_napi_enable_all - enable NAPI on all queue vectors

 * @adapter: board private structure

/**

 * iavf_napi_disable_all - disable NAPI on all queue vectors

 * @adapter: board private structure

/**

 * iavf_configure - set up transmit and receive data structures

 * @adapter: board private structure

/**

 * iavf_up_complete - Finish the last steps of bringing up a connection

 * @adapter: board private structure

 *

 * Expects to be called while holding the __IAVF_IN_CRITICAL_TASK bit lock.

/**

 * iavf_down - Shutdown the connection processing

 * @adapter: board private structure

 *

 * Expects to be called while holding the __IAVF_IN_CRITICAL_TASK bit lock.

 clear the sync flag on all filters */

 remove all MAC filters */

 remove all VLAN filters */

 remove all cloud filters */

 remove all Flow Director filters */

 remove all advance RSS configuration */

 cancel any current operation */

		/* Schedule operations to close down the HW. Don't wait

		 * here for this to complete. The watchdog is still running

		 * and it will take care of this.

/**

 * iavf_acquire_msix_vectors - Setup the MSIX capability

 * @adapter: board private structure

 * @vectors: number of vectors to request

 *

 * Work with the OS to set up the MSIX vectors needed.

 *

 * Returns 0 on success, negative on failure

	/* We'll want at least 3 (vector_threshold):

	 * 0) Other (Admin Queue and link, mostly)

	 * 1) TxQ[0] Cleanup

	 * 2) RxQ[0] Cleanup

	/* The more we get, the more we will assign to Tx/Rx Cleanup

	 * for the separate queues...where Rx Cleanup >= Tx Cleanup.

	 * Right now, we simply care about how many we'll get; we'll

	 * set them up later while requesting irq's.

	/* Adjust for only the vectors we'll use, which is minimum

	 * of max_msix_q_vectors + NONQ_VECS, or the number of

	 * vectors we were allocated.

/**

 * iavf_free_queues - Free memory for all rings

 * @adapter: board private structure to initialize

 *

 * Free all of the memory associated with queue pairs.

/**

 * iavf_alloc_queues - Allocate memory for all rings

 * @adapter: board private structure to initialize

 *

 * We allocate one ring per queue at run-time since we don't know the

 * number of queues at compile-time.  The polling_netdev array is

 * intended for Multiqueue, but should work fine with a single queue.

	/* If we're in reset reallocating queues we don't actually know yet for

	 * certain the PF gave us the number of queues we asked for but we'll

	 * assume it did.  Once basic reset is finished we'll confirm once we

	 * start negotiating config with PF.

/**

 * iavf_set_interrupt_capability - set MSI-X or FAIL if not supported

 * @adapter: board private structure to initialize

 *

 * Attempt to configure the interrupts using the best available

 * capabilities of the hardware and the kernel.

	/* It's easy to be greedy for MSI-X vectors, but it really doesn't do

	 * us much good if we have more vectors than CPUs. However, we already

	 * limit the total number of queues by the number of CPUs so we do not

	 * need any further limiting here.

/**

 * iavf_config_rss_aq - Configure RSS keys and lut by using AQ commands

 * @adapter: board private structure

 *

 * Return 0 on success, negative on failure

 bail because we already have a command pending */

/**

 * iavf_config_rss_reg - Configure RSS keys and lut by writing registers

 * @adapter: board private structure

 *

 * Returns 0 on success, negative on failure

/**

 * iavf_config_rss - Configure RSS keys and lut

 * @adapter: board private structure

 *

 * Returns 0 on success, negative on failure

/**

 * iavf_fill_rss_lut - Fill the lut with default values

 * @adapter: board private structure

/**

 * iavf_init_rss - Prepare for RSS

 * @adapter: board private structure

 *

 * Return 0 on success, negative on failure

 Enable PCTYPES for RSS, TCP/UDP with IPv4/IPv6 */

/**

 * iavf_alloc_q_vectors - Allocate memory for interrupt vectors

 * @adapter: board private structure to initialize

 *

 * We allocate one q_vector per queue interrupt.  If allocation fails we

 * return -ENOMEM.

/**

 * iavf_free_q_vectors - Free memory allocated for interrupt vectors

 * @adapter: board private structure to initialize

 *

 * This function frees the memory allocated to the q_vectors.  In addition if

 * NAPI is enabled it will delete any references to the NAPI struct prior

 * to freeing the q_vector.

/**

 * iavf_reset_interrupt_capability - Reset MSIX setup

 * @adapter: board private structure

 *

/**

 * iavf_init_interrupt_scheme - Determine if MSIX is supported and init

 * @adapter: board private structure to initialize

 *

	/* If we've made it so far while ADq flag being ON, then we haven't

	 * bailed out anywhere in middle. And ADq isn't just enabled but actual

	 * resources have been allocated in the reset path.

	 * Now we can truly claim that ADq is enabled.

/**

 * iavf_free_rss - Free memory used by RSS structs

 * @adapter: board private structure

/**

 * iavf_reinit_interrupt_scheme - Reallocate queues and vectors

 * @adapter: board private structure

 *

 * Returns 0 on success, negative on failure

/**

 * iavf_process_aq_command - process aq_required flags

 * and sends aq command

 * @adapter: pointer to iavf adapter structure

 *

 * Returns 0 on success

 * Returns error code if no command was sent

 * or error code if the command failed.

		/* This message goes straight to the firmware, not the

		 * PF, so we don't have to set current_op as we will

		 * not get a response through the ARQ.

/**

 * iavf_startup - first step of driver startup

 * @adapter: board private structure

 *

 * Function process __IAVF_STARTUP driver state.

 * When success the state is changed to __IAVF_INIT_VERSION_CHECK

 * when fails the state is changed to __IAVF_INIT_FAILED

 driver loaded, probe complete */

/**

 * iavf_init_version_check - second step of driver startup

 * @adapter: board private structure

 *

 * Function process __IAVF_INIT_VERSION_CHECK driver state.

 * When success the state is changed to __IAVF_INIT_GET_RESOURCES

 * when fails the state is changed to __IAVF_INIT_FAILED

 aq msg sent, awaiting reply */

/**

 * iavf_init_get_resources - third step of driver startup

 * @adapter: board private structure

 *

 * Function process __IAVF_INIT_GET_RESOURCES driver state and

 * finishes driver initialization procedure.

 * When success the state is changed to __IAVF_DOWN

 * when fails the state is changed to __IAVF_INIT_FAILED

 aq msg sent, awaiting reply */

		/* We only get ERR_PARAM if the device is in a very bad

		 * state or if we've been disabled for previous bad

		 * behavior. Either way, we're done now.

 MTU range: 68 - 9710 */

	/* set the semaphore to prevent any callbacks after device registration

	 * up to time when state of driver will be set to __IAVF_DOWN

/**

 * iavf_watchdog_task - Periodic call-back task

 * @work: pointer to work_struct

 Try again from failed step*/

 A chance for redemption! */

			/* When init task contacts the PF and

			 * gets everything set up again, it'll restart the

			 * watchdog for us. Down, boy. Sit. Stay. Woof.

			/* An error will be returned if no commands were

			 * processed; use this opportunity to update stats

 check for hw reset */

	/* We don't use netif_running() because it may be true prior to

	 * ndo_open() returning, so we can't assume it means all our open

	 * tasks have finished, since we're not holding the rtnl_lock here.

 Delete all of the filters */

/**

 * iavf_reset_task - Call-back task to handle hardware reset

 * @work: pointer to work_struct

 *

 * During reset we need to shut down and reinitialize the admin queue

 * before we can use it to communicate with the PF again. We also clear

 * and reinit the rings because that context is lost as well.

	/* When device is being removed it doesn't make sense to run the reset

	 * task, just return in such a case.

		/* Restart the AQ here. If we have been reset but didn't

		 * detect it, or if the PF had to reinit, our AQ will be hosed.

 poll until we see the reset actually happen */

 act like the reset happened */

 wait until the reset is complete and the PF is responding to us */

 sleep first to make sure a minimum wait time is met */

 Do not attempt to reinit. It's dead, Jim. */

	/* We don't use netif_running() because it may be true prior to

	 * ndo_open() returning, so we can't assume it means all our open

	 * tasks have finished, since we're not holding the rtnl_lock here.

	/* free the Tx/Rx rings and descriptors, might be better to just

	 * re-use them sometime in the future

 kill and reinit the admin queue */

	/* Delete filter for the current MAC address, it could have

	 * been changed by the PF via administratively set MAC.

	 * Will be re-added via VIRTCHNL_OP_GET_VF_RESOURCES.

 re-add all MAC filters */

 re-add all VLAN filters */

 check if TCs are running and re-add all cloud filters */

	/* We were running when the reset started, so we need to restore some

	 * state here.

 allocate transmit descriptors */

 allocate receive descriptors */

		/* iavf_up_complete() will switch device back

		 * to __IAVF_RUNNING

/**

 * iavf_adminq_task - worker thread to clean the admin queue

 * @work: pointer to work_struct containing our data

 No event to process or error cleaning ARQ */

 check for error indications */

 device in reset */

 re-enable Admin queue interrupt cause */

/**

 * iavf_client_task - worker thread to perform client work

 * @work: pointer to work_struct containing our data

 *

 * This task handles client interactions. Because client calls can be

 * reentrant, we can't handle them in the watchdog.

	/* If we can't get the client bit, just give up. We'll be rescheduled

	 * later.

/**

 * iavf_free_all_tx_resources - Free Tx Resources for All Queues

 * @adapter: board private structure

 *

 * Free all transmit software resources

/**

 * iavf_setup_all_tx_resources - allocate all queues Tx resources

 * @adapter: board private structure

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

/**

 * iavf_setup_all_rx_resources - allocate all queues Rx resources

 * @adapter: board private structure

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

/**

 * iavf_free_all_rx_resources - Free Rx Resources for All Queues

 * @adapter: board private structure

 *

 * Free all receive software resources

/**

 * iavf_validate_tx_bandwidth - validate the max Tx bandwidth

 * @adapter: board private structure

 * @max_tx_rate: max Tx bw for a tc

/**

 * iavf_validate_ch_config - validate queue mapping info

 * @adapter: board private structure

 * @mqprio_qopt: queue parameters

 *

 * This function validates if the config provided by the user to

 * configure queue channels is valid or not. Returns 0 on a valid

 * config.

convert to Mbps */

/**

 * iavf_del_all_cloud_filters - delete all cloud filters on the traffic classes

 * @adapter: board private structure

/**

 * __iavf_setup_tc - configure multiple traffic classes

 * @netdev: network interface device structure

 * @type_data: tc offload data

 *

 * This function processes the config information provided by the

 * user to configure traffic classes/queue channels and packages the

 * information to request the PF to setup traffic classes.

 *

 * Returns 0 on success.

 delete queue_channel */

 reset the tc configuration */

 add queue channel */

 Return if same TC config is requested */

 convert to Mbps */

 Report the tc mapping up the stack */

/**

 * iavf_parse_cls_flower - Parse tc flower filters provided by kernel

 * @adapter: board private structure

 * @f: pointer to struct flow_cls_offload

 * @filter: pointer to cloud filter structure

 specify flow type as TCP IPv6 */

 use is_broadcast and is_zero to check for all 0xf or 0 */

 set the mask if a valid dst_mac address */

 set the mask if a valid dst_mac address */

 validate mask, make sure it is not IPV6_ADDR_ANY */

		/* src and dest IPv6 address should not be LOOPBACK

		 * (0:0:0:0:0:0:0:1) which can be represented as ::1

/**

 * iavf_handle_tclass - Forward to a traffic class on the device

 * @adapter: board private structure

 * @tc: traffic class index on the device

 * @filter: pointer to cloud filter structure

 redirect to a traffic class on the same device */

/**

 * iavf_configure_clsflower - Add tc flower filters

 * @adapter: board private structure

 * @cls_flower: Pointer to struct flow_cls_offload

 set the mask to all zeroes to begin with */

 start out with flow type and eth type IPv4 to begin with */

 add filter to the list */

/* iavf_find_cf - Find the cloud filter in the list

 * @adapter: Board private structure

 * @cookie: filter specific cookie

 *

 * Returns ptr to the filter object or NULL. Must be called while holding the

 * cloud_filter_list_lock.

/**

 * iavf_delete_clsflower - Remove tc flower filters

 * @adapter: board private structure

 * @cls_flower: Pointer to struct flow_cls_offload

/**

 * iavf_setup_tc_cls_flower - flower classifier offloads

 * @adapter: board private structure

 * @cls_flower: pointer to flow_cls_offload struct with flow info

/**

 * iavf_setup_tc_block_cb - block callback for tc

 * @type: type of offload

 * @type_data: offload data

 * @cb_priv:

 *

 * This function is the block callback for traffic classes

/**

 * iavf_setup_tc - configure multiple traffic classes

 * @netdev: network interface device structure

 * @type: type of offload

 * @type_data: tc offload data

 *

 * This function is the callback to ndo_setup_tc in the

 * netdev_ops.

 *

 * Returns 0 on success

/**

 * iavf_open - Called when a network interface is made active

 * @netdev: network interface device structure

 *

 * Returns 0 on success, negative value on failure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP).  At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the watchdog is started,

 * and the stack is notified that the interface is ready.

 allocate transmit descriptors */

 allocate receive descriptors */

 clear any pending interrupts, may auto mask */

 Restore VLAN filters that were removed with IFF_DOWN */

/**

 * iavf_close - Disables a network interface

 * @netdev: network interface device structure

 *

 * Returns 0, this is not allowed to fail

 *

 * The close entry point is called when an interface is de-activated

 * by the OS.  The hardware is still under the drivers control, but

 * needs to be disabled. All IRQs except vector 0 (reserved for admin queue)

 * are freed, along with all transmit and receive resources.

	/* We explicitly don't free resources here because the hardware is

	 * still active and can DMA into memory. Resources are cleared in

	 * iavf_virtchnl_completion() after we get confirmation from the PF

	 * driver that the rings have been stopped.

	 *

	 * Also, we wait for state to transition to __IAVF_DOWN before

	 * returning. State change occurs in iavf_virtchnl_completion() after

	 * VF resources are released (which occurs after PF driver processes and

	 * responds to admin queue commands).

/**

 * iavf_change_mtu - Change the Maximum Transfer Unit

 * @netdev: network interface device structure

 * @new_mtu: new value for maximum frame size

 *

 * Returns 0 on success, negative on failure

/**

 * iavf_set_features - set the netdev feature flags

 * @netdev: ptr to the netdev being adjusted

 * @features: the feature set that the stack is suggesting

 * Note: expects to be called while under rtnl_lock()

	/* Don't allow changing VLAN_RX flag when adapter is not capable

	 * of VLAN offload

/**

 * iavf_features_check - Validate encapsulated packet conforms to limits

 * @skb: skb buff

 * @dev: This physical port's netdev

 * @features: Offload features that the stack believes apply

	/* No point in doing any of this if neither checksum nor GSO are

	 * being requested for this frame.  We can rule out both by just

	 * checking for CHECKSUM_PARTIAL

	/* We cannot support GSO if the MSS is going to be less than

	 * 64 bytes.  If it is then we need to drop support for GSO.

 MACLEN can support at most 63 words */

 IPLEN and EIPLEN can support at most 127 dwords */

 L4TUNLEN can support 127 words */

 IPLEN can support at most 127 dwords */

	/* No need to validate L4LEN as TCP is the only protocol with a

	 * a flexible value and we support all possible values supported

	 * by TCP, which is at most 15 dwords

/**

 * iavf_fix_features - fix up the netdev feature bits

 * @netdev: our net device

 * @features: desired feature bits

 *

 * Returns fixed-up features bits

/**

 * iavf_check_reset_complete - check that VF reset is complete

 * @hw: pointer to hw struct

 *

 * Returns 0 if device is ready to use, or -EBUSY if it's in reset.

/**

 * iavf_process_config - Process the config information we got from the PF

 * @adapter: board private structure

 *

 * Verify that we have a valid config struct, and set up our netdev features

 * and our VSI struct.

 got VF config message back from PF, now we can parse it */

		/* Problem.  The PF gave us fewer queues than what we had

		 * negotiated in our request.  Need a reset to see if we can't

		 * get back to a working state.

	/* advertise to stack only if offloads for encapsulated packets is

	 * supported

 record features VLANs can make use of */

	/* Write features and hw_features separately to avoid polluting

	 * with, or dropping, features that are set when we registered.

 Enable VLAN features if supported */

 Enable cloud filter if ADQ is supported */

	/* Do not turn on offloads when they are requested to be turned off.

	 * TSO needs minimum 576 bytes to work correctly.

/**

 * iavf_shutdown - Shutdown the device in preparation for a reboot

 * @pdev: pci device structure

 Prevent the watchdog from running. */

/**

 * iavf_probe - Device Initialization Routine

 * @pdev: PCI device information struct

 * @ent: entry in iavf_pci_tbl

 *

 * Returns 0 on success, negative on failure

 *

 * iavf_probe initializes an adapter identified by a pci_dev structure.

 * The OS initialization, configuring of the adapter private structure,

 * and a hardware reset occur.

 Call save state here because it relies on the adapter struct. */

	/* set up the locks for the AQ, do this only once in probe

	 * and destroy them only once in remove

 Setup the wait queue for indicating transition to down status */

/**

 * iavf_suspend - Power management suspend routine

 * @dev_d: device info pointer

 *

 * Called when the system (VM) is entering sleep/suspend.

/**

 * iavf_resume - Power management resume routine

 * @dev_d: device info pointer

 *

 * Called when the system (VM) is resumed from sleep/suspend.

/**

 * iavf_remove - Device Removal Routine

 * @pdev: PCI device information struct

 *

 * iavf_remove is called by the PCI subsystem to alert the driver

 * that it should release a PCI device.  The could be caused by a

 * Hot-Plug event, or because the driver is going to be removed from

 * memory.

 Indicate we are in remove and not to run reset_task */

 If the FW isn't responding, kick it once, but only once. */

 Shut down all the garbage mashers on the detention level */

	/* In case we enter iavf_remove from erroneous state, free traffic irqs

	 * here, so as to not cause a kernel crash, when calling

	 * iavf_reset_interrupt_capability.

 destroy the locks only once, here */

	/* If we got removed before an up/down sequence, we've got a filter

	 * hanging out there that we need to get rid of.

/**

 * iavf_init_module - Driver Registration Routine

 *

 * iavf_init_module is the first routine called when the driver is

 * loaded. All it does is register with the PCI subsystem.

/**

 * iavf_exit_module - Driver Exit Cleanup Routine

 *

 * iavf_exit_module is called just before the driver is removed

 * from memory.

 iavf_main.c */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

 busy wait delay in msec */

/**

 * iavf_send_pf_msg

 * @adapter: adapter structure

 * @op: virtual channel opcode

 * @msg: pointer to message buffer

 * @len: message length

 *

 * Send message to PF and print status if failure.

 nothing to see here, move along */

/**

 * iavf_send_api_ver

 * @adapter: adapter structure

 *

 * Send API version admin queue message to the PF. The reply is not checked

 * in this function. Returns 0 if the message was successfully

 * sent, or one of the IAVF_ADMIN_QUEUE_ERROR_ statuses if not.

/**

 * iavf_verify_api_ver

 * @adapter: adapter structure

 *

 * Compare API versions with the PF. Must be called after admin queue is

 * initialized. Returns 0 if API versions match, -EIO if they do not,

 * IAVF_ERR_ADMIN_QUEUE_NO_WORK if the admin queue is empty, and any errors

 * from the firmware are propagated.

		/* When the AQ is empty, iavf_clean_arq_element will return

		 * nonzero and this loop will terminate.

/**

 * iavf_send_vf_config_msg

 * @adapter: adapter structure

 *

 * Send VF configuration request admin queue message to the PF. The reply

 * is not checked in this function. Returns 0 if the message was

 * successfully sent, or one of the IAVF_ADMIN_QUEUE_ERROR_ statuses if not.

/**

 * iavf_validate_num_queues

 * @adapter: adapter structure

 *

 * Validate that the number of queues the PF has sent in

 * VIRTCHNL_OP_GET_VF_RESOURCES is not larger than the VF can handle.

/**

 * iavf_get_vf_config

 * @adapter: private adapter structure

 *

 * Get VF configuration from PF and populate hw structure. Must be called after

 * admin queue is initialized. Busy waits until response is received from PF,

 * with maximum timeout. Response from PF is returned in the buffer for further

 * processing by the caller.

		/* When the AQ is empty, iavf_clean_arq_element will return

		 * nonzero and this loop will terminate.

	/* some PFs send more queues than we should have so validate that

	 * we aren't getting too many queues

/**

 * iavf_configure_queues

 * @adapter: adapter structure

 *

 * Request that the PF set up our (previously allocated) queues.

 bail because we already have a command pending */

 Limit maximum frame size when jumbo frames is not enabled */

	/* Size check is not needed here - HW max is 16 queue pairs, and we

	 * can fit info for 31 of them into the AQ buffer before it overflows.

/**

 * iavf_enable_queues

 * @adapter: adapter structure

 *

 * Request that the PF enable all of our queues.

 bail because we already have a command pending */

/**

 * iavf_disable_queues

 * @adapter: adapter structure

 *

 * Request that the PF disable all of our queues.

 bail because we already have a command pending */

/**

 * iavf_map_queues

 * @adapter: adapter structure

 *

 * Request that the PF map queues to interrupt vectors. Misc causes, including

 * admin queue, are always mapped to vector 0.

 bail because we already have a command pending */

 Queue vectors first */

 Misc vector last - this is only for AdminQ messages */

/**

 * iavf_add_ether_addrs

 * @adapter: adapter structure

 *

 * Request that the PF add one or more addresses to our filters.

 bail because we already have a command pending */

/**

 * iavf_del_ether_addrs

 * @adapter: adapter structure

 *

 * Request that the PF remove one or more addresses from our filters.

 bail because we already have a command pending */

/**

 * iavf_mac_add_ok

 * @adapter: adapter structure

 *

 * Submit list of filters based on PF response.

/**

 * iavf_mac_add_reject

 * @adapter: adapter structure

 *

 * Remove filters from list based on PF response.

/**

 * iavf_add_vlans

 * @adapter: adapter structure

 *

 * Request that the PF add one or more VLAN filters to our VSI.

 bail because we already have a command pending */

/**

 * iavf_del_vlans

 * @adapter: adapter structure

 *

 * Request that the PF remove one or more VLAN filters from our VSI.

 bail because we already have a command pending */

/**

 * iavf_set_promiscuous

 * @adapter: adapter structure

 * @flags: bitmask to control unicast/multicast promiscuous.

 *

 * Request that the PF enable promiscuous mode for our VSI.

 bail because we already have a command pending */

/**

 * iavf_request_stats

 * @adapter: adapter structure

 *

 * Request VSI statistics from PF.

 no error message, this isn't crucial */

 queue maps are ignored for this message - only the vsi is used */

 if the request failed, don't lock out others */

/**

 * iavf_get_hena

 * @adapter: adapter structure

 *

 * Request hash enable capabilities from PF

 bail because we already have a command pending */

/**

 * iavf_set_hena

 * @adapter: adapter structure

 *

 * Request the PF to set our RSS hash capabilities

 bail because we already have a command pending */

/**

 * iavf_set_rss_key

 * @adapter: adapter structure

 *

 * Request the PF to set our RSS hash key

 bail because we already have a command pending */

/**

 * iavf_set_rss_lut

 * @adapter: adapter structure

 *

 * Request the PF to set our RSS lookup table

 bail because we already have a command pending */

/**

 * iavf_enable_vlan_stripping

 * @adapter: adapter structure

 *

 * Request VLAN header stripping to be enabled

 bail because we already have a command pending */

/**

 * iavf_disable_vlan_stripping

 * @adapter: adapter structure

 *

 * Request VLAN header stripping to be disabled

 bail because we already have a command pending */

/**

 * iavf_print_link_message - print link up or down

 * @adapter: adapter structure

 *

 * Log a message telling the world of our wonderous link status

 convert to Gbps inline */

/**

 * iavf_get_vpe_link_status

 * @adapter: adapter structure

 * @vpe: virtchnl_pf_event structure

 *

 * Helper function for determining the link status

/**

 * iavf_set_adapter_link_speed_from_vpe

 * @adapter: adapter structure for which we are setting the link speed

 * @vpe: virtchnl_pf_event structure that contains the link speed we are setting

 *

 * Helper function for setting iavf_adapter link speed

/**

 * iavf_enable_channels

 * @adapter: adapter structure

 *

 * Request that the PF enable channels as specified by

 * the user via tc tool.

 bail because we already have a command pending */

/**

 * iavf_disable_channels

 * @adapter: adapter structure

 *

 * Request that the PF disable channels that are configured

 bail because we already have a command pending */

/**

 * iavf_print_cloud_filter

 * @adapter: adapter structure

 * @f: cloud filter to print

 *

 * Print the cloud filter

/**

 * iavf_add_cloud_filter

 * @adapter: adapter structure

 *

 * Request that the PF add cloud filters as specified

 * by the user via tc tool.

 bail because we already have a command pending */

/**

 * iavf_del_cloud_filter

 * @adapter: adapter structure

 *

 * Request that the PF delete cloud filters as specified

 * by the user via tc tool.

 bail because we already have a command pending */

/**

 * iavf_add_fdir_filter

 * @adapter: the VF adapter structure

 *

 * Request that the PF add Flow Director filters as specified

 * by the user via ethtool.

 bail because we already have a command pending */

		/* prevent iavf_add_fdir_filter() from being called when there

		 * are no filters to add

/**

 * iavf_del_fdir_filter

 * @adapter: the VF adapter structure

 *

 * Request that the PF delete Flow Director filters as specified

 * by the user via ethtool.

 bail because we already have a command pending */

/**

 * iavf_add_adv_rss_cfg

 * @adapter: the VF adapter structure

 *

 * Request that the PF add RSS configuration as specified

 * by the user via ethtool.

 bail because we already have a command pending */

/**

 * iavf_del_adv_rss_cfg

 * @adapter: the VF adapter structure

 *

 * Request that the PF delete RSS configuration as specified

 * by the user via ethtool.

 bail because we already have a command pending */

/**

 * iavf_request_reset

 * @adapter: adapter structure

 *

 * Request that the PF reset this VF. No response is expected.

 Don't check CURRENT_OP - this is always higher priority */

/**

 * iavf_virtchnl_completion

 * @adapter: adapter structure

 * @v_opcode: opcode sent by PF

 * @v_retval: retval sent by PF

 * @msg: message sent by PF

 * @msglen: message length

 *

 * Asynchronous completion function for admin queue messages. Rather than busy

 * wait, we fire off our requests and assume that no errors will be returned.

 * This function handles the reply messages.

 we've already got the right link status, bail */

				/* If we get link up message and start queues

				 * before our queues are configured it will

				 * trigger a TX hang. In that case, just ignore

				 * the link status message,we'll get another one

				 * after we enable queues and actually prepared

				 * to send traffic.

				/* For ADq enabled VF, we reconfigure VSIs and

				 * re-allocate queues. Hence wait till all

				 * queues are enabled.

 restore administratively set MAC address */

 restore current mac address */

 refresh current mac address if changed */

 enable transmits */

		/* Don't display an error if we get these out of sequence.

		 * If the firmware needed to get kicked, we'll get these and

		 * it's no problem.

		/* Gobble zero-length replies from the PF. They indicate that

		 * a previous message was received OK, and the client doesn't

		 * care about that.

 switch v_opcode */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2021, Intel Corporation. */

 advanced RSS configuration ethtool support for iavf */

/**

 * iavf_fill_adv_rss_ip4_hdr - fill the IPv4 RSS protocol header

 * @hdr: the virtchnl message protocol header data structure

 * @hash_flds: the RSS configuration protocol hash fields

/**

 * iavf_fill_adv_rss_ip6_hdr - fill the IPv6 RSS protocol header

 * @hdr: the virtchnl message protocol header data structure

 * @hash_flds: the RSS configuration protocol hash fields

/**

 * iavf_fill_adv_rss_tcp_hdr - fill the TCP RSS protocol header

 * @hdr: the virtchnl message protocol header data structure

 * @hash_flds: the RSS configuration protocol hash fields

/**

 * iavf_fill_adv_rss_udp_hdr - fill the UDP RSS protocol header

 * @hdr: the virtchnl message protocol header data structure

 * @hash_flds: the RSS configuration protocol hash fields

/**

 * iavf_fill_adv_rss_sctp_hdr - fill the SCTP RSS protocol header

 * @hdr: the virtchnl message protocol header data structure

 * @hash_flds: the RSS configuration protocol hash fields

/**

 * iavf_fill_adv_rss_cfg_msg - fill the RSS configuration into virtchnl message

 * @rss_cfg: the virtchnl message to be filled with RSS configuration setting

 * @packet_hdrs: the RSS configuration protocol header types

 * @hash_flds: the RSS configuration protocol hash fields

 *

 * Returns 0 if the RSS configuration virtchnl message is filled successfully

 always outer layer */

/**

 * iavf_find_adv_rss_cfg_by_hdrs - find RSS configuration with header type

 * @adapter: pointer to the VF adapter structure

 * @packet_hdrs: protocol header type to find.

 *

 * Returns pointer to advance RSS configuration if found or null

/**

 * iavf_print_adv_rss_cfg

 * @adapter: pointer to the VF adapter structure

 * @rss: pointer to the advance RSS configuration to print

 * @action: the string description about how to handle the RSS

 * @result: the string description about the virtchnl result

 *

 * Print the advance RSS configuration

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 *  iavf_adminq_init_regs - Initialize AdminQ registers

 *  @hw: pointer to the hardware structure

 *

 *  This assumes the alloc_asq and alloc_arq functions have already been called

 set head and tail registers in our local struct */

/**

 *  iavf_alloc_adminq_asq_ring - Allocate Admin Queue send rings

 *  @hw: pointer to the hardware structure

/**

 *  iavf_alloc_adminq_arq_ring - Allocate Admin Queue receive rings

 *  @hw: pointer to the hardware structure

/**

 *  iavf_free_adminq_asq - Free Admin Queue send rings

 *  @hw: pointer to the hardware structure

 *

 *  This assumes the posted send buffers have already been cleaned

 *  and de-allocated

/**

 *  iavf_free_adminq_arq - Free Admin Queue receive rings

 *  @hw: pointer to the hardware structure

 *

 *  This assumes the posted receive buffers have already been cleaned

 *  and de-allocated

/**

 *  iavf_alloc_arq_bufs - Allocate pre-posted buffers for the receive queue

 *  @hw: pointer to the hardware structure

	/* We'll be allocating the buffer info memory first, then we can

	 * allocate the mapped buffers for the event processing

 buffer_info structures do not need alignment */

 allocate the mapped buffers */

 now configure the descriptors for use */

		/* This is in accordance with Admin queue design, there is no

		 * register for buffer size configuration

 don't try to free the one that failed... */

/**

 *  iavf_alloc_asq_bufs - Allocate empty buffer structs for the send queue

 *  @hw: pointer to the hardware structure

 No mapped memory needed yet, just the buffer info structures */

 allocate the mapped buffers */

 don't try to free the one that failed... */

/**

 *  iavf_free_arq_bufs - Free receive queue buffer info elements

 *  @hw: pointer to the hardware structure

 free descriptors */

 free the descriptor memory */

 free the dma header */

/**

 *  iavf_free_asq_bufs - Free send queue buffer info elements

 *  @hw: pointer to the hardware structure

 only unmap if the address is non-NULL */

 free the buffer info list */

 free the descriptor memory */

 free the dma header */

/**

 *  iavf_config_asq_regs - configure ASQ registers

 *  @hw: pointer to the hardware structure

 *

 *  Configure base address and length registers for the transmit queue

 Clear Head and Tail */

 set starting point */

 Check one register to verify that config was applied */

/**

 *  iavf_config_arq_regs - ARQ register configuration

 *  @hw: pointer to the hardware structure

 *

 * Configure base address and length registers for the receive (event queue)

 Clear Head and Tail */

 set starting point */

 Update tail in the HW to post pre-allocated buffers */

 Check one register to verify that config was applied */

/**

 *  iavf_init_asq - main initialization routine for ASQ

 *  @hw: pointer to the hardware structure

 *

 *  This is the main initialization routine for the Admin Send Queue

 *  Prior to calling this function, drivers *MUST* set the following fields

 *  in the hw->aq structure:

 *     - hw->aq.num_asq_entries

 *     - hw->aq.arq_buf_size

 *

 *  Do *NOT* hold the lock when calling this as the memory allocation routines

 *  called are not going to be atomic context safe

 queue already initialized */

 verify input for valid configuration */

 allocate the ring memory */

 allocate buffers in the rings */

 initialize base registers */

 success! */

/**

 *  iavf_init_arq - initialize ARQ

 *  @hw: pointer to the hardware structure

 *

 *  The main initialization routine for the Admin Receive (Event) Queue.

 *  Prior to calling this function, drivers *MUST* set the following fields

 *  in the hw->aq structure:

 *     - hw->aq.num_asq_entries

 *     - hw->aq.arq_buf_size

 *

 *  Do *NOT* hold the lock when calling this as the memory allocation routines

 *  called are not going to be atomic context safe

 queue already initialized */

 verify input for valid configuration */

 allocate the ring memory */

 allocate buffers in the rings */

 initialize base registers */

 success! */

/**

 *  iavf_shutdown_asq - shutdown the ASQ

 *  @hw: pointer to the hardware structure

 *

 *  The main shutdown routine for the Admin Send Queue

 Stop firmware AdminQ processing */

 to indicate uninitialized queue */

 free ring buffers */

/**

 *  iavf_shutdown_arq - shutdown ARQ

 *  @hw: pointer to the hardware structure

 *

 *  The main shutdown routine for the Admin Receive Queue

 Stop firmware AdminQ processing */

 to indicate uninitialized queue */

 free ring buffers */

/**

 *  iavf_init_adminq - main initialization routine for Admin Queue

 *  @hw: pointer to the hardware structure

 *

 *  Prior to calling this function, drivers *MUST* set the following fields

 *  in the hw->aq structure:

 *     - hw->aq.num_asq_entries

 *     - hw->aq.num_arq_entries

 *     - hw->aq.arq_buf_size

 *     - hw->aq.asq_buf_size

 verify input for valid configuration */

 Set up register offsets */

 setup ASQ command write back timeout */

 allocate the ASQ */

 allocate the ARQ */

 success! */

/**

 *  iavf_shutdown_adminq - shutdown routine for the Admin Queue

 *  @hw: pointer to the hardware structure

/**

 *  iavf_clean_asq - cleans Admin send queue

 *  @hw: pointer to the hardware structure

 *

 *  returns the number of free desc

/**

 *  iavf_asq_done - check if FW has processed the Admin Send Queue

 *  @hw: pointer to the hw struct

 *

 *  Returns true if the firmware has processed all descriptors on the

 *  admin send queue. Returns false if there are still requests pending.

	/* AQ designers suggest use of head for better

	 * timing reliability than DD bit

/**

 *  iavf_asq_send_command - send command to Admin Queue

 *  @hw: pointer to the hw struct

 *  @desc: prefilled descriptor describing the command (non DMA mem)

 *  @buff: buffer to use for indirect commands

 *  @buff_size: size of buffer for indirect commands

 *  @cmd_details: pointer to command details structure

 *

 *  This is the main send command driver routine for the Admin Queue send

 *  queue.  It runs the queue, cleans the queue, etc

 can be NULL */

		/* If the cmd_details are defined copy the cookie.  The

		 * cpu_to_le32 is not needed here because the data is ignored

		 * by the FW, only used by the driver

 clear requested flags and then set additional flags if defined */

	/* call clean and check queue available function to reclaim the

	 * descriptors that were processed by FW, the function returns the

	 * number of desc available

	/* the clean function called here could be called in a separate thread

	 * in case of asynchronous completions

 initialize the temp desc pointer with the right desc */

 if the desc is available copy the temp desc to the right place */

 if buff is not NULL assume indirect command */

 copy the user buff into the respective DMA buff */

		/* Update the address values in the desc with the pa value

		 * for respective buffer

 bump the tail */

	/* if cmd_details are not defined or async flag is not set,

	 * we need to wait for desc write back

			/* AQ designers suggest use of head for better

			 * timing reliability than DD bit

 if ready, copy the desc back to temp */

 strip off FW internal code */

 save writeback aq if requested */

 update the error if time out occurred */

/**

 *  iavf_fill_default_direct_cmd_desc - AQ descriptor helper function

 *  @desc:     pointer to the temp descriptor (non DMA mem)

 *  @opcode:   the opcode can be used to decide which flags to turn off or on

 *

 *  Fill the desc with default values

 zero out the desc */

/**

 *  iavf_clean_arq_element

 *  @hw: pointer to the hw struct

 *  @e: event info from the receive descriptor, includes any buffers

 *  @pending: number of events that could be left to process

 *

 *  This function cleans one Admin Receive Queue element and returns

 *  the contents through e.  It can also return how many events are

 *  left to process through 'pending'

 pre-clean the event info */

 take the lock before we start messing with the ring */

 set next_to_use to head */

 nothing to do - shouldn't need to update ring's values */

 now clean the next descriptor */

	/* Restore the original datalen and buffer address in the desc,

	 * FW updates datalen to indicate the event message

	 * size

 set tail = the last cleaned desc index. */

 ntc is updated to tail + 1 */

 Set pending if needed, unlock and return */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2020, Intel Corporation. */

 flow director ethtool support for iavf */

/**

 * iavf_pkt_udp_no_pay_len - the length of UDP packet without payload

 * @fltr: Flow Director filter data structure

/**

 * iavf_fill_fdir_gtpu_hdr - fill the GTP-U protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the GTP-U protocol header is set successfully

 Extension Header if it exists */

 skip N_PDU */

 PDU Session Container Extension Header (PSC) */

 skip Type */

 The PF ignores the UDP header fields */

/**

 * iavf_fill_fdir_pfcp_hdr - fill the PFCP protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the PFCP protocol header is set successfully

 The PF ignores the UDP header fields */

/**

 * iavf_fill_fdir_nat_t_esp_hdr - fill the NAT-T-ESP protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the NAT-T-ESP protocol header is set successfully

 Not support IKE Header Format with SPI 0 */

 The PF ignores the UDP header fields */

/**

 * iavf_fill_fdir_udp_flex_pay_hdr - fill the UDP payload header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the UDP payload defined protocol header is set successfully

/**

 * iavf_fill_fdir_ip4_hdr - fill the IPv4 protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the IPv4 protocol header is set successfully

/**

 * iavf_fill_fdir_ip6_hdr - fill the IPv6 protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the IPv6 protocol header is set successfully

/**

 * iavf_fill_fdir_tcp_hdr - fill the TCP protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the TCP protocol header is set successfully

/**

 * iavf_fill_fdir_udp_hdr - fill the UDP protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the UDP protocol header is set successfully

/**

 * iavf_fill_fdir_sctp_hdr - fill the SCTP protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the SCTP protocol header is set successfully

/**

 * iavf_fill_fdir_ah_hdr - fill the AH protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the AH protocol header is set successfully

/**

 * iavf_fill_fdir_esp_hdr - fill the ESP protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the ESP protocol header is set successfully

/**

 * iavf_fill_fdir_l4_hdr - fill the L4 protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the L4 protocol header is set successfully

 IPv4/IPv6 header only */

 L2TPv3 over IP with 'Session ID' */

/**

 * iavf_fill_fdir_eth_hdr - fill the Ethernet protocol header

 * @fltr: Flow Director filter data structure

 * @proto_hdrs: Flow Director protocol headers data structure

 *

 * Returns 0 if the Ethernet protocol header is set successfully

/**

 * iavf_fill_fdir_add_msg - fill the Flow Director filter into virtchnl message

 * @adapter: pointer to the VF adapter structure

 * @fltr: Flow Director filter data structure

 *

 * Returns 0 if the add Flow Director virtchnl message is filled successfully

 L2 always exists */

/**

 * iavf_fdir_flow_proto_name - get the flow protocol name

 * @flow_type: Flow Director filter flow type

/**

 * iavf_print_fdir_fltr

 * @adapter: adapter structure

 * @fltr: Flow Director filter to print

 *

 * Print the Flow Director filter

/**

 * iavf_fdir_is_dup_fltr - test if filter is already in list

 * @adapter: pointer to the VF adapter structure

 * @fltr: Flow Director filter data structure

 *

 * Returns true if the filter is found in the list

/**

 * iavf_find_fdir_fltr_by_loc - find filter with location

 * @adapter: pointer to the VF adapter structure

 * @loc: location to find.

 *

 * Returns pointer to Flow Director filter if found or null

/**

 * iavf_fdir_list_add_fltr - add a new node to the flow director filter list

 * @adapter: pointer to the VF adapter structure

 * @fltr: filter node to add to structure

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 * iavf_set_mac_type - Sets MAC type

 * @hw: pointer to the HW structure

 *

 * This function sets the mac type of the adapter based on the

 * vendor ID and device ID stored in the hw structure.

/**

 * iavf_aq_str - convert AQ err code to a string

 * @hw: pointer to the HW structure

 * @aq_err: the AQ error code to convert

/**

 * iavf_stat_str - convert status err code to a string

 * @hw: pointer to the HW structure

 * @stat_err: the status error code to convert

/**

 * iavf_debug_aq

 * @hw: debug mask related to admin queue

 * @mask: debug mask

 * @desc: pointer to admin queue descriptor

 * @buffer: pointer to command buffer

 * @buf_len: max length of buffer

 *

 * Dumps debug log about adminq command with descriptor contents.

 write the full 16-byte chunks */

/**

 * iavf_check_asq_alive

 * @hw: pointer to the hw struct

 *

 * Returns true if Queue is enabled else false.

/**

 * iavf_aq_queue_shutdown

 * @hw: pointer to the hw struct

 * @unloading: is the driver unloading itself

 *

 * Tell the Firmware that we're shutting down the AdminQ and whether

 * or not the driver is unloading as well.

/**

 * iavf_aq_get_set_rss_lut

 * @hw: pointer to the hardware structure

 * @vsi_id: vsi fw index

 * @pf_lut: for PF table set true, for VSI table set false

 * @lut: pointer to the lut buffer provided by the caller

 * @lut_size: size of the lut buffer

 * @set: set true to set the table, false to get the table

 *

 * Internal function to get or set RSS look up table

 Indirect command */

/**

 * iavf_aq_get_rss_lut

 * @hw: pointer to the hardware structure

 * @vsi_id: vsi fw index

 * @pf_lut: for PF table set true, for VSI table set false

 * @lut: pointer to the lut buffer provided by the caller

 * @lut_size: size of the lut buffer

 *

 * get the RSS lookup table, PF or VSI type

/**

 * iavf_aq_set_rss_lut

 * @hw: pointer to the hardware structure

 * @vsi_id: vsi fw index

 * @pf_lut: for PF table set true, for VSI table set false

 * @lut: pointer to the lut buffer provided by the caller

 * @lut_size: size of the lut buffer

 *

 * set the RSS lookup table, PF or VSI type

/**

 * iavf_aq_get_set_rss_key

 * @hw: pointer to the hw struct

 * @vsi_id: vsi fw index

 * @key: pointer to key info struct

 * @set: set true to set the key, false to get the key

 *

 * get the RSS key per VSI

 Indirect command */

/**

 * iavf_aq_get_rss_key

 * @hw: pointer to the hw struct

 * @vsi_id: vsi fw index

 * @key: pointer to key info struct

 *

/**

 * iavf_aq_set_rss_key

 * @hw: pointer to the hw struct

 * @vsi_id: vsi fw index

 * @key: pointer to key info struct

 *

 * set the RSS key per VSI

/* The iavf_ptype_lookup table is used to convert from the 8-bit ptype in the

 * hardware to a bit-field that can be used by SW to more easily determine the

 * packet type.

 *

 * Macros are used to shorten the table lines and make this table human

 * readable.

 *

 * We store the PTYPE in the top byte of the bit field - this is just so that

 * we can check that the table doesn't have a row missing, as the index into

 * the table should be the PTYPE.

 *

 * Typical work flow:

 *

 * IF NOT iavf_ptype_lookup[ptype].known

 * THEN

 *      Packet is unknown

 * ELSE IF iavf_ptype_lookup[ptype].outer_ip == IAVF_RX_PTYPE_OUTER_IP

 *      Use the rest of the fields to look at the tunnels, inner protocols, etc

 * ELSE

 *      Use the enum iavf_rx_l2_ptype to decode the packet type

 * ENDIF

 macro to make the table lines short, use explicit indexing with [PTYPE] */

 shorter macros makes the table fit but are terse */

 Lookup table mapping the 8-bit HW PTYPE to the bit field for decoding */

 L2 Packet types */

 Non Tunneled IPv4 */

 IPv4 --> IPv4 */

 IPv4 --> IPv6 */

 IPv4 --> GRE/NAT */

 IPv4 --> GRE/NAT --> IPv4 */

 IPv4 --> GRE/NAT --> IPv6 */

 IPv4 --> GRE/NAT --> MAC */

 IPv4 --> GRE/NAT --> MAC --> IPv4 */

 IPv4 --> GRE/NAT -> MAC --> IPv6 */

 IPv4 --> GRE/NAT --> MAC/VLAN */

 IPv4 ---> GRE/NAT -> MAC/VLAN --> IPv4 */

 IPv4 -> GRE/NAT -> MAC/VLAN --> IPv6 */

 Non Tunneled IPv6 */

 IPv6 --> IPv4 */

 IPv6 --> IPv6 */

 IPv6 --> GRE/NAT */

 IPv6 --> GRE/NAT -> IPv4 */

 IPv6 --> GRE/NAT -> IPv6 */

 IPv6 --> GRE/NAT -> MAC */

 IPv6 --> GRE/NAT -> MAC -> IPv4 */

 IPv6 --> GRE/NAT -> MAC -> IPv6 */

 IPv6 --> GRE/NAT -> MAC/VLAN */

 IPv6 --> GRE/NAT -> MAC/VLAN --> IPv4 */

 IPv6 --> GRE/NAT -> MAC/VLAN --> IPv6 */

 unused entries */

/**

 * iavf_aq_send_msg_to_pf

 * @hw: pointer to the hardware structure

 * @v_opcode: opcodes for VF-PF communication

 * @v_retval: return error code

 * @msg: pointer to the msg buffer

 * @msglen: msg length

 * @cmd_details: pointer to command details

 *

 * Send message to PF driver using admin queue. By default, this message

 * is sent asynchronously, i.e. iavf_asq_send_command() does not wait for

 * completion before returning.

/**

 * iavf_vf_parse_hw_config

 * @hw: pointer to the hardware structure

 * @msg: pointer to the virtual channel VF resource structure

 *

 * Given a VF resource message from the PF, populate the hw struct

 * with appropriate information.

/**

 * iavf_vf_reset

 * @hw: pointer to the hardware structure

 *

 * Send a VF_RESET message to the PF. Does not wait for response from PF

 * as none will be forthcoming. Immediately after calling this function,

 * the admin queue should be shut down and (optionally) reinitialized.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2006 Intel Corporation. */

/* e1000_hw.c

 * Shared functions for accessing and configuring the MAC

 IGP cable length table */

/**

 * e1000_set_phy_type - Set the phy type member in the hw struct.

 * @hw: Struct containing variables accessed by shared code

 Should never have loaded on this device */

/**

 * e1000_phy_init_script - IGP phy init script - initializes the GbE PHY

 * @hw: Struct containing variables accessed by shared code

		/* Save off the current value of register 0x2F5B to be restored

		 * at the end of this routine.

 Disabled the PHY transmitter */

 Now enable the transmitter */

 Move to analog registers page */

/**

 * e1000_set_mac_type - Set the mac type member in the hw struct.

 * @hw: Struct containing variables accessed by shared code

 Invalid 82542 revision ID */

 Should never have loaded on this device */

	/* The 82543 chip does not count tx_carrier_errors properly in

	 * FD mode

/**

 * e1000_set_media_type - Set media type and TBI compatibility.

 * @hw: Struct containing variables accessed by shared code

 tbi_compatibility is only valid on 82543 */

 tbi_compatibility not valid on fiber */

/**

 * e1000_reset_hw - reset the hardware completely

 * @hw: Struct containing variables accessed by shared code

 *

 * Reset the transmit and receive units; mask and clear all interrupts.

 For 82542 (rev 2.0), disable MWI before issuing a device reset */

 Clear interrupt mask to stop board from generating interrupts */

	/* Disable the Transmit and Receive units.  Then delay to allow

	 * any pending transactions to complete before we hit the MAC with

	 * the global reset.

 The tbi_compatibility_on Flag must be cleared when Rctl is cleared. */

	/* Delay to allow any outstanding PCI transactions to complete before

	 * resetting the device

 Must reset the PHY before resetting the MAC */

	/* Issue a global reset to the MAC.  This will reset the chip's

	 * transmit, receive, DMA, and link units.  It will not effect

	 * the current PCI configuration.  The global reset bit is self-

	 * clearing, and should clear within a microsecond.

		/* These controllers can't ack the 64-bit write when issuing the

		 * reset, so use IO-mapping as a workaround to issue the reset

 Reset is performed on a shadow of the control register */

	/* After MAC reset, force reload of EEPROM to restore power-on settings

	 * to device.  Later controllers reload the EEPROM automatically, so

	 * just wait for reload to complete.

 Wait for reset to complete */

 Wait for EEPROM reload */

 Wait for EEPROM reload */

 Auto read done will delay 5ms or poll based on mac type */

 Disable HW ARPs on ASF enabled adapters */

 Configure activity LED after PHY reset */

 Clear interrupt mask to stop board from generating interrupts */

 Clear any pending interrupt events. */

 If MWI was previously enabled, reenable it. */

/**

 * e1000_init_hw - Performs basic configuration of the adapter.

 * @hw: Struct containing variables accessed by shared code

 *

 * Assumes that the controller has previously been reset and is in a

 * post-reset uninitialized state. Initializes the receive address registers,

 * multicast table, and VLAN filter table. Calls routines to setup link

 * configuration and flow control settings. Clears all on-chip counters. Leaves

 * the transmit and receive units disabled and uninitialized.

 Initialize Identification LED */

 Set the media type and TBI compatibility */

 Disabling VLAN filtering. */

 For 82542 (rev 2.0), disable MWI and put the receiver into reset */

	/* Setup the receive address. This involves initializing all of the

	 * Receive Address Registers (RARs 0 - 15).

 For 82542 (rev 2.0), take the receiver out of reset and enable MWI */

 Zero out the Multicast HASH table */

		/* use write flush to prevent Memory Write Block (MWB) from

		 * occurring when accessing our register space

	/* Set the PCI priority bit correctly in the CTRL register.  This

	 * determines if the adapter gives priority to receives, or if it

	 * gives equal priority to transmits and receives.  Valid only on

	 * 82542 and 82543 silicon.

		/* Workaround for PCI-X problem when BIOS sets MMRBC

		 * incorrectly.

 Call a subroutine to configure the link and setup flow control. */

 Set the transmit descriptor write-back policy */

	/* Clear all of the statistics registers (clear on read).  It is

	 * important that we do this after we have tried to establish link

	 * because the symbol error count will increment wildly if there

	 * is no link.

		/* Relaxed ordering must be disabled to avoid a parity

		 * error crash in a PCI slot.

/**

 * e1000_adjust_serdes_amplitude - Adjust SERDES output amplitude based on EEPROM setting.

 * @hw: Struct containing variables accessed by shared code.

 Adjust SERDES output amplitude only. */

/**

 * e1000_setup_link - Configures flow control and link settings.

 * @hw: Struct containing variables accessed by shared code

 *

 * Determines which flow control settings to use. Calls the appropriate media-

 * specific link configuration function. Configures the flow control settings.

 * Assuming the adapter has a valid link partner, a valid link should be

 * established. Assumes the hardware has previously been reset and the

 * transmitter and receiver are not enabled.

	/* Read and store word 0x0F of the EEPROM. This word contains bits

	 * that determine the hardware's default PAUSE (flow control) mode,

	 * a bit that determines whether the HW defaults to enabling or

	 * disabling auto-negotiation, and the direction of the

	 * SW defined pins. If there is no SW over-ride of the flow

	 * control setting, then the variable hw->fc will

	 * be initialized based on a value in the EEPROM.

	/* We want to save off the original Flow Control configuration just

	 * in case we get disconnected and then reconnected into a different

	 * hub or switch with different Flow Control capabilities.

	/* Take the 4 bits from EEPROM word 0x0F that determine the initial

	 * polarity value for the SW controlled pins, and setup the

	 * Extended Device Control reg with that info.

	 * This is needed because one of the SW controlled pins is used for

	 * signal detection.  So this should be done before e1000_setup_pcs_link()

	 * or e1000_phy_setup() is called.

 Call the necessary subroutine to configure the link. */

	/* Initialize the flow control address, type, and PAUSE timer

	 * registers to their default values.  This is done even if flow

	 * control is disabled, because it does not hurt anything to

	 * initialize these registers.

	/* Set the flow control receive threshold registers.  Normally,

	 * these registers will be set to a default threshold that may be

	 * adjusted later by the driver's runtime code.  However, if the

	 * ability to transmit pause frames in not enabled, then these

	 * registers will be set to 0.

		/* We need to set up the Receive Threshold high and low water

		 * marks as well as (optionally) enabling the transmission of

		 * XON frames.

/**

 * e1000_setup_fiber_serdes_link - prepare fiber or serdes link

 * @hw: Struct containing variables accessed by shared code

 *

 * Manipulates Physical Coding Sublayer functions in order to configure

 * link. Assumes the hardware has been previously reset and the transmitter

 * and receiver are not enabled.

	/* On adapters with a MAC newer than 82544, SWDP 1 will be

	 * set when the optics detect a signal. On older adapters, it will be

	 * cleared when there is a signal.  This applies to fiber media only.

	 * If we're on serdes media, adjust the output amplitude to value

	 * set in the EEPROM.

 Take the link out of reset */

 Adjust VCO speed to improve BER performance */

	/* Check for a software override of the flow control settings, and setup

	 * the device accordingly.  If auto-negotiation is enabled, then

	 * software will have to set the "PAUSE" bits to the correct value in

	 * the Tranmsit Config Word Register (TXCW) and re-start

	 * auto-negotiation.  However, if auto-negotiation is disabled, then

	 * software will have to manually configure the two flow control enable

	 * bits in the CTRL register.

	 *

	 * The possible values of the "fc" parameter are:

	 *  0:  Flow control is completely disabled

	 *  1:  Rx flow control is enabled (we can receive pause frames, but

	 *      not send pause frames).

	 *  2:  Tx flow control is enabled (we can send pause frames but we do

	 *      not support receiving pause frames).

	 *  3:  Both Rx and TX flow control (symmetric) are enabled.

 Flow ctrl is completely disabled by a software over-ride */

		/* Rx Flow control is enabled and Tx Flow control is disabled by

		 * a software over-ride. Since there really isn't a way to

		 * advertise that we are capable of Rx Pause ONLY, we will

		 * advertise that we support both symmetric and asymmetric Rx

		 * PAUSE. Later, we will disable the adapter's ability to send

		 * PAUSE frames.

		/* Tx Flow control is enabled, and Rx Flow control is disabled,

		 * by a software over-ride.

		/* Flow control (both Rx and Tx) is enabled by a software

		 * over-ride.

	/* Since auto-negotiation is enabled, take the link out of reset (the

	 * link will be in reset, because we previously reset the chip). This

	 * will restart auto-negotiation.  If auto-negotiation is successful

	 * then the link-up status bit will be set and the flow control enable

	 * bits (RFCE and TFCE) will be set according to their negotiated value.

	/* If we have a signal (the cable is plugged in) then poll for a

	 * "Link-Up" indication in the Device Status Register.  Time-out if a

	 * link isn't seen in 500 milliseconds seconds (Auto-negotiation should

	 * complete in less than 500 milliseconds even if the other end is doing

	 * it in SW). For internal serdes, we just assume a signal is present,

	 * then poll.

			/* AutoNeg failed to achieve a link, so we'll call

			 * e1000_check_for_link. This routine will force the

			 * link up if we detect a signal. This will allow us to

			 * communicate with non-autonegotiating link partners.

/**

 * e1000_copper_link_rtl_setup - Copper link setup for e1000_phy_rtl series.

 * @hw: Struct containing variables accessed by shared code

 *

 * Commits changes to PHY configuration by calling e1000_phy_reset().

 SW reset the PHY so all changes take effect */

 Set RMII mode */

 Disable the J/K bits required for receive */

/**

 * e1000_copper_link_preconfig - early configuration for copper

 * @hw: Struct containing variables accessed by shared code

 *

 * Make sure we have a valid PHY and change PHY mode before link setup.

	/* With 82543, we need to force speed and duplex on the MAC equal to

	 * what the PHY speed and duplex configuration is. In addition, we need

	 * to perform a hardware reset on the PHY to take it out of reset.

 Make sure we have a valid PHY */

 Set PHY to class A mode (if necessary) */

/**

 * e1000_copper_link_igp_setup - Copper link setup for e1000_phy_igp series.

 * @hw: Struct containing variables accessed by shared code

 Wait 15ms for MAC to configure PHY from eeprom settings */

 Configure activity LED after PHY reset */

 The NVM settings will configure LPLU in D3 for IGP2 and IGP3 PHYs */

 disable lplu d3 during driver init */

 Configure mdi-mdix settings */

 Force MDI for earlier revs of the IGP PHY */

 set auto-master slave resolution settings */

		/* when autonegotiation advertisement is only 1000Mbps then we

		 * should disable SmartSpeed and enable Auto MasterSlave

		 * resolution as hardware default.

 Disable SmartSpeed */

 Set auto Master/Slave resolution process */

 load defaults for future use */

/**

 * e1000_copper_link_mgp_setup - Copper link setup for e1000_phy_m88 series.

 * @hw: Struct containing variables accessed by shared code

 Enable CRS on TX. This must be set for half-duplex operation. */

	/* Options:

	 *   MDI/MDI-X = 0 (default)

	 *   0 - Auto for all speeds

	 *   1 - MDI mode

	 *   2 - MDI-X mode

	 *   3 - Auto for 1000Base-T only (MDI-X for 10/100Base-T modes)

	/* Options:

	 *   disable_polarity_correction = 0 (default)

	 *       Automatic Correction for Reversed Cable Polarity

	 *   0 - Disabled

	 *   1 - Enabled

		/* Force TX_CLK in the Extended PHY Specific Control Register

		 * to 25MHz clock.

 Vidalia Phy, set the downshift counter to 5x */

 Configure Master and Slave downshift values */

 SW Reset the PHY so all changes take effect */

/**

 * e1000_copper_link_autoneg - setup auto-neg

 * @hw: Struct containing variables accessed by shared code

 *

 * Setup auto-negotiation and flow control advertisements,

 * and then perform auto-negotiation.

	/* Perform some bounds checking on the hw->autoneg_advertised

	 * parameter.  If this variable is zero, then set it to the default.

	/* If autoneg_advertised is zero, we assume it was not defaulted

	 * by the calling code so we set to advertise full capability.

 IFE/RTL8201N PHY only supports 10/100 */

	/* Restart auto-negotiation by setting the Auto Neg Enable bit and

	 * the Auto Neg Restart bit in the PHY control register.

	/* Does the user want to wait for Auto-Neg to complete here, or

	 * check at a later time (for example, callback routine).

/**

 * e1000_copper_link_postconfig - post link setup

 * @hw: Struct containing variables accessed by shared code

 *

 * Config the MAC and the PHY after link is up.

 *   1) Set up the MAC to the current PHY speed/duplex

 *      if we are on 82543.  If we

 *      are on newer silicon, we only need to configure

 *      collision distance in the Transmit Control Register.

 *   2) Set up flow control on the MAC to that established with

 *      the link partner.

 *   3) Config DSP to improve Gigabit link quality for some PHY revisions.

 Config DSP to improve Giga link quality */

/**

 * e1000_setup_copper_link - phy/speed/duplex setting

 * @hw: Struct containing variables accessed by shared code

 *

 * Detects which PHY is present and sets up the speed and duplex

 Check if it is a valid PHY and set PHY mode if necessary. */

		/* Setup autoneg and flow control advertisement

		 * and perform autonegotiation

		/* PHY will be set to 10H, 10F, 100H,or 100F

		 * depending on value from forced_speed_duplex.

	/* Check link status. Wait up to 100 microseconds for link to become

	 * valid.

 Config the MAC and PHY after link is up */

/**

 * e1000_phy_setup_autoneg - phy settings

 * @hw: Struct containing variables accessed by shared code

 *

 * Configures PHY autoneg and flow control advertisement settings

 Read the MII Auto-Neg Advertisement Register (Address 4). */

 Read the MII 1000Base-T Control Register (Address 9). */

	/* Need to parse both autoneg_advertised and fc and set up

	 * the appropriate PHY registers.  First we will parse for

	 * autoneg_advertised software override.  Since we can advertise

	 * a plethora of combinations, we need to check each bit

	 * individually.

	/* First we clear all the 10/100 mb speed bits in the Auto-Neg

	 * Advertisement Register (Address 4) and the 1000 mb speed bits in

	 * the  1000Base-T Control Register (Address 9).

 Do we want to advertise 10 Mb Half Duplex? */

 Do we want to advertise 10 Mb Full Duplex? */

 Do we want to advertise 100 Mb Half Duplex? */

 Do we want to advertise 100 Mb Full Duplex? */

 We do not allow the Phy to advertise 1000 Mb Half Duplex */

 Do we want to advertise 1000 Mb Full Duplex? */

	/* Check for a software override of the flow control settings, and

	 * setup the PHY advertisement registers accordingly.  If

	 * auto-negotiation is enabled, then software will have to set the

	 * "PAUSE" bits to the correct value in the Auto-Negotiation

	 * Advertisement Register (PHY_AUTONEG_ADV) and re-start

	 * auto-negotiation.

	 *

	 * The possible values of the "fc" parameter are:

	 *      0:  Flow control is completely disabled

	 *      1:  Rx flow control is enabled (we can receive pause frames

	 *          but not send pause frames).

	 *      2:  Tx flow control is enabled (we can send pause frames

	 *          but we do not support receiving pause frames).

	 *      3:  Both Rx and TX flow control (symmetric) are enabled.

	 *  other:  No software override.  The flow control configuration

	 *          in the EEPROM is used.

 0 */

		/* Flow control (RX & TX) is completely disabled by a

		 * software over-ride.

 1 */

		/* RX Flow control is enabled, and TX Flow control is

		 * disabled, by a software over-ride.

		/* Since there really isn't a way to advertise that we are

		 * capable of RX Pause ONLY, we will advertise that we

		 * support both symmetric and asymmetric RX PAUSE.  Later

		 * (in e1000_config_fc_after_link_up) we will disable the

		 * hw's ability to send PAUSE frames.

 2 */

		/* TX Flow control is enabled, and RX Flow control is

		 * disabled, by a software over-ride.

 3 */

		/* Flow control (both RX and TX) is enabled by a software

		 * over-ride.

/**

 * e1000_phy_force_speed_duplex - force link settings

 * @hw: Struct containing variables accessed by shared code

 *

 * Force PHY speed and duplex settings to hw->forced_speed_duplex

 Turn off Flow control if we are forcing speed and duplex. */

 Read the Device Control Register. */

 Set the bits to Force Speed and Duplex in the Device Ctrl Reg. */

 Clear the Auto Speed Detect Enable bit. */

 Read the MII Control Register. */

 We need to disable autoneg in order to force link and duplex. */

 Are we forcing Full or Half Duplex? */

		/* We want to force full duplex so we SET the full duplex bits

		 * in the Device and MII Control Registers.

		/* We want to force half duplex so we CLEAR the full duplex bits

		 * in the Device and MII Control Registers.

 Are we forcing 100Mbps??? */

 Set the 100Mb bit and turn off the 1000Mb and 10Mb bits. */

 Set the 10Mb bit and turn off the 1000Mb and 100Mb bits. */

 Write the configured values back to the Device Control Reg. */

		/* Clear Auto-Crossover to force MDI manually. M88E1000 requires

		 * MDI forced whenever speed are duplex are forced.

 Need to reset the PHY or these changes will be ignored */

 Disable MDI-X support for 10/100 */

		/* Clear Auto-Crossover to force MDI manually.  IGP requires MDI

		 * forced whenever speed or duplex are forced.

 Write back the modified PHY MII control register. */

	/* The wait_autoneg_complete flag may be a little misleading here.

	 * Since we are forcing speed and duplex, Auto-Neg is not enabled.

	 * But we do want to delay for a period while forcing only so we

	 * don't generate false No Link messages.  So we will wait here

	 * only if the user has set wait_autoneg_complete to 1, which is

	 * the default.

 We will wait for autoneg to complete. */

 Wait for autoneg to complete or 4.5 seconds to expire */

			/* Read the MII Status Register and wait for Auto-Neg

			 * Complete bit to be set.

			/* We didn't get link.  Reset the DSP and wait again

			 * for link.

		/* This loop will early-out if the link condition has been

		 * met

			/* Read the MII Status Register and wait for Auto-Neg

			 * Complete bit to be set.

		/* Because we reset the PHY above, we need to re-force TX_CLK in

		 * the Extended PHY Specific Control Register to 25MHz clock.

		 * This value defaults back to a 2.5MHz clock when the PHY is

		 * reset.

		/* In addition, because of the s/w reset above, we need to

		 * enable CRS on Tx.  This must be set for both full and half

		 * duplex operation.

/**

 * e1000_config_collision_dist - set collision distance register

 * @hw: Struct containing variables accessed by shared code

 *

 * Sets the collision distance in the Transmit Control register.

 * Link should have been established previously. Reads the speed and duplex

 * information from the Device Status register.

/**

 * e1000_config_mac_to_phy - sync phy and mac settings

 * @hw: Struct containing variables accessed by shared code

 *

 * Sets MAC speed and duplex settings to reflect the those in the PHY

 * The contents of the PHY register containing the needed information need to

 * be passed in.

	/* 82544 or newer MAC, Auto Speed Detection takes care of

	 * MAC speed/duplex configuration.

	/* Read the Device Control Register and set the bits to Force Speed

	 * and Duplex.

		/* Set up duplex in the Device Control and Transmit Control

		 * registers depending on negotiated values.

		/* Set up speed in the Device Control register depending on

		 * negotiated values.

 Write the configured values back to the Device Control Reg. */

/**

 * e1000_force_mac_fc - force flow control settings

 * @hw: Struct containing variables accessed by shared code

 *

 * Forces the MAC's flow control settings.

 * Sets the TFCE and RFCE bits in the device control register to reflect

 * the adapter settings. TFCE and RFCE need to be explicitly set by

 * software when a Copper PHY is used because autonegotiation is managed

 * by the PHY rather than the MAC. Software must also configure these

 * bits when link is forced on a fiber connection.

 Get the current configuration of the Device Control Register */

	/* Because we didn't get link via the internal auto-negotiation

	 * mechanism (we either forced link or we got link via PHY

	 * auto-neg), we have to manually enable/disable transmit an

	 * receive flow control.

	 *

	 * The "Case" statement below enables/disable flow control

	 * according to the "hw->fc" parameter.

	 *

	 * The possible values of the "fc" parameter are:

	 *      0:  Flow control is completely disabled

	 *      1:  Rx flow control is enabled (we can receive pause

	 *          frames but not send pause frames).

	 *      2:  Tx flow control is enabled (we can send pause frames

	 *          frames but we do not receive pause frames).

	 *      3:  Both Rx and TX flow control (symmetric) is enabled.

	 *  other:  No other values should be possible at this point.

 Disable TX Flow Control for 82542 (rev 2.0) */

/**

 * e1000_config_fc_after_link_up - configure flow control after autoneg

 * @hw: Struct containing variables accessed by shared code

 *

 * Configures flow control settings after link is established

 * Should be called immediately after a valid link has been established.

 * Forces MAC flow control settings if link was forced. When in MII/GMII mode

 * and autonegotiation is enabled, the MAC flow control settings will be set

 * based on the flow control negotiated by the PHY. In TBI mode, the TFCE

 * and RFCE bits will be automatically set to the negotiated flow control mode.

	/* Check for the case where we have fiber media and auto-neg failed

	 * so we had to force link.  In this case, we need to force the

	 * configuration of the MAC to match the "fc" parameter.

	/* Check for the case where we have copper media and auto-neg is

	 * enabled.  In this case, we need to check and see if Auto-Neg

	 * has completed, and if so, how the PHY and link partner has

	 * flow control configured.

		/* Read the MII Status Register and check to see if AutoNeg

		 * has completed.  We read this twice because this reg has

		 * some "sticky" (latched) bits.

			/* The AutoNeg process has completed, so we now need to

			 * read both the Auto Negotiation Advertisement Register

			 * (Address 4) and the Auto_Negotiation Base Page

			 * Ability Register (Address 5) to determine how flow

			 * control was negotiated.

			/* Two bits in the Auto Negotiation Advertisement

			 * Register (Address 4) and two bits in the Auto

			 * Negotiation Base Page Ability Register (Address 5)

			 * determine flow control for both the PHY and the link

			 * partner.  The following table, taken out of the IEEE

			 * 802.3ab/D6.0 dated March 25, 1999, describes these

			 * PAUSE resolution bits and how flow control is

			 * determined based upon these settings.

			 * NOTE:  DC = Don't Care

			 *

			 *   LOCAL DEVICE  |   LINK PARTNER

			 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | NIC Resolution

			 *-------|---------|-------|---------|------------------

			 *   0   |    0    |  DC   |   DC    | E1000_FC_NONE

			 *   0   |    1    |   0   |   DC    | E1000_FC_NONE

			 *   0   |    1    |   1   |    0    | E1000_FC_NONE

			 *   0   |    1    |   1   |    1    | E1000_FC_TX_PAUSE

			 *   1   |    0    |   0   |   DC    | E1000_FC_NONE

			 *   1   |   DC    |   1   |   DC    | E1000_FC_FULL

			 *   1   |    1    |   0   |    0    | E1000_FC_NONE

			 *   1   |    1    |   0   |    1    | E1000_FC_RX_PAUSE

			 *

			/* Are both PAUSE bits set to 1?  If so, this implies

			 * Symmetric Flow Control is enabled at both ends.  The

			 * ASM_DIR bits are irrelevant per the spec.

			 *

			 * For Symmetric Flow Control:

			 *

			 *   LOCAL DEVICE  |   LINK PARTNER

			 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

			 *-------|---------|-------|---------|------------------

			 *   1   |   DC    |   1   |   DC    | E1000_FC_FULL

			 *

				/* Now we need to check if the user selected Rx

				 * ONLY of pause frames.  In this case, we had

				 * to advertise FULL flow control because we

				 * could not advertise Rx ONLY. Hence, we must

				 * now check to see if we need to turn OFF the

				 * TRANSMISSION of PAUSE frames.

			/* For receiving PAUSE frames ONLY.

			 *

			 *   LOCAL DEVICE  |   LINK PARTNER

			 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

			 *-------|---------|-------|---------|------------------

			 *   0   |    1    |   1   |    1    | E1000_FC_TX_PAUSE

			 *

			/* For transmitting PAUSE frames ONLY.

			 *

			 *   LOCAL DEVICE  |   LINK PARTNER

			 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result

			 *-------|---------|-------|---------|------------------

			 *   1   |    1    |   0   |    1    | E1000_FC_RX_PAUSE

			 *

			/* Per the IEEE spec, at this point flow control should

			 * be disabled.  However, we want to consider that we

			 * could be connected to a legacy switch that doesn't

			 * advertise desired flow control, but can be forced on

			 * the link partner.  So if we advertised no flow

			 * control, that is what we will resolve to.  If we

			 * advertised some kind of receive capability (Rx Pause

			 * Only or Full Flow Control) and the link partner

			 * advertised none, we will configure ourselves to

			 * enable Rx Flow Control only.  We can do this safely

			 * for two reasons:  If the link partner really

			 * didn't want flow control enabled, and we enable Rx,

			 * no harm done since we won't be receiving any PAUSE

			 * frames anyway.  If the intent on the link partner was

			 * to have flow control enabled, then by us enabling Rx

			 * only, we can at least receive pause frames and

			 * process them. This is a good idea because in most

			 * cases, since we are predominantly a server NIC, more

			 * times than not we will be asked to delay transmission

			 * of packets than asking our link partner to pause

			 * transmission of frames.

			/* Now we need to do one last check...  If we auto-

			 * negotiated to HALF DUPLEX, flow control should not be

			 * enabled per IEEE 802.3 spec.

			/* Now we call a subroutine to actually force the MAC

			 * controller to use the correct flow control settings.

/**

 * e1000_check_for_serdes_link_generic - Check for link (Serdes)

 * @hw: pointer to the HW structure

 *

 * Checks for link up on the hardware.  If link is not up and we have

 * a signal, then we need to force link up.

	/* If we don't have link (auto-negotiation failed or link partner

	 * cannot auto-negotiate), and our link partner is not trying to

	 * auto-negotiate with us (we are receiving idles or data),

	 * we need to force link up. We also need to give auto-negotiation

	 * time to complete.

 (ctrl & E1000_CTRL_SWDPIN1) == 1 == have signal */

 Disable auto-negotiation in the TXCW register */

 Force link-up and also force full-duplex. */

 Configure Flow Control after forcing link up. */

		/* If we are forcing link and we are receiving /C/ ordered

		 * sets, re-enable auto-negotiation in the TXCW register

		 * and disable forced link in the Device Control register

		 * in an attempt to auto-negotiate with our link partner.

		/* If we force link for non-auto-negotiation switch, check

		 * link status based on MAC synchronization for internal

		 * serdes media type.

 SYNCH bit and IV bit are sticky. */

 SYNCH bit and IV bit are sticky, so reread rxcw. */

/**

 * e1000_check_for_link

 * @hw: Struct containing variables accessed by shared code

 *

 * Checks to see if the link status of the hardware has changed.

 * Called by any function that needs to check the link status of the adapter.

	/* On adapters with a MAC newer than 82544, SW Definable pin 1 will be

	 * set when the optics detect a signal. On older adapters, it will be

	 * cleared when there is a signal.  This applies to fiber media only.

	/* If we have a copper PHY then we only want to go out to the PHY

	 * registers to see if Auto-Neg has completed and/or if our link

	 * status has changed.  The get_link_status flag will be set if we

	 * receive a Link Status Change interrupt or we have Rx Sequence

	 * Errors.

		/* First we want to see if the MII Status Register reports

		 * link.  If so, then we want to get the current speed/duplex

		 * of the PHY.

		 * Read the register twice since the link bit is sticky.

			/* Check if there was DownShift, must be checked

			 * immediately after link-up

			/* If we are on 82544 or 82543 silicon and speed/duplex

			 * are forced to 10H or 10F, then we will implement the

			 * polarity reversal workaround.  We disable interrupts

			 * first, and upon returning, place the devices

			 * interrupt state to its previous value except for the

			 * link status change interrupt which will

			 * happen due to the execution of this workaround.

 No link detected */

		/* If we are forcing speed/duplex, then we simply return since

		 * we have already determined whether we have link or not.

 optimize the dsp settings for the igp phy */

		/* We have a M88E1000 PHY and Auto-Neg is enabled.  If we

		 * have Si on board that is 82544 or newer, Auto

		 * Speed Detection takes care of MAC speed/duplex

		 * configuration.  So we only need to configure Collision

		 * Distance in the MAC.  Otherwise, we need to force

		 * speed/duplex on the MAC to the current PHY speed/duplex

		 * settings.

		/* Configure Flow Control now that Auto-Neg has completed.

		 * First, we need to restore the desired flow control settings

		 * because we may have had to re-autoneg with a different link

		 * partner.

		/* At this point we know that we are on copper and we have

		 * auto-negotiated link.  These are conditions for checking the

		 * link partner capability register.  We use the link speed to

		 * determine if TBI compatibility needs to be turned on or off.

		 * If the link is not at gigabit speed, then TBI compatibility

		 * is not needed.  If we are at gigabit speed, we turn on TBI

		 * compatibility.

				/* If link speed is not set to gigabit speed, we

				 * do not need to enable TBI compatibility.

					/* If we previously were in the mode,

					 * turn it off.

				/* If TBI compatibility is was previously off,

				 * turn it on. For compatibility with a TBI link

				 * partner, we will store bad packets. Some

				 * frames have an additional byte on the end and

				 * will look like CRC errors to the hardware.

/**

 * e1000_get_speed_and_duplex

 * @hw: Struct containing variables accessed by shared code

 * @speed: Speed of the connection

 * @duplex: Duplex setting of the connection

 *

 * Detects the current speed and duplex settings of the hardware.

	/* IGP01 PHY may advertise full duplex operation after speed downgrade

	 * even if it is operating at half duplex.  Here we set the duplex

	 * settings to match the duplex in the link partner's capabilities.

/**

 * e1000_wait_autoneg

 * @hw: Struct containing variables accessed by shared code

 *

 * Blocks until autoneg completes or times out (~4.5 seconds)

 We will wait for autoneg to complete or 4.5 seconds to expire. */

		/* Read the MII Status Register and wait for Auto-Neg

		 * Complete bit to be set.

/**

 * e1000_raise_mdi_clk - Raises the Management Data Clock

 * @hw: Struct containing variables accessed by shared code

 * @ctrl: Device control register's current value

	/* Raise the clock input to the Management Data Clock (by setting the

	 * MDC bit), and then delay 10 microseconds.

/**

 * e1000_lower_mdi_clk - Lowers the Management Data Clock

 * @hw: Struct containing variables accessed by shared code

 * @ctrl: Device control register's current value

	/* Lower the clock input to the Management Data Clock (by clearing the

	 * MDC bit), and then delay 10 microseconds.

/**

 * e1000_shift_out_mdi_bits - Shifts data bits out to the PHY

 * @hw: Struct containing variables accessed by shared code

 * @data: Data to send out to the PHY

 * @count: Number of bits to shift out

 *

 * Bits are shifted out in MSB to LSB order.

	/* We need to shift "count" number of bits out to the PHY. So, the value

	 * in the "data" parameter will be shifted out to the PHY one bit at a

	 * time. In order to do this, "data" must be broken down into bits.

 Set MDIO_DIR and MDC_DIR direction bits to be used as output pins. */

		/* A "1" is shifted out to the PHY by setting the MDIO bit to

		 * "1" and then raising and lowering the Management Data Clock.

		 * A "0" is shifted out to the PHY by setting the MDIO bit to

		 * "0" and then raising and lowering the clock.

/**

 * e1000_shift_in_mdi_bits - Shifts data bits in from the PHY

 * @hw: Struct containing variables accessed by shared code

 *

 * Bits are shifted in MSB to LSB order.

	/* In order to read a register from the PHY, we need to shift in a total

	 * of 18 bits from the PHY. The first two bit (turnaround) times are

	 * used to avoid contention on the MDIO pin when a read operation is

	 * performed. These two bits are ignored by us and thrown away. Bits are

	 * "shifted in" by raising the input to the Management Data Clock

	 * (setting the MDC bit), and then reading the value of the MDIO bit.

	/* Clear MDIO_DIR (SWDPIO1) to indicate this bit is to be used as

	 * input.

	/* Raise and Lower the clock before reading in the data. This accounts

	 * for the turnaround bits. The first clock occurred when we clocked out

	 * the last bit of the Register Address.

 Check to see if we shifted in a "1". */

/**

 * e1000_read_phy_reg - read a phy register

 * @hw: Struct containing variables accessed by shared code

 * @reg_addr: address of the PHY register to read

 * @phy_data: pointer to the value on the PHY register

 *

 * Reads the value from a PHY register, if the value is on a specific non zero

 * page, sets the page first.

		/* Set up Op-code, Phy Address, and register address in the MDI

		 * Control register.  The MAC will take care of interfacing with

		 * the PHY to retrieve the desired data.

			/* Poll the ready bit to see if the MDI read

			 * completed

			/* Poll the ready bit to see if the MDI read

			 * completed

		/* We must first send a preamble through the MDIO pin to signal

		 * the beginning of an MII instruction.  This is done by sending

		 * 32 consecutive "1" bits.

		/* Now combine the next few fields that are required for a read

		 * operation.  We use this method instead of calling the

		 * e1000_shift_out_mdi_bits routine five different times. The

		 * format of a MII read instruction consists of a shift out of

		 * 14 bits and is defined as follows:

		 *    <Preamble><SOF><Op Code><Phy Addr><Reg Addr>

		 * followed by a shift in of 18 bits.  This first two bits

		 * shifted in are TurnAround bits used to avoid contention on

		 * the MDIO pin when a READ operation is performed.  These two

		 * bits are thrown away followed by a shift in of 16 bits which

		 * contains the desired data.

		/* Now that we've shifted out the read command to the MII, we

		 * need to "shift in" the 16-bit value (18 total bits) of the

		 * requested PHY register address.

/**

 * e1000_write_phy_reg - write a phy register

 *

 * @hw: Struct containing variables accessed by shared code

 * @reg_addr: address of the PHY register to write

 * @phy_data: data to write to the PHY

 *

 * Writes a value to a PHY register

		/* Set up Op-code, Phy Address, register address, and data

		 * intended for the PHY register in the MDI Control register.

		 * The MAC will take care of interfacing with the PHY to send

		 * the desired data.

			/* Poll the ready bit to see if the MDI read

			 * completed

			/* Poll the ready bit to see if the MDI read

			 * completed

		/* We'll need to use the SW defined pins to shift the write

		 * command out to the PHY. We first send a preamble to the PHY

		 * to signal the beginning of the MII instruction.  This is done

		 * by sending 32 consecutive "1" bits.

		/* Now combine the remaining required fields that will indicate

		 * a write operation. We use this method instead of calling the

		 * e1000_shift_out_mdi_bits routine for each field in the

		 * command. The format of a MII write instruction is as follows:

		 * <Preamble><SOF><OpCode><PhyAddr><RegAddr><Turnaround><Data>.

/**

 * e1000_phy_hw_reset - reset the phy, hardware style

 * @hw: Struct containing variables accessed by shared code

 *

 * Returns the PHY to the power-on reset state

		/* Read the device control register and assert the

		 * E1000_CTRL_PHY_RST bit. Then, take it out of reset.

		 * For e1000 hardware, we delay for 10ms between the assert

		 * and de-assert.

		/* Read the Extended Device Control Register, assert the

		 * PHY_RESET_DIR bit to put the PHY into reset. Then, take it

		 * out of reset.

 Configure activity LED after PHY reset */

 Wait for FW to finish PHY configuration. */

/**

 * e1000_phy_reset - reset the phy to commit settings

 * @hw: Struct containing variables accessed by shared code

 *

 * Resets the PHY

 * Sets bit 15 of the MII Control register

/**

 * e1000_detect_gig_phy - check the phy type

 * @hw: Struct containing variables accessed by shared code

 *

 * Probes the expected PHY address for known PHY IDs

 Read the PHY ID Registers to identify which PHY is onboard. */

/**

 * e1000_phy_reset_dsp - reset DSP

 * @hw: Struct containing variables accessed by shared code

 *

 * Resets the PHY's DSP

/**

 * e1000_phy_igp_get_info - get igp specific registers

 * @hw: Struct containing variables accessed by shared code

 * @phy_info: PHY information structure

 *

 * Get PHY information from various PHY registers for igp PHY only.

	/* The downshift status is checked only once, after link is established,

	 * and it stored in the hw->speed_downgraded parameter.

 IGP01E1000 does not need to support it. */

 IGP01E1000 always correct polarity reversal */

 Check polarity status */

		/* Local/Remote Receiver Information are only valid @ 1000

		 * Mbps

 Get cable length */

 Translate to old method */

/**

 * e1000_phy_m88_get_info - get m88 specific registers

 * @hw: Struct containing variables accessed by shared code

 * @phy_info: PHY information structure

 *

 * Get PHY information from various PHY registers for m88 PHY only.

	/* The downshift status is checked only once, after link is established,

	 * and it stored in the hw->speed_downgraded parameter.

 Check polarity status */

		/* Cable Length Estimation and Local/Remote Receiver Information

		 * are only valid at 1000 Mbps.

/**

 * e1000_phy_get_info - request phy info

 * @hw: Struct containing variables accessed by shared code

 * @phy_info: PHY information structure

 *

 * Get PHY information from various PHY registers

/**

 * e1000_init_eeprom_params - initialize sw eeprom vars

 * @hw: Struct containing variables accessed by shared code

 *

 * Sets up eeprom variables in the hw struct.  Must be called after mac_type

 * is configured.

		/* eeprom_size will be an enum [0..8] that maps to eeprom sizes

		 * 128B to 32KB (incremented by powers of 2).

 Set to default value for initial eeprom read. */

		/* 256B eeprom size was not supported in earlier hardware, so we

		 * bump eeprom_size up one to ensure that "1" (which maps to

		 * 256B) is never the result used in the shifting logic below.

/**

 * e1000_raise_ee_clk - Raises the EEPROM's clock input.

 * @hw: Struct containing variables accessed by shared code

 * @eecd: EECD's current value

	/* Raise the clock input to the EEPROM (by setting the SK bit), and then

	 * wait <delay> microseconds.

/**

 * e1000_lower_ee_clk - Lowers the EEPROM's clock input.

 * @hw: Struct containing variables accessed by shared code

 * @eecd: EECD's current value

	/* Lower the clock input to the EEPROM (by clearing the SK bit), and

	 * then wait 50 microseconds.

/**

 * e1000_shift_out_ee_bits - Shift data bits out to the EEPROM.

 * @hw: Struct containing variables accessed by shared code

 * @data: data to send to the EEPROM

 * @count: number of bits to shift out

	/* We need to shift "count" bits out to the EEPROM. So, value in the

	 * "data" parameter will be shifted out to the EEPROM one bit at a time.

	 * In order to do this, "data" must be broken down into bits.

		/* A "1" is shifted out to the EEPROM by setting bit "DI" to a

		 * "1", and then raising and then lowering the clock (the SK bit

		 * controls the clock input to the EEPROM).  A "0" is shifted

		 * out to the EEPROM by setting "DI" to "0" and then raising and

		 * then lowering the clock.

 We leave the "DI" bit set to "0" when we leave this routine. */

/**

 * e1000_shift_in_ee_bits - Shift data bits in from the EEPROM

 * @hw: Struct containing variables accessed by shared code

 * @count: number of bits to shift in

	/* In order to read a register from the EEPROM, we need to shift 'count'

	 * bits in from the EEPROM. Bits are "shifted in" by raising the clock

	 * input to the EEPROM (setting the SK bit), and then reading the value

	 * of the "DO" bit.  During this "shifting in" process the "DI" bit

	 * should always be clear.

/**

 * e1000_acquire_eeprom - Prepares EEPROM for access

 * @hw: Struct containing variables accessed by shared code

 *

 * Lowers EEPROM clock. Clears input pin. Sets the chip select pin. This

 * function should be called before issuing a command to the EEPROM.

 Request EEPROM Access */

 Setup EEPROM for Read/Write */

 Clear SK and DI */

 Set CS */

 Clear SK and CS */

/**

 * e1000_standby_eeprom - Returns EEPROM to a "standby" state

 * @hw: Struct containing variables accessed by shared code

 Clock high */

 Select EEPROM */

 Clock low */

 Toggle CS to flush commands */

/**

 * e1000_release_eeprom - drop chip select

 * @hw: Struct containing variables accessed by shared code

 *

 * Terminates a command by inverting the EEPROM's chip select pin

 Pull CS high */

 Lower SCK */

 cleanup eeprom */

 CS on Microwire is active-high */

 Rising edge of clock */

 Falling edge of clock */

 Stop requesting EEPROM access */

/**

 * e1000_spi_eeprom_ready - Reads a 16 bit word from the EEPROM.

 * @hw: Struct containing variables accessed by shared code

	/* Read "Status Register" repeatedly until the LSB is cleared.  The

	 * EEPROM will signal that the command has been completed by clearing

	 * bit 0 of the internal status register.  If it's not cleared within

	 * 5 milliseconds, then error out.

	/* ATMEL SPI write time could vary from 0-20mSec on 3.3V devices (and

	 * only 0-5mSec on 5V devices)

/**

 * e1000_read_eeprom - Reads a 16 bit word from the EEPROM.

 * @hw: Struct containing variables accessed by shared code

 * @offset: offset of  word in the EEPROM to read

 * @data: word read from the EEPROM

 * @words: number of words to read

	/* A check for invalid values:  offset too large, too many words, and

	 * not enough words.

	/* EEPROM's that don't use EERD to read require us to bit-bang the SPI

	 * directly. In this case, we need to acquire the EEPROM so that

	 * FW or other port software does not interrupt.

 Prepare the EEPROM for bit-bang reading */

	/* Set up the SPI or Microwire EEPROM for bit-bang reading.  We have

	 * acquired the EEPROM at this point, so any returns should release it

		/* Some SPI eeproms use the 8th address bit embedded in the

		 * opcode

 Send the READ command (opcode + addr)  */

		/* Read the data.  The address of the eeprom internally

		 * increments with each byte (spi) being read, saving on the

		 * overhead of eeprom setup and tear-down.  The address counter

		 * will roll over if reading beyond the size of the eeprom, thus

		 * allowing the entire memory to be read starting from any

		 * offset.

 Send the READ command (opcode + addr)  */

			/* Read the data.  For microwire, each word requires the

			 * overhead of eeprom setup and tear-down.

 End this read operation */

/**

 * e1000_validate_eeprom_checksum - Verifies that the EEPROM has a valid checksum

 * @hw: Struct containing variables accessed by shared code

 *

 * Reads the first 64 16 bit words of the EEPROM and sums the values read.

 * If the sum of the 64 16 bit words is 0xBABA, the EEPROM's checksum is

 * valid.

 This is a signature and not a checksum on HP c8000 */

/**

 * e1000_update_eeprom_checksum - Calculates/writes the EEPROM checksum

 * @hw: Struct containing variables accessed by shared code

 *

 * Sums the first 63 16 bit words of the EEPROM. Subtracts the sum from 0xBABA.

 * Writes the difference to word offset 63 of the EEPROM.

/**

 * e1000_write_eeprom - write words to the different EEPROM types.

 * @hw: Struct containing variables accessed by shared code

 * @offset: offset within the EEPROM to be written to

 * @words: number of words to write

 * @data: 16 bit word to be written to the EEPROM

 *

 * If e1000_update_eeprom_checksum is not called after this function, the

 * EEPROM will most likely contain an invalid checksum.

	/* A check for invalid values:  offset too large, too many words, and

	 * not enough words.

 Prepare the EEPROM for writing  */

 Done with writing */

/**

 * e1000_write_eeprom_spi - Writes a 16 bit word to a given offset in an SPI EEPROM.

 * @hw: Struct containing variables accessed by shared code

 * @offset: offset within the EEPROM to be written to

 * @words: number of words to write

 * @data: pointer to array of 8 bit words to be written to the EEPROM

  Send the WRITE ENABLE command (8 bit opcode )  */

		/* Some SPI eeproms use the 8th address bit embedded in the

		 * opcode

 Send the Write command (8-bit opcode + addr) */

 Send the data */

		/* Loop to allow for up to whole page write (32 bytes) of

		 * eeprom

			/* Some larger eeprom sizes are capable of a 32-byte

			 * PAGE WRITE operation, while the smaller eeproms are

			 * capable of an 8-byte PAGE WRITE operation.  Break the

			 * inner loop to pass new address

/**

 * e1000_write_eeprom_microwire - Writes a 16 bit word to a given offset in a Microwire EEPROM.

 * @hw: Struct containing variables accessed by shared code

 * @offset: offset within the EEPROM to be written to

 * @words: number of words to write

 * @data: pointer to array of 8 bit words to be written to the EEPROM

	/* Send the write enable command to the EEPROM (3-bit opcode plus

	 * 6/8-bit dummy address beginning with 11).  It's less work to include

	 * the 11 of the dummy address as part of the opcode than it is to shift

	 * it over the correct number of bits for the address.  This puts the

	 * EEPROM into write/erase mode.

 Prepare the EEPROM */

 Send the Write command (3-bit opcode + addr) */

 Send the data */

		/* Toggle the CS line.  This in effect tells the EEPROM to

		 * execute the previous command.

		/* Read DO repeatedly until it is high (equal to '1').  The

		 * EEPROM will signal that the command has been completed by

		 * raising the DO signal. If DO does not go high in 10

		 * milliseconds, then error out.

 Recover from write */

	/* Send the write disable command to the EEPROM (3-bit opcode plus

	 * 6/8-bit dummy address beginning with 10).  It's less work to include

	 * the 10 of the dummy address as part of the opcode than it is to shift

	 * it over the correct number of bits for the address.  This takes the

	 * EEPROM out of write/erase mode.

/**

 * e1000_read_mac_addr - read the adapters MAC from eeprom

 * @hw: Struct containing variables accessed by shared code

 *

 * Reads the adapter's MAC address from the EEPROM and inverts the LSB for the

 * second function of dual function devices

/**

 * e1000_init_rx_addrs - Initializes receive address filters.

 * @hw: Struct containing variables accessed by shared code

 *

 * Places the MAC address in receive address register 0 and clears the rest

 * of the receive address registers. Clears the multicast table. Assumes

 * the receiver is in reset when the routine is called.

 Setup the receive address. */

	/* Zero out the following 14 receive addresses. RAR[15] is for

	 * manageability

/**

 * e1000_hash_mc_addr - Hashes an address to determine its location in the multicast table

 * @hw: Struct containing variables accessed by shared code

 * @mc_addr: the multicast address to hash

	/* The portion of the address that is used for the hash table is

	 * determined by the mc_filter_type setting.

		/* [0] [1] [2] [3] [4] [5]

		 * 01  AA  00  12  34  56

		 * LSB                 MSB

 [47:36] i.e. 0x563 for above example address */

 [46:35] i.e. 0xAC6 for above example address */

 [45:34] i.e. 0x5D8 for above example address */

 [43:32] i.e. 0x634 for above example address */

/**

 * e1000_rar_set - Puts an ethernet address into a receive address register.

 * @hw: Struct containing variables accessed by shared code

 * @addr: Address to put into receive address register

 * @index: Receive address register to write

	/* HW expects these in little endian so we reverse the byte order

	 * from network order (big endian) to little endian

	/* Disable Rx and flush all Rx frames before enabling RSS to avoid Rx

	 * unit hang.

	 *

	 * Description:

	 * If there are any Rx frames queued up or otherwise present in the HW

	 * before RSS is enabled, and then we enable RSS, the HW Rx unit will

	 * hang.  To work around this issue, we have to disable receives and

	 * flush out all Rx frames before we enable RSS. To do so, we modify we

	 * redirect all Rx traffic to manageability and then reset the HW.

	 * This flushes away Rx frames, and (since the redirections to

	 * manageability persists across resets) keeps new ones from coming in

	 * while we work.  Then, we clear the Address Valid AV bit for all MAC

	 * addresses and undo the re-direction to manageability.

	 * Now, frames are coming in again, but the MAC won't accept them, so

	 * far so good.  We now proceed to initialize RSS (if necessary) and

	 * configure the Rx unit.  Last, we re-enable the AV bits and continue

	 * on our merry way.

 Indicate to hardware the Address is Valid. */

/**

 * e1000_write_vfta - Writes a value to the specified offset in the VLAN filter table.

 * @hw: Struct containing variables accessed by shared code

 * @offset: Offset in VLAN filer table to write

 * @value: Value to write into VLAN filter table

/**

 * e1000_clear_vfta - Clears the VLAN filer table

 * @hw: Struct containing variables accessed by shared code

 Nothing to do */

 Do nothing */

 Do nothing */

/**

 * e1000_setup_led

 * @hw: Struct containing variables accessed by shared code

 *

 * Prepares SW controlable LED for use and saves the current state of the LED.

 No setup necessary */

 Turn off PHY Smart Power Down (if enabled) */

 Save current LEDCTL settings */

 Turn off LED0 */

/**

 * e1000_cleanup_led - Restores the saved state of the SW controlable LED.

 * @hw: Struct containing variables accessed by shared code

 No cleanup necessary */

 Turn on PHY Smart Power Down (if previously enabled) */

 Restore LEDCTL settings */

/**

 * e1000_led_on - Turns on the software controllable LED

 * @hw: Struct containing variables accessed by shared code

 Set SW Defineable Pin 0 to turn on the LED */

 Set SW Defineable Pin 0 to turn on the LED */

 Clear SW Defineable Pin 0 to turn on the LED */

 Clear SW Defineable Pin 0 to turn on the LED */

/**

 * e1000_led_off - Turns off the software controllable LED

 * @hw: Struct containing variables accessed by shared code

 Clear SW Defineable Pin 0 to turn off the LED */

 Clear SW Defineable Pin 0 to turn off the LED */

 Set SW Defineable Pin 0 to turn off the LED */

 Set SW Defineable Pin 0 to turn off the LED */

/**

 * e1000_clear_hw_cntrs - Clears all hardware statistics counters.

 * @hw: Struct containing variables accessed by shared code

/**

 * e1000_reset_adaptive - Resets Adaptive IFS to its default state.

 * @hw: Struct containing variables accessed by shared code

 *

 * Call this after e1000_init_hw. You may override the IFS defaults by setting

 * hw->ifs_params_forced to true. However, you must initialize hw->

 * current_ifs_val, ifs_min_val, ifs_max_val, ifs_step_size, and ifs_ratio

 * before calling this function.

/**

 * e1000_update_adaptive - update adaptive IFS

 * @hw: Struct containing variables accessed by shared code

 *

 * Called during the callback/watchdog routine to update IFS value based on

 * the ratio of transmits to collisions.

/**

 * e1000_get_bus_info

 * @hw: Struct containing variables accessed by shared code

 *

 * Gets the current PCI bus type, speed, and width of the hardware

/**

 * e1000_write_reg_io

 * @hw: Struct containing variables accessed by shared code

 * @offset: offset to write to

 * @value: value to write

 *

 * Writes a value to one of the devices registers using port I/O (as opposed to

 * memory mapped I/O). Only 82544 and newer devices support port I/O.

/**

 * e1000_get_cable_length - Estimates the cable length.

 * @hw: Struct containing variables accessed by shared code

 * @min_length: The estimated minimum length

 * @max_length: The estimated maximum length

 *

 * returns: - E1000_ERR_XXX

 *            E1000_SUCCESS

 *

 * This function always returns a ranged length (minimum & maximum).

 * So for M88 phy's, this function interprets the one value returned from the

 * register to the minimum and maximum range.

 * For IGP phy's, the function calculates the range by the AGC registers.

 Use old method for Phy older than IGP */

 Convert the enum value to ranged values */

 For IGP PHY */

 Read the AGC registers for all channels */

 Value bound check. */

 Update minimal AGC value. */

 Remove the minimal AGC result for length < 50m */

 Get the average length of the remaining 3 channels */

 Get the average length of all the 4 channels. */

 Set the range of the calculated length. */

/**

 * e1000_check_polarity - Check the cable polarity

 * @hw: Struct containing variables accessed by shared code

 * @polarity: output parameter : 0 - Polarity is not reversed

 *                               1 - Polarity is reversed.

 *

 * returns: - E1000_ERR_XXX

 *            E1000_SUCCESS

 *

 * For phy's older than IGP, this function simply reads the polarity bit in the

 * Phy Status register.  For IGP phy's, this bit is valid only if link speed is

 * 10 Mbps.  If the link speed is 100 Mbps there is no polarity so this bit will

 * return 0.  If the link speed is 1000 Mbps the polarity status is in the

 * IGP01E1000_PHY_PCS_INIT_REG.

 return the Polarity bit in the Status register. */

 Read the Status register to check the speed */

		/* If speed is 1000 Mbps, must read the

		 * IGP01E1000_PHY_PCS_INIT_REG to find the polarity status

 Read the GIG initialization PCS register (0x00B4) */

 Check the polarity bits */

			/* For 10 Mbps, read the polarity bit in the status

			 * register. (for 100 Mbps this bit is always 0)

/**

 * e1000_check_downshift - Check if Downshift occurred

 * @hw: Struct containing variables accessed by shared code

 *

 * returns: - E1000_ERR_XXX

 *            E1000_SUCCESS

 *

 * For phy's older than IGP, this function reads the Downshift bit in the Phy

 * Specific Status register.  For IGP phy's, it reads the Downgrade bit in the

 * Link Health register.  In IGP this bit is latched high, so the driver must

 * read it immediately after link is established.

 clear previous idle error counts */

/**

 * e1000_config_dsp_after_link_change

 * @hw: Struct containing variables accessed by shared code

 * @link_up: was link up at the time this was called

 *

 * returns: - E1000_ERR_PHY if fail to read/write the PHY

 *            E1000_SUCCESS at any other case.

 *

 * 82541_rev_2 & 82547_rev_2 have the capability to configure the DSP when a

 * gigabit link is achieved to improve link quality.

			/* Save off the current value of register 0x2F5B to be

			 * restored at the end of the routines.

 Disable the PHY transmitter */

 Now enable the transmitter */

			/* Save off the current value of register 0x2F5B to be

			 * restored at the end of the routines.

 Disable the PHY transmitter */

 Now enable the transmitter */

/**

 * e1000_set_phy_mode - Set PHY to class A mode

 * @hw: Struct containing variables accessed by shared code

 *

 * Assumes the following operations will follow to enable the new class mode.

 *  1. Do a PHY soft reset

 *  2. Restart auto-negotiation or force link.

/**

 * e1000_set_d3_lplu_state - set d3 link power state

 * @hw: Struct containing variables accessed by shared code

 * @active: true to enable lplu false to disable lplu.

 *

 * This function sets the lplu state according to the active flag.  When

 * activating lplu this function also disables smart speed and vise versa.

 * lplu will not be activated unless the device autonegotiation advertisement

 * meets standards of either 10 or 10/100 or 10/100/1000 at all duplexes.

 *

 * returns: - E1000_ERR_PHY if fail to read/write the PHY

 *            E1000_SUCCESS at any other case.

	/* During driver activity LPLU should not be used or it will attain link

	 * from the lowest speeds starting from 10Mbps. The capability is used

	 * for Dx transitions and states

		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used

		 * during Dx states where the power conservation is most

		 * important.  During driver activity we should enable

		 * SmartSpeed, so performance is maintained.

 When LPLU is enabled we should disable SmartSpeed */

/**

 * e1000_set_vco_speed

 * @hw: Struct containing variables accessed by shared code

 *

 * Change VCO speed register to improve Bit Error Rate performance of SERDES.

 Set PHY register 30, page 5, bit 8 to 0 */

 Set PHY register 30, page 4, bit 11 to 1 */

/**

 * e1000_enable_mng_pass_thru - check for bmc pass through

 * @hw: Struct containing variables accessed by shared code

 *

 * Verifies the hardware needs to allow ARPs to be processed by the host

 * returns: - true/false

 Polarity reversal workaround for forced 10F/10H links. */

 Disable the transmitter on the PHY */

 This loop will early-out if the NO link condition has been met. */

		/* Read the MII Status Register and wait for Link Status bit

		 * to be clear.

 Recommended delay time after link has been lost */

 Now we will re-enable th transmitter on the PHY */

 This loop will early-out if the link condition has been met. */

		/* Read the MII Status Register and wait for Link Status bit

		 * to be set.

/**

 * e1000_get_auto_rd_done

 * @hw: Struct containing variables accessed by shared code

 *

 * Check for EEPROM Auto Read bit done.

 * returns: - E1000_ERR_RESET if fail to reset MAC

 *            E1000_SUCCESS at any other case.

/**

 * e1000_get_phy_cfg_done

 * @hw: Struct containing variables accessed by shared code

 *

 * Checks if the PHY configuration is done

 * returns: - E1000_ERR_RESET if fail to reset MAC

 *            E1000_SUCCESS at any other case.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2006 Intel Corporation. */

/* e1000_pci_tbl - PCI Device ID Table

 *

 * Last entry must be all 0s

 *

 * Macro expands to...

 *   {PCI_DEVICE(PCI_VENDOR_ID_INTEL, device_id)}

 required last entry */

 for netdump / net console */

/**

 * e1000_get_hw_dev - helper function for getting netdev

 * @hw: pointer to HW struct

 *

 * return device used by hardware layer to print debugging information

 *

/**

 * e1000_init_module - Driver Registration Routine

 *

 * e1000_init_module is the first routine called when the driver is

 * loaded. All it does is register with the PCI subsystem.

/**

 * e1000_exit_module - Driver Exit Cleanup Routine

 *

 * e1000_exit_module is called just before the driver is removed

 * from memory.

/**

 * e1000_irq_disable - Mask off interrupt generation on the NIC

 * @adapter: board private structure

/**

 * e1000_irq_enable - Enable default interrupt generation settings

 * @adapter: board private structure

 disable hardware interception of ARP */

 re-enable hardware interception of ARP */

/**

 * e1000_configure - configure the hardware for RX and TX

 * @adapter: private board structure

	/* call E1000_DESC_UNUSED which always leaves

	 * at least 1 descriptor unused to make sure

	 * next_to_use != next_to_clean

 hardware has been reset, we need to reload some things */

 fire a link change interrupt to start the watchdog */

/**

 * e1000_power_up_phy - restore link in case the phy was powered down

 * @adapter: address of board private structure

 *

 * The phy may be powered down to save power and turn off link when the

 * driver is unloaded and wake on lan is not enabled (among others)

 * *** this routine MUST be followed by a call to e1000_reset ***

 Just clear the power down bit to wake the phy back up */

		/* according to the manual, the phy will retain its

		 * settings across a power-down/up cycle

	/* Power down the PHY so no link is implied when interface is down *

	 * The PHY cannot be powered down if any of the following is true *

	 * (a) WoL is enabled

	 * (b) AMT is active

	 * (c) SoL/IDER session is active

	/*

	 * Since the watchdog task can reschedule other tasks, we should cancel

	 * it first, otherwise we can run into the situation when a work is

	 * still running after the adapter has been turned down.

 Only kill reset task if adapter is not resetting */

 disable receives in the hardware */

 flush and sleep below */

 disable transmits in the hardware */

 flush both disables and wait for them to finish */

	/* Set the carrier off after transmits have been disabled in the

	 * hardware, to avoid race conditions with e1000_watchdog() (which

	 * may be running concurrently to us, checking for the carrier

	 * bit to decide whether it should enable transmits again). Such

	 * a race condition would result into transmission being disabled

	 * in the hardware until the next IFF_DOWN+IFF_UP cycle.

	/* Setting DOWN must be after irq_disable to prevent

	 * a screaming interrupt.  Setting DOWN also prevents

	 * tasks from rescheduling.

 only run the task if not already down */

	/* Repartition Pba for greater than 9k mtu

	 * To take effect CTRL.RST is required.

 allocate more FIFO for Tx */

 adjust PBA for jumbo frames */

		/* To maintain wire speed transmits, the Tx FIFO should be

		 * large enough to accommodate two full transmit packets,

		 * rounded up to the next 1KB and expressed in KB.  Likewise,

		 * the Rx FIFO should be large enough to accommodate at least

		 * one full receive packet and is similarly rounded up and

		 * expressed in KB.

 upper 16 bits has Tx packet buffer allocation size in KB */

 lower 16 bits has Rx packet buffer allocation size in KB */

		/* the Tx fifo also stores 16 bytes of information about the Tx

		 * but don't include ethernet FCS because hardware appends it

 software strips receive CRC, so leave room for it */

		/* If current Tx allocation is less than the min Tx FIFO size,

		 * and the min Tx FIFO size is less than the current Rx FIFO

		 * allocation, take space away from current Rx allocation

 PCI/PCIx hardware has PBA alignment constraints */

			/* if short on Rx space, Rx wins and must trump Tx

			 * adjustment or use Early Receive if available

	/* flow control settings:

	 * The high water mark must be low enough to fit one full frame

	 * (or the size used for early receive) above it in the Rx FIFO.

	 * Set it to the lower of:

	 * - 90% of the Rx FIFO size, and

	 * - the full Rx FIFO size minus the early receive size (for parts

	 *   with ERT support assuming ERT set to E1000_ERT_2048), or

	 * - the full Rx FIFO size minus one full frame

 8-byte granularity */

 Allow time for pending master requests to run */

 if (adapter->hwflags & HWFLAGS_PHY_PWR_BIT) { */

		/* clear phy power management bit if we are in gig only mode,

		 * which if enabled will attempt negotiation to 100Mb, which

		 * can cause a loss of link at power off or driver unload

 Enable h/w to recognize an 802.1Q VLAN Ethernet packet */

 Dump the eeprom for users having checksum issues */

********************/\n");

********************/\n");

/**

 * e1000_is_need_ioport - determine if an adapter needs ioport resources or not

 * @pdev: PCI device information struct

 *

 * Return true if an adapter needs ioport resources

	/* Since there is no support for separate Rx/Tx vlan accel

	 * enable/disable make sure Tx flag is always in same state as Rx.

/**

 * e1000_init_hw_struct - initialize members of hw struct

 * @adapter: board private struct

 * @hw: structure used by e1000_hw.c

 *

 * Factors out initialization of the e1000_hw struct to its own function

 * that can be called very early at init (just after struct allocation).

 * Fields are initialized based on PCI device information and

 * OS network device settings (MTU size).

 * Returns negative error codes if MAC type setup fails.

 PCI config space info */

 identify the MAC */

 Copper options */

/**

 * e1000_probe - Device Initialization Routine

 * @pdev: PCI device information struct

 * @ent: entry in e1000_pci_tbl

 *

 * Returns 0 on success, negative on failure

 *

 * e1000_probe initializes an adapter identified by a pci_dev structure.

 * The OS initialization, configuring of the adapter private structure,

 * and a hardware reset occur.

 global ksp3 port a indication */

 do not allocate ioport bars when not needed */

 make ready for any if (hw->...) below */

	/* there is a workaround being applied below that limits

	 * 64-bit DMA addresses to 64-bit hardware.  There are some

	 * 32-bit adapters that Tx hang when given 64-bit DMA addresses

 setup the private structure */

 Do not set IFF_UNICAST_FLT for VMWare's 82545EM */

 MTU range: 46 - 16110 */

 initialize eeprom parameters */

	/* before reading the EEPROM, reset the controller to

	 * put the device in a known good starting state

 make sure the EEPROM is good */

		/* set MAC address to all zeroes to invalidate and temporary

		 * disable this device for the user. This blocks regular

		 * traffic while still permitting ethtool ioctls from reaching

		 * the hardware as well as allowing the user to run the

		 * interface after manually setting a hw addr using

		 * `ip set address`

 copy the MAC address out of the EEPROM */

 don't block initialization here due to bad MAC address */

	/* Initial Wake on LAN setting

	 * If APM wake is enabled in the EEPROM,

	 * enable the ACPI Magic Packet filter

	/* now that we have the eeprom settings, apply the special cases

	 * where the eeprom may be wrong or the board simply won't support

	 * wake on lan on a particular port

		/* Wake events only supported on port A for dual fiber

		 * regardless of eeprom setting

 if quad port adapter, disable WoL on all but port A */

 Reset for multiple quad port adapters */

 initialize the wol settings based on the eeprom settings */

 Auto detect PHY address */

 reset the hardware with the new settings */

 print bus type/speed/width info */

 carrier off reporting is important to ethtool even BEFORE open */

/**

 * e1000_remove - Device Removal Routine

 * @pdev: PCI device information struct

 *

 * e1000_remove is called by the PCI subsystem to alert the driver

 * that it should release a PCI device. That could be caused by a

 * Hot-Plug event, or because the driver is going to be removed from

 * memory.

/**

 * e1000_sw_init - Initialize general software structures (struct e1000_adapter)

 * @adapter: board private structure to initialize

 *

 * e1000_sw_init initializes the Adapter private data structure.

 * e1000_init_hw_struct MUST be called before this function

 Explicitly disable IRQ since the NIC can be in any state. */

/**

 * e1000_alloc_queues - Allocate memory for all rings

 * @adapter: board private structure to initialize

 *

 * We allocate one ring per queue at run-time since we don't know the

 * number of queues at compile-time.

/**

 * e1000_open - Called when a network interface is made active

 * @netdev: network interface device structure

 *

 * Returns 0 on success, negative value on failure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP).  At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the watchdog task is started,

 * and the stack is notified that the interface is ready.

 disallow open during test */

 allocate transmit descriptors */

 allocate receive descriptors */

	/* before we allocate an interrupt, we must be ready to handle it.

	 * Setting DEBUG_SHIRQ in the kernel makes it fire an interrupt

	 * as soon as we call pci_request_irq, so we have to setup our

	 * clean_rx handler before we do so.

 From here on the code is the same as e1000_up() */

 fire a link status change interrupt to start the watchdog */

/**

 * e1000_close - Disables a network interface

 * @netdev: network interface device structure

 *

 * Returns 0, this is not allowed to fail

 *

 * The close entry point is called when an interface is de-activated

 * by the OS.  The hardware is still under the drivers control, but

 * needs to be disabled.  A global MAC reset is issued to stop the

 * hardware, and all transmit and receive resources are freed.

 signal that we're down so that the reset task will no longer run */

	/* kill manageability vlan ID if supported, but not if a vlan with

	 * the same ID is registered on the host OS (let 8021q kill it)

/**

 * e1000_check_64k_bound - check that memory doesn't cross 64kB boundary

 * @adapter: address of board private structure

 * @start: address of beginning of memory

 * @len: length of memory

	/* First rev 82545 and 82546 need to not allow any memory

	 * write location to cross 64k boundary due to errata 23

/**

 * e1000_setup_tx_resources - allocate Tx resources (Descriptors)

 * @adapter: board private structure

 * @txdr:    tx descriptor ring (for a specific queue) to setup

 *

 * Return 0 on success, negative on failure

 round up to nearest 4K */

 Fix for errata 23, can't cross 64kB boundary */

 Try again, without freeing the previous */

 Failed allocation, critical failure */

 give up */

 Free old allocation, new allocation was successful */

/**

 * e1000_setup_all_tx_resources - wrapper to allocate Tx resources

 * 				  (Descriptors) for all queues

 * @adapter: board private structure

 *

 * Return 0 on success, negative on failure

/**

 * e1000_configure_tx - Configure 8254x Transmit Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Tx unit of the MAC after a reset.

 Setup the HW Tx Head and Tail descriptor pointers */

 Set the default values for the Tx Inter Packet Gap timer */

 Set the Tx Interrupt Delay register */

 Program the Transmit Control Register */

 Setup Transmit Descriptor Settings for eop descriptor */

 only set IDE if we are delaying interrupts using the timers */

	/* Cache if we're 82544 running in PCI-X because we'll

	 * need this to apply a workaround later in the send path.

/**

 * e1000_setup_rx_resources - allocate Rx resources (Descriptors)

 * @adapter: board private structure

 * @rxdr:    rx descriptor ring (for a specific queue) to setup

 *

 * Returns 0 on success, negative on failure

 Round up to nearest 4K */

 Fix for errata 23, can't cross 64kB boundary */

 Try again, without freeing the previous */

 Failed allocation, critical failure */

 give up */

 Free old allocation, new allocation was successful */

/**

 * e1000_setup_all_rx_resources - wrapper to allocate Rx resources

 * 				  (Descriptors) for all queues

 * @adapter: board private structure

 *

 * Return 0 on success, negative on failure

/**

 * e1000_setup_rctl - configure the receive control registers

 * @adapter: Board private structure

 Setup buffer sizes */

 This is useful for sniffing bad packets. */

		/* UPE and MPE will be handled by normal PROMISC logic

		 * in e1000e_set_rx_mode

 Receive bad packets */

 RX All Bcast Pkts */

 RX All MAC Ctrl Pkts */

 Disable VLAN filter */

 Allow filtered pause */

 Dis VLAN CFIEN Filter */

		/* Do not mess with E1000_CTRL_VME, it affects transmit as well,

		 * and that breaks VLANs.

/**

 * e1000_configure_rx - Configure 8254x Receive Unit after Reset

 * @adapter: board private structure

 *

 * Configure the Rx unit of the MAC after a reset.

 disable receives while setting up the descriptors */

 set the Receive Delay Timer Register */

	/* Setup the HW Rx Head and Tail Descriptor Pointers and

	 * the Base and Length of the Rx Descriptor Ring

 Enable 82543 Receive Checksum Offload for TCP and UDP */

 don't need to clear IPPCSE as it defaults to 0 */

 Enable Receives */

/**

 * e1000_free_tx_resources - Free Tx Resources per Queue

 * @adapter: board private structure

 * @tx_ring: Tx descriptor ring for a specific queue

 *

 * Free all transmit software resources

/**

 * e1000_free_all_tx_resources - Free Tx Resources for All Queues

 * @adapter: board private structure

 *

 * Free all transmit software resources

 buffer_info must be completely set up in the transmit path */

/**

 * e1000_clean_tx_ring - Free Tx Buffers

 * @adapter: board private structure

 * @tx_ring: ring to be cleaned

 Free all the Tx ring sk_buffs */

 Zero out the descriptor ring */

/**

 * e1000_clean_all_tx_rings - Free Tx Buffers for all queues

 * @adapter: board private structure

/**

 * e1000_free_rx_resources - Free Rx Resources

 * @adapter: board private structure

 * @rx_ring: ring to clean the resources from

 *

 * Free all receive software resources

/**

 * e1000_free_all_rx_resources - Free Rx Resources for All Queues

 * @adapter: board private structure

 *

 * Free all receive software resources

/**

 * e1000_clean_rx_ring - Free Rx Buffers per Queue

 * @adapter: board private structure

 * @rx_ring: ring to free buffers from

 Free all the Rx netfrags */

 there also may be some cached data from a chained receive */

 Zero out the descriptor ring */

/**

 * e1000_clean_all_rx_rings - Free Rx Buffers for all queues

 * @adapter: board private structure

/* The 82542 2.0 (revision 2) needs to have the receive unit in reset

 * and memory write and invalidate disabled for certain operations

 No need to loop, because 82542 supports only 1 queue */

/**

 * e1000_set_mac - Change the Ethernet Address of the NIC

 * @netdev: network interface device structure

 * @p: pointer to an address structure

 *

 * Returns 0 on success, negative on failure

 82542 2.0 needs to be in reset to write receive address registers */

/**

 * e1000_set_rx_mode - Secondary Unicast, Multicast and Promiscuous mode set

 * @netdev: network interface device structure

 *

 * The set_rx_mode entry point is called whenever the unicast or multicast

 * address lists or the network interface flags are updated. This routine is

 * responsible for configuring the hardware for proper unicast, multicast,

 * promiscuous mode, and all-multi behavior.

 Check for Promiscuous and All Multicast modes */

 Enable VLAN filter if there is a VLAN */

 82542 2.0 needs to be in reset to write receive address registers */

	/* load the first 14 addresses into the exact filters 1-14. Unicast

	 * addresses take precedence to avoid disabling unicast filtering

	 * when possible.

	 *

	 * RAR 0 is used for the station MAC address

	 * if there are not 14 addresses, go ahead and clear the filters

 load any remaining addresses into the hash table */

	/* write the hash table completely, write from bottom to avoid

	 * both stupid write combining chipsets, and flushing each write

		/* If we are on an 82544 has an errata where writing odd

		 * offsets overwrites the previous even offset, but writing

		 * backwards over the range solves the issue by always

		 * writing the odd offset first

/**

 * e1000_update_phy_info_task - get phy info

 * @work: work struct contained inside adapter struct

 *

 * Need to wait a few seconds after link up to get diagnostic information from

 * the phy

/**

 * e1000_82547_tx_fifo_stall_task - task to complete work

 * @work: work struct contained inside adapter struct

	/* get_link_status is set on LSC (link status) interrupt or rx

	 * sequence error interrupt (except on intel ce4100).

	 * get_link_status will stay false until the

	 * e1000_check_for_link establishes link for copper adapters

	 * ONLY

/**

 * e1000_watchdog - work function

 * @work: work struct contained inside adapter struct

 update snapshot of PHY registers on LSC */

 adjust timeout factor according to speed/duplex */

 maybe add some timeout factor ? */

 enable transmits in the hardware */

			/* We've lost link, so the controller stops DMA,

			 * but we've got queued Tx work that's never going

			 * to get done, so reset controller to flush Tx.

			 * (Do the reset outside of interrupt context).

 exit immediately since reset is imminent */

 Simple mode for Interrupt Throttle Rate (ITR) */

		/* Symmetric Tx/Rx gets a reduced ITR=2000;

		 * Total asymmetrical Tx or Rx gets ITR=8000;

		 * everyone else is between 2000-8000.

 Cause software interrupt to ensure rx ring is cleaned */

 Force detection of hung controller every watchdog period */

 Reschedule the task */

/**

 * e1000_update_itr - update the dynamic ITR value based on statistics

 * @adapter: pointer to adapter

 * @itr_setting: current adapter->itr

 * @packets: the number of packets during this measurement interval

 * @bytes: the number of bytes during this measurement interval

 *

 *      Stores a new ITR value based on packets and byte

 *      counts during the last interrupt.  The advantage of per interrupt

 *      computation is faster updates and more accurate ITR for the current

 *      traffic pattern.  Constants in this function were computed

 *      based on theoretical maximum wire speed and thresholds were set based

 *      on testing data as well as attempting to minimize response time

 *      while increasing bulk throughput.

 *      this functionality is controlled by the InterruptThrottleRate module

 *      parameter (see e1000_param.c)

 jumbo frames get bulk treatment*/

 50 usec aka 20000 ints/s */

 jumbo frames need bulk latency setting */

 250 usec aka 4000 ints/s */

 for non-gigabit speeds, just fix the interrupt rate at 4000 */

 conservative mode (itr 3) eliminates the lowest_latency setting */

 conservative mode (itr 3) eliminates the lowest_latency setting */

 counts and packets in update_itr are dependent on these numbers */

 aka hwitr = ~200 */

		/* this attempts to bias the interrupt rate towards Bulk

		 * by adding intermediate steps when interrupt rate is

		 * increasing

 XXX not handling all IPV6 headers */

		/* Workaround for Controller erratum --

		 * descriptor for non-tso packet in a linear SKB that follows a

		 * tso gets written back prematurely before the data is fully

		 * DMA'd to the controller

		/* Workaround for premature desc write-backs

		 * in TSO mode.  Append 4-byte sentinel desc

		/* work-around for errata 10 and it applies

		 * to all controllers in PCI-X mode

		 * The fix is to make sure that the first descriptor of a

		 * packet is smaller than 2048 - 16 - 16 (or 2016) bytes

		/* Workaround for potential 82544 hang in PCI-X.  Avoid

		 * terminating buffers within evenly-aligned dwords.

 set time_stamp *before* dma to help avoid a possible race */

			/* Workaround for premature desc write-backs

			 * in TSO mode.  Append 4-byte sentinel desc

			/* Workaround for potential 82544 hang in PCI-X.

			 * Avoid terminating buffers within evenly-aligned

			 * dwords.

 multiply data chunks by size of headers */

 txd_cmd re-enables FCS, so we'll re-disable it here as desired. */

	/* Force memory writes to complete before letting h/w

	 * know there are new descriptors to fetch.  (Only

	 * applicable for weak-ordered memory model archs,

	 * such as IA-64).

/* 82547 workaround to avoid controller hang in half-duplex environment.

 * The workaround is to avoid queuing a large packet that would span

 * the internal Tx FIFO ring boundary by notifying the stack to resend

 * the packet at a later time.  This gives the Tx FIFO an opportunity to

 * flush all packets.  When that occurs, we reset the Tx FIFO pointers

 * to the beginning of the Tx FIFO.

	/* Herbert's original patch had:

	 *  smp_mb__after_netif_stop_queue();

	 * but since that doesn't exist yet, just open code it.

	/* We need to check again in a case another CPU has just

	 * made room available.

 A reprieve! */

	/* This goes back to the question of how to logically map a Tx queue

	 * to a flow.  Right now, performance is impacted slightly negatively

	 * if using multiple Tx queues.  If the stack breaks away from a

	 * single qdisc implementation, we can look at this again.

	/* On PCI/PCI-X HW, if packet size is less than ETH_ZLEN,

	 * packets may get corrupted during padding by HW.

	 * To WA this issue, pad all small packets manually.

	/* The controller does a simple calculation to

	 * make sure there is enough room in the FIFO before

	 * initiating the DMA for each buffer.  The calc is:

	 * 4 = ceil(buffer len/mss).  To make sure we don't

	 * overrun the FIFO, adjust the max buffer len if mss

	 * drops.

				/* Make sure we have room to chop off 4 bytes,

				 * and that the end alignment will work out to

				 * this hardware's requirements

				 * NOTE: this is a TSO only workaround

				 * if end byte alignment not correct move us

				 * into the next dword

 do nothing */

 reserve a descriptor for the offload context */

 Controller Erratum workaround */

	/* work-around for errata 10 and it applies to all controllers

	 * in PCI-X mode, so add one more descriptor to the count

	/* need: count + 2 desc gap to keep tail from touching

	 * head, otherwise try next time

		/* The descriptors needed is higher than other Intel drivers

		 * due to a number of workarounds.  The breakdown is below:

		 * Data descriptors: MAX_SKB_FRAGS + 1

		 * Context Descriptor: 1

		 * Keep head from touching tail: 2

		 * Workarounds: 3

		/* 82544 potentially requires twice as many data descriptors

		 * in order to guarantee buffers don't end on evenly-aligned

		 * dwords

 Make sure there is space in the ring for the next send. */

 1 based count */

/*

 * e1000_dump: Print registers, tx ring and rx ring

 this code doesn't handle multiple rings */

 Print Registers */

 transmit dump */

	/* Transmit Descriptor Formats - DEXT[29] is 0 (Legacy) or 1 (Extended)

	 *

	 * Legacy Transmit Descriptor

	 *   +--------------------------------------------------------------+

	 * 0 |         Buffer Address [63:0] (Reserved on Write Back)       |

	 *   +--------------------------------------------------------------+

	 * 8 | Special  |    CSS     | Status |  CMD    |  CSO   |  Length  |

	 *   +--------------------------------------------------------------+

	 *   63       48 47        36 35    32 31     24 23    16 15        0

	 *

	 * Extended Context Descriptor (DTYP=0x0) for TSO or checksum offload

	 *   63      48 47    40 39       32 31             16 15    8 7      0

	 *   +----------------------------------------------------------------+

	 * 0 |  TUCSE  | TUCS0  |   TUCSS   |     IPCSE       | IPCS0 | IPCSS |

	 *   +----------------------------------------------------------------+

	 * 8 |   MSS   | HDRLEN | RSV | STA | TUCMD | DTYP |      PAYLEN      |

	 *   +----------------------------------------------------------------+

	 *   63      48 47    40 39 36 35 32 31   24 23  20 19                0

	 *

	 * Extended Data Descriptor (DTYP=0x1)

	 *   +----------------------------------------------------------------+

	 * 0 |                     Buffer Address [63:0]                      |

	 *   +----------------------------------------------------------------+

	 * 8 | VLAN tag |  POPTS  | Rsvd | Status | Command | DTYP |  DTALEN  |

	 *   +----------------------------------------------------------------+

	 *   63       48 47     40 39  36 35    32 31     24 23  20 19        0

 receive dump */

	/* Legacy Receive Descriptor Format

	 *

	 * +-----------------------------------------------------+

	 * |                Buffer Address [63:0]                |

	 * +-----------------------------------------------------+

	 * | VLAN Tag | Errors | Status 0 | Packet csum | Length |

	 * +-----------------------------------------------------+

	 * 63       48 47    40 39      32 31         16 15      0

 for */

 dump the descriptor caches */

 rx */

 tx */

/**

 * e1000_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: number of the Tx queue that hung (unused)

 Do the reset outside of interrupt context */

/**

 * e1000_change_mtu - Change the Maximum Transfer Unit

 * @netdev: network interface device structure

 * @new_mtu: new value for maximum frame size

 *

 * Returns 0 on success, negative on failure

 Adapter-specific max frame size limits. */

 Capable of supporting up to MAX_JUMBO_FRAME_SIZE limit. */

 e1000_down has a dependency on max_frame_size */

 prevent buffers from being reallocated */

	/* NOTE: netdev_alloc_skb reserves 16 bytes, and typically NET_IP_ALIGN

	 * means we reserve 2 more, this pushes us to allocate from the next

	 * larger slab size.

	 * i.e. RXBUFFER_2048 --> size-4096 slab

	 * however with the new *_jumbo_rx* routines, jumbo receives will use

	 * fragmented skbs

 adjust allocation if LPE protects us, and we aren't using SBP */

/**

 * e1000_update_stats - Update the board statistics counters

 * @adapter: board private structure

	/* Prevent stats update while adapter is being reset, or if the pci

	 * connection is down.

	/* these counters are modified from e1000_tbi_adjust_stats,

	 * called from the interrupt context, so they must only

	 * be written while holding adapter->stats_lock

 used for adaptive IFS */

 Fill out the OS statistics structure */

 Rx Errors */

	/* RLEC on some newer hardware can be incorrect so build

	 * our own version based on RUC and ROC

 Tx Errors */

 Tx Dropped needs to be maintained elsewhere */

 Phy Stats */

 Management Stats */

/**

 * e1000_intr - Interrupt Handler

 * @irq: interrupt number

 * @data: pointer to a network interface device structure

 Not our interrupt */

	/* we might have caused the interrupt, but the above

	 * read cleared it, and just in case the driver is

	 * down there is nothing to do so return handled

 guard against interrupt when we're going down */

 disable interrupts, without the synchronize_irq bit */

		/* this really should not happen! if it does it is basically a

		 * bug, but not a hard error, so enable ints and continue

/**

 * e1000_clean - NAPI Rx polling callback

 * @napi: napi struct containing references to driver info

 * @budget: budget given to driver for receive packets

	/* Exit the polling mode, but don't re-enable interrupts if stack might

	 * poll us due to busy-polling

/**

 * e1000_clean_tx_irq - Reclaim resources after transmit completes

 * @adapter: board private structure

 * @tx_ring: ring to clean

 read buffer_info after eop_desc */

	/* Synchronize with E1000_DESC_UNUSED called from e1000_xmit_frame,

	 * which will reuse the cleaned buffers.

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

		/* Detect a transmit hang in hardware, this serializes the

		 * check with the clearing of time_stamp and movement of i

 detected Tx unit hang */

/**

 * e1000_rx_checksum - Receive Checksum Offload for 82543

 * @adapter:     board private structure

 * @status_err:  receive descriptor status and error fields

 * @csum:        receive descriptor csum field

 * @skb:         socket buffer with received data

 82543 or newer only */

 Ignore Checksum bit is set */

 TCP/UDP checksum error bit is set */

 let the stack verify checksum errors */

 TCP/UDP Checksum has not been calculated */

 It must be a TCP or UDP packet with a valid checksum */

 TCP checksum is good */

/**

 * e1000_consume_page - helper function for jumbo Rx path

 * @bi: software descriptor shadow data

 * @skb: skb being modified

 * @length: length of data being added

/**

 * e1000_receive_skb - helper function to handle rx indications

 * @adapter: board private structure

 * @status: descriptor status field as written by hardware

 * @vlan: descriptor vlan field as written by hardware (no le/be conversion)

 * @skb: pointer to sk_buff to be indicated to stack

/**

 * e1000_tbi_adjust_stats

 * @hw: Struct containing variables accessed by shared code

 * @stats: point to stats struct

 * @frame_len: The length of the frame in question

 * @mac_addr: The Ethernet destination address of the frame in question

 *

 * Adjusts the statistic counters when a frame is accepted by TBI_ACCEPT

 First adjust the frame length. */

	/* We need to adjust the statistics counters, since the hardware

	 * counters overcount this packet as a CRC error and undercount

	 * the packet as a good packet

 This packet should not be counted as a CRC error. */

 This packet does count as a Good Packet Received. */

 Adjust the Good Octets received counters */

	/* If the high bit of Gorcl (the low 32 bits of the Good Octets

	 * Received Count) was one before the addition,

	 * AND it is zero after, then we lost the carry out,

	 * need to add one to Gorch (Good Octets Received Count High).

	 * This could be simplified if all environments supported

	 * 64-bit integers.

	/* Is this a broadcast or multicast?  Check broadcast first,

	 * since the test for a multicast frame will test positive on

	 * a broadcast frame.

		/* In this case, the hardware has overcounted the number of

		 * oversize frames.

	/* Adjust the bin counters when the extra byte put the frame in the

	 * wrong bin. Remember that the frame_len was adjusted above.

/**

 * e1000_clean_jumbo_rx_irq - Send received data up the network stack; legacy

 * @adapter: board private structure

 * @rx_ring: ring to clean

 * @work_done: amount of napi work completed this call

 * @work_to_do: max amount of work allowed for this call to do

 *

 * the return value indicates whether actual cleaning was done, there

 * is no guarantee that everything was cleaned

 read descriptor and rx_buffer_info after status DD */

 errors is only valid for DD + EOP descriptors */

				/* an error means any chain goes out the window

				 * too

 this descriptor is only the beginning (or middle) */

 this is the beginning of a chain */

 this is the middle of a chain */

 end of the chain */

				/* no chain, got EOP, this buf is the packet

				 * copybreak to save the put_page/alloc_page

					/* re-use the page, so don't erase

					 * buffer_info->rxbuf.page

 Receive Checksum Offload XXX recompute due to CRC strip? */

 don't count FCS */

 return some buffers to hardware, one at a time is too slow */

 use prefetched values */

/* this should improve performance for small packets with large amounts

 * of reassembly being done in the stack

/**

 * e1000_clean_rx_irq - Send received data up the network stack; legacy

 * @adapter: board private structure

 * @rx_ring: ring to clean

 * @work_done: amount of napi work completed this call

 * @work_to_do: max amount of work allowed for this call to do

 read descriptor and rx_buffer_info after status DD */

		/* !EOP means multiple descriptors were used to store a single

		 * packet, if thats the case we need to toss it.  In fact, we

		 * to toss every packet with the EOP bit clear and the next

		 * frame that _does_ have the EOP bit set, as it is by

		 * definition only a frame fragment

 All receives must fit into a single buffer */

 don't count FCS */

			/* adjust length to remove Ethernet CRC, this must be

			 * done after the TBI_ACCEPT workaround above

 copybreak skb */

 Receive Checksum Offload */

 return some buffers to hardware, one at a time is too slow */

 use prefetched values */

/**

 * e1000_alloc_jumbo_rx_buffers - Replace used jumbo receive buffers

 * @adapter: address of board private structure

 * @rx_ring: pointer to receive ring structure

 * @cleaned_count: number of buffers to allocate this pass

 allocate a new page if necessary */

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

/**

 * e1000_alloc_rx_buffers - Replace used receive buffers; legacy & extended

 * @adapter: address of board private structure

 * @rx_ring: pointer to ring struct

 * @cleaned_count: number of new Rx buffers to try to allocate

 Better luck next round */

 Fix for errata 23, can't cross 64kB boundary */

 Try again, without freeing the previous */

 Failed allocation, critical failure */

 give up */

 Use new allocation */

		/* XXX if it was allocated cleanly it will never map to a

		 * boundary crossing

 Fix for errata 23, can't cross 64kB boundary */

		/* Force memory writes to complete before letting h/w

		 * know there are new descriptors to fetch.  (Only

		 * applicable for weak-ordered memory model archs,

		 * such as IA-64).

/**

 * e1000_smartspeed - Workaround for SmartSpeed on 82541 and 82547 controllers.

 * @adapter: address of board private structure

		/* If Master/Slave config fault is asserted twice,

		 * we assume back-to-back

 If still no link, perhaps using 2/3 pair cable */

 Restart process after E1000_SMARTSPEED_MAX iterations */

/**

 * e1000_ioctl - handle ioctl calls

 * @netdev: pointer to our netdev

 * @ifr: pointer to interface request structure

 * @cmd: ioctl data

/**

 * e1000_mii_ioctl -

 * @netdev: pointer to our netdev

 * @ifr: pointer to interface request structure

 * @cmd: ioctl data

 enable VLAN tag insert/strip */

 disable VLAN tag insert/strip */

 enable VLAN receive filtering */

 disable VLAN receive filtering */

 add VID to filter table */

 remove VID from filter table */

	/* Make sure dplx is at most 1 bit and lsb of speed is not set

	 * for the switch() below to work

 Fiber NICs only allow 1000 gbps Full duplex */

 not supported */

 clear MDI, MDI(-X) override is only allowed when autoneg enabled */

 turn on all-multi mode if wake on multicast is enabled */

 enable receives in the hardware */

 advertise wake from D3Cold */

 phy power management enable */

 keep the laser running in D3 */

 make sure adapter isn't asleep if manageability is enabled */

 flush memory to make sure state is correct */

/* Polling 'interrupt' - used by things like netconsole to send skbs

 * without having to re-enable interrupts. It's not called while

 * the interrupt routine is executing.

/**

 * e1000_io_error_detected - called when PCI error is detected

 * @pdev: Pointer to PCI device

 * @state: The current pci connection state

 *

 * This function is called after a PCI bus error affecting

 * this device has been detected.

 Request a slot reset. */

/**

 * e1000_io_slot_reset - called after the pci bus has been reset.

 * @pdev: Pointer to PCI device

 *

 * Restart the card from scratch, as if from a cold-boot. Implementation

 * resembles the first-half of the e1000_resume routine.

 flush memory to make sure state is correct */

/**

 * e1000_io_resume - called when traffic can start flowing again.

 * @pdev: Pointer to PCI device

 *

 * This callback is called when the error recovery driver tells us that

 * its OK to resume normal operation. Implementation resembles the

 * second-half of the e1000_resume routine.

 e1000_main.c */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2006 Intel Corporation. */

 ethtool support for e1000 */

 the e1000 autoneg seems to match ethtool nicely */

		/* unfortunately FULL_DUPLEX != DUPLEX_FULL

		 * and HALF_DUPLEX != DUPLEX_HALF

 MDI-X => 1; MDI => 0 */

	/* MDI setting is only allowed when autoneg enabled because

	 * some hardware doesn't allow MDI setting when speed or

	 * duplex is forced.

 calling this overrides forced MDI setting */

 MDI-X => 2; MDI => 1; Auto => 3 */

 reset the link */

	/* If the link is not reported up to netdev, interrupts are disabled,

	 * and so the physical link state may have changed since we last

	 * looked. Set get_link_status to make sure that the true link

	 * state is interrogated, rather than pulling a cached and possibly

	 * stale link state from the driver.

 PHY type (IGP=1, M88=0) */

 cable length */

 cable length */

 cable length */

 cable length */

 extended 10bt distance (not needed) */

 cable polarity */

 cable polarity */

 polarity correction enabled (always) */

 phy receive errors (unavailable) */

 mdix mode */

 cable length */

 Dummy (to align w/ IGP phy reg dump) */

 Dummy (to align w/ IGP phy reg dump) */

 Dummy (to align w/ IGP phy reg dump) */

 extended 10bt distance */

 cable polarity */

 Dummy (to align w/ IGP phy reg dump) */

 polarity correction */

 phy receive errors */

 mdix mode */

 phy idle errors */

 phy local receiver status */

 phy remote receiver status */

 Device's eeprom is always little-endian, word addressable */

		/* need read/modify/write of first changed EEPROM word

		 * only the second byte of the word is being modified

		/* need read/modify/write of last changed EEPROM word

		 * only the first byte of the word is being modified

 Device's eeprom is always little-endian, word addressable */

 Update the checksum over the first part of the EEPROM if needed */

 Try to get new resources before deleting old */

		/* save the new, restore the old in order to free it,

		 * then restore the new back again

	/* The status register is Read Only, so a write should fail.

	 * Some bits that get toggled are ignored.

 there are several bits on newer hardware that are r/w */

 restore previous status */

 Read and add up the contents of the EEPROM */

 If Checksum is not Correct return error else test passed */

	/* NOTE: we don't test MSI interrupts here, yet

	 * Hook up test interrupt handler just for this test

 Disable all the interrupts */

 Test each interrupt */

 Interrupt to test */

			/* Disable the interrupt to be reported in

			 * the cause register and then force the same

			 * interrupt and see if one gets posted.  If

			 * an interrupt was posted to the bus, the

			 * test failed.

		/* Enable the interrupt to be reported in

		 * the cause register and then force the same

		 * interrupt and see if one gets posted.  If

		 * an interrupt was not posted to the bus, the

		 * test failed.

			/* Disable the other interrupts to be reported in

			 * the cause register and then force the other

			 * interrupts and see if any get posted.  If

			 * an interrupt was posted to the bus, the

			 * test failed.

 Disable all the interrupts */

 Unhook test interrupt handler */

 Setup Tx descriptor ring and Tx buffers */

 Setup Rx descriptor ring and Rx buffers */

 Write out to PHY registers 29 and 30 to disable the Receiver. */

	/* Because we reset the PHY above, we need to re-force TX_CLK in the

	 * Extended PHY Specific Control Register to 25MHz clock.  This

	 * value defaults back to a 2.5MHz clock when the PHY is reset.

	/* In addition, because of the s/w reset above, we need to enable

	 * CRS on TX.  This must be set for both full and half duplex

	 * operation.

 Setup the Device Control Register for PHY loopback test. */

 Invert Loss-Of-Signal */

 Set the Force Speed Bit */

 Set the Force Duplex Bit */

 Force Speed to 1000 */

 Force Duplex to FULL */

 Read the PHY Specific Control Register (0x10) */

	/* Clear Auto-Crossover bits in PHY Specific Control Register

	 * (bits 6:5).

 Perform software reset on the PHY */

 Have to setup TX_CLK and TX_CRS after software reset */

 Wait for reset to complete. */

 Have to setup TX_CLK and TX_CRS after software reset */

 Write out to PHY registers 29 and 30 to disable the Receiver. */

 Set the loopback bit in the PHY control register. */

 Setup TX_CLK and TX_CRS one more time. */

 Check Phy Configuration */

 Auto-MDI/MDIX Off */

 reset to update Auto-MDI/MDIX */

 autoneg off */

 force 1000, set loopback */

 Now set up the MAC to the same speed/duplex as the PHY. */

 Clear the speed sel bits */

 Set the Force Speed Bit */

 Set the Force Duplex Bit */

 Force Speed to 1000 */

 Force Duplex to FULL */

 Invert Loss of Signal */

		/* Set the ILOS bit on the fiber Nic is half

		 * duplex link is detected.

	/* Disable the receiver on the PHY so when a cable is plugged in, the

	 * PHY does not begin to autoneg when a cable is reconnected to the NIC.

			/* Attempt to setup Loopback mode on Non-integrated PHY.

			 * Some PHY registers get corrupted at random, so

			 * attempt this 10 times.

		/* Default PHY loopback work is to read the MII

		 * control register and assert bit 14 (loopback mode).

	/* Calculate the loop count based on the largest descriptor ring

	 * The idea is to wrap the largest ring a number of times using 64

	 * send/receive pairs during each loop

 loop count loop */

 send the packets */

 set the start time for the receive */

 receive the sent packets */

			/* time + 20 msecs (200 msecs on 2.4) is more than

			 * enough time to complete the receives, if it's

			 * exceeded, break and error off

 ret_val is the same as mis-compare */

 error code for time out error */

 end loop count loop */

		/* On some blade server designs, link establishment

		 * could take as long as 2-3 minutes

 if auto_neg is set wait for it */

 Offline tests */

 save speed, duplex, autoneg settings */

		/* Link test performed before hardware reset so autoneg doesn't

		 * interfere with test result

 indicate we're in test mode */

 make sure the phy is powered up */

 restore speed, duplex, autoneg settings */

 Online tests */

 Online tests aren't run; pass by default */

 fail by default */

 these don't support WoL at all */

 Wake events not supported on port B */

 return success for non excluded adapter ports */

 quad port adapters only support WoL on port A */

 return success for non excluded adapter ports */

		/* dual port cards only support WoL on port A from now on

		 * unless it was enabled in the eeprom for port B

		 * so exclude FUNC_1 ports from having WoL enabled

	/* this function will set ->supported = 0 and return 1 if wol is not

	 * supported by this hardware

 apply any specific unsupported masks here */

 KSP3 does not support UCAST wake-ups */

 these settings will always override what we currently have */

 BUG_ON(i != E1000_STATS_LEN); */

 BUG_ON(p - data != E1000_STATS_LEN * ETH_GSTRING_LEN); */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 1999 - 2006 Intel Corporation. */

/* This is the only thing that needs to be changed to adjust the

 * maximum number of ports that the driver can manage.

/* All parameters are treated the same, as an integer array of values.

 * This macro just reduces the need to repeat the same declaration code

 * over and over (plus this helps to avoid typo bugs).

/* Transmit Descriptor Count

 *

 * Valid Range: 80-256 for 82542 and 82543 gigabit ethernet controllers

 * Valid Range: 80-4096 for 82544 and newer

 *

 * Default Value: 256

/* Receive Descriptor Count

 *

 * Valid Range: 80-256 for 82542 and 82543 gigabit ethernet controllers

 * Valid Range: 80-4096 for 82544 and newer

 *

 * Default Value: 256

/* User Specified Speed Override

 *

 * Valid Range: 0, 10, 100, 1000

 *  - 0    - auto-negotiate at all supported speeds

 *  - 10   - only link at 10 Mbps

 *  - 100  - only link at 100 Mbps

 *  - 1000 - only link at 1000 Mbps

 *

 * Default Value: 0

/* User Specified Duplex Override

 *

 * Valid Range: 0-2

 *  - 0 - auto-negotiate for duplex

 *  - 1 - only link at half duplex

 *  - 2 - only link at full duplex

 *

 * Default Value: 0

/* Auto-negotiation Advertisement Override

 *

 * Valid Range: 0x01-0x0F, 0x20-0x2F (copper); 0x20 (fiber)

 *

 * The AutoNeg value is a bit mask describing which speed and duplex

 * combinations should be advertised during auto-negotiation.

 * The supported speed and duplex modes are listed below

 *

 * Bit           7     6     5      4      3     2     1      0

 * Speed (Mbps)  N/A   N/A   1000   N/A    100   100   10     10

 * Duplex                    Full          Full  Half  Full   Half

 *

 * Default Value: 0x2F (copper); 0x20 (fiber)

/* User Specified Flow Control Override

 *

 * Valid Range: 0-3

 *  - 0 - No Flow Control

 *  - 1 - Rx only, respond to PAUSE frames but do not generate them

 *  - 2 - Tx only, generate PAUSE frames but ignore them on receive

 *  - 3 - Full Flow Control Support

 *

 * Default Value: Read flow control settings from the EEPROM

/* XsumRX - Receive Checksum Offload Enable/Disable

 *

 * Valid Range: 0, 1

 *  - 0 - disables all checksum offload

 *  - 1 - enables receive IP/TCP/UDP checksum offload

 *        on 82543 and newer -based NICs

 *

 * Default Value: 1

/* Transmit Interrupt Delay in units of 1.024 microseconds

 *  Tx interrupt delay needs to typically be set to something non zero

 *

 * Valid Range: 0-65535

/* Transmit Absolute Interrupt Delay in units of 1.024 microseconds

 *

 * Valid Range: 0-65535

/* Receive Interrupt Delay in units of 1.024 microseconds

 *   hardware will likely hang if you set this to anything but zero.

 *

 * Valid Range: 0-65535

/* Receive Absolute Interrupt Delay in units of 1.024 microseconds

 *

 * Valid Range: 0-65535

/* Interrupt Throttle Rate (interrupts/sec)

 *

 * Valid Range: 100-100000 (0=off, 1=dynamic, 3=dynamic conservative)

/* Enable Smart Power Down of the PHY

 *

 * Valid Range: 0, 1

 *

 * Default Value: 0 (disabled)

 range_option info */

 list_option info */

/**

 * e1000_check_options - Range Checking for Command Line Parameters

 * @adapter: board private structure

 *

 * This routine checks all command line parameters for valid user

 * input.  If an invalid value is given, or if no user specified

 * value exists, a default value is used.  The final value is stored

 * in a variable in the adapter structure.

 Transmit Descriptor Count */

 Receive Descriptor Count */

 Checksum Offload Enable/Disable */

 Flow Control */

 Transmit Interrupt Delay */

 Transmit Absolute Interrupt Delay */

 Receive Interrupt Delay */

 Receive Absolute Interrupt Delay */

 Interrupt Throttling Rate */

				/* save the setting, because the dynamic bits

				 * change itr.

				 * clear the lower two bits because they are

				 * used as control

 Smart Power Down */

/**

 * e1000_check_fiber_options - Range Checking for Link Options, Fiber Version

 * @adapter: board private structure

 *

 * Handles speed and duplex options on fiber adapters

/**

 * e1000_check_copper_options - Range Checking for Link Options, Copper Version

 * @adapter: board private structure

 *

 * Handles speed and duplex options on copper adapters

 Speed */

 Duplex */

 Autoneg */

 Speed, AutoNeg and MDI/MDI-X must all play nice */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

 lan specific interface functions */

/**

 * i40e_align_l2obj_base - aligns base object pointer to 512 bytes

 * @offset: base address offset needing alignment

 *

 * Aligns the layer 2 function private memory so it's 512-byte aligned.

/**

 * i40e_calculate_l2fpm_size - calculates layer 2 FPM memory size

 * @txq_num: number of Tx queues needing backing context

 * @rxq_num: number of Rx queues needing backing context

 * @fcoe_cntx_num: amount of FCoE statefull contexts needing backing context

 * @fcoe_filt_num: number of FCoE filters needing backing context

 *

 * Calculates the maximum amount of memory for the function required, based

 * on the number of resources it must provide context for.

/**

 * i40e_init_lan_hmc - initialize i40e_hmc_info struct

 * @hw: pointer to the HW structure

 * @txq_num: number of Tx queues needing backing context

 * @rxq_num: number of Rx queues needing backing context

 * @fcoe_cntx_num: amount of FCoE statefull contexts needing backing context

 * @fcoe_filt_num: number of FCoE filters needing backing context

 *

 * This function will be called once per physical function initialization.

 * It will fill out the i40e_hmc_obj_info structure for LAN objects based on

 * the driver's provided input, as well as information from the HMC itself

 * loaded from NVRAM.

 *

 * Assumptions:

 *   - HMC Resource Profile has been selected before calling this function.

 allocate memory for hmc_obj */

 The full object will be used to create the LAN HMC SD */

 Tx queue context information */

 validate values requested by driver don't exceed HMC capacity */

 aggregate values into the full LAN object for later */

 Rx queue context information */

 validate values requested by driver don't exceed HMC capacity */

 aggregate values into the full LAN object for later */

 FCoE context information */

 validate values requested by driver don't exceed HMC capacity */

 aggregate values into the full LAN object for later */

 FCoE filter information */

 validate values requested by driver don't exceed HMC capacity */

 aggregate values into the full LAN object for later */

 allocate the sd_entry members in the sd_table */

 store in the LAN full object for later */

/**

 * i40e_remove_pd_page - Remove a page from the page descriptor table

 * @hw: pointer to the HW structure

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: segment descriptor index to find the relevant page descriptor

 *

 * This function:

 *	1. Marks the entry in pd table (for paged address mode) invalid

 *	2. write to register PMPDINV to invalidate the backing page in FV cache

 *	3. Decrement the ref count for  pd_entry

 * assumptions:

 *	1. caller can deallocate the memory used by pd after this function

 *	   returns.

/**

 * i40e_remove_sd_bp - remove a backing page from a segment descriptor

 * @hw: pointer to our HW structure

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: the page index

 *

 * This function:

 *	1. Marks the entry in sd table (for direct address mode) invalid

 *	2. write to register PMSDCMD, PMSDDATALOW(PMSDDATALOW.PMSDVALID set

 *	   to 0) and PMSDDATAHIGH to invalidate the sd page

 *	3. Decrement the ref count for the sd_entry

 * assumptions:

 *	1. caller can deallocate the memory used by backing storage after this

 *	   function returns.

/**

 * i40e_create_lan_hmc_object - allocate backing store for hmc objects

 * @hw: pointer to the HW structure

 * @info: pointer to i40e_hmc_create_obj_info struct

 *

 * This will allocate memory for PDs and backing pages and populate

 * the sd and pd entries.

 find sd index and limit */

 find pd index */

	/* This is to cover for cases where you may not want to have an SD with

	 * the full 2M memory but something smaller. By not filling out any

	 * size, the function will default the SD size to be 2M.

	/* check if all the sds are valid. If not, allocate a page and

	 * initialize it.

 update the sd table entry */

			/* check if all the pds in this sd are valid. If not,

			 * allocate a page and initialize it.

 find pd_idx and pd_lmt in this sd */

 update the pd table entry */

 remove the backing pages from pd_idx1 to i */

 cleanup for sd entries from j to sd_idx */

/**

 * i40e_configure_lan_hmc - prepare the HMC backing store

 * @hw: pointer to the hw structure

 * @model: the model for the layout of the SD/PD tables

 *

 * - This function will be called once per physical function initialization.

 * - This function will be called after i40e_init_lan_hmc() and before

 *   any LAN/FCoE HMC objects can be created.

 Initialize part of the create object info struct */

 Build the SD entry for the LAN objects */

 Make one big object, a single SD */

 else clause falls through the break */

 Make one big object in the PD table */

 unsupported type */

 Configure and program the FPM registers so objects can be created */

 Tx contexts */

 Rx contexts */

 FCoE contexts */

 FCoE filters */

/**

 * i40e_delete_lan_hmc_object - remove hmc objects

 * @hw: pointer to the HW structure

 * @info: pointer to i40e_hmc_delete_obj_info struct

 *

 * This will de-populate the SDs and PDs.  It frees

 * the memory for PDS and backing storage.  After this function is returned,

 * caller should deallocate memory allocated previously for

 * book-keeping information about PDs and backing storage.

 find sd index and limit */

/**

 * i40e_shutdown_lan_hmc - Remove HMC backing store, free allocated memory

 * @hw: pointer to the hw structure

 *

 * This must be called by drivers as they are shutting down and being

 * removed from the OS.

 delete the object */

 free the SD table entry for LAN */

 free memory used for hmc_obj */

 LAN Tx Queue Context */

 Field      Width    LSB */

 line 1 */

 line 7 */

 LAN Rx Queue Context */

 Field      Width    LSB */

/**

 * i40e_write_byte - replace HMC context byte

 * @hmc_bits: pointer to the HMC memory

 * @ce_info: a description of the struct to be read from

 * @src: the struct to be read from

 copy from the next struct field */

 prepare the bits and mask */

 shift to correct alignment */

 get the current bits from the target bit string */

 get the bits not changing */

 add in the new bits */

 put it all back */

/**

 * i40e_write_word - replace HMC context word

 * @hmc_bits: pointer to the HMC memory

 * @ce_info: a description of the struct to be read from

 * @src: the struct to be read from

 copy from the next struct field */

 prepare the bits and mask */

	/* don't swizzle the bits until after the mask because the mask bits

	 * will be in a different bit position on big endian machines

 shift to correct alignment */

 get the current bits from the target bit string */

 get the bits not changing */

 add in the new bits */

 put it all back */

/**

 * i40e_write_dword - replace HMC context dword

 * @hmc_bits: pointer to the HMC memory

 * @ce_info: a description of the struct to be read from

 * @src: the struct to be read from

 copy from the next struct field */

 prepare the bits and mask */

	/* if the field width is exactly 32 on an x86 machine, then the shift

	 * operation will not work because the SHL instructions count is masked

	 * to 5 bits so the shift will do nothing

	/* don't swizzle the bits until after the mask because the mask bits

	 * will be in a different bit position on big endian machines

 shift to correct alignment */

 get the current bits from the target bit string */

 get the bits not changing */

 add in the new bits */

 put it all back */

/**

 * i40e_write_qword - replace HMC context qword

 * @hmc_bits: pointer to the HMC memory

 * @ce_info: a description of the struct to be read from

 * @src: the struct to be read from

 copy from the next struct field */

 prepare the bits and mask */

	/* if the field width is exactly 64 on an x86 machine, then the shift

	 * operation will not work because the SHL instructions count is masked

	 * to 6 bits so the shift will do nothing

	/* don't swizzle the bits until after the mask because the mask bits

	 * will be in a different bit position on big endian machines

 shift to correct alignment */

 get the current bits from the target bit string */

 get the bits not changing */

 add in the new bits */

 put it all back */

/**

 * i40e_clear_hmc_context - zero out the HMC context bits

 * @hw:       the hardware struct

 * @context_bytes: pointer to the context bit array (DMA memory)

 * @hmc_type: the type of HMC resource

 clean the bit array */

/**

 * i40e_set_hmc_context - replace HMC context bits

 * @context_bytes: pointer to the context bit array

 * @ce_info:  a description of the struct to be filled

 * @dest:     the struct to be filled

		/* we have to deal with each element of the HMC using the

		 * correct size so that we are correct regardless of the

		 * endianness of the machine

/**

 * i40e_hmc_get_object_va - retrieves an object's virtual address

 * @hw: the hardware struct, from which we obtain the i40e_hmc_info pointer

 * @object_base: pointer to u64 to get the va

 * @rsrc_type: the hmc resource type

 * @obj_idx: hmc object index

 *

 * This function retrieves the object's virtual address from the object

 * base pointer.  This function is used for LAN Queue contexts.

 find sd index and limit */

/**

 * i40e_clear_lan_tx_queue_context - clear the HMC context for the queue

 * @hw:    the hardware struct

 * @queue: the queue we care about

/**

 * i40e_set_lan_tx_queue_context - set the HMC context for the queue

 * @hw:    the hardware struct

 * @queue: the queue we care about

 * @s:     the struct to be filled

/**

 * i40e_clear_lan_rx_queue_context - clear the HMC context for the queue

 * @hw:    the hardware struct

 * @queue: the queue we care about

/**

 * i40e_set_lan_rx_queue_context - set the HMC context for the queue

 * @hw:    the hardware struct

 * @queue: the queue we care about

 * @s:     the struct to be filled

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2021 Intel Corporation. */

/**

 * i40e_get_pfc_delay - retrieve PFC Link Delay

 * @hw: pointer to hardware struct

 * @delay: holds the PFC Link delay value

 *

 * Returns PFC Link Delay from the PRTDCB_GENC.PFCLDA

/**

 * i40e_dcbnl_ieee_getets - retrieve local IEEE ETS configuration

 * @dev: the corresponding netdev

 * @ets: structure to hold the ETS information

 *

 * Returns local IEEE ETS configuration

/**

 * i40e_dcbnl_ieee_getpfc - retrieve local IEEE PFC configuration

 * @dev: the corresponding netdev

 * @pfc: structure to hold the PFC information

 *

 * Returns local IEEE PFC configuration

 Get Requests/Indications */

/**

 * i40e_dcbnl_ieee_setets - set IEEE ETS configuration

 * @netdev: the corresponding netdev

 * @ets: structure to hold the ETS information

 *

 * Set IEEE ETS configuration

 Copy current config into temp */

 Update the ETS configuration for temp */

 Commit changes to HW */

/**

 * i40e_dcbnl_ieee_setpfc - set local IEEE PFC configuration

 * @netdev: the corresponding netdev

 * @pfc: structure to hold the PFC information

 *

 * Sets local IEEE PFC configuration

 Copy current config into temp */

/**

 * i40e_dcbnl_ieee_setapp - set local IEEE App configuration

 * @netdev: the corresponding netdev

 * @app: structure to hold the Application information

 *

 * Sets local IEEE App configuration

 Already internally available */

 Copy current config into temp */

 Add the app */

/**

 * i40e_dcbnl_ieee_delapp - delete local IEEE App configuration

 * @netdev: the corresponding netdev

 * @app: structure to hold the Application information

 *

 * Deletes local IEEE App configuration other than the first application

 * required by firmware

 Need one app for FW so keep it */

 Copy current config into temp */

 Find and reset the app */

 Reset the app data */

 If the specific DCB app not found */

 Overwrite the tmp_cfg app */

/**

 * i40e_dcbnl_getstate - Get DCB enabled state

 * @netdev: the corresponding netdev

 *

 * Get the current DCB enabled state

/**

 * i40e_dcbnl_setstate - Set DCB state

 * @netdev: the corresponding netdev

 * @state: enable or disable

 *

 * Set the DCB state

 Nothing to do */

 Cannot directly manipulate FW LLDP Agent */

/**

 * i40e_dcbnl_set_pg_tc_cfg_tx - Set CEE PG Tx config

 * @netdev: the corresponding netdev

 * @tc: the corresponding traffic class

 * @prio_type: the traffic priority type

 * @bwg_id: the BW group id the traffic class belongs to

 * @bw_pct: the BW percentage for the corresponding BWG

 * @up_map: prio mapped to corresponding tc

 *

 * Set Tx PG settings for CEE mode

 LLTC not supported yet */

 prio_type, bwg_id and bw_pct per UP are not supported */

 Use only up_map to map tc */

/**

 * i40e_dcbnl_set_pg_bwg_cfg_tx - Set CEE PG Tx BW config

 * @netdev: the corresponding netdev

 * @pgid: the corresponding traffic class

 * @bw_pct: the BW percentage for the specified traffic class

 *

 * Set Tx BW settings for CEE mode

 LLTC not supported yet */

/**

 * i40e_dcbnl_set_pg_tc_cfg_rx - Set CEE PG Rx config

 * @netdev: the corresponding netdev

 * @prio: the corresponding traffic class

 * @prio_type: the traffic priority type

 * @pgid: the BW group id the traffic class belongs to

 * @bw_pct: the BW percentage for the corresponding BWG

 * @up_map: prio mapped to corresponding tc

 *

 * Set Rx BW settings for CEE mode. The hardware does not support this

 * so we won't allow setting of this parameter.

/**

 * i40e_dcbnl_set_pg_bwg_cfg_rx - Set CEE PG Rx config

 * @netdev: the corresponding netdev

 * @pgid: the corresponding traffic class

 * @bw_pct: the BW percentage for the specified traffic class

 *

 * Set Rx BW settings for CEE mode. The hardware does not support this

 * so we won't allow setting of this parameter.

/**

 * i40e_dcbnl_get_pg_tc_cfg_tx - Get CEE PG Tx config

 * @netdev: the corresponding netdev

 * @prio: the corresponding user priority

 * @prio_type: traffic priority type

 * @pgid: the BW group ID the traffic class belongs to

 * @bw_pct: BW percentage for the corresponding BWG

 * @up_map: prio mapped to corresponding TC

 *

 * Get Tx PG settings for CEE mode

/**

 * i40e_dcbnl_get_pg_bwg_cfg_tx - Get CEE PG BW config

 * @netdev: the corresponding netdev

 * @pgid: the corresponding traffic class

 * @bw_pct: the BW percentage for the corresponding TC

 *

 * Get Tx BW settings for given TC in CEE mode

/**

 * i40e_dcbnl_get_pg_tc_cfg_rx - Get CEE PG Rx config

 * @netdev: the corresponding netdev

 * @prio: the corresponding user priority

 * @prio_type: the traffic priority type

 * @pgid: the PG ID

 * @bw_pct: the BW percentage for the corresponding BWG

 * @up_map: prio mapped to corresponding TC

 *

 * Get Rx PG settings for CEE mode. The UP2TC map is applied in same

 * manner for Tx and Rx (symmetrical) so return the TC information for

 * given priority accordingly.

/**

 * i40e_dcbnl_get_pg_bwg_cfg_rx - Get CEE PG BW Rx config

 * @netdev: the corresponding netdev

 * @pgid: the corresponding traffic class

 * @bw_pct: the BW percentage for the corresponding TC

 *

 * Get Rx BW settings for given TC in CEE mode

 * The adapter doesn't support Rx ETS and runs in strict priority

 * mode in Rx path and hence just return 0.

/**

 * i40e_dcbnl_set_pfc_cfg - Set CEE PFC configuration

 * @netdev: the corresponding netdev

 * @prio: the corresponding user priority

 * @setting: the PFC setting for given priority

 *

 * Set the PFC enabled/disabled setting for given user priority

/**

 * i40e_dcbnl_get_pfc_cfg - Get CEE PFC configuration

 * @netdev: the corresponding netdev

 * @prio: the corresponding user priority

 * @setting: the PFC setting for given priority

 *

 * Get the PFC enabled/disabled setting for given user priority

/**

 * i40e_dcbnl_cee_set_all - Commit CEE DCB settings to hardware

 * @netdev: the corresponding netdev

 *

 * Commit the current DCB configuration to hardware

/**

 * i40e_dcbnl_get_cap - Get DCBX capabilities of adapter

 * @netdev: the corresponding netdev

 * @capid: the capability type

 * @cap: the capability value

 *

 * Return the capability value for a given capability type

/**

 * i40e_dcbnl_getnumtcs - Get max number of traffic classes supported

 * @netdev: the corresponding netdev

 * @tcid: the TC id

 * @num: total number of TCs supported by the device

 *

 * Return the total number of TCs supported by the adapter

/**

 * i40e_dcbnl_setnumtcs - Set CEE number of traffic classes

 * @netdev: the corresponding netdev

 * @tcid: the TC id

 * @num: total number of TCs

 *

 * Set the total number of TCs (Unsupported)

/**

 * i40e_dcbnl_getpfcstate - Get CEE PFC mode

 * @netdev: the corresponding netdev

 *

 * Get the current PFC enabled state

 Return enabled if any PFC enabled UP */

/**

 * i40e_dcbnl_setpfcstate - Set CEE PFC mode

 * @netdev: the corresponding netdev

 * @state: required state

 *

 * The PFC state to be set; this is enabled/disabled based on the PFC

 * priority settings and not via this call for i40e driver

/**

 * i40e_dcbnl_getapp - Get CEE APP

 * @netdev: the corresponding netdev

 * @idtype: the App selector

 * @id: the App ethtype or port number

 *

 * Return the CEE mode app for the given idtype and id

/**

 * i40e_dcbnl_setdcbx - set required DCBx capability

 * @netdev: the corresponding netdev

 * @mode: new DCB mode managed or CEE+IEEE

 *

 * Set DCBx capability features

 Do not allow to set mode if managed by Firmware */

 No support for LLD_MANAGED modes or CEE+IEEE */

 Already set to the given mode no change */

/**

 * i40e_dcbnl_getdcbx - retrieve current DCBx capability

 * @dev: the corresponding netdev

 *

 * Returns DCBx capability features

/**

 * i40e_dcbnl_get_perm_hw_addr - MAC address used by DCBx

 * @dev: the corresponding netdev

 * @perm_addr: buffer to store the MAC address

 *

 * Returns the SAN MAC address used for LLDP exchange

/**

 * i40e_dcbnl_set_all - set all the apps and ieee data from DCBx config

 * @vsi: the corresponding vsi

 *

 * Set up all the IEEE APPs in the DCBNL App Table and generate event for

 * other settings

 SW DCB taken care by DCBNL set calls */

 DCB not enabled */

 MFP mode but not an iSCSI PF so return */

 Set up all the App TLVs if DCBx is negotiated */

 Add APP only if the TC is enabled for this VSI */

 Notify user-space of the changes */

/**

 * i40e_dcbnl_vsi_del_app - Delete APP for given VSI

 * @vsi: the corresponding vsi

 * @app: APP to delete

 *

 * Delete given APP from the DCBNL APP table for given

 * VSI

/**

 * i40e_dcbnl_del_app - Delete APP on all VSIs

 * @pf: the corresponding PF

 * @app: APP to delete

 *

 * Delete given APP from all the VSIs for given PF

/**

 * i40e_dcbnl_find_app - Search APP in given DCB config

 * @cfg: DCBX configuration data

 * @app: APP to search for

 *

 * Find given APP in the DCB configuration

/**

 * i40e_dcbnl_flush_apps - Delete all removed APPs

 * @pf: the corresponding PF

 * @old_cfg: old DCBX configuration data

 * @new_cfg: new DCBX configuration data

 *

 * Find and delete all APPs that are not present in the passed

 * DCB configuration

 MFP mode but not an iSCSI PF so return */

 The APP is not available anymore delete it */

/**

 * i40e_dcbnl_setup - DCBNL setup

 * @vsi: the corresponding vsi

 *

 * Set up DCBNL ops and initial APP TLVs

 Not DCB capable */

 Set initial IEEE DCB settings */

 CONFIG_I40E_DCB */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 * i40e_add_sd_table_entry - Adds a segment descriptor to the table

 * @hw: pointer to our hw struct

 * @hmc_info: pointer to the HMC configuration information struct

 * @sd_index: segment descriptor index to manipulate

 * @type: what type of segment descriptor we're manipulating

 * @direct_mode_sz: size to alloc in direct mode

 allocate a 4K pd page or 2M backing page */

 initialize the sd entry */

 increment the ref count */

 Increment backing page reference count */

/**

 * i40e_add_pd_table_entry - Adds page descriptor to the specified table

 * @hw: pointer to our HW structure

 * @hmc_info: pointer to the HMC configuration information structure

 * @pd_index: which page descriptor index to manipulate

 * @rsrc_pg: if not NULL, use preallocated page instead of allocating new one.

 *

 * This function:

 *	1. Initializes the pd entry

 *	2. Adds pd_entry in the pd_table

 *	3. Mark the entry valid in i40e_hmc_pd_entry structure

 *	4. Initializes the pd_entry's ref count to 1

 * assumptions:

 *	1. The memory for pd should be pinned down, physically contiguous and

 *	   aligned on 4K boundary and zeroed memory.

 *	2. It should be 4K in size.

 find corresponding sd */

 allocate a 4K backing page */

 Set page address and valid bit */

 Add the backing page physical address in the pd entry */

/**

 * i40e_remove_pd_bp - remove a backing page from a page descriptor

 * @hw: pointer to our HW structure

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: the page index

 *

 * This function:

 *	1. Marks the entry in pd tabe (for paged address mode) or in sd table

 *	   (for direct address mode) invalid.

 *	2. Write to register PMPDINV to invalidate the backing page in FV cache

 *	3. Decrement the ref count for the pd _entry

 * assumptions:

 *	1. Caller can deallocate the memory used by backing storage after this

 *	   function returns.

 calculate index */

 get the entry and decrease its ref counter */

 mark the entry invalid */

 free memory here */

/**

 * i40e_prep_remove_sd_bp - Prepares to remove a backing page from a sd entry

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: the page index

 get the entry and decrease its ref counter */

 mark the entry invalid */

/**

 * i40e_remove_sd_bp_new - Removes a backing page from a segment descriptor

 * @hw: pointer to our hw struct

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: the page index

 * @is_pf: used to distinguish between VF and PF

 get the entry and decrease its ref counter */

/**

 * i40e_prep_remove_pd_page - Prepares to remove a PD page from sd entry.

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: segment descriptor index to find the relevant page descriptor

 mark the entry invalid */

/**

 * i40e_remove_pd_page_new - Removes a PD page from sd entry.

 * @hw: pointer to our hw struct

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: segment descriptor index to find the relevant page descriptor

 * @is_pf: used to distinguish between VF and PF

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 * i40e_client_get_params - Get the params that can change at runtime

 * @vsi: the VSI with the message

 * @params: client param struct

 *

 If TC is not enabled for VSI use TC0 for UP */

/**

 * i40e_notify_client_of_vf_msg - call the client vf message callback

 * @vsi: the VSI with the message

 * @vf_id: the absolute VF id that sent the message

 * @msg: message buffer

 * @len: length of the message

 *

 * If there is a client to this VSI, call the client

/**

 * i40e_notify_client_of_l2_param_changes - call the client notify callback

 * @vsi: the VSI with l2 param changes

 *

 * If there is a client to this VSI, call the client

/**

 * i40e_client_release_qvlist - release MSI-X vector mapping for client

 * @ldev: pointer to L2 context.

 *

/**

 * i40e_notify_client_of_netdev_close - call the client close callback

 * @vsi: the VSI with netdev closed

 * @reset: true when close called due to a reset pending

 *

 * If there is a client to this netdev, call the client with close

/**

 * i40e_notify_client_of_vf_reset - call the client vf reset callback

 * @pf: PF device pointer

 * @vf_id: asolute id of VF being reset

 *

 * If there is a client attached to this PF, notify when a VF is reset

/**

 * i40e_notify_client_of_vf_enable - call the client vf notification callback

 * @pf: PF device pointer

 * @num_vfs: the number of VFs currently enabled, 0 for disable

 *

 * If there is a client attached to this PF, call its VF notification routine

/**

 * i40e_vf_client_capable - ask the client if it likes the specified VF

 * @pf: PF device pointer

 * @vf_id: the VF in question

 *

 * If there is a client of the specified type attached to this PF, call

 * its vf_capable routine

/**

 * i40e_client_add_instance - add a client instance struct to the instance list

 * @pf: pointer to the board struct

 *

/**

 * i40e_client_del_instance - removes a client instance from the list

 * @pf: pointer to the board struct

 *

/**

 * i40e_client_subtask - client maintenance work

 * @pf: board private structure

 If we're down or resetting, just bail */

	/* Here we handle client opens. If the client is down, and

	 * the netdev is registered, then open the client.

 Remove failed client instance */

	/* enable/disable PE TCP_ENA flag based on netdev down/up

/**

 * i40e_lan_add_device - add a lan device struct to the list of lan devices

 * @pf: pointer to the board struct

 *

 * Returns 0 on success or none 0 on error

/**

 * i40e_lan_del_device - removes a lan device from the device list

 * @pf: pointer to the board struct

 *

 * Returns 0 on success or non-0 on error

 First, remove any client instance. */

/**

 * i40e_client_virtchnl_send - TBD

 * @ldev: pointer to L2 context

 * @client: Client pointer

 * @vf_id: absolute VF identifier

 * @msg: message buffer

 * @len: length of message buffer

 *

 * Return 0 on success or < 0 on error

/**

 * i40e_client_setup_qvlist

 * @ldev: pointer to L2 context.

 * @client: Client pointer.

 * @qvlist_info: queue and vector list

 *

 * Return 0 on success or < 0 on error

 Validate vector id belongs to this client */

 Special case - No CEQ mapped on this vector */

 Mitigate sync problems with iwarp VF driver */

/**

 * i40e_client_request_reset

 * @ldev: pointer to L2 context.

 * @client: Client pointer.

 * @reset_level: reset level

/**

 * i40e_client_update_vsi_ctxt

 * @ldev: pointer to L2 context.

 * @client: Client pointer.

 * @is_vf: if this for the VF

 * @vf_id: if is_vf true this carries the vf_id

 * @flag: Any device level setting that needs to be done for PE

 * @valid_flag: Bits in this match up and enable changing of flag bits

 *

 * Return 0 on success or < 0 on error

 TODO: for now do not allow setting VF's VSI setting */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2021 Intel Corporation. */

/**

 * i40e_set_mac_type - Sets MAC type

 * @hw: pointer to the HW structure

 *

 * This function sets the mac type of the adapter based on the

 * vendor ID and device ID stored in the hw structure.

/**

 * i40e_aq_str - convert AQ err code to a string

 * @hw: pointer to the HW structure

 * @aq_err: the AQ error code to convert

/**

 * i40e_stat_str - convert status err code to a string

 * @hw: pointer to the HW structure

 * @stat_err: the status error code to convert

/**

 * i40e_debug_aq

 * @hw: debug mask related to admin queue

 * @mask: debug mask

 * @desc: pointer to admin queue descriptor

 * @buffer: pointer to command buffer

 * @buf_len: max length of buffer

 *

 * Dumps debug log about adminq command with descriptor contents.

/**

 * i40e_check_asq_alive

 * @hw: pointer to the hw struct

 *

 * Returns true if Queue is enabled else false.

/**

 * i40e_aq_queue_shutdown

 * @hw: pointer to the hw struct

 * @unloading: is the driver unloading itself

 *

 * Tell the Firmware that we're shutting down the AdminQ and whether

 * or not the driver is unloading as well.

/**

 * i40e_aq_get_set_rss_lut

 * @hw: pointer to the hardware structure

 * @vsi_id: vsi fw index

 * @pf_lut: for PF table set true, for VSI table set false

 * @lut: pointer to the lut buffer provided by the caller

 * @lut_size: size of the lut buffer

 * @set: set true to set the table, false to get the table

 *

 * Internal function to get or set RSS look up table

 Indirect command */

/**

 * i40e_aq_get_rss_lut

 * @hw: pointer to the hardware structure

 * @vsi_id: vsi fw index

 * @pf_lut: for PF table set true, for VSI table set false

 * @lut: pointer to the lut buffer provided by the caller

 * @lut_size: size of the lut buffer

 *

 * get the RSS lookup table, PF or VSI type

/**

 * i40e_aq_set_rss_lut

 * @hw: pointer to the hardware structure

 * @vsi_id: vsi fw index

 * @pf_lut: for PF table set true, for VSI table set false

 * @lut: pointer to the lut buffer provided by the caller

 * @lut_size: size of the lut buffer

 *

 * set the RSS lookup table, PF or VSI type

/**

 * i40e_aq_get_set_rss_key

 * @hw: pointer to the hw struct

 * @vsi_id: vsi fw index

 * @key: pointer to key info struct

 * @set: set true to set the key, false to get the key

 *

 * get the RSS key per VSI

 Indirect command */

/**

 * i40e_aq_get_rss_key

 * @hw: pointer to the hw struct

 * @vsi_id: vsi fw index

 * @key: pointer to key info struct

 *

/**

 * i40e_aq_set_rss_key

 * @hw: pointer to the hw struct

 * @vsi_id: vsi fw index

 * @key: pointer to key info struct

 *

 * set the RSS key per VSI

/* The i40e_ptype_lookup table is used to convert from the 8-bit ptype in the

 * hardware to a bit-field that can be used by SW to more easily determine the

 * packet type.

 *

 * Macros are used to shorten the table lines and make this table human

 * readable.

 *

 * We store the PTYPE in the top byte of the bit field - this is just so that

 * we can check that the table doesn't have a row missing, as the index into

 * the table should be the PTYPE.

 *

 * Typical work flow:

 *

 * IF NOT i40e_ptype_lookup[ptype].known

 * THEN

 *      Packet is unknown

 * ELSE IF i40e_ptype_lookup[ptype].outer_ip == I40E_RX_PTYPE_OUTER_IP

 *      Use the rest of the fields to look at the tunnels, inner protocols, etc

 * ELSE

 *      Use the enum i40e_rx_l2_ptype to decode the packet type

 * ENDIF

 macro to make the table lines short, use explicit indexing with [PTYPE] */

 shorter macros makes the table fit but are terse */

 Lookup table mapping in the 8-bit HW PTYPE to the bit field for decoding */

 L2 Packet types */

 Non Tunneled IPv4 */

 IPv4 --> IPv4 */

 IPv4 --> IPv6 */

 IPv4 --> GRE/NAT */

 IPv4 --> GRE/NAT --> IPv4 */

 IPv4 --> GRE/NAT --> IPv6 */

 IPv4 --> GRE/NAT --> MAC */

 IPv4 --> GRE/NAT --> MAC --> IPv4 */

 IPv4 --> GRE/NAT -> MAC --> IPv6 */

 IPv4 --> GRE/NAT --> MAC/VLAN */

 IPv4 ---> GRE/NAT -> MAC/VLAN --> IPv4 */

 IPv4 -> GRE/NAT -> MAC/VLAN --> IPv6 */

 Non Tunneled IPv6 */

 IPv6 --> IPv4 */

 IPv6 --> IPv6 */

 IPv6 --> GRE/NAT */

 IPv6 --> GRE/NAT -> IPv4 */

 IPv6 --> GRE/NAT -> IPv6 */

 IPv6 --> GRE/NAT -> MAC */

 IPv6 --> GRE/NAT -> MAC -> IPv4 */

 IPv6 --> GRE/NAT -> MAC -> IPv6 */

 IPv6 --> GRE/NAT -> MAC/VLAN */

 IPv6 --> GRE/NAT -> MAC/VLAN --> IPv4 */

 IPv6 --> GRE/NAT -> MAC/VLAN --> IPv6 */

 unused entries */

/**

 * i40e_init_shared_code - Initialize the shared code

 * @hw: pointer to hardware structure

 *

 * This assigns the MAC type and PHY code and inits the NVM.

 * Does not touch the hardware. This function must be called prior to any

 * other function in the shared code. The i40e_hw structure should be

 * memset to 0 prior to calling this function.  The following fields in

 * hw structure should be filled in prior to calling this function:

 * hw_addr, back, device_id, vendor_id, subsystem_device_id,

 * subsystem_vendor_id, and revision_id

 Determine port number and PF number*/

/**

 * i40e_aq_mac_address_read - Retrieve the MAC addresses

 * @hw: pointer to the hw struct

 * @flags: a return indicator of what addresses were added to the addr store

 * @addrs: the requestor's mac addr store

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_mac_address_write - Change the MAC addresses

 * @hw: pointer to the hw struct

 * @flags: indicates which MAC to be written

 * @mac_addr: address to write

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_get_mac_addr - get MAC address

 * @hw: pointer to the HW structure

 * @mac_addr: pointer to MAC address

 *

 * Reads the adapter's MAC address from register

/**

 * i40e_get_port_mac_addr - get Port MAC address

 * @hw: pointer to the HW structure

 * @mac_addr: pointer to Port MAC address

 *

 * Reads the adapter's Port MAC address

/**

 * i40e_pre_tx_queue_cfg - pre tx queue configure

 * @hw: pointer to the HW structure

 * @queue: target PF queue index

 * @enable: state change request

 *

 * Handles hw requirement to indicate intention to enable

 * or disable target queue.

/**

 *  i40e_read_pba_string - Reads part number string from EEPROM

 *  @hw: pointer to hardware structure

 *  @pba_num: stores the part number string from the EEPROM

 *  @pba_num_size: part number string buffer length

 *

 *  Reads the part number string from the EEPROM.

	/* Subtract one to get PBA word count (PBA Size word is included in

	 * total size)

/**

 * i40e_get_media_type - Gets media type

 * @hw: pointer to the hardware structure

/**

 * i40e_poll_globr - Poll for Global Reset completion

 * @hw: pointer to the hardware structure

 * @retry_limit: how many times to retry before failure

/**

 * i40e_pf_reset - Reset the PF

 * @hw: pointer to the hardware structure

 *

 * Assuming someone else has triggered a global reset,

 * assure the global reset is complete and then reset the PF

	/* Poll for Global Reset steady state in case of recent GRST.

	 * The grst delay value is in 100ms units, and we'll wait a

	 * couple counts longer to be sure we don't just miss the end.

	/* It can take upto 15 secs for GRST steady state.

	 * Bump it to 16 secs max to be safe.

 Now Wait for the FW to be ready */

	/* If there was a Global Reset in progress when we got here,

	 * we don't need to do the PF Reset

/**

 * i40e_clear_hw - clear out any left over hw state

 * @hw: pointer to the hw struct

 *

 * Clear queues and interrupts, typically called at init time,

 * but after the capabilities have been found so we know how many

 * queues and msix vectors have been allocated.

 get number of interrupts, queues, and VFs */

 stop all the interrupts */

 Set the FIRSTQ_INDX field to 0x7FF in PFINT_LNKLSTx */

 warn the HW of the coming Tx disables */

 stop all the queues */

 short wait for all queue disables to settle */

/**

 * i40e_clear_pxe_mode - clear pxe operations mode

 * @hw: pointer to the hw struct

 *

 * Make sure all PXE mode settings are cleared, including things

 * like descriptor fetch/write-back mode.

 Clear single descriptor fetch/write-back mode */

 As a work around clear PXE_MODE instead of setting it */

/**

 * i40e_led_is_mine - helper to find matching led

 * @hw: pointer to the hw struct

 * @idx: index into GPIO registers

 *

 * returns: 0 if no match, otherwise the value of the GPIO_CTL register

	/* if PRT_NUM_NA is 1 then this LED is not port specific, OR

	 * if it is not our port then ignore

/**

 * i40e_led_get - return current on/off mode

 * @hw: pointer to the hw struct

 *

 * The value returned is the 'mode' field as defined in the

 * GPIO register definitions: 0x0 = off, 0xf = on, and other

 * values are variations of possible behaviors relating to

 * blink, link, and wire.

	/* as per the documentation GPIO 22-29 are the LED

	 * GPIO pins named LED0..LED7

/**

 * i40e_led_set - set new on/off mode

 * @hw: pointer to the hw struct

 * @mode: 0=off, 0xf=on (else see manual for mode details)

 * @blink: true if the LED should blink when on, false if steady

 *

 * if this function is used to turn on the blink it should

 * be used to disable the blink when restoring the original state.

	/* as per the documentation GPIO 22-29 are the LED

	 * GPIO pins named LED0..LED7

 this & is a bit of paranoia, but serves as a range check */

 Admin command wrappers */

/**

 * i40e_aq_get_phy_capabilities

 * @hw: pointer to the hw struct

 * @abilities: structure for PHY capabilities to be filled

 * @qualified_modules: report Qualified Modules

 * @report_init: report init capabilities (active are default)

 * @cmd_details: pointer to command details structure or NULL

 *

 * Returns the various PHY abilities supported on the Port.

 also covers I40E_AQ_RC_OK */

/**

 * i40e_aq_set_phy_config

 * @hw: pointer to the hw struct

 * @config: structure with PHY configuration to be set

 * @cmd_details: pointer to command details structure or NULL

 *

 * Set the various PHY configuration parameters

 * supported on the Port.One or more of the Set PHY config parameters may be

 * ignored in an MFP mode as the PF may not have the privilege to set some

 * of the PHY Config parameters. This status will be indicated by the

 * command response.

 clear the old pause settings */

 set the new abilities */

 If the abilities have changed, then set the new config */

 Auto restart link so settings take effect */

 Copy over all the old settings */

/**

 * i40e_set_fc

 * @hw: pointer to the hw struct

 * @aq_failures: buffer to return AdminQ failure information

 * @atomic_restart: whether to enable atomic link restart

 *

 * Set the requested flow control mode using set_phy_config.

 Get the current phy config */

 Update the link info */

		/* Wait a little bit (on 40G cards it sometimes takes a really

		 * long time for link to come back from the atomic reset)

		 * and try once more

/**

 * i40e_aq_clear_pxe_mode

 * @hw: pointer to the hw struct

 * @cmd_details: pointer to command details structure or NULL

 *

 * Tell the firmware that the driver is taking over from PXE

/**

 * i40e_aq_set_link_restart_an

 * @hw: pointer to the hw struct

 * @enable_link: if true: enable link, if false: disable link

 * @cmd_details: pointer to command details structure or NULL

 *

 * Sets up the link and restarts the Auto-Negotiation over the link.

/**

 * i40e_aq_get_link_info

 * @hw: pointer to the hw struct

 * @enable_lse: enable/disable LinkStatusEvent reporting

 * @link: pointer to link status structure - optional

 * @cmd_details: pointer to command details structure or NULL

 *

 * Returns the link status of the adapter.

 save off old link status information */

 update link status */

 update fc info */

 save link status information */

 flag cleared so helper functions don't call AQ again */

/**

 * i40e_aq_set_phy_int_mask

 * @hw: pointer to the hw struct

 * @mask: interrupt mask to be set

 * @cmd_details: pointer to command details structure or NULL

 *

 * Set link interrupt mask.

/**

 * i40e_aq_set_phy_debug

 * @hw: pointer to the hw struct

 * @cmd_flags: debug command flags

 * @cmd_details: pointer to command details structure or NULL

 *

 * Reset the external PHY.

/**

 * i40e_is_aq_api_ver_ge

 * @aq: pointer to AdminQ info containing HW API version to compare

 * @maj: API major value

 * @min: API minor value

 *

 * Assert whether current HW API version is greater/equal than provided.

/**

 * i40e_aq_add_vsi

 * @hw: pointer to the hw struct

 * @vsi_ctx: pointer to a vsi context struct

 * @cmd_details: pointer to command details structure or NULL

 *

 * Add a VSI context to the hardware.

/**

 * i40e_aq_set_default_vsi

 * @hw: pointer to the hw struct

 * @seid: vsi number

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_clear_default_vsi

 * @hw: pointer to the hw struct

 * @seid: vsi number

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_set_vsi_unicast_promiscuous

 * @hw: pointer to the hw struct

 * @seid: vsi number

 * @set: set unicast promiscuous enable/disable

 * @cmd_details: pointer to command details structure or NULL

 * @rx_only_promisc: flag to decide if egress traffic gets mirrored in promisc

/**

 * i40e_aq_set_vsi_multicast_promiscuous

 * @hw: pointer to the hw struct

 * @seid: vsi number

 * @set: set multicast promiscuous enable/disable

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_set_vsi_mc_promisc_on_vlan

 * @hw: pointer to the hw struct

 * @seid: vsi number

 * @enable: set MAC L2 layer unicast promiscuous enable/disable for a given VLAN

 * @vid: The VLAN tag filter - capture any multicast packet with this VLAN tag

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_set_vsi_uc_promisc_on_vlan

 * @hw: pointer to the hw struct

 * @seid: vsi number

 * @enable: set MAC L2 layer unicast promiscuous enable/disable for a given VLAN

 * @vid: The VLAN tag filter - capture any unicast packet with this VLAN tag

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_set_vsi_bc_promisc_on_vlan

 * @hw: pointer to the hw struct

 * @seid: vsi number

 * @enable: set broadcast promiscuous enable/disable for a given VLAN

 * @vid: The VLAN tag filter - capture any broadcast packet with this VLAN tag

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_set_vsi_broadcast

 * @hw: pointer to the hw struct

 * @seid: vsi number

 * @set_filter: true to set filter, false to clear filter

 * @cmd_details: pointer to command details structure or NULL

 *

 * Set or clear the broadcast promiscuous flag (filter) for a given VSI.

/**

 * i40e_aq_set_vsi_vlan_promisc - control the VLAN promiscuous setting

 * @hw: pointer to the hw struct

 * @seid: vsi number

 * @enable: set MAC L2 layer unicast promiscuous enable/disable for a given VLAN

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_get_vsi_params - get VSI configuration info

 * @hw: pointer to the hw struct

 * @vsi_ctx: pointer to a vsi context struct

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_update_vsi_params

 * @hw: pointer to the hw struct

 * @vsi_ctx: pointer to a vsi context struct

 * @cmd_details: pointer to command details structure or NULL

 *

 * Update a VSI context.

/**

 * i40e_aq_get_switch_config

 * @hw: pointer to the hardware structure

 * @buf: pointer to the result buffer

 * @buf_size: length of input buffer

 * @start_seid: seid to start for the report, 0 == beginning

 * @cmd_details: pointer to command details structure or NULL

 *

 * Fill the buf with switch configuration returned from AdminQ command

/**

 * i40e_aq_set_switch_config

 * @hw: pointer to the hardware structure

 * @flags: bit flag values to set

 * @mode: cloud filter mode

 * @valid_flags: which bit flags to set

 * @mode: cloud filter mode

 * @cmd_details: pointer to command details structure or NULL

 *

 * Set switch configuration bits

/**

 * i40e_aq_get_firmware_version

 * @hw: pointer to the hw struct

 * @fw_major_version: firmware major version

 * @fw_minor_version: firmware minor version

 * @fw_build: firmware build number

 * @api_major_version: major queue version

 * @api_minor_version: minor queue version

 * @cmd_details: pointer to command details structure or NULL

 *

 * Get the firmware version from the admin queue commands

/**

 * i40e_aq_send_driver_version

 * @hw: pointer to the hw struct

 * @dv: driver's major, minor version

 * @cmd_details: pointer to command details structure or NULL

 *

 * Send the driver version to the firmware

/**

 * i40e_get_link_status - get status of the HW network link

 * @hw: pointer to the hw struct

 * @link_up: pointer to bool (true/false = linkup/linkdown)

 *

 * Variable link_up true if link is up, false if link is down.

 * The variable link_up is invalid if returned value of status != 0

 *

 * Side effect: LinkStatusEvent reporting becomes enabled

/**

 * i40e_update_link_info - update status of the HW network link

 * @hw: pointer to the hw struct

 extra checking needed to ensure link info to user is timely */

/**

 * i40e_aq_add_veb - Insert a VEB between the VSI and the MAC

 * @hw: pointer to the hw struct

 * @uplink_seid: the MAC or other gizmo SEID

 * @downlink_seid: the VSI SEID

 * @enabled_tc: bitmap of TCs to be enabled

 * @default_port: true for default port VSI, false for control port

 * @veb_seid: pointer to where to put the resulting VEB SEID

 * @enable_stats: true to turn on VEB stats

 * @cmd_details: pointer to command details structure or NULL

 *

 * This asks the FW to add a VEB between the uplink and downlink

 * elements.  If the uplink SEID is 0, this will be a floating VEB.

 SEIDs need to either both be set or both be 0 for floating VEB */

 reverse logic here: set the bitflag to disable the stats */

/**

 * i40e_aq_get_veb_parameters - Retrieve VEB parameters

 * @hw: pointer to the hw struct

 * @veb_seid: the SEID of the VEB to query

 * @switch_id: the uplink switch id

 * @floating: set to true if the VEB is floating

 * @statistic_index: index of the stats counter block for this VEB

 * @vebs_used: number of VEB's used by function

 * @vebs_free: total VEB's not reserved by any function

 * @cmd_details: pointer to command details structure or NULL

 *

 * This retrieves the parameters for a particular VEB, specified by

 * uplink_seid, and returns them to the caller.

/**

 * i40e_aq_add_macvlan

 * @hw: pointer to the hw struct

 * @seid: VSI for the mac address

 * @mv_list: list of macvlans to be added

 * @count: length of the list

 * @cmd_details: pointer to command details structure or NULL

 *

 * Add MAC/VLAN addresses to the HW filtering

 prep the rest of the request */

/**

 * i40e_aq_remove_macvlan

 * @hw: pointer to the hw struct

 * @seid: VSI for the mac address

 * @mv_list: list of macvlans to be removed

 * @count: length of the list

 * @cmd_details: pointer to command details structure or NULL

 *

 * Remove MAC/VLAN addresses from the HW filtering

 prep the rest of the request */

/**

 * i40e_mirrorrule_op - Internal helper function to add/delete mirror rule

 * @hw: pointer to the hw struct

 * @opcode: AQ opcode for add or delete mirror rule

 * @sw_seid: Switch SEID (to which rule refers)

 * @rule_type: Rule Type (ingress/egress/VLAN)

 * @id: Destination VSI SEID or Rule ID

 * @count: length of the list

 * @mr_list: list of mirrored VSI SEIDs or VLAN IDs

 * @cmd_details: pointer to command details structure or NULL

 * @rule_id: Rule ID returned from FW

 * @rules_used: Number of rules used in internal switch

 * @rules_free: Number of rules free in internal switch

 *

 * Add/Delete a mirror rule to a specific switch. Mirror rules are supported for

 * VEBs/VEPA elements only

 prep the rest of the request */

 Dest VSI for add, rule_id for delete */

/**

 * i40e_aq_add_mirrorrule - add a mirror rule

 * @hw: pointer to the hw struct

 * @sw_seid: Switch SEID (to which rule refers)

 * @rule_type: Rule Type (ingress/egress/VLAN)

 * @dest_vsi: SEID of VSI to which packets will be mirrored

 * @count: length of the list

 * @mr_list: list of mirrored VSI SEIDs or VLAN IDs

 * @cmd_details: pointer to command details structure or NULL

 * @rule_id: Rule ID returned from FW

 * @rules_used: Number of rules used in internal switch

 * @rules_free: Number of rules free in internal switch

 *

 * Add mirror rule. Mirror rules are supported for VEBs or VEPA elements only

/**

 * i40e_aq_delete_mirrorrule - delete a mirror rule

 * @hw: pointer to the hw struct

 * @sw_seid: Switch SEID (to which rule refers)

 * @rule_type: Rule Type (ingress/egress/VLAN)

 * @count: length of the list

 * @rule_id: Rule ID that is returned in the receive desc as part of

 *		add_mirrorrule.

 * @mr_list: list of mirrored VLAN IDs to be removed

 * @cmd_details: pointer to command details structure or NULL

 * @rules_used: Number of rules used in internal switch

 * @rules_free: Number of rules free in internal switch

 *

 * Delete a mirror rule. Mirror rules are supported for VEBs/VEPA elements only

 Rule ID has to be valid except rule_type: INGRESS VLAN mirroring */

		/* count and mr_list shall be valid for rule_type INGRESS VLAN

		 * mirroring. For other rule_type, count and rule_type should

		 * not matter.

/**

 * i40e_aq_send_msg_to_vf

 * @hw: pointer to the hardware structure

 * @vfid: VF id to send msg

 * @v_opcode: opcodes for VF-PF communication

 * @v_retval: return error code

 * @msg: pointer to the msg buffer

 * @msglen: msg length

 * @cmd_details: pointer to command details

 *

 * send msg to vf

/**

 * i40e_aq_debug_read_register

 * @hw: pointer to the hw struct

 * @reg_addr: register address

 * @reg_val: register value

 * @cmd_details: pointer to command details structure or NULL

 *

 * Read the register using the admin queue commands

/**

 * i40e_aq_debug_write_register

 * @hw: pointer to the hw struct

 * @reg_addr: register address

 * @reg_val: register value

 * @cmd_details: pointer to command details structure or NULL

 *

 * Write to a register using the admin queue commands

/**

 * i40e_aq_request_resource

 * @hw: pointer to the hw struct

 * @resource: resource id

 * @access: access type

 * @sdp_number: resource number

 * @timeout: the maximum time in ms that the driver may hold the resource

 * @cmd_details: pointer to command details structure or NULL

 *

 * requests common resource using the admin queue commands

	/* The completion specifies the maximum time in ms that the driver

	 * may hold the resource in the Timeout field.

	 * If the resource is held by someone else, the command completes with

	 * busy return value and the timeout field indicates the maximum time

	 * the current owner of the resource has to free it.

/**

 * i40e_aq_release_resource

 * @hw: pointer to the hw struct

 * @resource: resource id

 * @sdp_number: resource number

 * @cmd_details: pointer to command details structure or NULL

 *

 * release common resource using the admin queue commands

/**

 * i40e_aq_read_nvm

 * @hw: pointer to the hw struct

 * @module_pointer: module pointer location in words from the NVM beginning

 * @offset: byte offset from the module beginning

 * @length: length of the section to be read (in bytes from the offset)

 * @data: command buffer (size [bytes] = length)

 * @last_command: tells if this is the last command in a series

 * @cmd_details: pointer to command details structure or NULL

 *

 * Read the NVM using the admin queue commands

 In offset the highest byte must be zeroed. */

 If this is the last command in a series, set the proper flag. */

/**

 * i40e_aq_erase_nvm

 * @hw: pointer to the hw struct

 * @module_pointer: module pointer location in words from the NVM beginning

 * @offset: offset in the module (expressed in 4 KB from module's beginning)

 * @length: length of the section to be erased (expressed in 4 KB)

 * @last_command: tells if this is the last command in a series

 * @cmd_details: pointer to command details structure or NULL

 *

 * Erase the NVM sector using the admin queue commands

 In offset the highest byte must be zeroed. */

 If this is the last command in a series, set the proper flag. */

/**

 * i40e_parse_discover_capabilities

 * @hw: pointer to the hw struct

 * @buff: pointer to a buffer containing device/function capability records

 * @cap_count: number of capability records in the list

 * @list_type_opc: type of capabilities list to parse

 *

 * Parse the device/function capabilities list.

 Capability revision >= 2 */

	/* Software override ensuring FCoE is disabled if npar or mfp

	 * mode because it is not supported in these modes.

 count the enabled ports (aka the "not disabled" ports) */

		/* use AQ read to get the physical register offset instead

		 * of the port relative offset

	/* OCP cards case: if a mezz is removed the Ethernet port is at

	 * disabled state in PRTGEN_CNF register. Additional NVM read is

	 * needed in order to check if we are dealing with OCP card.

	 * Those cards have 4 PFs at minimum, so using PRTGEN_CNF for counting

	 * physical ports results in wrong partition id calculation and thus

	 * not supporting WoL.

	/* partition id is 1-based, and functions are evenly spread

	 * across the ports as partitions

	/* additional HW specific goodies that might

	 * someday be HW version specific

/**

 * i40e_aq_discover_capabilities

 * @hw: pointer to the hw struct

 * @buff: a virtual buffer to hold the capabilities

 * @buff_size: Size of the virtual buffer

 * @data_size: Size of the returned data, or buff size needed if AQ err==ENOMEM

 * @list_type_opc: capabilities type to discover - pass in the command opcode

 * @cmd_details: pointer to command details structure or NULL

 *

 * Get the device capabilities descriptions from the firmware

/**

 * i40e_aq_update_nvm

 * @hw: pointer to the hw struct

 * @module_pointer: module pointer location in words from the NVM beginning

 * @offset: byte offset from the module beginning

 * @length: length of the section to be written (in bytes from the offset)

 * @data: command buffer (size [bytes] = length)

 * @last_command: tells if this is the last command in a series

 * @preservation_flags: Preservation mode flags

 * @cmd_details: pointer to command details structure or NULL

 *

 * Update the NVM using the admin queue commands

 In offset the highest byte must be zeroed. */

 If this is the last command in a series, set the proper flag. */

/**

 * i40e_aq_rearrange_nvm

 * @hw: pointer to the hw struct

 * @rearrange_nvm: defines direction of rearrangement

 * @cmd_details: pointer to command details structure or NULL

 *

 * Rearrange NVM structure, available only for transition FW

/**

 * i40e_aq_get_lldp_mib

 * @hw: pointer to the hw struct

 * @bridge_type: type of bridge requested

 * @mib_type: Local, Remote or both Local and Remote MIBs

 * @buff: pointer to a user supplied buffer to store the MIB block

 * @buff_size: size of the buffer (in bytes)

 * @local_len : length of the returned Local LLDP MIB

 * @remote_len: length of the returned Remote LLDP MIB

 * @cmd_details: pointer to command details structure or NULL

 *

 * Requests the complete LLDP MIB (entire packet).

 Indirect Command */

/**

 * i40e_aq_set_lldp_mib - Set the LLDP MIB

 * @hw: pointer to the hw struct

 * @mib_type: Local, Remote or both Local and Remote MIBs

 * @buff: pointer to a user supplied buffer to store the MIB block

 * @buff_size: size of the buffer (in bytes)

 * @cmd_details: pointer to command details structure or NULL

 *

 * Set the LLDP MIB.

 Indirect Command */

/**

 * i40e_aq_cfg_lldp_mib_change_event

 * @hw: pointer to the hw struct

 * @enable_update: Enable or Disable event posting

 * @cmd_details: pointer to command details structure or NULL

 *

 * Enable or Disable posting of an event on ARQ when LLDP MIB

 * associated with the interface changes

/**

 * i40e_aq_restore_lldp

 * @hw: pointer to the hw struct

 * @setting: pointer to factory setting variable or NULL

 * @restore: True if factory settings should be restored

 * @cmd_details: pointer to command details structure or NULL

 *

 * Restore LLDP Agent factory settings if @restore set to True. In other case

 * only returns factory setting in AQ response.

/**

 * i40e_aq_stop_lldp

 * @hw: pointer to the hw struct

 * @shutdown_agent: True if LLDP Agent needs to be Shutdown

 * @persist: True if stop of LLDP should be persistent across power cycles

 * @cmd_details: pointer to command details structure or NULL

 *

 * Stop or Shutdown the embedded LLDP Agent

/**

 * i40e_aq_start_lldp

 * @hw: pointer to the hw struct

 * @persist: True if start of LLDP should be persistent across power cycles

 * @cmd_details: pointer to command details structure or NULL

 *

 * Start the embedded LLDP Agent on all ports.

/**

 * i40e_aq_set_dcb_parameters

 * @hw: pointer to the hw struct

 * @cmd_details: pointer to command details structure or NULL

 * @dcb_enable: True if DCB configuration needs to be applied

 *

/**

 * i40e_aq_get_cee_dcb_config

 * @hw: pointer to the hw struct

 * @buff: response buffer that stores CEE operational configuration

 * @buff_size: size of the buffer passed

 * @cmd_details: pointer to command details structure or NULL

 *

 * Get CEE DCBX mode operational configuration from firmware

/**

 * i40e_aq_add_udp_tunnel

 * @hw: pointer to the hw struct

 * @udp_port: the UDP port to add in Host byte order

 * @protocol_index: protocol index type

 * @filter_index: pointer to filter index

 * @cmd_details: pointer to command details structure or NULL

 *

 * Note: Firmware expects the udp_port value to be in Little Endian format,

 * and this function will call cpu_to_le16 to convert from Host byte order to

 * Little Endian order.

/**

 * i40e_aq_del_udp_tunnel

 * @hw: pointer to the hw struct

 * @index: filter index

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_delete_element - Delete switch element

 * @hw: pointer to the hw struct

 * @seid: the SEID to delete from the switch

 * @cmd_details: pointer to command details structure or NULL

 *

 * This deletes a switch element from the switch.

/**

 * i40e_aq_dcb_updated - DCB Updated Command

 * @hw: pointer to the hw struct

 * @cmd_details: pointer to command details structure or NULL

 *

 * EMP will return when the shared RPB settings have been

 * recomputed and modified. The retval field in the descriptor

 * will be set to 0 when RPB is modified.

/**

 * i40e_aq_tx_sched_cmd - generic Tx scheduler AQ command handler

 * @hw: pointer to the hw struct

 * @seid: seid for the physical port/switching component/vsi

 * @buff: Indirect buffer to hold data parameters and response

 * @buff_size: Indirect buffer size

 * @opcode: Tx scheduler AQ command opcode

 * @cmd_details: pointer to command details structure or NULL

 *

 * Generic command handler for Tx scheduler AQ commands

 Indirect command */

/**

 * i40e_aq_config_vsi_bw_limit - Configure VSI BW Limit

 * @hw: pointer to the hw struct

 * @seid: VSI seid

 * @credit: BW limit credits (0 = disabled)

 * @max_credit: Max BW limit credits

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_config_vsi_tc_bw - Config VSI BW Allocation per TC

 * @hw: pointer to the hw struct

 * @seid: VSI seid

 * @bw_data: Buffer holding enabled TCs, relative TC BW limit/credits

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_config_switch_comp_ets - Enable/Disable/Modify ETS on the port

 * @hw: pointer to the hw struct

 * @seid: seid of the switching component connected to Physical Port

 * @ets_data: Buffer holding ETS parameters

 * @opcode: Tx scheduler AQ command opcode

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_config_switch_comp_bw_config - Config Switch comp BW Alloc per TC

 * @hw: pointer to the hw struct

 * @seid: seid of the switching component

 * @bw_data: Buffer holding enabled TCs, relative/absolute TC BW limit/credits

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_query_vsi_bw_config - Query VSI BW configuration

 * @hw: pointer to the hw struct

 * @seid: seid of the VSI

 * @bw_data: Buffer to hold VSI BW configuration

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_query_vsi_ets_sla_config - Query VSI BW configuration per TC

 * @hw: pointer to the hw struct

 * @seid: seid of the VSI

 * @bw_data: Buffer to hold VSI BW configuration per TC

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_query_switch_comp_ets_config - Query Switch comp BW config per TC

 * @hw: pointer to the hw struct

 * @seid: seid of the switching component

 * @bw_data: Buffer to hold switching component's per TC BW config

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_query_port_ets_config - Query Physical Port ETS configuration

 * @hw: pointer to the hw struct

 * @seid: seid of the VSI or switching component connected to Physical Port

 * @bw_data: Buffer to hold current ETS configuration for the Physical Port

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_query_switch_comp_bw_config - Query Switch comp BW configuration

 * @hw: pointer to the hw struct

 * @seid: seid of the switching component

 * @bw_data: Buffer to hold switching component's BW configuration

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_validate_filter_settings

 * @hw: pointer to the hardware structure

 * @settings: Filter control settings

 *

 * Check and validate the filter control settings passed.

 * The function checks for the valid filter/context sizes being

 * passed for FCoE and PE.

 *

 * Returns 0 if the values passed are valid and within

 * range else returns an error.

 Validate FCoE settings passed */

 Validate PE settings passed */

 FCHSIZE + FCDSIZE should not be greater than PMFCOEFMAX */

/**

 * i40e_set_filter_control

 * @hw: pointer to the hardware structure

 * @settings: Filter control settings

 *

 * Set the Queue Filters for PE/FCoE and enable filters required

 * for a single PF. It is expected that these settings are programmed

 * at the driver initialization time.

 Validate the input settings */

 Read the PF Queue Filter control register */

 Program required PE hash buckets for the PF */

 Program required PE contexts for the PF */

 Program required FCoE hash buckets for the PF */

 Program required FCoE DDP contexts for the PF */

 Program Hash LUT size for the PF */

 Enable FDIR, Ethertype and MACVLAN filters for PF and VFs */

/**

 * i40e_aq_add_rem_control_packet_filter - Add or Remove Control Packet Filter

 * @hw: pointer to the hw struct

 * @mac_addr: MAC address to use in the filter

 * @ethtype: Ethertype to use in the filter

 * @flags: Flags that needs to be applied to the filter

 * @vsi_seid: seid of the control VSI

 * @queue: VSI queue number to send the packet to

 * @is_add: Add control packet filter if True else remove

 * @stats: Structure to hold information on control filter counts

 * @cmd_details: pointer to command details structure or NULL

 *

 * This command will Add or Remove control packet filter for a control VSI.

 * In return it will update the total number of perfect filter count in

 * the stats member.

/**

 * i40e_add_filter_to_drop_tx_flow_control_frames- filter to drop flow control

 * @hw: pointer to the hw struct

 * @seid: VSI seid to add ethertype filter from

/**

 * i40e_aq_alternate_read

 * @hw: pointer to the hardware structure

 * @reg_addr0: address of first dword to be read

 * @reg_val0: pointer for data read from 'reg_addr0'

 * @reg_addr1: address of second dword to be read

 * @reg_val1: pointer for data read from 'reg_addr1'

 *

 * Read one or two dwords from alternate structure. Fields are indicated

 * by 'reg_addr0' and 'reg_addr1' register numbers. If 'reg_val1' pointer

 * is not passed then only register at 'reg_addr0' is read.

 *

/**

 * i40e_aq_suspend_port_tx

 * @hw: pointer to the hardware structure

 * @seid: port seid

 * @cmd_details: pointer to command details structure or NULL

 *

 * Suspend port's Tx traffic

/**

 * i40e_aq_resume_port_tx

 * @hw: pointer to the hardware structure

 * @cmd_details: pointer to command details structure or NULL

 *

 * Resume port's Tx traffic

/**

 * i40e_set_pci_config_data - store PCI bus info

 * @hw: pointer to hardware structure

 * @link_status: the link status word from PCI config space

 *

 * Stores the PCI bus info (speed, width, type) within the i40e_hw structure

/**

 * i40e_aq_debug_dump

 * @hw: pointer to the hardware structure

 * @cluster_id: specific cluster to dump

 * @table_id: table id within cluster

 * @start_index: index of line in the block to read

 * @buff_size: dump buffer size

 * @buff: dump buffer

 * @ret_buff_size: actual buffer size returned

 * @ret_next_table: next block to read

 * @ret_next_index: next index to read

 * @cmd_details: pointer to command details structure or NULL

 *

 * Dump internal FW/HW data for debug purposes.

 *

 Indirect Command */

/**

 * i40e_read_bw_from_alt_ram

 * @hw: pointer to the hardware structure

 * @max_bw: pointer for max_bw read

 * @min_bw: pointer for min_bw read

 * @min_valid: pointer for bool that is true if min_bw is a valid value

 * @max_valid: pointer for bool that is true if max_bw is a valid value

 *

 * Read bw from the alternate ram for the given pf

 Calculate the address of the min/max bw registers */

 Read the bandwidths from alt ram */

/**

 * i40e_aq_configure_partition_bw

 * @hw: pointer to the hardware structure

 * @bw_data: Buffer holding valid pfs and bw limits

 * @cmd_details: pointer to command details

 *

 * Configure partitions guaranteed/max bw

 Indirect command */

/**

 * i40e_read_phy_register_clause22

 * @hw: pointer to the HW structure

 * @reg: register address in the page

 * @phy_addr: PHY address on MDIO interface

 * @value: PHY register value

 *

 * Reads specified PHY register value

/**

 * i40e_write_phy_register_clause22

 * @hw: pointer to the HW structure

 * @reg: register address in the page

 * @phy_addr: PHY address on MDIO interface

 * @value: PHY register value

 *

 * Writes specified PHY register value

/**

 * i40e_read_phy_register_clause45

 * @hw: pointer to the HW structure

 * @page: registers page number

 * @reg: register address in the page

 * @phy_addr: PHY address on MDIO interface

 * @value: PHY register value

 *

 * Reads specified PHY register value

/**

 * i40e_write_phy_register_clause45

 * @hw: pointer to the HW structure

 * @page: registers page number

 * @reg: register address in the page

 * @phy_addr: PHY address on MDIO interface

 * @value: PHY register value

 *

 * Writes value to specified PHY register

/**

 * i40e_write_phy_register

 * @hw: pointer to the HW structure

 * @page: registers page number

 * @reg: register address in the page

 * @phy_addr: PHY address on MDIO interface

 * @value: PHY register value

 *

 * Writes value to specified PHY register

/**

 * i40e_read_phy_register

 * @hw: pointer to the HW structure

 * @page: registers page number

 * @reg: register address in the page

 * @phy_addr: PHY address on MDIO interface

 * @value: PHY register value

 *

 * Reads specified PHY register value

/**

 * i40e_get_phy_address

 * @hw: pointer to the HW structure

 * @dev_num: PHY port num that address we want

 *

 * Gets PHY address for current port

/**

 * i40e_blink_phy_link_led

 * @hw: pointer to the HW structure

 * @time: time how long led will blinks in secs

 * @interval: gap between LED on and off in msecs

 *

 * Blinks PHY link LED

/**

 * i40e_led_get_reg - read LED register

 * @hw: pointer to the HW structure

 * @led_addr: LED register address

 * @reg_val: read register value

/**

 * i40e_led_set_reg - write LED register

 * @hw: pointer to the HW structure

 * @led_addr: LED register address

 * @reg_val: register value to write

/**

 * i40e_led_get_phy - return current on/off mode

 * @hw: pointer to the hw struct

 * @led_addr: address of led register to use

 * @val: original value of register to use

 *

/**

 * i40e_led_set_phy

 * @hw: pointer to the HW structure

 * @on: true or false

 * @led_addr: address of led register to use

 * @mode: original val plus bit for set or ignore

 *

 * Set led's on or off when controlled by the PHY

 *

/**

 * i40e_aq_rx_ctl_read_register - use FW to read from an Rx control register

 * @hw: pointer to the hw struct

 * @reg_addr: register address

 * @reg_val: ptr to register value

 * @cmd_details: pointer to command details structure or NULL

 *

 * Use the firmware to read the Rx control register,

 * especially useful if the Rx unit is under heavy pressure

/**

 * i40e_read_rx_ctl - read from an Rx control register

 * @hw: pointer to the hw struct

 * @reg_addr: register address

 if the AQ access failed, try the old-fashioned way */

/**

 * i40e_aq_rx_ctl_write_register

 * @hw: pointer to the hw struct

 * @reg_addr: register address

 * @reg_val: register value

 * @cmd_details: pointer to command details structure or NULL

 *

 * Use the firmware to write to an Rx control register,

 * especially useful if the Rx unit is under heavy pressure

/**

 * i40e_write_rx_ctl - write to an Rx control register

 * @hw: pointer to the hw struct

 * @reg_addr: register address

 * @reg_val: register value

 if the AQ access failed, try the old-fashioned way */

/**

 * i40e_mdio_if_number_selection - MDIO I/F number selection

 * @hw: pointer to the hw struct

 * @set_mdio: use MDIO I/F number specified by mdio_num

 * @mdio_num: MDIO I/F number

 * @cmd: pointer to PHY Register command structure

/**

 * i40e_aq_set_phy_register_ext

 * @hw: pointer to the hw struct

 * @phy_select: select which phy should be accessed

 * @dev_addr: PHY device address

 * @page_change: flag to indicate if phy page should be updated

 * @set_mdio: use MDIO I/F number specified by mdio_num

 * @mdio_num: MDIO I/F number

 * @reg_addr: PHY register address

 * @reg_val: new register value

 * @cmd_details: pointer to command details structure or NULL

 *

 * Write the external PHY register.

 * NOTE: In common cases MDIO I/F number should not be changed, thats why you

 * may use simple wrapper i40e_aq_set_phy_register.

/**

 * i40e_aq_get_phy_register_ext

 * @hw: pointer to the hw struct

 * @phy_select: select which phy should be accessed

 * @dev_addr: PHY device address

 * @page_change: flag to indicate if phy page should be updated

 * @set_mdio: use MDIO I/F number specified by mdio_num

 * @mdio_num: MDIO I/F number

 * @reg_addr: PHY register address

 * @reg_val: read register value

 * @cmd_details: pointer to command details structure or NULL

 *

 * Read the external PHY register.

 * NOTE: In common cases MDIO I/F number should not be changed, thats why you

 * may use simple wrapper i40e_aq_get_phy_register.

/**

 * i40e_aq_write_ddp - Write dynamic device personalization (ddp)

 * @hw: pointer to the hw struct

 * @buff: command buffer (size in bytes = buff_size)

 * @buff_size: buffer size in bytes

 * @track_id: package tracking id

 * @error_offset: returns error offset

 * @error_info: returns error information

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_aq_get_ddp_list - Read dynamic device personalization (ddp)

 * @hw: pointer to the hw struct

 * @buff: command buffer (size in bytes = buff_size)

 * @buff_size: buffer size in bytes

 * @flags: AdminQ command flags

 * @cmd_details: pointer to command details structure or NULL

/**

 * i40e_find_segment_in_package

 * @segment_type: the segment type to search for (i.e., SEGMENT_TYPE_I40E)

 * @pkg_hdr: pointer to the package header to be searched

 *

 * This function searches a package file for a particular segment type. On

 * success it returns a pointer to the segment header, otherwise it will

 * return NULL.

 Search all package segments for the requested segment type */

 Get section table in profile */

 Get section header in profile */

/**

 * i40e_find_section_in_profile

 * @section_type: the section type to search for (i.e., SECTION_TYPE_NOTE)

 * @profile: pointer to the i40e segment header to be searched

 *

 * This function searches i40e segment for a particular section type. On

 * success it returns a pointer to the section header, otherwise it will

 * return NULL.

/**

 * i40e_ddp_exec_aq_section - Execute generic AQ for DDP

 * @hw: pointer to the hw struct

 * @aq: command buffer containing all data to execute AQ

 copy returned desc to aq_buf */

/**

 * i40e_validate_profile

 * @hw: pointer to the hardware structure

 * @profile: pointer to the profile segment of the package to be validated

 * @track_id: package tracking id

 * @rollback: flag if the profile is for rollback.

 *

 * Validates supported devices and profile's sections.

 Validate sections types */

/**

 * i40e_write_profile

 * @hw: pointer to the hardware structure

 * @profile: pointer to the profile segment of the package to be downloaded

 * @track_id: package tracking id

 *

 * Handles the download of a complete package.

 Process generic admin command */

 Skip any non-mmio sections */

 Write MMIO section */

/**

 * i40e_rollback_profile

 * @hw: pointer to the hardware structure

 * @profile: pointer to the profile segment of the package to be removed

 * @track_id: package tracking id

 *

 * Rolls back previously loaded package.

 For rollback write sections in reverse */

 Skip any non-rollback sections */

 Write roll-back MMIO section */

/**

 * i40e_add_pinfo_to_list

 * @hw: pointer to the hardware structure

 * @profile: pointer to the profile segment of the package

 * @profile_info_sec: buffer for information section

 * @track_id: package tracking id

 *

 * Register a profile to the list of loaded profiles.

/**

 * i40e_aq_add_cloud_filters

 * @hw: pointer to the hardware structure

 * @seid: VSI seid to add cloud filters from

 * @filters: Buffer which contains the filters to be added

 * @filter_count: number of filters contained in the buffer

 *

 * Set the cloud filters for a given VSI.  The contents of the

 * i40e_aqc_cloud_filters_element_data are filled in by the caller

 * of the function.

 *

/**

 * i40e_aq_add_cloud_filters_bb

 * @hw: pointer to the hardware structure

 * @seid: VSI seid to add cloud filters from

 * @filters: Buffer which contains the filters in big buffer to be added

 * @filter_count: number of filters contained in the buffer

 *

 * Set the big buffer cloud filters for a given VSI.  The contents of the

 * i40e_aqc_cloud_filters_element_bb are filled in by the caller of the

 * function.

 *

		/* Due to hardware eccentricities, the VNI for Geneve is shifted

		 * one more byte further than normally used for Tenant ID in

		 * other tunnel types.

/**

 * i40e_aq_rem_cloud_filters

 * @hw: pointer to the hardware structure

 * @seid: VSI seid to remove cloud filters from

 * @filters: Buffer which contains the filters to be removed

 * @filter_count: number of filters contained in the buffer

 *

 * Remove the cloud filters for a given VSI.  The contents of the

 * i40e_aqc_cloud_filters_element_data are filled in by the caller

 * of the function.

 *

/**

 * i40e_aq_rem_cloud_filters_bb

 * @hw: pointer to the hardware structure

 * @seid: VSI seid to remove cloud filters from

 * @filters: Buffer which contains the filters in big buffer to be removed

 * @filter_count: number of filters contained in the buffer

 *

 * Remove the big buffer cloud filters for a given VSI.  The contents of the

 * i40e_aqc_cloud_filters_element_bb are filled in by the caller of the

 * function.

 *

		/* Due to hardware eccentricities, the VNI for Geneve is shifted

		 * one more byte further than normally used for Tenant ID in

		 * other tunnel types.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2021 Intel Corporation. */

/**

 * i40e_get_dcbx_status

 * @hw: pointer to the hw struct

 * @status: Embedded DCBX Engine Status

 *

 * Get the DCBX status from the Firmware

/**

 * i40e_parse_ieee_etscfg_tlv

 * @tlv: IEEE 802.1Qaz ETS CFG TLV

 * @dcbcfg: Local store to update ETS CFG data

 *

 * Parses IEEE 802.1Qaz ETS CFG TLV

	/* First Octet post subtype

	 * --------------------------

	 * |will-|CBS  | Re-  | Max |

	 * |ing  |     |served| TCs |

	 * --------------------------

	 * |1bit | 1bit|3 bits|3bits|

 Move offset to Priority Assignment Table */

	/* Priority Assignment Table (4 octets)

	 * Octets:|    1    |    2    |    3    |    4    |

	 *        -----------------------------------------

	 *        |pri0|pri1|pri2|pri3|pri4|pri5|pri6|pri7|

	 *        -----------------------------------------

	 *   Bits:|7  4|3  0|7  4|3  0|7  4|3  0|7  4|3  0|

	 *        -----------------------------------------

	/* TC Bandwidth Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

	/* TSA Assignment Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

/**

 * i40e_parse_ieee_etsrec_tlv

 * @tlv: IEEE 802.1Qaz ETS REC TLV

 * @dcbcfg: Local store to update ETS REC data

 *

 * Parses IEEE 802.1Qaz ETS REC TLV

 Move offset to priority table */

	/* Priority Assignment Table (4 octets)

	 * Octets:|    1    |    2    |    3    |    4    |

	 *        -----------------------------------------

	 *        |pri0|pri1|pri2|pri3|pri4|pri5|pri6|pri7|

	 *        -----------------------------------------

	 *   Bits:|7  4|3  0|7  4|3  0|7  4|3  0|7  4|3  0|

	 *        -----------------------------------------

	/* TC Bandwidth Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

	/* TSA Assignment Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

/**

 * i40e_parse_ieee_pfccfg_tlv

 * @tlv: IEEE 802.1Qaz PFC CFG TLV

 * @dcbcfg: Local store to update PFC CFG data

 *

 * Parses IEEE 802.1Qaz PFC CFG TLV

	/* ----------------------------------------

	 * |will-|MBC  | Re-  | PFC |  PFC Enable  |

	 * |ing  |     |served| cap |              |

	 * -----------------------------------------

	 * |1bit | 1bit|2 bits|4bits| 1 octet      |

/**

 * i40e_parse_ieee_app_tlv

 * @tlv: IEEE 802.1Qaz APP TLV

 * @dcbcfg: Local store to update APP PRIO data

 *

 * Parses IEEE 802.1Qaz APP PRIO TLV

 The App priority table starts 5 octets after TLV header */

 Move offset to App Priority Table */

	/* Application Priority Table (3 octets)

	 * Octets:|         1          |    2    |    3    |

	 *        -----------------------------------------

	 *        |Priority|Rsrvd| Sel |    Protocol ID    |

	 *        -----------------------------------------

	 *   Bits:|23    21|20 19|18 16|15                0|

	 *        -----------------------------------------

 Move to next app */

/**

 * i40e_parse_ieee_tlv

 * @tlv: IEEE 802.1Qaz TLV

 * @dcbcfg: Local store to update ETS REC data

 *

 * Get the TLV subtype and send it to parsing function

 * based on the subtype value

/**

 * i40e_parse_cee_pgcfg_tlv

 * @tlv: CEE DCBX PG CFG TLV

 * @dcbcfg: Local store to update ETS CFG data

 *

 * Parses CEE DCBX PG CFG TLV

	/* Priority Group Table (4 octets)

	 * Octets:|    1    |    2    |    3    |    4    |

	 *        -----------------------------------------

	 *        |pri0|pri1|pri2|pri3|pri4|pri5|pri6|pri7|

	 *        -----------------------------------------

	 *   Bits:|7  4|3  0|7  4|3  0|7  4|3  0|7  4|3  0|

	 *        -----------------------------------------

	/* PG Percentage Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |pg0|pg1|pg2|pg3|pg4|pg5|pg6|pg7|

	 *        ---------------------------------

 Number of TCs supported (1 octet) */

/**

 * i40e_parse_cee_pfccfg_tlv

 * @tlv: CEE DCBX PFC CFG TLV

 * @dcbcfg: Local store to update PFC CFG data

 *

 * Parses CEE DCBX PFC CFG TLV

	/* ------------------------

	 * | PFC Enable | PFC TCs |

	 * ------------------------

	 * | 1 octet    | 1 octet |

/**

 * i40e_parse_cee_app_tlv

 * @tlv: CEE DCBX APP TLV

 * @dcbcfg: Local store to update APP PRIO data

 *

 * Parses CEE DCBX APP PRIO TLV

 Get Selector from lower 2 bits, and convert to IEEE */

 Keep selector as it is for unknown types */

 Move to next app */

/**

 * i40e_parse_cee_tlv

 * @tlv: CEE DCBX TLV

 * @dcbcfg: Local store to update DCBX config data

 *

 * Get the TLV subtype and send it to parsing function

 * based on the subtype value

 Return if not CEE DCBX */

 Return if no CEE DCBX Feature TLVs */

 Invalid Sub-type return */

 Move to next sub TLV */

/**

 * i40e_parse_org_tlv

 * @tlv: Organization specific TLV

 * @dcbcfg: Local store to update ETS REC data

 *

 * Currently only IEEE 802.1Qaz TLV is supported, all others

 * will be returned

/**

 * i40e_lldp_to_dcb_config

 * @lldpmib: LLDPDU to be parsed

 * @dcbcfg: store for LLDPDU data

 *

 * Parse DCB configuration from the LLDPDU

 set to the start of LLDPDU */

 END TLV or beyond LLDPDU size */

 Move to next TLV */

/**

 * i40e_aq_get_dcb_config

 * @hw: pointer to the hw struct

 * @mib_type: mib type for the query

 * @bridgetype: bridge type for the query (remote)

 * @dcbcfg: store for LLDPDU data

 *

 * Query DCB configuration from the Firmware

 Allocate the LLDPDU */

 Parse LLDP MIB to get dcb configuration */

/**

 * i40e_cee_to_dcb_v1_config

 * @cee_cfg: pointer to CEE v1 response configuration struct

 * @dcbcfg: DCB configuration struct

 *

 * Convert CEE v1 configuration from firmware to DCB configuration

 CEE PG data to ETS config */

	/* Note that the FW creates the oper_prio_tc nibbles reversed

	 * from those in the CEE Priority Group sub-TLV.

 Map it to next empty TC */

 CEE PFC data to ETS config */

 Add APPs if Error is False */

 CEE operating configuration supports FCoE/iSCSI/FIP only */

 FCoE APP */

 iSCSI APP */

 FIP APP */

/**

 * i40e_cee_to_dcb_config

 * @cee_cfg: pointer to CEE configuration struct

 * @dcbcfg: DCB configuration struct

 *

 * Convert CEE configuration from firmware to DCB configuration

 CEE PG data to ETS config */

	/* Note that the FW creates the oper_prio_tc nibbles reversed

	 * from those in the CEE Priority Group sub-TLV.

 Map it to next empty TC */

 CEE PFC data to ETS config */

 Add FCoE APP if Error is False and Oper/Sync is True */

 FCoE APP */

 Add iSCSI APP if Error is False and Oper/Sync is True */

 iSCSI APP */

 Add FIP APP if Error is False and Oper/Sync is True */

 FIP APP */

/**

 * i40e_get_ieee_dcb_config

 * @hw: pointer to the hw struct

 *

 * Get IEEE mode DCB configuration from the Firmware

 IEEE mode */

 Get Local DCB Config */

 Get Remote DCB Config */

 Don't treat ENOENT as an error for Remote MIBs */

/**

 * i40e_get_dcb_config

 * @hw: pointer to the hw struct

 *

 * Get DCB configuration from the Firmware

 If Firmware version < v4.33 on X710/XL710, IEEE only */

 If Firmware version == v4.33 on X710/XL710, use old CEE struct */

 CEE mode */

 CEE mode */

 CEE mode not enabled try querying IEEE data */

 Get CEE DCB Desired Config */

 Get Remote DCB Config */

 Don't treat ENOENT as an error for Remote MIBs */

/**

 * i40e_init_dcb

 * @hw: pointer to the hw struct

 * @enable_mib_change: enable mib change event

 *

 * Update DCB configuration from the Firmware

 Read LLDP NVM area */

 Get the LLDP AdminStatus for the current port */

 LLDP agent disabled */

 Get DCBX status */

 Check the DCBX Status */

 Get current DCBX configuration */

 Configure the LLDP MIB change event */

/**

 * i40e_get_fw_lldp_status

 * @hw: pointer to the hw struct

 * @lldp_status: pointer to the status enum

 *

 * Get status of FW Link Layer Discovery Protocol (LLDP) Agent.

 * Status of agent is reported via @lldp_status parameter.

 Allocate buffer for the LLDPDU */

 MIB is not available yet but the agent is running */

/**

 * i40e_add_ieee_ets_tlv - Prepare ETS TLV in IEEE format

 * @tlv: Fill the ETS config data in IEEE format

 * @dcbcfg: Local store which holds the DCB Config

 *

 * Prepare IEEE 802.1Qaz ETS CFG TLV

	/* First Octet post subtype

	 * --------------------------

	 * |will-|CBS  | Re-  | Max |

	 * |ing  |     |served| TCs |

	 * --------------------------

	 * |1bit | 1bit|3 bits|3bits|

 Move offset to Priority Assignment Table */

	/* Priority Assignment Table (4 octets)

	 * Octets:|    1    |    2    |    3    |    4    |

	 *        -----------------------------------------

	 *        |pri0|pri1|pri2|pri3|pri4|pri5|pri6|pri7|

	 *        -----------------------------------------

	 *   Bits:|7  4|3  0|7  4|3  0|7  4|3  0|7  4|3  0|

	 *        -----------------------------------------

	/* TC Bandwidth Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

	/* TSA Assignment Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

/**

 * i40e_add_ieee_etsrec_tlv - Prepare ETS Recommended TLV in IEEE format

 * @tlv: Fill ETS Recommended TLV in IEEE format

 * @dcbcfg: Local store which holds the DCB Config

 *

 * Prepare IEEE 802.1Qaz ETS REC TLV

 First Octet is reserved */

 Move offset to Priority Assignment Table */

	/* Priority Assignment Table (4 octets)

	 * Octets:|    1    |    2    |    3    |    4    |

	 *        -----------------------------------------

	 *        |pri0|pri1|pri2|pri3|pri4|pri5|pri6|pri7|

	 *        -----------------------------------------

	 *   Bits:|7  4|3  0|7  4|3  0|7  4|3  0|7  4|3  0|

	 *        -----------------------------------------

	/* TC Bandwidth Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

	/* TSA Assignment Table (8 octets)

	 * Octets:| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |

	 *        ---------------------------------

	 *        |tc0|tc1|tc2|tc3|tc4|tc5|tc6|tc7|

	 *        ---------------------------------

/**

 * i40e_add_ieee_pfc_tlv - Prepare PFC TLV in IEEE format

 * @tlv: Fill PFC TLV in IEEE format

 * @dcbcfg: Local store to get PFC CFG data

 *

 * Prepare IEEE 802.1Qaz PFC CFG TLV

	/* ----------------------------------------

	 * |will-|MBC  | Re-  | PFC |  PFC Enable  |

	 * |ing  |     |served| cap |              |

	 * -----------------------------------------

	 * |1bit | 1bit|2 bits|4bits| 1 octet      |

/**

 * i40e_add_ieee_app_pri_tlv -  Prepare APP TLV in IEEE format

 * @tlv: Fill APP TLV in IEEE format

 * @dcbcfg: Local store to get APP CFG data

 *

 * Prepare IEEE 802.1Qaz APP CFG TLV

 No APP TLVs then just return */

 Move offset to App Priority Table */

	/* Application Priority Table (3 octets)

	 * Octets:|         1          |    2    |    3    |

	 *        -----------------------------------------

	 *        |Priority|Rsrvd| Sel |    Protocol ID    |

	 *        -----------------------------------------

	 *   Bits:|23    21|20 19|18 16|15                0|

	 *        -----------------------------------------

 Move to next app */

 length includes size of ouisubtype + 1 reserved + 3*numapps */

/**

 * i40e_add_dcb_tlv - Add all IEEE TLVs

 * @tlv: pointer to org tlv

 * @dcbcfg: pointer to modified dcbx config structure *

 * @tlvid: tlv id to be added

 * add tlv information

/**

 * i40e_set_dcb_config - Set the local LLDP MIB to FW

 * @hw: pointer to the hw struct

 *

 * Set DCB configuration to the Firmware

 update the hw local config */

 Allocate the LLDPDU */

/**

 * i40e_dcb_config_to_lldp - Convert Dcbconfig to MIB format

 * @lldpmib: pointer to mib to be output

 * @miblen: pointer to u16 for length of lldpmib

 * @dcbcfg: store for LLDPDU data

 *

 * send DCB configuration to FW

 END TLV or beyond LLDPDU size */

 Move to next TLV */

/**

 * i40e_dcb_hw_rx_fifo_config

 * @hw: pointer to the hw struct

 * @ets_mode: Strict Priority or Round Robin mode

 * @non_ets_mode: Strict Priority or Round Robin

 * @max_exponent: Exponent to calculate max refill credits

 * @lltc_map: Low latency TC bitmap

 *

 * Configure HW Rx FIFO as part of DCB configuration.

/**

 * i40e_dcb_hw_rx_cmd_monitor_config

 * @hw: pointer to the hw struct

 * @num_tc: Total number of traffic class

 * @num_ports: Total number of ports on device

 *

 * Configure HW Rx command monitor as part of DCB configuration.

 Set the threshold and fifo_size based on number of ports */

	/* The hardware manual describes setting up of I40E_PRT_SWR_PM_THR

	 * based on the number of ports and traffic classes for a given port as

	 * part of DCB configuration.

/**

 * i40e_dcb_hw_pfc_config

 * @hw: pointer to the hw struct

 * @pfc_en: Bitmap of PFC enabled priorities

 * @prio_tc: priority to tc assignment indexed by priority

 *

 * Configure HW Priority Flow Controller as part of DCB configuration.

 Get Number of PFC TCs and TC2PFC map */

 Set bit for the PFC TC */

 FCTTV and FCRTV to be set by default */

		/* PRTMAC_HSEC_CTL_TX_PAUSE_QUANTA default value is 0xFFFF

		 * for all user priorities

/**

 * i40e_dcb_hw_set_num_tc

 * @hw: pointer to the hw struct

 * @num_tc: number of traffic classes

 *

 * Configure number of traffic classes in HW

/**

 * i40e_dcb_hw_get_num_tc

 * @hw: pointer to the hw struct

 *

 * Returns number of traffic classes configured in HW

/**

 * i40e_dcb_hw_rx_ets_bw_config

 * @hw: pointer to the hw struct

 * @bw_share: Bandwidth share indexed per traffic class

 * @mode: Strict Priority or Round Robin mode between UP sharing same

 * traffic class

 * @prio_type: TC is ETS enabled or strict priority

 *

 * Configure HW Rx ETS bandwidth as part of DCB configuration.

/**

 * i40e_dcb_hw_rx_up2tc_config

 * @hw: pointer to the hw struct

 * @prio_tc: priority to tc assignment indexed by priority

 *

 * Configure HW Rx UP2TC map as part of DCB configuration.

/**

 * i40e_dcb_hw_calculate_pool_sizes - configure dcb pool sizes

 * @hw: pointer to the hw struct

 * @num_ports: Number of available ports on the device

 * @eee_enabled: EEE enabled for the given port

 * @pfc_en: Bit map of PFC enabled traffic classes

 * @mfs_tc: Array of max frame size for each traffic class

 * @pb_cfg: pointer to packet buffer configuration

 *

 * Calculate the shared and dedicated per TC pool sizes,

 * watermarks and threshold values.

 Need signed variable */

 Get the MFS(max) for the port */

 Calculate effective Rx PB size per port */

 Step 1 Calculating tc pool/shared pool sizes and watermarks */

/**

 * i40e_dcb_hw_rx_pb_config

 * @hw: pointer to the hw struct

 * @old_pb_cfg: Existing Rx Packet buffer configuration

 * @new_pb_cfg: New Rx Packet buffer configuration

 *

 * Program the Rx Packet Buffer registers.

	/* The Rx Packet buffer register programming needs to be done in a

	 * certain order and the following code is based on that

	 * requirement.

 Program the shared pool low water mark per port if decreasing */

	/* Program the shared pool low threshold and tc pool

	 * low water mark per TC that are decreasing.

 Program the shared pool high water mark per port if decreasing */

	/* Program the shared pool high threshold and tc pool

	 * high water mark per TC that are decreasing.

 Write Dedicated Pool Sizes per TC */

 Write Shared Pool Size per port */

 Program the shared pool low water mark per port if increasing */

	/* Program the shared pool low threshold and tc pool

	 * low water mark per TC that are increasing.

 Program the shared pool high water mark per port if increasing */

	/* Program the shared pool high threshold and tc pool

	 * high water mark per TC that are increasing.

/**

 * _i40e_read_lldp_cfg - generic read of LLDP Configuration data from NVM

 * @hw: pointer to the HW structure

 * @lldp_cfg: pointer to hold lldp configuration variables

 * @module: address of the module pointer

 * @word_offset: offset of LLDP configuration

 *

 * Reads the LLDP configuration data from NVM using passed addresses

	/* Check if this pointer needs to be read in word size or 4K sector

	 * units.

/**

 * i40e_read_lldp_cfg - read LLDP Configuration data from NVM

 * @hw: pointer to the HW structure

 * @lldp_cfg: pointer to hold lldp configuration variables

 *

 * Reads the LLDP configuration data from NVM

	/* Read a bit that holds information whether we are running flat or

	 * structured NVM image. Flat image has LLDP configuration in shadow

	 * ram, so there is a need to pass different addresses for both cases.

 Flat NVM case */

 Good old structured NVM image */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 *  i40e_adminq_init_regs - Initialize AdminQ registers

 *  @hw: pointer to the hardware structure

 *

 *  This assumes the alloc_asq and alloc_arq functions have already been called

 set head and tail registers in our local struct */

/**

 *  i40e_alloc_adminq_asq_ring - Allocate Admin Queue send rings

 *  @hw: pointer to the hardware structure

/**

 *  i40e_alloc_adminq_arq_ring - Allocate Admin Queue receive rings

 *  @hw: pointer to the hardware structure

/**

 *  i40e_free_adminq_asq - Free Admin Queue send rings

 *  @hw: pointer to the hardware structure

 *

 *  This assumes the posted send buffers have already been cleaned

 *  and de-allocated

/**

 *  i40e_free_adminq_arq - Free Admin Queue receive rings

 *  @hw: pointer to the hardware structure

 *

 *  This assumes the posted receive buffers have already been cleaned

 *  and de-allocated

/**

 *  i40e_alloc_arq_bufs - Allocate pre-posted buffers for the receive queue

 *  @hw: pointer to the hardware structure

	/* We'll be allocating the buffer info memory first, then we can

	 * allocate the mapped buffers for the event processing

 buffer_info structures do not need alignment */

 allocate the mapped buffers */

 now configure the descriptors for use */

		/* This is in accordance with Admin queue design, there is no

		 * register for buffer size configuration

 don't try to free the one that failed... */

/**

 *  i40e_alloc_asq_bufs - Allocate empty buffer structs for the send queue

 *  @hw: pointer to the hardware structure

 No mapped memory needed yet, just the buffer info structures */

 allocate the mapped buffers */

 don't try to free the one that failed... */

/**

 *  i40e_free_arq_bufs - Free receive queue buffer info elements

 *  @hw: pointer to the hardware structure

 free descriptors */

 free the descriptor memory */

 free the dma header */

/**

 *  i40e_free_asq_bufs - Free send queue buffer info elements

 *  @hw: pointer to the hardware structure

 only unmap if the address is non-NULL */

 free the buffer info list */

 free the descriptor memory */

 free the dma header */

/**

 *  i40e_config_asq_regs - configure ASQ registers

 *  @hw: pointer to the hardware structure

 *

 *  Configure base address and length registers for the transmit queue

 Clear Head and Tail */

 set starting point */

 Check one register to verify that config was applied */

/**

 *  i40e_config_arq_regs - ARQ register configuration

 *  @hw: pointer to the hardware structure

 *

 * Configure base address and length registers for the receive (event queue)

 Clear Head and Tail */

 set starting point */

 Update tail in the HW to post pre-allocated buffers */

 Check one register to verify that config was applied */

/**

 *  i40e_init_asq - main initialization routine for ASQ

 *  @hw: pointer to the hardware structure

 *

 *  This is the main initialization routine for the Admin Send Queue

 *  Prior to calling this function, drivers *MUST* set the following fields

 *  in the hw->aq structure:

 *     - hw->aq.num_asq_entries

 *     - hw->aq.arq_buf_size

 *

 *  Do *NOT* hold the lock when calling this as the memory allocation routines

 *  called are not going to be atomic context safe

 queue already initialized */

 verify input for valid configuration */

 allocate the ring memory */

 allocate buffers in the rings */

 initialize base registers */

 success! */

/**

 *  i40e_init_arq - initialize ARQ

 *  @hw: pointer to the hardware structure

 *

 *  The main initialization routine for the Admin Receive (Event) Queue.

 *  Prior to calling this function, drivers *MUST* set the following fields

 *  in the hw->aq structure:

 *     - hw->aq.num_asq_entries

 *     - hw->aq.arq_buf_size

 *

 *  Do *NOT* hold the lock when calling this as the memory allocation routines

 *  called are not going to be atomic context safe

 queue already initialized */

 verify input for valid configuration */

 allocate the ring memory */

 allocate buffers in the rings */

 initialize base registers */

 success! */

/**

 *  i40e_shutdown_asq - shutdown the ASQ

 *  @hw: pointer to the hardware structure

 *

 *  The main shutdown routine for the Admin Send Queue

 Stop firmware AdminQ processing */

 to indicate uninitialized queue */

 free ring buffers */

/**

 *  i40e_shutdown_arq - shutdown ARQ

 *  @hw: pointer to the hardware structure

 *

 *  The main shutdown routine for the Admin Receive Queue

 Stop firmware AdminQ processing */

 to indicate uninitialized queue */

 free ring buffers */

/**

 *  i40e_set_hw_flags - set HW flags

 *  @hw: pointer to the hardware structure

 The ability to RX (not drop) 802.1ad frames */

 Newer versions of firmware require lock when reading the NVM */

/**

 *  i40e_init_adminq - main initialization routine for Admin Queue

 *  @hw: pointer to the hardware structure

 *

 *  Prior to calling this function, drivers *MUST* set the following fields

 *  in the hw->aq structure:

 *     - hw->aq.num_asq_entries

 *     - hw->aq.num_arq_entries

 *     - hw->aq.arq_buf_size

 *     - hw->aq.asq_buf_size

 verify input for valid configuration */

 Set up register offsets */

 setup ASQ command write back timeout */

 allocate the ASQ */

 allocate the ARQ */

	/* There are some cases where the firmware may not be quite ready

	 * for AdminQ operations, so we retry the AdminQ setup a few times

	 * if we see timeouts in this first AQ call.

	/* Some features were introduced in different FW API version

	 * for different MAC type.

 get the NVM version info */

 The ability to RX (not drop) 802.1ad frames was added in API 1.7 */

 pre-emptive resource lock release */

 success! */

/**

 *  i40e_shutdown_adminq - shutdown routine for the Admin Queue

 *  @hw: pointer to the hardware structure

/**

 *  i40e_clean_asq - cleans Admin send queue

 *  @hw: pointer to the hardware structure

 *

 *  returns the number of free desc

/**

 *  i40e_asq_done - check if FW has processed the Admin Send Queue

 *  @hw: pointer to the hw struct

 *

 *  Returns true if the firmware has processed all descriptors on the

 *  admin send queue. Returns false if there are still requests pending.

	/* AQ designers suggest use of head for better

	 * timing reliability than DD bit

/**

 *  i40e_asq_send_command - send command to Admin Queue

 *  @hw: pointer to the hw struct

 *  @desc: prefilled descriptor describing the command (non DMA mem)

 *  @buff: buffer to use for indirect commands

 *  @buff_size: size of buffer for indirect commands

 *  @cmd_details: pointer to command details structure

 *

 *  This is the main send command driver routine for the Admin Queue send

 *  queue.  It runs the queue, cleans the queue, etc

 can be NULL */

		/* If the cmd_details are defined copy the cookie.  The

		 * cpu_to_le32 is not needed here because the data is ignored

		 * by the FW, only used by the driver

 clear requested flags and then set additional flags if defined */

	/* call clean and check queue available function to reclaim the

	 * descriptors that were processed by FW, the function returns the

	 * number of desc available

	/* the clean function called here could be called in a separate thread

	 * in case of asynchronous completions

 initialize the temp desc pointer with the right desc */

 if the desc is available copy the temp desc to the right place */

 if buff is not NULL assume indirect command */

 copy the user buff into the respective DMA buff */

		/* Update the address values in the desc with the pa value

		 * for respective buffer

 bump the tail */

	/* if cmd_details are not defined or async flag is not set,

	 * we need to wait for desc write back

			/* AQ designers suggest use of head for better

			 * timing reliability than DD bit

 if ready, copy the desc back to temp */

 strip off FW internal code */

 save writeback aq if requested */

 update the error if time out occurred */

/**

 *  i40e_fill_default_direct_cmd_desc - AQ descriptor helper function

 *  @desc:     pointer to the temp descriptor (non DMA mem)

 *  @opcode:   the opcode can be used to decide which flags to turn off or on

 *

 *  Fill the desc with default values

 zero out the desc */

/**

 *  i40e_clean_arq_element

 *  @hw: pointer to the hw struct

 *  @e: event info from the receive descriptor, includes any buffers

 *  @pending: number of events that could be left to process

 *

 *  This function cleans one Admin Receive Queue element and returns

 *  the contents through e.  It can also return how many events are

 *  left to process through 'pending'

 pre-clean the event info */

 take the lock before we start messing with the ring */

 set next_to_use to head */

 nothing to do - shouldn't need to update ring's values */

 now clean the next descriptor */

	/* Restore the original datalen and buffer address in the desc,

	 * FW updates datalen to indicate the event message

	 * size

 set tail = the last cleaned desc index. */

 ntc is updated to tail + 1 */

 Set pending if needed, unlock and return */

 Registers are reset after PF reset */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/* The XL710 timesync is very much like Intel's 82599 design when it comes to

 * the fundamental clock design. However, the clock operations are much simpler

 * in the XL710 because the device supports a full 64 bits of nanoseconds.

 * Because the field is so wide, we can forgo the cycle counter and just

 * operate with the nanosecond field directly without fear of overflow.

 *

 * Much like the 82599, the update period is dependent upon the link speed:

 * At 40Gb, 25Gb, or no link, the period is 1.6ns.

 * At 10Gb or 5Gb link, the period is multiplied by 2. (3.2ns)

 * At 1Gb link, the period is multiplied by 20. (32ns)

 * 1588 functionality is not supported at 100Mbps.

 name     idx      func      chan */

/**

 * i40e_ptp_extts0_work - workqueue task function

 * @work: workqueue task structure

 *

 * Service for PTP external clock event

	/* Event time is captured by one of the two matched registers

	 *      PRTTSYN_EVNT_L: 32 LSB of sampled time event

	 *      PRTTSYN_EVNT_H: 32 MSB of sampled time event

	 * Event is defined in PRTTSYN_EVNT_0 register

 fire event */

/**

 * i40e_is_ptp_pin_dev - check if device supports PTP pins

 * @hw: pointer to the hardware structure

 *

 * Return true if device supports PTP pins, false otherwise.

/**

 * i40e_can_set_pins - check possibility of manipulating the pins

 * @pf: board private structure

 *

 * Check if all conditions are satisfied to manipulate PTP pins.

 * Return CAN_SET_PINS if pins can be set on a specific PF or

 * return CAN_DO_PINS if pins can be manipulated within a NIC or

 * return CANT_DO_PINS otherwise.

/**

 * i40_ptp_reset_timing_events - Reset PTP timing events

 * @pf: Board private structure

 *

 * This function resets timing events for pf.

 reading and automatically clearing timing events registers */

 reading and automatically clearing timing events registers */

/**

 * i40e_ptp_verify - check pins

 * @ptp: ptp clock

 * @pin: pin index

 * @func: assigned function

 * @chan: channel

 *

 * Check pins consistency.

 * Return 0 on success or error on failure.

/**

 * i40e_ptp_read - Read the PHC time from the device

 * @pf: Board private structure

 * @ts: timespec structure to hold the current time value

 * @sts: structure to hold the system time before and after reading the PHC

 *

 * This function reads the PRTTSYN_TIME registers and stores them in a

 * timespec. However, since the registers are 64 bits of nanoseconds, we must

 * convert the result to a timespec before we can return.

 The timer latches on the lowest register read. */

/**

 * i40e_ptp_write - Write the PHC time to the device

 * @pf: Board private structure

 * @ts: timespec structure that holds the new time value

 *

 * This function writes the PRTTSYN_TIME registers with the user value. Since

 * we receive a timespec from the stack, we must convert that timespec into

 * nanoseconds before programming the registers.

	/* The timer will not update until the high register is written, so

	 * write the low register first.

/**

 * i40e_ptp_convert_to_hwtstamp - Convert device clock to system time

 * @hwtstamps: Timestamp structure to update

 * @timestamp: Timestamp from the hardware

 *

 * We need to convert the NIC clock value into a hwtstamp which can be used by

 * the upper level timestamping functions. Since the timestamp is simply a 64-

 * bit nanosecond value, we can call ns_to_ktime directly to handle this.

/**

 * i40e_ptp_adjfreq - Adjust the PHC frequency

 * @ptp: The PTP clock structure

 * @ppb: Parts per billion adjustment from the base

 *

 * Adjust the frequency of the PHC by the indicated parts per billion from the

 * base frequency.

	/* At some link speeds, the base incval is so large that directly

	 * multiplying by ppb would result in arithmetic overflow even when

	 * using a u64. Avoid this by instead calculating the new incval

	 * always in terms of the 40GbE clock rate and then multiplying by the

	 * link speed factor afterwards. This does result in slightly lower

	 * precision at lower link speeds, but it is fairly minor.

 Force any pending update before accessing. */

/**

 * i40e_ptp_set_1pps_signal_hw - configure 1PPS PTP signal for pins

 * @pf: the PF private data structure

 *

 * Configure 1PPS signal used for PTP pins

 I40E_PRTTSYN_TGT_L(1) */

 I40E_PRTTSYN_TGT_H(1) */

/**

 * i40e_ptp_adjtime - Adjust the PHC time

 * @ptp: The PTP clock structure

 * @delta: Offset in nanoseconds to adjust the PHC time by

 *

 * Adjust the current clock time by a delta specified in nanoseconds.

/**

 * i40e_ptp_gettimex - Get the time of the PHC

 * @ptp: The PTP clock structure

 * @ts: timespec structure to hold the current time value

 * @sts: structure to hold the system time before and after reading the PHC

 *

 * Read the device clock and return the correct value on ns, after converting it

 * into a timespec struct.

/**

 * i40e_ptp_settime - Set the time of the PHC

 * @ptp: The PTP clock structure

 * @ts: timespec64 structure that holds the new time value

 *

 * Set the device clock to the user input value. The conversion from timespec

 * to ns happens in the write function.

/**

 * i40e_pps_configure - configure PPS events

 * @ptp: ptp clock

 * @rq: clock request

 * @on: status

 *

 * Configure PPS events for external clock source.

 * Return 0 on success or error on failure.

/**

 * i40e_pin_state - determine PIN state

 * @index: PIN index

 * @func: function assigned to PIN

 *

 * Determine PIN state based on PIN index and function assigned.

 * Return PIN state.

/**

 * i40e_ptp_enable_pin - enable PINs.

 * @pf: private board structure

 * @chan: channel

 * @func: PIN function

 * @on: state

 *

 * Enable PTP pins for external clock source.

 * Return 0 on success or error code on failure.

 Use PF0 to set pins. Return success for user space tools */

 Preserve previous state of pins that we don't touch */

	/* To turn on the pin - find the corresponding one based on

	 * the given index. To to turn the function off - find

	 * which pin had it assigned. Don't use ptp_find_pin here

	 * because it tries to lock the pincfg_mux which is locked by

	 * ptp_pin_store() that calls here.

/**

 * i40e_ptp_feature_enable - Enable external clock pins

 * @ptp: The PTP clock structure

 * @rq: The PTP clock request structure

 * @on: To turn feature on/off

 *

 * Setting on/off PTP PPS feature for pin.

 TODO: Implement flags handling for EXTTS and PEROUT */

/**

 * i40e_ptp_get_rx_events - Read I40E_PRTTSYN_STAT_1 and latch events

 * @pf: the PF data structure

 *

 * This function reads I40E_PRTTSYN_STAT_1 and updates the corresponding timers

 * for noticed latch events. This allows the driver to keep track of the first

 * time a latch event was noticed which will be used to help clear out Rx

 * timestamps for packets that got dropped or lost.

 *

 * This function will return the current value of I40E_PRTTSYN_STAT_1 and is

 * expected to be called only while under the ptp_rx_lock.

	/* Update the jiffies time for any newly latched timestamp. This

	 * ensures that we store the time that we first discovered a timestamp

	 * was latched by the hardware. The service task will later determine

	 * if we should free the latch and drop that timestamp should too much

	 * time pass. This flow ensures that we only update jiffies for new

	 * events latched since the last time we checked, and not all events

	 * currently latched, so that the service task accounting remains

	 * accurate.

 Finally, we store the current status of the Rx timestamp latches */

/**

 * i40e_ptp_rx_hang - Detect error case when Rx timestamp registers are hung

 * @pf: The PF private data structure

 *

 * This watchdog task is scheduled to detect error case where hardware has

 * dropped an Rx packet that was timestamped when the ring is full. The

 * particular error is rare but leaves the device in a state unable to timestamp

 * any future packets.

	/* Since we cannot turn off the Rx timestamp logic if the device is

	 * configured for Tx timestamping, we check if Rx timestamping is

	 * configured. We don't want to spuriously warn about Rx timestamp

	 * hangs if we don't care about the timestamps.

 Update current latch times for Rx events */

	/* Check all the currently latched Rx events and see whether they have

	 * been latched for over a second. It is assumed that any timestamp

	 * should have been cleared within this time, or else it was captured

	 * for a dropped frame that the driver never received. Thus, we will

	 * clear any timestamp that has been latched for over 1 second.

	/* Log a warning if more than 2 timestamps got dropped in the same

	 * check. We don't want to warn about all drops because it can occur

	 * in normal scenarios such as PTP frames on multicast addresses we

	 * aren't listening to. However, administrator should know if this is

	 * the reason packets aren't receiving timestamps.

 Finally, update the rx_hwtstamp_cleared counter */

/**

 * i40e_ptp_tx_hang - Detect error case when Tx timestamp register is hung

 * @pf: The PF private data structure

 *

 * This watchdog task is run periodically to make sure that we clear the Tx

 * timestamp logic if we don't obtain a timestamp in a reasonable amount of

 * time. It is unexpected in the normal case but if it occurs it results in

 * permanently preventing timestamps of future packets.

 Nothing to do if we're not already waiting for a timestamp */

	/* We already have a handler routine which is run when we are notified

	 * of a Tx timestamp in the hardware. If we don't get an interrupt

	 * within a second it is reasonable to assume that we never will.

 Free the skb after we clear the bitlock */

/**

 * i40e_ptp_tx_hwtstamp - Utility function which returns the Tx timestamp

 * @pf: Board private structure

 *

 * Read the value of the Tx timestamp from the registers, convert it into a

 * value consumable by the stack, and store that result into the shhwtstamps

 * struct before returning it up the stack.

 don't attempt to timestamp if we don't have an skb */

	/* Clear the bit lock as soon as possible after reading the register,

	 * and prior to notifying the stack via skb_tstamp_tx(). Otherwise

	 * applications might wake up and attempt to request another transmit

	 * timestamp prior to the bit lock being cleared.

 Notify the stack and free the skb after we've unlocked */

/**

 * i40e_ptp_rx_hwtstamp - Utility function which checks for an Rx timestamp

 * @pf: Board private structure

 * @skb: Particular skb to send timestamp with

 * @index: Index into the receive timestamp registers for the timestamp

 *

 * The XL710 receives a notification in the receive descriptor with an offset

 * into the set of RXTIME registers where the timestamp is for that skb. This

 * function goes and fetches the receive timestamp from that offset, if a valid

 * one exists. The RXTIME registers are in ns, so we must convert the result

 * first.

	/* Since we cannot turn off the Rx timestamp logic if the device is

	 * doing Tx timestamping, check if Rx timestamping is configured.

 Get current Rx events and update latch times */

 TODO: Should we warn about missing Rx timestamp event? */

 Clear the latched event since we're about to read its register */

/**

 * i40e_ptp_set_increment - Utility function to update clock increment rate

 * @pf: Board private structure

 *

 * During a link change, the DMA frequency that drives the 1588 logic will

 * change. In order to keep the PRTTSYN_TIME registers in units of nanoseconds,

 * we must update the increment value per clock tick.

	/* The increment value is calculated by taking the base 40GbE incvalue

	 * and multiplying it by a factor based on the link speed.

	/* Write the new increment value into the increment register. The

	 * hardware will not update the clock until both registers have been

	 * written.

 Update the base adjustement value. */

 Force the above update. */

/**

 * i40e_ptp_get_ts_config - ioctl interface to read the HW timestamping

 * @pf: Board private structure

 * @ifr: ioctl data

 *

 * Obtain the current hardware timestamping settigs as requested. To do this,

 * keep a shadow copy of the timestamp settings rather than attempting to

 * deconstruct it from the registers.

/**

 * i40e_ptp_free_pins - free memory used by PTP pins

 * @pf: Board private structure

 *

 * Release memory allocated for PTP pins.

/**

 * i40e_ptp_set_pin_hw - Set HW GPIO pin

 * @hw: pointer to the hardware structure

 * @pin: pin index

 * @state: pin state

 *

 * Set status of GPIO pin for external clock handling.

/**

 * i40e_ptp_set_led_hw - Set HW GPIO led

 * @hw: pointer to the hardware structure

 * @led: led index

 * @state: led state

 *

 * Set status of GPIO led for external clock handling.

/**

 * i40e_ptp_init_leds_hw - init LEDs

 * @hw: pointer to a hardware structure

 *

 * Set initial state of LEDs

/**

 * i40e_ptp_set_pins_hw - Set HW GPIO pins

 * @pf: Board private structure

 *

 * This function sets GPIO pins for PTP

 pin must be disabled before it may be used */

/**

 * i40e_ptp_set_pins - set PTP pins in HW

 * @pf: Board private structure

 * @pins: PTP pins to be applied

 *

 * Validate and set PTP pins in HW for specific PF.

 * Return 0 on success or negative value on error.

/**

 * i40e_ptp_alloc_pins - allocate PTP pins structure

 * @pf: Board private structure

 *

 * allocate PTP pins structure

 Use PF0 to set pins in HW. Return success for user space tools */

/**

 * i40e_ptp_set_timestamp_mode - setup hardware for requested timestamp mode

 * @pf: Board private structure

 * @config: hwtstamp settings requested or saved

 *

 * Control hardware registers to enter the specific mode requested by the

 * user. Also used during reset path to ensure that timestamp settings are

 * maintained.

 *

 * Note: modifies config in place, and may update the requested mode to be

 * more broad if the specific filter is not directly supported.

 Selects external trigger to cause event */

 Bit 17:16 is EVNTLVL, 01B rising edge */

 regval: 0001 0000 0000 0000 0000 */

 Enabel interrupts */

 Reserved for future extensions. */

		/* We set the type to V1, but do not enable UDP packet

		 * recognition. In this way, we should be as close to

		 * disabling PTP Rx timestamps as possible since V1 packets

		 * are always UDP, since L2 packets are a V2 feature.

 Clear out all 1588-related registers to clear and unlatch them. */

 Enable/disable the Tx timestamp interrupt based on user input. */

	/* Although there is no simple on/off switch for Rx, we "disable" Rx

	 * timestamps by setting to V1 only mode and clear the UDP

	 * recognition. This ought to disable all PTP Rx timestamps as V1

	 * packets are always over UDP. Note that software is configured to

	 * ignore Rx timestamps via the pf->ptp_rx flag.

 clear everything but the enable bit */

 now enable bits for desired Rx timestamps */

/**

 * i40e_ptp_set_ts_config - ioctl interface to control the HW timestamping

 * @pf: Board private structure

 * @ifr: ioctl data

 *

 * Respond to the user filter requests and make the appropriate hardware

 * changes here. The XL710 cannot support splitting of the Tx/Rx timestamping

 * logic, so keep track in software of whether to indicate these timestamps

 * or not.

 *

 * It is permissible to "upgrade" the user request to a broader filter, as long

 * as the user receives the timestamps they care about and the user is notified

 * the filter has been broadened.

 save these settings for future reference */

/**

 * i40e_init_pin_config - initialize pins.

 * @pf: private board structure

 *

 * Initialize pins for external clock source.

 * Return 0 on success or error code on failure.

/**

 * i40e_ptp_create_clock - Create PTP clock device for userspace

 * @pf: Board private structure

 *

 * This function creates a new PTP clock device. It only creates one if we

 * don't already have one, so it is safe to call. Will return error if it

 * can't create one, but success if we already have a device. Should be used

 * by i40e_ptp_init to create clock initially, and prevent global resets from

 * creating new clock devices.

 no need to create a clock device if we already have one */

 Attempt to register the clock before enabling the hardware. */

	/* clear the hwtstamp settings here during clock create, instead of

	 * during regular init, so that we can maintain settings across a

	 * reset or suspend.

 Set the previous "reset" time to the current Kernel clock time */

/**

 * i40e_ptp_save_hw_time - Save the current PTP time as ptp_prev_hw_time

 * @pf: Board private structure

 *

 * Read the current PTP time and save it into pf->ptp_prev_hw_time. This should

 * be called at the end of preparing to reset, just before hardware reset

 * occurs, in order to preserve the PTP time as close as possible across

 * resets.

 don't try to access the PTP clock if it's not enabled */

 Get a monotonic starting time for this reset */

/**

 * i40e_ptp_restore_hw_time - Restore the ptp_prev_hw_time + delta to PTP regs

 * @pf: Board private structure

 *

 * Restore the PTP hardware clock registers. We previously cached the PTP

 * hardware time as pf->ptp_prev_hw_time. To be as accurate as possible,

 * update this value based on the time delta since the time was saved, using

 * CLOCK_MONOTONIC (via ktime_get()) to calculate the time difference.

 *

 * This ensures that the hardware clock is restored to nearly what it should

 * have been if a reset had not occurred.

 Update the previous HW time with the ktime delta */

 Restore the hardware clock registers */

/**

 * i40e_ptp_init - Initialize the 1588 support after device probe or reset

 * @pf: Board private structure

 *

 * This function sets device up for 1588 support. The first time it is run, it

 * will create a PHC clock device. It does not create a clock device if one

 * already exists. It also reconfigures the device after a reset.

 *

 * The first time a clock is created, i40e_ptp_create_clock will set

 * pf->ptp_prev_hw_time to the current system time. During resets, it is

 * expected that this timespec will be set to the last known PTP clock time,

 * in order to preserve the clock time as close as possible across a reset.

	/* Only one PF is assigned to control 1588 logic per port. Do not

	 * enable any support for PFs not assigned via PRTTSYN_CTL0.PF_ID

 ensure we have a clock device */

 Ensure the clocks are running. */

 Set the increment value per clock tick. */

 reset timestamping mode */

 Restore the clock time based on last known value */

/**

 * i40e_ptp_stop - Disable the driver/hardware support and unregister the PHC

 * @pf: Board private structure

 *

 * This function handles the cleanup work required from the initialization by

 * clearing out the important information and unregistering the PHC.

 Disable interrupts */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2018 Intel Corporation. */

/**

 * i40e_xsk_pool_enable - Enable/associate an AF_XDP buffer pool to a

 * certain ring/qid

 * @vsi: Current VSI

 * @pool: buffer pool

 * @qid: Rx ring to associate buffer pool with

 *

 * Returns 0 on success, <0 on failure

 Kick start the NAPI context so that receiving will start */

/**

 * i40e_xsk_pool_disable - Disassociate an AF_XDP buffer pool from a

 * certain ring/qid

 * @vsi: Current VSI

 * @qid: Rx ring to associate buffer pool with

 *

 * Returns 0 on success, <0 on failure

/**

 * i40e_xsk_pool_setup - Enable/disassociate an AF_XDP buffer pool to/from

 * a ring/qid

 * @vsi: Current VSI

 * @pool: Buffer pool to enable/associate to a ring, or NULL to disable

 * @qid: Rx ring to (dis)associate buffer pool (from)to

 *

 * This function enables or disables a buffer pool to a certain ring.

 *

 * Returns 0 on success, <0 on failure

/**

 * i40e_run_xdp_zc - Executes an XDP program on an xdp_buff

 * @rx_ring: Rx ring

 * @xdp: xdp_buff used as input to the XDP program

 *

 * Returns any of I40E_XDP_{PASS, CONSUMED, TX, REDIR}

	/* NB! xdp_prog will always be !NULL, due to the fact that

	 * this path is enabled by setting an XDP program.

 handle aborts by dropping packet */

 clear the status bits for the next_to_use descriptor */

/**

 * i40e_construct_skb_zc - Create skbuff from zero-copy Rx buffer

 * @rx_ring: Rx ring

 * @xdp: xdp_buff

 *

 * This functions allocates a new skb from a zero-copy Rx buffer.

 *

 * Returns the skb, or NULL on failure.

 allocate a skb to store the frags */

		/* NB! We are not checking for errors using

		 * i40e_test_staterr with

		 * BIT(I40E_RXD_QW1_ERROR_SHIFT). This is due to that

		 * SBP is *not* set in PRT_SBPVSI (default not set).

	/* Should never get here, as all valid cases have been handled already.

/**

 * i40e_clean_rx_irq_zc - Consumes Rx packets from the hardware ring

 * @rx_ring: Rx ring

 * @budget: NAPI budget

 *

 * Returns amount of work completed

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we have

		 * verified the descriptor has been written back.

/**

 * i40e_xmit_zc - Performs zero-copy Tx AF_XDP

 * @xdp_ring: XDP Tx ring

 * @budget: NAPI budget

 *

 * Returns true if the work is finished.

 Request an interrupt for the last frame and bump tail ptr. */

/**

 * i40e_clean_xdp_tx_buffer - Frees and unmaps an XDP Tx entry

 * @tx_ring: XDP Tx ring

 * @tx_bi: Tx buffer info to clean

/**

 * i40e_clean_xdp_tx_irq - Completes AF_XDP entries, and cleans XDP entries

 * @vsi: Current VSI

 * @tx_ring: XDP Tx ring

 *

 * Returns true if cleanup/tranmission is done.

/**

 * i40e_xsk_wakeup - Implements the ndo_xsk_wakeup

 * @dev: the netdevice

 * @queue_id: queue id to wake up

 * @flags: ignored in our case since we have Rx and Tx in the same NAPI.

 *

 * Returns <0 for errors, 0 otherwise.

	/* The idea here is that if NAPI is running, mark a miss, so

	 * it will run again. If not, trigger an interrupt and

	 * schedule the NAPI from interrupt context. If NAPI would be

	 * scheduled here, the interrupt affinity would not be

	 * honored.

/**

 * i40e_xsk_clean_tx_ring - Clean the XDP Tx ring on shutdown

 * @tx_ring: XDP Tx ring

/**

 * i40e_xsk_any_rx_ring_enabled - Checks if Rx rings have an AF_XDP

 * buffer pool attached

 * @vsi: vsi

 *

 * Returns true if any of the Rx rings has an AF_XDP buffer pool attached

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

********************notification routines***********************/

/**

 * i40e_vc_vf_broadcast

 * @pf: pointer to the PF structure

 * @v_opcode: operation code

 * @v_retval: return value

 * @msg: pointer to the msg buffer

 * @msglen: msg length

 *

 * send a message to all VFs on a given PF

 Not all vfs are enabled so skip the ones that are not */

		/* Ignore return value on purpose - a given VF may fail, but

		 * we need to keep going and send to all of them

/**

 * i40e_vc_link_speed2mbps

 * converts i40e_aq_link_speed to integer value of Mbps

 * @link_speed: the speed to convert

 *

 * return the speed as direct value of Mbps.

/**

 * i40e_set_vf_link_state

 * @vf: pointer to the VF structure

 * @pfe: pointer to PF event structure

 * @ls: pointer to link status structure

 *

 * set a link state on a single vf

/**

 * i40e_vc_notify_vf_link_state

 * @vf: pointer to the VF structure

 *

 * send a link status message to a single VF

/**

 * i40e_vc_notify_link_state

 * @pf: pointer to the PF structure

 *

 * send a link status message to all VFs on a given PF

/**

 * i40e_vc_notify_reset

 * @pf: pointer to the PF structure

 *

 * indicate a pending reset to all VFs on a given PF

/**

 * i40e_vc_notify_vf_reset

 * @vf: pointer to the VF structure

 *

 * indicate a pending reset to the given VF

 validate the request */

 verify if the VF is in either init or active before proceeding */

**********************misc routines*****************************/

/**

 * i40e_vc_reset_vf

 * @vf: pointer to the VF info

 * @notify_vf: notify vf about reset or not

 * Reset VF handler.

	/* We want to ensure that an actual reset occurs initiated after this

	 * function was called. However, we do not want to wait forever, so

	 * we'll give a reasonable time and print a message if we failed to

	 * ensure a reset.

		/* If PF is in VFs releasing state reset VF is impossible,

		 * so leave it.

/**

 * i40e_vc_isvalid_vsi_id

 * @vf: pointer to the VF info

 * @vsi_id: VF relative VSI id

 *

 * check for the valid VSI id

/**

 * i40e_vc_isvalid_queue_id

 * @vf: pointer to the VF info

 * @vsi_id: vsi id

 * @qid: vsi relative queue id

 *

 * check for the valid queue id

/**

 * i40e_vc_isvalid_vector_id

 * @vf: pointer to the VF info

 * @vector_id: VF relative vector id

 *

 * check for the valid vector id

**********************vf resource mgmt routines*****************/

/**

 * i40e_vc_get_pf_queue_id

 * @vf: pointer to the VF info

 * @vsi_id: id of VSI as provided by the FW

 * @vsi_queue_id: vsi relative queue id

 *

 * return PF relative queue id

/**

 * i40e_get_real_pf_qid

 * @vf: pointer to the VF info

 * @vsi_id: vsi id

 * @queue_id: queue number

 *

 * wrapper function to get pf_queue_id handling ADq code as well

		/* Although VF considers all the queues(can be 1 to 16) as its

		 * own but they may actually belong to different VSIs(up to 4).

		 * We need to find which queues belongs to which VSI.

			/* find right queue id which is relative to a

			 * given VSI.

/**

 * i40e_config_irq_link_list

 * @vf: pointer to the VF info

 * @vsi_id: id of VSI as given by the FW

 * @vecmap: irq map info

 *

 * configure irq link list from the map

 setup the head */

 Special case - No queues mapped on this vector */

 format for the RQCTL & TQCTL regs is same */

	/* if the vf is running in polling mode and using interrupt zero,

	 * need to disable auto-mask on enabling zero interrupt for VFs.

/**

 * i40e_release_iwarp_qvlist

 * @vf: pointer to the VF.

 *

			/* Figure out the queue after CEQ and make that the

			 * first queue.

/**

 * i40e_config_iwarp_qvlist

 * @vf: pointer to the VF info

 * @qvlist_info: queue and vector list

 *

 * Return 0 on success or < 0 on error

 Validate vector id belongs to this vf */

		/* We might be sharing the interrupt, so get the first queue

		 * index and type, push it down the list by adding the new

		 * queue on top. Also link it with the new queue in CEQCTL.

/**

 * i40e_config_vsi_tx_queue

 * @vf: pointer to the VF info

 * @vsi_id: id of VSI as provided by the FW

 * @vsi_queue_id: vsi relative queue index

 * @info: config. info

 *

 * configure tx queue

 clear the context structure first */

 only set the required fields */

 clear the context in the HMC */

 set the context in the HMC */

 associate this queue with the PCI VF function */

/**

 * i40e_config_vsi_rx_queue

 * @vf: pointer to the VF info

 * @vsi_id: id of VSI  as provided by the FW

 * @vsi_queue_id: vsi relative queue index

 * @info: config. info

 *

 * configure rx queue

 clear the context structure first */

 only set the required fields */

 header length validation */

 set split mode 10b */

 databuffer length validation */

 max pkt. length validation */

 if port VLAN is configured increase the max packet size */

 enable 32bytes desc always */

 default values */

 clear the context in the HMC */

 set the context in the HMC */

/**

 * i40e_alloc_vsi_res

 * @vf: pointer to the VF info

 * @idx: VSI index, applies only for ADq mode, zero otherwise

 *

 * alloc VF vsi context & resources

		/* If the port VLAN has been configured and then the

		 * VF driver was removed then the VSI port VLAN

		 * configuration was destroyed.  Check if there is

		 * a port VLAN and restore the VSI configuration if

		 * needed.

 program mac filter only for VF VSI */

 storing VSI index and id for ADq and don't apply the mac filter */

 Set VF bandwidth if specified */

/**

 * i40e_map_pf_queues_to_vsi

 * @vf: pointer to the VF info

 *

 * PF maps LQPs to a VF by programming VSILAN_QTABLE & VPLAN_QTABLE. This

 * function takes care of first part VSILAN_QTABLE, mapping pf queues to VSI.

 VF has at least one traffic class */

 end of list */

/**

 * i40e_map_pf_to_vf_queues

 * @vf: pointer to the VF info

 *

 * PF maps LQPs to a VF by programming VSILAN_QTABLE & VPLAN_QTABLE. This

 * function takes care of the second part VPLAN_QTABLE & completes VF mappings.

 VF has at least one traffic class */

/**

 * i40e_enable_vf_mappings

 * @vf: pointer to the VF info

 *

 * enable VF mappings

	/* Tell the hardware we're using noncontiguous mapping. HW requires

	 * that VF queues be mapped using this method, even when they are

	 * contiguous in real life

 enable VF vplan_qtable mappings */

/**

 * i40e_disable_vf_mappings

 * @vf: pointer to the VF info

 *

 * disable VF mappings

 disable qp mappings */

/**

 * i40e_free_vf_res

 * @vf: pointer to the VF info

 *

 * free VF resources

	/* Start by disabling VF's configuration API to prevent the OS from

	 * accessing the VF's VSI after it's freed / invalidated.

	/* It's possible the VF had requeuested more queues than the default so

	 * do the accounting here when we're about to free them.

 free vsi & disconnect it from the parent uplink */

 do the accounting and remove additional ADq VSI's */

			/* At this point VSI0 is already released so don't

			 * release it again and only clear their values in

			 * structure variables

 disable interrupts so the VF starts in a known state */

 format is same for both registers */

 clear the irq settings */

 format is same for both registers */

 reset some of the state variables keeping track of the resources */

/**

 * i40e_alloc_vf_res

 * @vf: pointer to the VF info

 *

 * allocate VF resources

 allocate hw vsi context & associated resources */

 allocate additional VSIs based on tc information for ADq */

 TC 0 always belongs to VF VSI */

 send correct number of queues */

	/* We account for each VF to get a default number of queue pairs.  If

	 * the VF has now requested more, we need to account for that to make

	 * certain we never request more queues than we actually have left in

	 * HW.

	/* store the total qps number for the runtime

	 * VF req validation

 VF is now completely initialized */

/**

 * i40e_quiesce_vf_pci

 * @vf: pointer to the VF structure

 *

 * Wait for VF PCI transactions to be cleared after reset. Returns -EIO

 * if the transactions never clear.

/**

 * __i40e_getnum_vf_vsi_vlan_filters

 * @vsi: pointer to the vsi

 *

 * called to get the number of VLANs offloaded on this VF

/**

 * i40e_getnum_vf_vsi_vlan_filters

 * @vsi: pointer to the vsi

 *

 * wrapper for __i40e_getnum_vf_vsi_vlan_filters() with spinlock held

/**

 * i40e_get_vlan_list_sync

 * @vsi: pointer to the VSI

 * @num_vlans: number of VLANs in mac_filter_hash, returned to caller

 * @vlan_list: list of VLANs present in mac_filter_hash, returned to caller.

 *             This array is allocated here, but has to be freed in caller.

 *

 * Called to get number of VLANs and VLAN list present in mac_filter_hash.

/**

 * i40e_set_vsi_promisc

 * @vf: pointer to the VF struct

 * @seid: VSI number

 * @multi_enable: set MAC L2 layer multicast promiscuous enable/disable

 *                for a given VLAN

 * @unicast_enable: set MAC L2 layer unicast promiscuous enable/disable

 *                  for a given VLAN

 * @vl: List of VLANs - apply filter for given VLANs

 * @num_vlans: Number of elements in @vl

 No VLAN to set promisc on, set on VSI */

/**

 * i40e_config_vf_promiscuous_mode

 * @vf: pointer to the VF info

 * @vsi_id: VSI id

 * @allmulti: set MAC L2 layer multicast promiscuous enable/disable

 * @alluni: set MAC L2 layer unicast promiscuous enable/disable

 *

 * Called from the VF to configure the promiscuous mode of

 * VF vsis and from the VF reset path to reset promiscuous mode.

 no VLANs to set on, set on VSI */

/**

 * i40e_trigger_vf_reset

 * @vf: pointer to the VF structure

 * @flr: VFLR was issued or not

 *

 * Trigger hardware to start a reset for a particular VF. Expects the caller

 * to wait the proper amount of time to allow hardware to reset the VF before

 * it cleans up and restores VF functionality.

 warn the VF */

	/* Disable VF's configuration API during reset. The flag is re-enabled

	 * in i40e_alloc_vf_res(), when it's safe again to access VF's VSI.

	 * It's normally disabled in i40e_free_vf_res(), but it's safer

	 * to do it earlier to give some time to finish to any VF config

	 * functions that may still be running at this point.

	/* In the case of a VFLR, the HW has already reset the VF and we

	 * just need to clean up, so don't hit the VFRTRIG register.

 reset VF using VPGEN_VFRTRIG reg */

 clear the VFLR bit in GLGEN_VFLRSTAT */

/**

 * i40e_cleanup_reset_vf

 * @vf: pointer to the VF structure

 *

 * Cleanup a VF after the hardware reset is finished. Expects the caller to

 * have verified whether the reset is finished properly, and ensure the

 * minimum amount of wait time has passed.

 disable promisc modes in case they were enabled */

 free VF resources to begin resetting the VSI state */

	/* Enable hardware by clearing the reset bit in the VPGEN_VFRTRIG reg.

	 * By doing this we allow HW to access VF memory at any point. If we

	 * did it any sooner, HW could access memory while it was being freed

	 * in i40e_free_vf_res(), causing an IOMMU fault.

	 *

	 * On the other hand, this needs to be done ASAP, because the VF driver

	 * is waiting for this to happen and may report a timeout. It's

	 * harmless, but it gets logged into Guest OS kernel log, so best avoid

	 * it.

 reallocate VF resources to finish resetting the VSI state */

 Do not notify the client during VF init */

	/* Tell the VF driver the reset is done. This needs to be done only

	 * after VF has been fully initialized, because the VF driver may

	 * request resources immediately after setting this flag.

/**

 * i40e_reset_vf

 * @vf: pointer to the VF structure

 * @flr: VFLR was issued or not

 *

 * Returns true if the VF is in reset, resets successfully, or resets

 * are disabled and false otherwise.

	/* If the VFs have been disabled, this means something else is

	 * resetting the VF, so we shouldn't continue.

	/* poll VPGEN_VFRSTAT reg to make sure

	 * that reset is complete

		/* VF reset requires driver to first reset the VF and then

		 * poll the status register to make sure that the reset

		 * completed successfully. Due to internal HW FIFO flushes,

		 * we must wait 10ms before the register will be valid.

 On initial reset, we don't have any queues to disable */

/**

 * i40e_reset_all_vfs

 * @pf: pointer to the PF structure

 * @flr: VFLR was issued or not

 *

 * Reset all allocated VFs in one go. First, tell the hardware to reset each

 * VF, then do all the waiting in one chunk, and finally finish restoring each

 * VF after the wait. This is useful during PF routines which need to reset

 * all VFs, as otherwise it must perform these resets in a serialized fashion.

 *

 * Returns true if any VFs were reset, and false otherwise.

 If we don't have any VFs, then there is nothing to reset */

 If VFs have been disabled, there is no need to reset */

 Begin reset on all VFs at once */

	/* HW requires some time to make sure it can flush the FIFO for a VF

	 * when it resets it. Poll the VPGEN_VFRSTAT register for each VF in

	 * sequence to make sure that it has completed. We'll keep track of

	 * the VFs using a simple iterator that increments once that VF has

	 * finished resetting.

		/* Check each VF in sequence, beginning with the VF to fail

		 * the previous check.

			/* If the current VF has finished resetting, move on

			 * to the next VF in sequence.

	/* Display a warning if at least one VF didn't manage to reset in

	 * time, but continue on with the operation.

	/* Begin disabling all the rings associated with VFs, but do not wait

	 * between each VF.

 On initial reset, we don't have any queues to disable */

	/* Now that we've notified HW to disable all of the VF rings, wait

	 * until they finish.

 On initial reset, we don't have any queues to disable */

	/* Hw may need up to 50ms to finish disabling the RX queues. We

	 * minimize the wait by delaying only once for all VFs.

 Finish the reset on each VF */

/**

 * i40e_free_vfs

 * @pf: pointer to the PF structure

 *

 * free VF resources

	/* Disable IOV before freeing resources. This lets any VF drivers

	 * running in the host get themselves cleaned up before we yank

	 * the carpet out from underneath their feet.

 Amortize wait time by stopping all VFs at the same time */

 free up VF resources */

 disable qp mappings */

	/* This check is for when the driver is unloaded while VFs are

	 * assigned. Setting the number of VFs to 0 through sysfs is caught

	 * before this function ever gets called.

		/* Acknowledge VFLR for all VFS. Without this, VFs will fail to

		 * work correctly when SR-IOV gets re-enabled.

/**

 * i40e_alloc_vfs

 * @pf: pointer to the PF structure

 * @num_alloc_vfs: number of VFs to allocate

 *

 * allocate VF resources

 Disable interrupt 0 so we don't try to handle the VFLR. */

 Check to see if we're just allocating resources for extant VFs */

 allocate memory */

 apply default profile */

 assign default capabilities */

 VF resources get allocated during reset */

 Re-enable interrupt 0. */

/**

 * i40e_pci_sriov_enable

 * @pdev: pointer to a pci_dev structure

 * @num_vfs: number of VFs to allocate

 *

 * Enable or change the number of VFs

/**

 * i40e_pci_sriov_configure

 * @pdev: pointer to a pci_dev structure

 * @num_vfs: number of VFs to allocate

 *

 * Enable or change the number of VFs. Called when the user updates the number

 * of VFs in sysfs.

**********************virtual channel routines******************/

/**

 * i40e_vc_send_msg_to_vf

 * @vf: pointer to the VF info

 * @v_opcode: virtual channel opcode

 * @v_retval: virtual channel return value

 * @msg: pointer to the msg buffer

 * @msglen: msg length

 *

 * send msg to VF

 validate the request */

 single place to detect unsuccessful return values */

 reset the invalid counter, if a valid message is received. */

/**

 * i40e_vc_send_resp_to_vf

 * @vf: pointer to the VF info

 * @opcode: operation code

 * @retval: return value

 *

 * send resp msg to VF

/**

 * i40e_vc_get_version_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to request the API version used by the PF

 VFs running the 1.0 API expect to get 1.0 back or they will cry. */

/**

 * i40e_del_qch - delete all the additional VSIs created as a part of ADq

 * @vf: pointer to VF structure

	/* first element in the array belongs to primary VF VSI and we shouldn't

	 * delete it. We should however delete the rest of the VSIs created

/**

 * i40e_vc_get_vf_resources_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to request its resources

 VFs only use TC 0 */

 send the response back to the VF */

/**

 * i40e_vc_config_promiscuous_mode_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to configure the promiscuous mode of

 * VF vsis

		/* Lie to the VF on purpose, because this is an error we can

		 * ignore. Unprivileged VF is not a virtual channel error.

 Multicast promiscuous handling*/

 send the response to the VF */

/**

 * i40e_vc_config_queues_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to configure the rx/tx

 * queues

		/* For ADq there can be up to 4 VSIs with max 4 queues each.

		 * VF does not know about these additional VSIs and all

		 * it cares is about its own queues. PF configures these queues

		 * to its appropriate VSIs based on TC mapping

 resetting the queue count */

 set vsi num_queue_pairs in use to num configured by VF */

 send the response to the VF */

/**

 * i40e_validate_queue_map - check queue map is valid

 * @vf: the VF structure pointer

 * @vsi_id: vsi id

 * @queuemap: Tx or Rx queue map

 *

 * check if Tx or Rx queue map is valid

/**

 * i40e_vc_config_irq_map_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to configure the irq to

 * queue map

 validate msg params */

 send the response to the VF */

/**

 * i40e_ctrl_vf_tx_rings

 * @vsi: the SRIOV VSI being configured

 * @q_map: bit map of the queues to be enabled

 * @enable: start or stop the queue

is xdp*/, enable);

/**

 * i40e_ctrl_vf_rx_rings

 * @vsi: the SRIOV VSI being configured

 * @q_map: bit map of the queues to be enabled

 * @enable: start or stop the queue

/**

 * i40e_vc_validate_vqs_bitmaps - validate Rx/Tx queue bitmaps from VIRTHCHNL

 * @vqs: virtchnl_queue_select structure containing bitmaps to validate

 *

 * Returns true if validation was successful, else false.

/**

 * i40e_vc_enable_queues_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to enable all or specific queue(s)

 Use the queue bit map sent by the VF */

 need to start the rings for additional ADq VSI's as well */

 zero belongs to LAN VSI */

 send the response to the VF */

/**

 * i40e_vc_disable_queues_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to disable all or specific

 * queue(s)

 Use the queue bit map sent by the VF */

 send the response to the VF */

/**

 * i40e_vc_request_queues_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * VFs get a default number of queues but can use this message to request a

 * different number.  If the request is successful, PF will reset the VF and

 * return 0.  If unsuccessful, PF will send message informing VF of number of

 * available queues and return result of sending VF a message.

 successful request */

/**

 * i40e_vc_get_stats_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * called from the VF to get vsi stats

 send the response back to the VF */

/* If the VF is not trusted restrict the number of MAC/VLAN it can program

 * MAC filters: 16 for multicast, 1 for MAC, 1 for broadcast

/**

 * i40e_check_vf_permission

 * @vf: pointer to the VF info

 * @al: MAC address list from virtchnl

 *

 * Check that the given list of MAC addresses is allowed. Will return -EPERM

 * if any address in the list is not valid. Checks the following conditions:

 *

 * 1) broadcast and zero addresses are never valid

 * 2) unicast addresses are not allowed if the VMM has administratively set

 *    the VF MAC address, unless the VF is marked as privileged.

 * 3) There is enough space to add all the addresses.

 *

 * Note that to guarantee consistency, it is expected this function be called

 * while holding the mac_filter_hash_lock, as otherwise the current number of

 * addresses might not be accurate.

		/* If the host VMM administrator has set the VF MAC address

		 * administratively via the ndo_set_vf_mac command then deny

		 * permission to the VF to add or delete unicast MAC addresses.

		 * Unless the VF is privileged and then it can do whatever.

		 * The VF may request to set the MAC address filter already

		 * assigned to it so do not return an error in that case.

count filters that really will be added*/

	/* If this VF is not privileged, then we can't add more than a limited

	 * number of addresses. Check to make sure that the additions do not

	 * push us over the limit.

/**

 * i40e_vc_add_mac_addr_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * add guest mac address filter

	/* Lock once, because all function inside for loop accesses VSI's

	 * MAC filter list which needs to be protected using same lock.

 add new addresses to the list */

 program the updated filter list */

 send the response to the VF */

/**

 * i40e_vc_del_mac_addr_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * remove guest mac address filter

 delete addresses from the list */

 program the updated filter list */

 set last unicast mac address as default */

 send the response to the VF */

/**

 * i40e_vc_add_vlan_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * program guest vlan id

 add new VLAN filter */

 send the response to the VF */

/**

 * i40e_vc_remove_vlan_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * remove programmed guest vlan id

 send the response to the VF */

/**

 * i40e_vc_iwarp_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 * @msglen: msg length

 *

 * called from the VF for the iwarp msgs

 send the response to the VF */

/**

 * i40e_vc_iwarp_qvmap_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 * @config: config qvmap or release it

 *

 * called from the VF for the iwarp msgs

 send the response to the VF */

/**

 * i40e_vc_config_rss_key

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Configure the VF's RSS key

 send the response to the VF */

/**

 * i40e_vc_config_rss_lut

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Configure the VF's RSS LUT

 send the response to the VF */

/**

 * i40e_vc_get_rss_hena

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Return the RSS HENA bits allowed by the hardware

 send the response back to the VF */

/**

 * i40e_vc_set_rss_hena

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Set the RSS HENA bits for the VF

 send the response to the VF */

/**

 * i40e_vc_enable_vlan_stripping

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Enable vlan header stripping for the VF

 send the response to the VF */

/**

 * i40e_vc_disable_vlan_stripping

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * Disable vlan header stripping for the VF

 send the response to the VF */

/**

 * i40e_validate_cloud_filter

 * @vf: pointer to VF structure

 * @tc_filter: pointer to filter requested

 *

 * This function validates cloud filter programmed as TC filter for ADq

 action_meta is TC number here to which the filter is applied */

	/* Check filter if it's programmed for advanced mode or basic mode.

	 * There are two ADq modes (for VF only),

	 * 1. Basic mode: intended to allow as many filter options as possible

	 *		  to be added to a VF in Non-trusted mode. Main goal is

	 *		  to add filters to its own MAC and VLAN id.

	 * 2. Advanced mode: is for allowing filters to be applied other than

	 *		  its own MAC or VLAN. This mode requires the VF to be

	 *		  Trusted.

 Check if VF is trusted */

/**

 * i40e_find_vsi_from_seid - searches for the vsi with the given seid

 * @vf: pointer to the VF info

 * @seid: seid of the vsi it is searching for

/**

 * i40e_del_all_cloud_filters

 * @vf: pointer to the VF info

 *

 * This function deletes all cloud filters

/**

 * i40e_vc_del_cloud_filter

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * This function deletes a cloud filter programmed as TC filter for ADq

 parse destination mac address */

 parse source mac address */

		/* TC filter can be configured based on different combinations

		 * and in this case IP is not a part of filter config

 get the vsi to which the tc belongs to */

 Deleting TC filter */

 for ipv4 data to be valid, only first byte of mask is set */

 for ipv6, mask is set for all sixteen bytes (4 words) */

/**

 * i40e_vc_add_cloud_filter

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 *

 * This function adds a cloud filter programmed as TC filter for ADq

 parse destination mac address */

 parse source mac address */

		/* TC filter can be configured based on different combinations

		 * and in this case IP is not a part of filter config

 get the VSI to which the TC belongs to */

 Adding cloud filter programmed as TC filter */

 release the pointer passing it to the collection */

/**

 * i40e_vc_add_qch_msg: Add queue channel and enable ADq

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 ADq cannot be applied if spoof check is ON */

 max number of traffic classes for VF currently capped at 4 */

 validate queues for each TC */

 need Max VF queues but already have default number of queues */

		/* we need to allocate max VF queues to enable ADq so as to

		 * make sure ADq enabled VF always gets back queues when it

		 * goes through a reset.

 get link speed in MB to validate rate limit */

 parse data from the queue channel info */

 set this flag only after making sure all inputs are sane */

	/* num_req_queues is set when user changes number of queues via ethtool

	 * and this causes issue for default VSI(which depends on this variable)

	 * when ADq is enabled, hence reset it.

 reset the VF in order to allocate resources */

 send the response to the VF */

/**

 * i40e_vc_del_qch_msg

 * @vf: pointer to the VF info

 * @msg: pointer to the msg buffer

 reset the VF in order to allocate resources */

/**

 * i40e_vc_process_vf_msg

 * @pf: pointer to the PF structure

 * @vf_id: source VF id

 * @v_opcode: operation code

 * @v_retval: unused return value code

 * @msg: pointer to the msg buffer

 * @msglen: msg length

 *

 * called from the common aeq/arq handler to

 * process request from VF

 Check if VF is disabled. */

 perform basic checks on the msg */

/**

 * i40e_vc_process_vflr_event

 * @pf: pointer to the PF structure

 *

 * called from the vlfr irq handler to

 * free up VF resources and state variables

	/* Re-enable the VFLR interrupt cause here, before looking for which

	 * VF got reset. Otherwise, if another VF gets a reset while the

	 * first one is being processed, that interrupt will be lost, and

	 * that VF will be stuck in reset forever.

 read GLGEN_VFLRSTAT register to find out the flr VFs */

 i40e_reset_vf will clear the bit in GLGEN_VFLRSTAT */

/**

 * i40e_validate_vf

 * @pf: the physical function

 * @vf_id: VF identifier

 *

 * Check that the VF is enabled and the VSI exists.

 *

 * Returns 0 on success, negative on failure

/**

 * i40e_ndo_set_vf_mac

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @mac: mac address

 *

 * program VF mac address

 validate the request */

	/* When the VF is resetting wait until it is done.

	 * It can take up to 200 milliseconds,

	 * but wait for up to 300 milliseconds to be safe.

	 * Acquire the VSI pointer only after the VF has been

	 * properly initialized.

	/* Lock once because below invoked function add/del_filter requires

	 * mac_filter_hash_lock to be held

 delete the temporary mac address */

	/* Delete all the filters for this VSI - we're going to kill it

	 * anyway.

 program mac filter */

	/* Force the VF interface down so it has to bring up with new MAC

	 * address

/**

 * i40e_ndo_set_vf_port_vlan

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @vlan_id: mac address

 * @qos: priority setting

 * @vlan_proto: vlan protocol

 *

 * program VF vlan id and/or qos

 validate the request */

 duplicate request, so just return success */

 During reset the VF got a new VSI, so refresh a pointer. */

 Locked once because multiple functions below iterate list */

	/* Check for condition where there was already a port VLAN ID

	 * filter set and now it is being deleted by setting it to zero.

	 * Additionally check for the condition where there was a port

	 * VLAN but now there is a new and different port VLAN being set.

	 * Before deleting all the old VLAN filters we must add new ones

	 * with -1 (I40E_VLAN_ANY) or otherwise we're left with all our

	 * MAC addresses deleted.

 remove all filters on the old VLAN */

 disable promisc modes in case they were enabled */

 add new VLAN filter for each MAC */

 remove the previously added non-VLAN MAC filters */

 Schedule the worker thread to take care of applying changes */

	/* The Port VLAN needs to be saved across resets the same as the

	 * default LAN MAC address.

/**

 * i40e_ndo_set_vf_bw

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @min_tx_rate: Minimum Tx rate

 * @max_tx_rate: Maximum Tx rate

 *

 * configure VF Tx rate

 validate the request */

/**

 * i40e_ndo_get_vf_config

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @ivi: VF configuration structure

 *

 * return VF configuration

 validate the request */

 first vsi is always the LAN vsi */

/**

 * i40e_ndo_set_vf_link_state

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @link: required link state

 *

 * Set the link state of a specified VF, regardless of physical link state

 validate the request */

 Notify the VF of its new link state */

/**

 * i40e_ndo_set_vf_spoofchk

 * @netdev: network interface device structure

 * @vf_id: VF identifier

 * @enable: flag to enable or disable feature

 *

 * Enable or disable VF spoof checking

 validate the request */

/**

 * i40e_ndo_set_vf_trust

 * @netdev: network interface device structure of the pf

 * @vf_id: VF identifier

 * @setting: trust setting

 *

 * Enable or disable VF trust setting

 validate the request */

/**

 * i40e_get_vf_stats - populate some stats for the VF

 * @netdev: the netdev of the PF

 * @vf_id: the host OS identifier (0-127)

 * @vf_stats: pointer to the OS memory to be initialized

 validate the request */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 * i40e_diag_reg_pattern_test

 * @hw: pointer to the hw struct

 * @reg: reg to be tested

 * @mask: bits to be touched

 offset               mask         elements   stride */

/**

 * i40e_diag_reg_test

 * @hw: pointer to the hw struct

 *

 * Perform registers diagnostic test

 set actual reg range for dynamically allocated resources */

 test register access */

/**

 * i40e_diag_eeprom_test

 * @hw: pointer to the hw struct

 *

 * Perform EEPROM diagnostic test

 read NVM control word and if NVM valid, validate EEPROM checksum*/

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

 ethtool support for i40e */

 ethtool statistics helpers */

/**

 * struct i40e_stats - definition for an ethtool statistic

 * @stat_string: statistic name to display in ethtool -S output

 * @sizeof_stat: the sizeof() the stat, must be no greater than sizeof(u64)

 * @stat_offset: offsetof() the stat from a base pointer

 *

 * This structure defines a statistic to be added to the ethtool stats buffer.

 * It defines a statistic as offset from a common base pointer. Stats should

 * be defined in constant arrays using the I40E_STAT macro, with every element

 * of the array using the same _type for calculating the sizeof_stat and

 * stat_offset.

 *

 * The @sizeof_stat is expected to be sizeof(u8), sizeof(u16), sizeof(u32) or

 * sizeof(u64). Other sizes are not expected and will produce a WARN_ONCE from

 * the i40e_add_ethtool_stat() helper function.

 *

 * The @stat_string is interpreted as a format string, allowing formatted

 * values to be inserted while looping over multiple structures for a given

 * statistics array. Thus, every statistic string in an array should have the

 * same type and number of format specifiers, to be formatted by variadic

 * arguments to the i40e_add_stat_string() helper function.

/* Helper macro to define an i40e_stat structure with proper size and type.

 * Use this when defining constant statistics arrays. Note that @_type expects

 * only a type name and is used multiple times.

/* Helper macro for defining some statistics directly copied from the netdev

 * stats structure.

 Helper macro for defining some statistics related to queues */

 Stats associated with a Tx or Rx ring */

/**

 * i40e_add_one_ethtool_stat - copy the stat into the supplied buffer

 * @data: location to store the stat value

 * @pointer: basis for where to copy from

 * @stat: the stat definition

 *

 * Copies the stat data defined by the pointer and stat structure pair into

 * the memory supplied as data. Used to implement i40e_add_ethtool_stats and

 * i40e_add_queue_stats. If the pointer is null, data will be zero'd.

		/* ensure that the ethtool data buffer is zero'd for any stats

		 * which don't have a valid pointer.

/**

 * __i40e_add_ethtool_stats - copy stats into the ethtool supplied buffer

 * @data: ethtool stats buffer

 * @pointer: location to copy stats from

 * @stats: array of stats to copy

 * @size: the size of the stats definition

 *

 * Copy the stats defined by the stats array using the pointer as a base into

 * the data buffer supplied by ethtool. Updates the data pointer to point to

 * the next empty location for successive calls to __i40e_add_ethtool_stats.

 * If pointer is null, set the data values to zero and update the pointer to

 * skip these stats.

/**

 * i40e_add_ethtool_stats - copy stats into ethtool supplied buffer

 * @data: ethtool stats buffer

 * @pointer: location where stats are stored

 * @stats: static const array of stat definitions

 *

 * Macro to ease the use of __i40e_add_ethtool_stats by taking a static

 * constant stats array and passing the ARRAY_SIZE(). This avoids typos by

 * ensuring that we pass the size associated with the given stats array.

 *

 * The parameter @stats is evaluated twice, so parameters with side effects

 * should be avoided.

/**

 * i40e_add_queue_stats - copy queue statistics into supplied buffer

 * @data: ethtool stats buffer

 * @ring: the ring to copy

 *

 * Queue statistics must be copied while protected by

 * u64_stats_fetch_begin_irq, so we can't directly use i40e_add_ethtool_stats.

 * Assumes that queue stats are defined in i40e_gstrings_queue_stats. If the

 * ring pointer is null, zero out the queue stat values and update the data

 * pointer. Otherwise safely copy the stats from the ring into the supplied

 * buffer and update the data pointer when finished.

 *

 * This function expects to be called while under rcu_read_lock().

	/* To avoid invalid statistics values, ensure that we keep retrying

	 * the copy until we get a consistent value according to

	 * u64_stats_fetch_retry_irq. But first, make sure our ring is

	 * non-null before attempting to access its syncp.

 Once we successfully copy the stats in, update the data pointer */

/**

 * __i40e_add_stat_strings - copy stat strings into ethtool buffer

 * @p: ethtool supplied buffer

 * @stats: stat definitions array

 * @size: size of the stats array

 *

 * Format and copy the strings described by stats into the buffer pointed at

 * by p.

/**

 * i40e_add_stat_strings - copy stat strings into ethtool buffer

 * @p: ethtool supplied buffer

 * @stats: stat definitions array

 *

 * Format and copy the strings described by the const static stats value into

 * the buffer pointed at by p.

 *

 * The parameter @stats is evaluated twice, so parameters with side effects

 * should be avoided. Additionally, stats must be an array such that

 * ARRAY_SIZE can be called on it.

/* These PF_STATs might look like duplicates of some NETDEV_STATs,

 * but they are separate.  This device supports Virtualization, and

 * as such might have several netdevs supporting VMDq and FCoE going

 * through a single port.  The NETDEV_STATs are for individual netdevs

 * seen at the top of the stack, and the PF_STATs are for the physical

 * function at the bottom of the stack hosting those netdevs.

 *

 * The PF_STATs are appended to the netdev stats only when ethtool -S

 * is queried on the base PF netdev, not on the VMDq or FCoE netdev.

 LPI stats */

 Length of stats for a single queue */

 NOTE: MFP setting cannot be changed */

 Private flags with a global effect, restricted to PF 0 */

/**

 * i40e_partition_setting_complaint - generic complaint for MFP restriction

 * @pf: the PF struct

/**

 * i40e_phy_type_to_ethtool - convert the phy_types to ethtool link modes

 * @pf: PF struct with phy_types

 * @ks: ethtool link ksettings struct to fill out

 *

 need to add 25G PHY types */

 need to add new 10G PHY types */

 Autoneg PHY types */

/**

 * i40e_get_settings_link_up_fec - Get the FEC mode encoding from mask

 * @req_fec_info: mask request FEC info

 * @ks: ethtool ksettings to fill in

/**

 * i40e_get_settings_link_up - Get the Link settings for when link is up

 * @hw: hw structure

 * @ks: ethtool ksettings to fill in

 * @netdev: network interface device structure

 * @pf: pointer to physical function struct

 Initialize supported and advertised settings based on phy settings */

 if we got here and link is up something bad is afoot */

	/* Now that we've worked out everything that could be supported by the

	 * current PHY type, get what is supported by the NVM and intersect

	 * them to get what is truly supported

 Set speed and duplex */

/**

 * i40e_get_settings_link_down - Get the Link settings for when link is down

 * @hw: hw structure

 * @ks: ethtool ksettings to fill in

 * @pf: pointer to physical function struct

 *

 * Reports link settings that can be determined when link is down

	/* link is down and the driver needs to fall back on

	 * supported phy types to figure out what info to display

 With no link speed and duplex are unknown */

/**

 * i40e_get_link_ksettings - Get Link Speed and Duplex settings

 * @netdev: network interface device structure

 * @ks: ethtool ksettings

 *

 * Reports speed/duplex settings based on media_type

 Now set the settings that don't rely on link being up/down */

 Set autoneg settings */

 Set media type settings */

 Set flow control settings */

/**

 * i40e_set_link_ksettings - Set Speed and Duplex

 * @netdev: network interface device structure

 * @ks: ethtool ksettings

 *

 * Set speed/duplex per media_types advertised/forced

	/* Changing port settings is not supported if this isn't the

	 * port's controlling PF

 copy the ksettings to copy_ks to avoid modifying the origin */

 save autoneg out of ksettings */

 get our own copy of the bits to check against */

	/* Get link modes supported by hardware and check against modes

	 * requested by the user.  Return an error if unsupported mode was set.

 set autoneg back to what it currently is */

	/* If copy_ks.base and safe_ks.base are not the same now, then they are

	 * trying to set something that we do not support.

 Get the current phy config */

	/* Copy abilities to config in case autoneg is not

	 * set below

 Check autoneg */

 If autoneg was not already enabled */

 If autoneg is not supported, return error */

 Autoneg is allowed to change */

 If autoneg is currently enabled */

			/* If autoneg is supported 10GBASE_T is the only PHY

			 * that can disable it, so otherwise return error

 Autoneg is allowed to change */

	/* If speed didn't get set, set it to what it currently is.

	 * This is needed because if advertise is 0 (as it is when autoneg

	 * is disabled) then speed won't get set.

 copy over the rest of the abilities */

 save the requested speeds */

 set link and auto negotiation so changes take effect */

 If link is up put link down */

			/* Tell the OS link is going down, the link will go

			 * back up when fw says it is ready asynchronously

 make the aq call */

 Get the current phy config */

			/* debug level message only due to relation to the link

			 * itself rather than to the FEC settings

			 * (e.g. no physical connection etc.)

 Get the current phy config */

 restart autonegotiation */

/**

 * i40e_get_pauseparam -  Get Flow Control status

 * @netdev: netdevice structure

 * @pause: buffer to return pause parameters

 *

 * Return tx/rx-pause status

 PFC enabled so report LFC as off */

/**

 * i40e_set_pauseparam - Set Flow Control parameter

 * @netdev: network interface device structure

 * @pause: return tx/rx flow control status

	/* Changing the port's flow control is not supported if this isn't the

	 * port's controlling PF

 If we have link and don't have autoneg */

 Send message that it might not necessarily work*/

	/* Tell the OS link is going down, the link will go back up when fw

	 * says it is ready asynchronously

 Set the fc mode and only restart an if link is up*/

 Give it a little more time to try to come back */

	/* Tell ethtool which driver-version-specific regs output we have.

	 *

	 * At some point, if we have ethtool doing special formatting of

	 * this data, it will rely on this version number to know how to

	 * interpret things.  Hence, this needs to be updated if/when the

	 * diags register table is changed.

 loop through the diags reg table for what to print */

 check for NVMUpdate access method */

 make sure it is the right magic for NVMUpdate */

 normal ethtool get_eeprom support */

 register returns value in power of 2, 64Kbyte chunks. */

 normal ethtool set_eeprom is not supported */

 check for NVMUpdate access method */

 if nothing to do return success */

	/* If there is a AF_XDP page pool attached to any of Rx rings,

	 * disallow changing the number of descriptors -- regardless

	 * if the netdev is running or not.

 simple case - set for the next time the netdev is started */

	/* We can't just free everything and then setup again,

	 * because the ISRs in MSI-X mode get passed pointers

	 * to the Tx and Rx ring structs.

 alloc updated Tx and XDP Tx resources */

			/* the desc and bi pointers will be reallocated in the

			 * setup call

 alloc updated Rx resources */

 clone ring and setup updated count */

			/* the desc and bi pointers will be reallocated in the

			 * setup call

 Clear cloned XDP RX-queue info before setup call */

			/* this is to allow wr32 to have something to write to

			 * during early allocation of Rx buffers

			/* now allocate the Rx buffers to make sure the OS

			 * has enough memory, any failure here means abort

	/* Bring interface down, copy in the new ring info,

	 * then restore the interface

 get the real tail offset */

			/* this is to fake out the allocation routine

			 * into thinking it has to realloc everything

			 * but the recycling logic will let us re-use

			 * the buffers allocated above

 do a struct copy */

 error cleanup if the Rx allocations failed after getting Tx */

/**

 * i40e_get_stats_count - return the stats count for a device

 * @netdev: the netdev to return the count for

 *

 * Returns the total number of statistics for this netdev. Note that even

 * though this is a function, it is required that the count for a specific

 * netdev must never change. Basing the count on static values such as the

 * maximum number of queues or the device type is ok. However, the API for

 * obtaining stats is *not* safe against changes based on non-static

 * values such as the *current* number of queues, or runtime flags.

 *

 * If a statistic is not always enabled, return it as part of the count

 * anyways, always return its string, and report its value as zero.

	/* The number of stats reported for a given net_device must remain

	 * constant throughout the life of that device.

	 *

	 * This is because the API for obtaining the size, strings, and stats

	 * is spread out over three separate ethtool ioctls. There is no safe

	 * way to lock the number of stats across these calls, so we must

	 * assume that they will never change.

	 *

	 * Due to this, we report the maximum number of queues, even if not

	 * every queue is currently configured. Since we always allocate

	 * queues in pairs, we'll just use netdev->num_tx_queues * 2. This

	 * works because the num_tx_queues is set at device creation and never

	 * changes.

/**

 * i40e_get_veb_tc_stats - copy VEB TC statistics to formatted structure

 * @tc: the TC statistics in VEB structure (veb->tc_stats)

 * @i: the index of traffic class in (veb->tc_stats) structure to copy

 *

 * Copy VEB TC statistics from structure of arrays (veb->tc_stats) to

 * one dimensional structure i40e_cp_veb_tc_stats.

 * Produce formatted i40e_cp_veb_tc_stats structure of the VEB TC

 * statistics for the given TC.

/**

 * i40e_get_pfc_stats - copy HW PFC statistics to formatted structure

 * @pf: the PF device structure

 * @i: the priority value to copy

 *

 * The PFC stats are found as arrays in pf->stats, which is not easy to pass

 * into i40e_add_ethtool_stats. Produce a formatted i40e_pfc_stats structure

 * of the PFC stats for the given priority.

/**

 * i40e_get_ethtool_stats - copy stat values into supplied buffer

 * @netdev: the netdev to collect stats for

 * @stats: ethtool stats command structure

 * @data: ethtool supplied buffer

 *

 * Copy the stats values for this netdev into the buffer. Expects data to be

 * pre-allocated to the size returned by i40e_get_stats_count.. Note that all

 * statistics must be copied in a static order, and the count must not change

 * for a given netdev. See i40e_get_stats_count for more details.

 *

 * If a statistic is not currently valid (such as a disabled queue), this

 * function reports its value as zero.

	/* If veb stats aren't enabled, pass NULL instead of the veb so that

	 * we initialize stats to zero and update the data pointer

	 * intelligently

/**

 * i40e_get_stat_strings - copy stat strings into supplied buffer

 * @netdev: the netdev to collect strings for

 * @data: supplied buffer to copy strings into

 *

 * Copy the strings related to stats for this netdev. Expects data to be

 * pre-allocated with the size reported by i40e_get_stats_count. Note that the

 * strings must be copied in a static order and the total count must not

 * change for a given netdev. See i40e_get_stats_count for more details.

 only report HW timestamping if PTP is enabled */

 forcebly clear the NVM Update state machine */

 Offline tests */

 If the device is online then take it offline */

 indicate we're in test mode */

			/* This reset does not affect link - if it is

			 * changed to a type of reset that does affect

			 * link then the following link test would have

			 * to be moved to before the reset

 run reg test last, a reset is required after it */

 Online tests */

 Offline only tests, not run in online; pass by default */

 NVM bit on means WoL disabled for the port */

/**

 * i40e_set_wol - set the WakeOnLAN configuration

 * @netdev: the netdev in question

 * @wol: the ethtool WoL setting data

 WoL not supported if this isn't the controlling PF on the port */

 NVM bit on means WoL disabled for the port */

 only magic packet is supported */

 is this a new value? */

/* NOTE: i40e hardware uses a conversion factor of 2 for Interrupt

 * Throttle Rate (ITR) ie. ITR(1) = 2us ITR(10) = 20 us, and also

 * 125us (8000 interrupts per second) == ITR(62)

/**

 * __i40e_get_coalesce - get per-queue coalesce settings

 * @netdev: the netdev to check

 * @ec: ethtool coalesce data structure

 * @queue: which queue to pick

 *

 * Gets the per-queue settings for coalescence. Specifically Rx and Tx usecs

 * are per queue. If queue is <0 then we default to queue 0 as the

 * representative value.

	/* rx and tx usecs has per queue value. If user doesn't specify the

	 * queue, return queue 0's value to represent.

	/* we use the _usecs_high to store/set the interrupt rate limit

	 * that the hardware supports, that almost but not quite

	 * fits the original intent of the ethtool variable,

	 * the rx_coalesce_usecs_high limits total interrupts

	 * per second from both tx/rx sources.

/**

 * i40e_get_coalesce - get a netdev's coalesce settings

 * @netdev: the netdev to check

 * @ec: ethtool coalesce data structure

 * @kernel_coal: ethtool CQE mode setting structure

 * @extack: extack for reporting error messages

 *

 * Gets the coalesce settings for a particular netdev. Note that if user has

 * modified per-queue settings, this only guarantees to represent queue 0. See

 * __i40e_get_coalesce for more details.

/**

 * i40e_get_per_queue_coalesce - gets coalesce settings for particular queue

 * @netdev: netdev structure

 * @ec: ethtool's coalesce settings

 * @queue: the particular queue to read

 *

 * Will read a specific queue's coalesce settings

/**

 * i40e_set_itr_per_queue - set ITR values for specific queue

 * @vsi: the VSI to set values for

 * @ec: coalesce settings from ethtool

 * @queue: the queue to modify

 *

 * Change the ITR settings for a specific queue.

	/* The interrupt handler itself will take care of programming

	 * the Tx and Rx ITR values based on the values we have entered

	 * into the q_vector, no need to write the values now.

/**

 * __i40e_set_coalesce - set coalesce settings for particular queue

 * @netdev: the netdev to change

 * @ec: ethtool coalesce settings

 * @queue: the queue to change

 *

 * Sets the coalesce settings for a particular queue.

 tx_coalesce_usecs_high is ignored, use rx-usecs-high instead */

	/* rx and tx usecs has per queue value. If user doesn't specify the

	 * queue, apply to all queues.

/**

 * i40e_set_coalesce - set coalesce settings for every queue on the netdev

 * @netdev: the netdev to change

 * @ec: ethtool coalesce settings

 * @kernel_coal: ethtool CQE mode setting structure

 * @extack: extack for reporting error messages

 *

 * This will set each queue to the same coalesce settings.

/**

 * i40e_set_per_queue_coalesce - set specific queue's coalesce settings

 * @netdev: the netdev to change

 * @ec: ethtool's coalesce settings

 * @queue: the queue to change

 *

 * Sets the specified queue's coalesce settings.

/**

 * i40e_get_rss_hash_opts - Get RSS hash Input Set for each flow type

 * @pf: pointer to the physical function struct

 * @cmd: ethtool rxnfc command

 *

 * Returns Success if the flow is supported, else Invalid Input.

 Default is src/dest for IP, no matter the L4 hashing */

 Read flow based hash input set register */

 Process bits of hash input set */

/**

 * i40e_check_mask - Check whether a mask field is set

 * @mask: the full mask value

 * @field: mask of the field to check

 *

 * If the given mask is fully set, return positive value. If the mask for the

 * field is fully unset, return zero. Otherwise return a negative error code.

/**

 * i40e_parse_rx_flow_user_data - Deconstruct user-defined data

 * @fsp: pointer to rx flow specification

 * @data: pointer to userdef data structure for storage

 *

 * Read the user-defined data and deconstruct the value into a structure. No

 * other code should read the user-defined data, so as to ensure that every

 * place consistently reads the value correctly.

 *

 * The user-defined field is a 64bit Big Endian format value, which we

 * deconstruct by reading bits or bit fields from it. Single bit flags shall

 * be defined starting from the highest bits, while small bit field values

 * shall be defined starting from the lowest bits.

 *

 * Returns 0 if the data is valid, and non-zero if the userdef data is invalid

 * and the filter should be rejected. The data structure will always be

 * modified even if FLOW_EXT is not set.

 *

 Zero memory first so it's always consistent. */

/**

 * i40e_fill_rx_flow_user_data - Fill in user-defined data field

 * @fsp: pointer to rx_flow specification

 * @data: pointer to return userdef data

 *

 * Reads the userdef data structure and properly fills in the user defined

 * fields of the rx_flow_spec.

/**

 * i40e_get_ethtool_fdir_all - Populates the rule count of a command

 * @pf: Pointer to the physical function struct

 * @cmd: The command to get or set Rx flow classification rules

 * @rule_locs: Array of used rule locations

 *

 * This function populates both the total and actual rule count of

 * the ethtool flow classification command

 *

 * Returns 0 on success or -EMSGSIZE if entry not found

 report total rule count */

/**

 * i40e_get_ethtool_fdir_entry - Look up a filter based on Rx flow

 * @pf: Pointer to the physical function struct

 * @cmd: The command to get or set Rx flow classification rules

 *

 * This function looks up a filter based on the Rx flow classification

 * command and fills the flow spec info for it if found

 *

 * Returns 0 on success or -EINVAL if filter not found

		/* Reverse the src and dest notion, since the HW views them

		 * from Tx perspective where as the user expects it from

		 * Rx filter view.

		/* Reverse the src and dest notion, since the HW views them

		 * from Tx perspective where as the user expects it from

		 * Rx filter view.

		/* If we have stored a filter with a flow type not listed here

		 * it is almost certainly a driver bug. WARN(), and then

		 * assign the input_set as if all fields are enabled to avoid

		 * reading unassigned memory.

			/* VFs are zero-indexed by the driver, but ethtool

			 * expects them to be one-indexed, so add one here

/**

 * i40e_get_rxnfc - command to get RX flow classification rules

 * @netdev: network interface device structure

 * @cmd: ethtool rxnfc command

 * @rule_locs: pointer to store rule data

 *

 * Returns Success if the command is supported.

 report total rule count */

/**

 * i40e_get_rss_hash_bits - Read RSS Hash bits from register

 * @nfc: pointer to user request

 * @i_setc: bits currently set

 *

 * Returns value of bits to be set per user request

 Any other flow type are not supported here */

/**

 * i40e_set_rss_hash_opt - Enable/Disable flow types for RSS hash

 * @pf: pointer to the physical function struct

 * @nfc: ethtool rxnfc command

 *

 * Returns Success if the flow input set is supported.

	/* RSS does not support anything other than hashing

	 * to queues on src and dst IPs and ports

/**

 * i40e_update_ethtool_fdir_entry - Updates the fdir filter entry

 * @vsi: Pointer to the targeted VSI

 * @input: The filter to update or NULL to indicate deletion

 * @sw_idx: Software index to the filter

 * @cmd: The command to get or set Rx flow classification rules

 *

 * This function updates (or deletes) a Flow Director entry from

 * the hlist of the corresponding PF

 *

 * Returns 0 on success

 hash found, or no matching entry */

 if there is an old rule occupying our place remove it */

		/* Remove this rule, since we're either deleting it, or

		 * replacing it.

	/* If we weren't given an input, this is a delete, so just return the

	 * error code indicating if there was an entry at the requested slot

 Otherwise, install the new rule as requested */

 add filter to the list */

 update counts */

/**

 * i40e_prune_flex_pit_list - Cleanup unused entries in FLX_PIT table

 * @pf: pointer to PF structure

 *

 * This function searches the list of filters and determines which FLX_PIT

 * entries are still required. It will prune any entries which are no longer

 * in use after the deletion.

 First, we'll check the l3 table */

		/* If we didn't find the filter, then we can prune this entry

		 * from the list.

 Followed by the L4 table */

			/* Skip this filter if it's L3, since we already

			 * checked those in the above loop

		/* If we didn't find the filter, then we can prune this entry

		 * from the list.

/**

 * i40e_del_fdir_entry - Deletes a Flow Director filter entry

 * @vsi: Pointer to the targeted VSI

 * @cmd: The command to get or set Rx flow classification rules

 *

 * The function removes a Flow Director filter entry from the

 * hlist of the corresponding PF

 *

 * Returns 0 on success

/**

 * i40e_unused_pit_index - Find an unused PIT index for given list

 * @pf: the PF data structure

 *

 * Find the first unused flexible PIT index entry. We search both the L3 and

 * L4 flexible PIT lists so that the returned index is unique and unused by

 * either currently programmed L3 or L4 filters. We use a bit field as storage

 * to track which indexes are already used.

	/* We need to make sure that the new index isn't in use by either L3

	 * or L4 filters so that IP_USER_FLOW filters can program both L3 and

	 * L4 to use the same index.

/**

 * i40e_find_flex_offset - Find an existing flex src_offset

 * @flex_pit_list: L3 or L4 flex PIT list

 * @src_offset: new src_offset to find

 *

 * Searches the flex_pit_list for an existing offset. If no offset is

 * currently programmed, then this will return an ERR_PTR if there is no space

 * to add a new offset, otherwise it returns NULL.

	/* Search for the src_offset first. If we find a matching entry

	 * already programmed, we can simply re-use it.

	/* If we haven't found an entry yet, then the provided src offset has

	 * not yet been programmed. We will program the src offset later on,

	 * but we need to indicate whether there is enough space to do so

	 * here. We'll make use of ERR_PTR for this purpose.

/**

 * i40e_add_flex_offset - Add src_offset to flex PIT table list

 * @flex_pit_list: L3 or L4 flex PIT list

 * @src_offset: new src_offset to add

 * @pit_index: the PIT index to program

 *

 * This function programs the new src_offset to the list. It is expected that

 * i40e_find_flex_offset has already been tried and returned NULL, indicating

 * that this offset is not programmed, and that the list has enough space to

 * store another offset.

 *

 * Returns 0 on success, and negative value on error.

	/* We need to insert this item such that the list is sorted by

	 * src_offset in ascending order.

		/* If we found an entry with our offset already programmed we

		 * can simply return here, after freeing the memory. However,

		 * if the pit_index does not match we need to report an error.

			/* If the PIT index is not the same we can't re-use

			 * the entry, so we must report an error.

	/* If we reached here, then we haven't yet added the item. This means

	 * that we should add the item at the end of the list.

/**

 * __i40e_reprogram_flex_pit - Re-program specific FLX_PIT table

 * @pf: Pointer to the PF structure

 * @flex_pit_list: list of flexible src offsets in use

 * @flex_pit_start: index to first entry for this section of the table

 *

 * In order to handle flexible data, the hardware uses a table of values

 * called the FLX_PIT table. This table is used to indicate which sections of

 * the input correspond to what PIT index values. Unfortunately, hardware is

 * very restrictive about programming this table. Entries must be ordered by

 * src_offset in ascending order, without duplicates. Additionally, unused

 * entries must be set to the unused index value, and must have valid size and

 * length according to the src_offset ordering.

 *

 * This function will reprogram the FLX_PIT register from a book-keeping

 * structure that we guarantee is already ordered correctly, and has no more

 * than 3 entries.

 *

 * To make things easier, we only support flexible values of one word length,

 * rather than allowing variable length flexible values.

	/* First, loop over the list of flex PIT entries, and reprogram the

	 * registers.

		/* We have to be careful when programming values for the

		 * largest SRC_OFFSET value. It is possible that adding

		 * additional empty values at the end would overflow the space

		 * for the SRC_OFFSET in the FLX_PIT register. To avoid this,

		 * we check here and add the empty values prior to adding the

		 * largest value.

		 *

		 * To determine this, we will use a loop from i+1 to 3, which

		 * will determine whether the unused entries would have valid

		 * SRC_OFFSET. Note that there cannot be extra entries past

		 * this value, because the only valid values would have been

		 * larger than I40E_MAX_FLEX_SRC_OFFSET, and thus would not

		 * have been added to the list in the first place.

 Now, we can program the actual value into the table */

	/* In order to program the last entries in the table, we need to

	 * determine the valid offset. If the list is empty, we'll just start

	 * with 0. Otherwise, we'll start with the last item offset and add 1.

	 * This ensures that all entries have valid sizes. If we don't do this

	 * correctly, the hardware will disable flexible field parsing.

/**

 * i40e_reprogram_flex_pit - Reprogram all FLX_PIT tables after input set change

 * @pf: pointer to the PF structure

 *

 * This function reprograms both the L3 and L4 FLX_PIT tables. See the

 * internal helper function for implementation details.

 We also need to program the L3 and L4 GLQF ORT register */

/**

 * i40e_flow_str - Converts a flow_type into a human readable string

 * @fsp: the flow specification

 *

 * Currently only flow types we support are included here, and the string

 * value attempts to match what ethtool would use to configure this flow type.

/**

 * i40e_pit_index_to_mask - Return the FLEX mask for a given PIT index

 * @pit_index: PIT index to convert

 *

 * Returns the mask for a given PIT index. Will return 0 if the pit_index is

 * of range.

/**

 * i40e_print_input_set - Show changes between two input sets

 * @vsi: the vsi being configured

 * @old: the old input set

 * @new: the new input set

 *

 * Print the difference between old and new input sets by showing which series

 * of words are toggled on or off. Only displays the bits we actually support

 * changing.

 Show change of flexible filter entries */

/**

 * i40e_check_fdir_input_set - Check that a given rx_flow_spec mask is valid

 * @vsi: pointer to the targeted VSI

 * @fsp: pointer to Rx flow specification

 * @userdef: userdefined data from flow specification

 *

 * Ensures that a given ethtool_rx_flow_spec has a valid mask. Some support

 * for partial matches exists with a few limitations. First, hardware only

 * supports masking by word boundary (2 bytes) and not per individual bit.

 * Second, hardware is limited to using one mask for a flow type and cannot

 * use a separate mask for each filter.

 *

 * To support these limitations, if we already have a configured filter for

 * the specified type, this function enforces that new filters of the type

 * match the configured input set. Otherwise, if we do not have a filter of

 * the specified type, we allow the input set to be updated to match the

 * desired filter.

 *

 * To help ensure that administrators understand why filters weren't displayed

 * as supported, we print a diagnostic message displaying how the input set

 * would change and warning to delete the preexisting filters if required.

 *

 * Returns 0 on successful input set match, and a negative return code on

 * failure.

 Read the current input set from register memory. */

	/* Determine, if any, the required changes to the input set in order

	 * to support the provided mask.

	 *

	 * Hardware only supports masking at word (2 byte) granularity and does

	 * not support full bitwise masking. This implementation simplifies

	 * even further and only supports fully enabled or fully disabled

	 * masks for each field, even though we could split the ip4src and

	 * ip4dst fields.

 IPv4 source address */

 IPv4 destination address */

 L4 source port */

 L4 destination port */

 Filtering on Type of Service is not supported. */

 Check if user provided IPv6 source address. */

 Check if user provided destination address. */

 L4 source port */

 L4 destination port */

 Filtering on Traffic Classes is not supported. */

 IPv4 source address */

 IPv4 destination address */

 First 4 bytes of L4 header */

 Filtering on Type of Service is not supported. */

 Filtering on IP version is not supported */

 Filtering on L4 protocol is not supported */

 Check if user provided IPv6 source address. */

 Check if user provided destination address. */

 Filtering on Traffic class is not supported. */

 Filtering on L4 protocol is not supported */

		/* Allow only 802.1Q and no etype defined, as

		 * later it's modified to 0x8100

 First, clear all flexible filter entries */

	/* If we have a flexible filter, try to add this offset to the correct

	 * flexible filter PIT list. Once finished, we can update the mask.

	 * If the src_offset changed, we will get a new mask value which will

	 * trigger an input set change.

		/* Flexible offset must be even, since the flexible payload

		 * must be aligned on 2-byte boundary.

 FLX_PIT source offset value is only so large */

		/* See if this offset has already been programmed. If we get

		 * an ERR_PTR, then the filter is not safe to add. Otherwise,

		 * if we get a NULL pointer, this means we will need to add

		 * the offset.

		/* IP_USER_FLOW filters match both L4 (ICMP) and L3 (unknown)

		 * packet types, and thus we need to program both L3 and L4

		 * flexible values. These must have identical flexible index,

		 * as otherwise we can't correctly program the input set. So

		 * we'll find both an L3 and L4 index and make sure they are

		 * the same.

				/* If we already had a matching L4 entry, we

				 * need to make sure that the L3 entry we

				 * obtained uses the same index.

		/* If we didn't find an existing flex offset, we need to

		 * program a new one. However, we don't immediately program it

		 * here because we will wait to program until after we check

		 * that it is safe to change the input set.

 Update the mask with the new offset */

	/* If the mask and flexible filter offsets for this filter match the

	 * currently programmed values we don't need any input set change, so

	 * this filter is safe to install.

	/* Hardware input sets are global across multiple ports, so even the

	 * main port cannot change them when in MFP mode as this would impact

	 * any filters on the other ports.

	/* This filter requires us to update the input set. However, hardware

	 * only supports one input set per flow type, and does not support

	 * separate masks for each filter. This means that we can only support

	 * a single mask for all filters of a specific type.

	 *

	 * If we have preexisting filters, they obviously depend on the

	 * current programmed input set. Display a diagnostic message in this

	 * case explaining why the filter could not be accepted.

	/* IP_USER_FLOW filters match both IPv4/Other and IPv4/Fragmented

	 * frames. If we're programming the input set for IPv4/Other, we also

	 * need to program the IPv4/Fragmented input set. Since we don't have

	 * separate support, we'll always assume and enforce that the two flow

	 * types must have matching input sets.

 Add the new offset and update table, if necessary */

/**

 * i40e_match_fdir_filter - Return true of two filters match

 * @a: pointer to filter struct

 * @b: pointer to filter struct

 *

 * Returns true if the two filters match exactly the same criteria. I.e. they

 * match the same flow type and have the same parameters. We don't need to

 * check any input-set since all filters of the same flow type must use the

 * same input set.

 The filters do not much if any of these criteria differ. */

/**

 * i40e_disallow_matching_filters - Check that new filters differ

 * @vsi: pointer to the targeted VSI

 * @input: new filter to check

 *

 * Due to hardware limitations, it is not possible for two filters that match

 * similar criteria to be programmed at the same time. This is true for a few

 * reasons:

 *

 * (a) all filters matching a particular flow type must use the same input

 * set, that is they must match the same criteria.

 * (b) different flow types will never match the same packet, as the flow type

 * is decided by hardware before checking which rules apply.

 * (c) hardware has no way to distinguish which order filters apply in.

 *

 * Due to this, we can't really support using the location data to order

 * filters in the hardware parsing. It is technically possible for the user to

 * request two filters matching the same criteria but which select different

 * queues. In this case, rather than keep both filters in the list, we reject

 * the 2nd filter when the user requests adding it.

 *

 * This avoids needing to track location for programming the filter to

 * hardware, and ensures that we avoid some strange scenarios involving

 * deleting filters which match the same criteria.

 Loop through every filter, and check that it doesn't match */

		/* Don't check the filters match if they share the same fd_id,

		 * since the new filter is actually just updating the target

		 * of the old filter.

		/* If any filters match, then print a warning message to the

		 * kernel message buffer and bail out.

/**

 * i40e_add_fdir_ethtool - Add/Remove Flow Director filters

 * @vsi: pointer to the targeted VSI

 * @cmd: command to get or set RX flow classification rules

 *

 * Add Flow Director filters for a specific flow spec based on their

 * protocol.  Returns 0 if the filters were successfully added.

 Parse the user-defined field */

 Extended MAC field is not supported */

	/* ring_cookie is either the drop index, or is a mask of the queue

	 * index and VF id we wish to target.

 VFs are zero-indexed, so we subtract one here */

		/* Reverse the src and dest notion, since the HW expects them

		 * to be from Tx perspective where as the input from user is

		 * from Rx filter view.

		/* Reverse the src and dest notion, since the HW expects them

		 * to be from Tx perspective where as the input from user is

		 * from Rx filter view.

 Avoid programming two filters with identical match criteria. */

	/* Add the input filter to the fdir_input_list, possibly replacing

	 * a previous filter. Do not free the input structure after adding it

	 * to the list as this would cause a use-after-free bug.

/**

 * i40e_set_rxnfc - command to set RX flow classification rules

 * @netdev: network interface device structure

 * @cmd: ethtool rxnfc command

 *

 * Returns Success if the command is supported.

/**

 * i40e_max_channels - get Max number of combined channels supported

 * @vsi: vsi pointer

 TODO: This code assumes DCB and FD is disabled for now. */

/**

 * i40e_get_channels - Get the current channels enabled and max supported etc.

 * @dev: network interface device structure

 * @ch: ethtool channels structure

 *

 * We don't support separate tx and rx queues as channels. The other count

 * represents how many queues are being used for control. max_combined counts

 * how many queue pairs we can support. They may not be mapped 1 to 1 with

 * q_vectors since we support a lot more queue pairs than q_vectors.

 report maximum channels */

 report info for other vector */

 Note: This code assumes DCB is disabled for now. */

/**

 * i40e_set_channels - Set the new channels count.

 * @dev: network interface device structure

 * @ch: ethtool channels structure

 *

 * The new channels count may not be the same as requested by the user

 * since it gets rounded down to a power of 2 value.

 We do not support setting channels for any other VSI at present */

	/* We do not support setting channels via ethtool when TCs are

	 * configured through mqprio

 verify they are not requesting separate vectors */

 verify other_count has not changed */

 verify the number of channels does not exceed hardware limits */

	/* verify that the number of channels does not invalidate any current

	 * flow director rules

 update feature limits from largest to smallest supported values */

 TODO: Flow director limit, DCB etc */

	/* use rss_reconfig to rebuild with new queue count and update traffic

	 * class queue mapping

/**

 * i40e_get_rxfh_key_size - get the RSS hash key size

 * @netdev: network interface device structure

 *

 * Returns the table size.

/**

 * i40e_get_rxfh_indir_size - get the rx flow hash indirection table size

 * @netdev: network interface device structure

 *

 * Returns the table size.

/**

 * i40e_get_rxfh - get the rx flow hash indirection table

 * @netdev: network interface device structure

 * @indir: indirection table

 * @key: hash key

 * @hfunc: hash function

 *

 * Reads the indirection table directly from the hardware. Returns 0 on

 * success.

/**

 * i40e_set_rxfh - set the rx flow hash indirection table

 * @netdev: network interface device structure

 * @indir: indirection table

 * @key: hash key

 * @hfunc: hash function to use

 *

 * Returns -EINVAL if the table specifies an invalid queue id, otherwise

 * returns 0 after programming the table.

 Each 32 bits pointed by 'indir' is stored with a lut entry */

/**

 * i40e_get_priv_flags - report device private flags

 * @dev: network interface device structure

 *

 * The get string set count and the string set should be matched for each

 * flag returned.  Add new strings for each flag to the i40e_gstrings_priv_flags

 * array.

 *

 * Returns a u32 bitmap of flags.

/**

 * i40e_set_priv_flags - set private flags

 * @dev: network interface device structure

 * @flags: bit flags to be set

 If this is a read-only flag, it can't be changed */

 If this is a read-only flag, it can't be changed */

	/* Before we finalize any flag changes, we need to perform some

	 * checks to ensure that the changes are supported and safe.

 ATR eviction is not supported on all devices */

	/* If the driver detected FW LLDP was disabled on init, this flag could

	 * be set, however we do not support _changing_ the flag:

	 * - on XL710 if NPAR is enabled or FW API version < 1.7

	 * - on X722 with FW API version < 1.6

	 * There are situations where older FW versions/NPAR enabled PFs could

	 * disable LLDP, however we _must_ not allow the user to enable/disable

	 * LLDP with this flag on unsupported FW versions.

	/* Process any additional changes needed as a result of flag changes.

	 * The changed_flags value reflects the list of bits that were

	 * changed in the code above.

 Flush current ATR settings if ATR was disabled */

 not a fatal problem, just keep going */

 CONFIG_I40E_DCB */

	/* Now that we've checked to ensure that the new flags are valid, load

	 * them into place. Since we only modify flags either (a) during

	 * initialization or (b) while holding the RTNL lock, we don't need

	 * anything fancy here.

	/* Issue reset to cause things to take effect, as additional bits

	 * are added we will need to create a mask of bits requiring reset

/**

 * i40e_get_module_info - get (Q)SFP+ module type info

 * @netdev: network interface device structure

 * @modinfo: module EEPROM size and layout information structure

 Check if firmware supports reading module EEPROM. */

		/* Check if the module requires address swap to access

		 * the other EEPROM memory page.

 Module is not SFF-8472 compliant */

			/* Module is SFF-8472 compliant but doesn't implement

			 * Digital Diagnostic Monitoring (DDM).

 Read from memory page 0. */

 Determine revision compliance byte */

 Module is SFF-8636 compliant */

/**

 * i40e_get_module_eeprom - fills buffer with (Q)SFP+ module memory contents

 * @netdev: network interface device structure

 * @ee: EEPROM dump request structure

 * @data: buffer to be filled with EEPROM contents

 Check if we need to access the other memory page */

 Compute memory page number and offset. */

 Get initial PHY capabilities */

	/* Check whether NIC configuration is compatible with Energy Efficient

	 * Ethernet (EEE) mode.

 Get current configuration */

 Deny parameters we don't support */

 Get initial PHY capabilities */

	/* Check whether NIC configuration is compatible with Energy Efficient

	 * Ethernet (EEE) mode.

 Cache initial EEE capability */

 Get current PHY configuration */

 Cache current PHY configuration */

 Set desired EEE state */

 Apply modified PHY configuration */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2018 Intel Corporation. */

/**

 * i40e_fdir - Generate a Flow Director descriptor based on fdata

 * @tx_ring: Tx ring to send buffer on

 * @fdata: Flow director filter data

 * @add: Indicate if we are adding a rule or deleting one

 *

 grab the next descriptor */

 Use LAN VSI Id if not programmed by user */

/**

 * i40e_program_fdir_filter - Program a Flow Director filter

 * @fdir_data: Packet data that will be filter parameters

 * @raw_packet: the pre-allocated packet buffer for FDir

 * @pf: The PF pointer

 * @add: True for add/update, False for remove

 find existing FDIR VSI */

 we need two descriptors to add/del a filter and we can wait */

 grab the next descriptor */

 Now program a dummy descriptor */

 record length, and DMA address */

	/* Force memory writes to complete before letting h/w

	 * know there are new descriptors to fetch.

 Mark the data descriptor to be watched */

/**

 * i40e_create_dummy_packet - Constructs dummy packet for HW

 * @dummy_packet: preallocated space for dummy packet

 * @ipv4: is layer 3 packet of version 4 or 6

 * @l4proto: next level protocol used in data portion of l3

 * @data: filter data

 *

 * Returns address of layer 4 protocol dummy packet.

/**

 * i40e_create_dummy_udp_packet - helper function to create UDP packet

 * @raw_packet: preallocated space for dummy packet

 * @ipv4: is layer 3 packet of version 4 or 6

 * @l4proto: next level protocol used in data portion of l3

 * @data: filter data

 *

 * Helper function to populate udp fields.

/**

 * i40e_create_dummy_tcp_packet - helper function to create TCP packet

 * @raw_packet: preallocated space for dummy packet

 * @ipv4: is layer 3 packet of version 4 or 6

 * @l4proto: next level protocol used in data portion of l3

 * @data: filter data

 *

 * Helper function to populate tcp fields.

 Dummy tcp packet */

/**

 * i40e_create_dummy_sctp_packet - helper function to create SCTP packet

 * @raw_packet: preallocated space for dummy packet

 * @ipv4: is layer 3 packet of version 4 or 6

 * @l4proto: next level protocol used in data portion of l3

 * @data: filter data

 *

 * Helper function to populate sctp fields.

/**

 * i40e_prepare_fdir_filter - Prepare and program fdir filter

 * @pf: physical function to attach filter to

 * @fd_data: filter data

 * @add: add or delete filter

 * @packet_addr: address of dummy packet, used in filtering

 * @payload_offset: offset from dummy packet address to user defined data

 * @pctype: Packet type for which filter is used

 *

 * Helper function to offset data of dummy packet, program it and

 * handle errors.

 If user provided vlan, offset payload by vlan header length */

 Free the packet buffer since it wasn't added to the ring */

/**

 * i40e_change_filter_num - Prepare and program fdir filter

 * @ipv4: is layer 3 packet of version 4 or 6

 * @add: add or delete filter

 * @ipv4_filter_num: field to update

 * @ipv6_filter_num: field to update

 *

 * Update filter number field for pf.

/**

 * i40e_add_del_fdir_udp - Add/Remove UDP filters

 * @vsi: pointer to the targeted VSI

 * @fd_data: the flow director data required for the FDir descriptor

 * @add: true adds a filter, false removes it

 * @ipv4: true is v4, false is v6

 *

 * Returns 0 if the filters were successfully added or removed

/**

 * i40e_add_del_fdir_tcp - Add/Remove TCPv4 filters

 * @vsi: pointer to the targeted VSI

 * @fd_data: the flow director data required for the FDir descriptor

 * @add: true adds a filter, false removes it

 * @ipv4: true is v4, false is v6

 *

 * Returns 0 if the filters were successfully added or removed

/**

 * i40e_add_del_fdir_sctp - Add/Remove SCTPv4 Flow Director filters for

 * a specific flow spec

 * @vsi: pointer to the targeted VSI

 * @fd_data: the flow director data required for the FDir descriptor

 * @add: true adds a filter, false removes it

 * @ipv4: true is v4, false is v6

 *

 * Returns 0 if the filters were successfully added or removed

/**

 * i40e_add_del_fdir_ip - Add/Remove IPv4 Flow Director filters for

 * a specific flow spec

 * @vsi: pointer to the targeted VSI

 * @fd_data: the flow director data required for the FDir descriptor

 * @add: true adds a filter, false removes it

 * @ipv4: true is v4, false is v6

 *

 * Returns 0 if the filters were successfully added or removed

 IPv6 no header option differs from IPv4 */

/**

 * i40e_add_del_fdir - Build raw packets to add/del fdir filter

 * @vsi: pointer to the targeted VSI

 * @input: filter to add or delete

 * @add: true adds a filter, false removes it

 *

 We cannot support masking based on protocol */

 We cannot support masking based on protocol */

	/* The buffer allocated here will be normally be freed by

	 * i40e_clean_fdir_tx_irq() as it reclaims resources after transmit

	 * completion. In the event of an error adding the buffer to the FDIR

	 * ring, it will immediately be freed. It may also be freed by

	 * i40e_clean_tx_ring() when closing the VSI.

/**

 * i40e_fd_handle_status - check the Programming Status for FD

 * @rx_ring: the Rx ring for this descriptor

 * @qword0_raw: qword0

 * @qword1: qword1 after le_to_cpu

 * @prog_id: the id originally used for programming

 *

 * This is used to verify if the FD programming or invalidation

 * requested by SW to the HW is successful or not and take actions accordingly.

		/* Check if the programming error is for ATR.

		 * If so, auto disable ATR and set a state for

		 * flush in progress. Next time we come here if flush is in

		 * progress do nothing, once flush is complete the state will

		 * be cleared.

 store the current atr filter count */

			/* These set_bit() calls aren't atomic with the

			 * test_bit() here, but worse case we potentially

			 * disable ATR and queue a flush right after SB

			 * support is re-enabled. That shouldn't cause an

			 * issue in practice

 filter programming failed most likely due to table full */

		/* If ATR is running fcnt_prog can quickly change,

		 * if we are very close to full, it makes sense to disable

		 * FD ATR/SB and then re-enable it when there is room.

/**

 * i40e_unmap_and_free_tx_resource - Release a Tx buffer

 * @ring:      the ring that owns the buffer

 * @tx_buffer: the buffer to free

 tx_buffer must be completely set up in the transmit path */

/**

 * i40e_clean_tx_ring - Free any empty Tx buffers

 * @tx_ring: ring to be cleaned

 ring already cleared, nothing to do */

 Free all the Tx ring sk_buffs */

 Zero out the descriptor ring */

 cleanup Tx queue statistics */

/**

 * i40e_free_tx_resources - Free Tx resources per queue

 * @tx_ring: Tx descriptor ring for a specific queue

 *

 * Free all transmit software resources

/**

 * i40e_get_tx_pending - how many tx descriptors not processed

 * @ring: the ring of descriptors

 * @in_sw: use SW variables

 *

 * Since there is no access to the ring head register

 * in XL710, we need to use our local copies

/**

 * i40e_detect_recover_hung - Function to detect and recover hung_queues

 * @vsi:  pointer to vsi struct with tx queues

 *

 * VSI has netdev and netdev has TX queues. This function is to check each of

 * those TX queues if they are hung, trigger recovery by issuing SW interrupt.

			/* If packet counter has not changed the queue is

			 * likely stalled, so force an interrupt for this

			 * queue.

			 *

			 * prev_pkt_ctr would be negative if there was no

			 * pending work.

			/* Memory barrier between read of packet count and call

			 * to i40e_get_tx_pending()

/**

 * i40e_clean_tx_irq - Reclaim resources after transmit completes

 * @vsi: the VSI we care about

 * @tx_ring: Tx ring to clean

 * @napi_budget: Used to determine if we are in netpoll

 *

 * Returns true if there's any budget left (e.g. the clean is finished)

 if next_to_watch is not set then there is no work pending */

 prevent any other reads prior to eop_desc */

 we have caught up to head, no work left to do */

 clear next_to_watch to prevent false hangs */

 update the statistics for this packet */

 free the skb/XDP data */

 unmap skb header data */

 clear tx_buffer data */

 unmap remaining buffers */

 unmap any remaining paged data */

 move us one more past the eop_desc for start of next pkt */

 update budget accounting */

 notify netdev of completed buffers */

		/* Make sure that anybody stopping the queue after this

		 * sees the new next_to_clean.

/**

 * i40e_enable_wb_on_itr - Arm hardware to do a wb, interrupts are not enabled

 * @vsi: the VSI we care about

 * @q_vector: the vector on which to enable writeback

 *

 set noitr */

 set noitr */

/**

 * i40e_force_wb - Issue SW Interrupt so HW does a wb

 * @vsi: the VSI we care about

 * @q_vector: the vector  on which to force writeback

 *

 set noitr */

 allow 00 to be written to the index */

 set noitr */

 allow 00 to be written to the index */

/**

 * i40e_update_itr - update the dynamic ITR value based on statistics

 * @q_vector: structure containing interrupt and ring information

 * @rc: structure containing ring performance data

 *

 * Stores a new ITR value based on packets and byte

 * counts during the last interrupt.  The advantage of per interrupt

 * computation is faster updates and more accurate ITR for the current

 * traffic pattern.  Constants in this function were computed

 * based on theoretical maximum wire speed and thresholds were set based

 * on testing data as well as attempting to minimize response time

 * while increasing bulk throughput.

	/* If we don't have any rings just leave ourselves set for maximum

	 * possible latency so we take ourselves out of the equation.

	/* For Rx we want to push the delay up and default to low latency.

	 * for Tx we want to pull the delay down and default to high latency.

	/* If we didn't update within up to 1 - 2 jiffies we can assume

	 * that either packets are coming in so slow there hasn't been

	 * any work, or that there is so much work that NAPI is dealing

	 * with interrupt moderation and we don't need to do anything.

	/* If itr_countdown is set it means we programmed an ITR within

	 * the last 4 interrupt cycles. This has a side effect of us

	 * potentially firing an early interrupt. In order to work around

	 * this we need to throw out any data received for a few

	 * interrupts following the update.

		/* If Rx there are 1 to 4 packets and bytes are less than

		 * 9000 assume insufficient data to use bulk rate limiting

		 * approach unless Tx is already in bulk rate limiting. We

		 * are likely latency driven.

		/* If we have Tx and Rx ITR maxed and Tx ITR is running in

		 * bulk mode and we are receiving 4 or fewer packets just

		 * reset the ITR_ADAPTIVE_LATENCY bit for latency mode so

		 * that the Rx can relax.

		/* If we have processed over 32 packets in a single interrupt

		 * for Tx assume we need to switch over to "bulk" mode.

	/* We have no packets to actually measure against. This means

	 * either one of the other queues on this vector is active or

	 * we are a Tx queue doing TSO with too high of an interrupt rate.

	 *

	 * Between 4 and 56 we can assume that our current interrupt delay

	 * is only slightly too low. As such we should increase it by a small

	 * fixed amount.

		/* Between 56 and 112 is our "goldilocks" zone where we are

		 * working out "just right". Just report that our current

		 * ITR is good for us.

		/* If packet count is 128 or greater we are likely looking

		 * at a slight overrun of the delay we want. Try halving

		 * our delay to see if that will cut the number of packets

		 * in half per interrupt.

	/* The paths below assume we are dealing with a bulk ITR since

	 * number of packets is greater than 256. We are just going to have

	 * to compute a value and try to bring the count under control,

	 * though for smaller packet sizes there isn't much we can do as

	 * NAPI polling will likely be kicking in sooner rather than later.

	/* If packet counts are 256 or greater we can assume we have a gross

	 * overestimation of what the rate should be. Instead of trying to fine

	 * tune it just use the formula below to try and dial in an exact value

	 * give the current packet size of the frame.

	/* The following is a crude approximation of:

	 *  wmem_default / (size + overhead) = desired_pkts_per_int

	 *  rate / bits_per_byte / (size + ethernet overhead) = pkt_rate

	 *  (desired_pkt_rate / pkt_rate) * usecs_per_sec = ITR value

	 *

	 * Assuming wmem_default is 212992 and overhead is 640 bytes per

	 * packet, (256 skb, 64 headroom, 320 shared info), we can reduce the

	 * formula down to

	 *

	 *  (170 * (size + 24)) / (size + 640) = ITR

	 *

	 * We first do some math on the packet size and then finally bitshift

	 * by 8 after rounding up. We also have to account for PCIe link speed

	 * difference as ITR scales based on this.

 Start at 250k ints/sec */

 250K ints/sec to 60K ints/sec */

 60K ints/sec to 36K ints/sec */

 36K ints/sec to 30K ints/sec */

 plateau at a limit of 30K ints/sec */

	/* If we are in low latency mode halve our delay which doubles the

	 * rate to somewhere between 100K to 16K ints/sec

	/* Resultant value is 256 times larger than it needs to be. This

	 * gives us room to adjust the value as needed to either increase

	 * or decrease the value based on link speeds of 10G, 2.5G, 1G, etc.

	 *

	 * Use addition as we have already recorded the new latency flag

	 * for the ITR value.

 write back value */

 next update should occur within next jiffy */

/**

 * i40e_reuse_rx_page - page flip buffer and store it back on the ring

 * @rx_ring: rx descriptor ring to store buffers on

 * @old_buff: donor buffer to have page reused

 *

 * Synchronizes page for reuse by the adapter

 update, and store next to alloc */

 transfer page from old buffer to new buffer */

 clear contents of buffer_info */

/**

 * i40e_clean_programming_status - clean the programming status descriptor

 * @rx_ring: the rx ring that has this descriptor

 * @qword0_raw: qword0

 * @qword1: qword1 representing status_error_len in CPU ordering

 *

 * Flow director should handle FD_FILTER_STATUS to check its filter programming

 * status being successful or not and take actions accordingly. FCoE should

 * handle its context/filter programming/invalidation status and take actions.

 *

 * Returns an i40e_rx_buffer to reuse if the cleanup occurred, otherwise NULL.

/**

 * i40e_setup_tx_descriptors - Allocate the Tx descriptors

 * @tx_ring: the tx ring to set up

 *

 * Return 0 on success, negative on error

 warn if we are about to overwrite the pointer */

 round up to nearest 4K */

	/* add u32 for head writeback, align after this takes care of

	 * guaranteeing this is at least one cache line in size

/**

 * i40e_clean_rx_ring - Free Rx buffers

 * @rx_ring: ring to be cleaned

 ring already cleared, nothing to do */

 Free all the Rx ring sk_buffs */

		/* Invalidate cache lines that may have been written to by

		 * device so that we avoid corrupting memory.

 free resources associated with mapping */

 Zero out the descriptor ring */

/**

 * i40e_free_rx_resources - Free Rx resources

 * @rx_ring: ring to clean the resources from

 *

 * Free all receive software resources

/**

 * i40e_setup_rx_descriptors - Allocate Rx descriptors

 * @rx_ring: Rx descriptor ring (for a specific queue) to setup

 *

 * Returns 0 on success, negative on failure

 Round up to nearest 4K */

 XDP RX-queue info only needed for RX rings exposed to XDP */

/**

 * i40e_release_rx_desc - Store the new tail and head values

 * @rx_ring: ring to bump

 * @val: new head index

 update next to alloc since we have filled the ring */

	/* Force memory writes to complete before letting h/w

	 * know there are new descriptors to fetch.  (Only

	 * applicable for weak-ordered memory model archs,

	 * such as IA-64).

 Must be power-of-2 */

/**

 * i40e_alloc_mapped_page - recycle or make a new page

 * @rx_ring: ring to use

 * @bi: rx_buffer struct to modify

 *

 * Returns true if the page was successfully allocated or

 * reused.

 since we are recycling buffers we should seldom need to alloc */

 alloc new page for storage */

 map page for use */

	/* if mapping failed free memory back to system since

	 * there isn't much point in holding memory we can't use

/**

 * i40e_alloc_rx_buffers - Replace used receive buffers

 * @rx_ring: ring to place buffers on

 * @cleaned_count: number of buffers to replace

 *

 * Returns false if all allocations were successful, true if any fail

 do nothing if no valid netdev defined */

 sync the buffer for use by the device */

		/* Refresh the desc even if buffer_addrs didn't change

		 * because each write-back erases this info.

 clear the status bits for the next_to_use descriptor */

	/* make sure to come back via polling to try again after

	 * allocation failure

/**

 * i40e_rx_checksum - Indicate in skb if hw indicated a good cksum

 * @vsi: the VSI we care about

 * @skb: skb currently being received and modified

 * @rx_desc: the receive descriptor

 Rx csum enabled and ip headers found? */

 did the hardware decode the packet and checksum? */

 both known and outer_ip must be set for the below code to work */

 likely incorrect csum if alternate IP extension headers found */

 don't increment checksum err here, non-fatal err */

 there was some L4 error, count error and punt packet to the stack */

	/* handle packets that were not able to be checksummed due

	 * to arrival speed, in this case the stack can compute

	 * the csum.

	/* If there is an outer header present that might contain a checksum

	 * we need to bump the checksum level by 1 to reflect the fact that

	 * we are indicating we validated the inner checksum.

 Only report checksum unnecessary for TCP, UDP, or SCTP */

/**

 * i40e_ptype_to_htype - get a hash type

 * @ptype: the ptype value from the descriptor

 *

 * Returns a hash type to be used by skb_set_hash

/**

 * i40e_rx_hash - set the hash value in the skb

 * @ring: descriptor ring

 * @rx_desc: specific descriptor

 * @skb: skb currently being received and modified

 * @rx_ptype: Rx packet type

/**

 * i40e_process_skb_fields - Populate skb header fields from Rx descriptor

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @rx_desc: pointer to the EOP Rx descriptor

 * @skb: pointer to current skb being populated

 *

 * This function checks the ring, descriptor, and packet information in

 * order to populate the hash, checksum, VLAN, protocol, and

 * other fields within the skb.

 modifies the skb - consumes the enet header */

/**

 * i40e_cleanup_headers - Correct empty headers

 * @rx_ring: rx descriptor ring packet is being transacted on

 * @skb: pointer to current skb being fixed

 * @rx_desc: pointer to the EOP Rx descriptor

 *

 * In addition if skb is not at least 60 bytes we need to pad it so that

 * it is large enough to qualify as a valid Ethernet frame.

 *

 * Returns true if an error was encountered and skb was freed.

	/* ERR_MASK will only have valid bits if EOP set, and

	 * what we are doing here is actually checking

	 * I40E_RX_DESC_ERROR_RXE_SHIFT, since it is the zeroth bit in

	 * the error field

 if eth_skb_pad returns an error the skb was freed */

/**

 * i40e_can_reuse_rx_page - Determine if page can be reused for another Rx

 * @rx_buffer: buffer containing the page

 * @rx_buffer_pgcnt: buffer page refcount pre xdp_do_redirect() call

 *

 * If page is reusable, we have a green light for calling i40e_reuse_rx_page,

 * which will assign the current buffer to the buffer that next_to_alloc is

 * pointing to; otherwise, the DMA mapping needs to be destroyed and

 * page freed

 Is any reuse possible? */

 if we are only owner of page we can reuse it */

	/* If we have drained the page fragment pool we need to update

	 * the pagecnt_bias and page count so that we fully restock the

	 * number of references the driver holds.

/**

 * i40e_add_rx_frag - Add contents of Rx buffer to sk_buff

 * @rx_ring: rx descriptor ring to transact packets on

 * @rx_buffer: buffer containing page to add

 * @skb: sk_buff to place the data into

 * @size: packet length from rx_desc

 *

 * This function will add the data contained in rx_buffer->page to the skb.

 * It will just attach the page as a frag to the skb.

 *

 * The function will then update the page offset.

 page is being used so we must update the page offset */

/**

 * i40e_get_rx_buffer - Fetch Rx buffer and synchronize data for use

 * @rx_ring: rx descriptor ring to transact packets on

 * @size: size of buffer to add to skb

 * @rx_buffer_pgcnt: buffer page refcount

 *

 * This function will pull an Rx buffer from the ring and synchronize it

 * for use by the CPU.

 we are reusing so sync this buffer for CPU use */

 We have pulled a buffer for use, so decrement pagecnt_bias */

/**

 * i40e_construct_skb - Allocate skb and populate it

 * @rx_ring: rx descriptor ring to transact packets on

 * @rx_buffer: rx buffer to pull data from

 * @xdp: xdp_buff pointing to the data

 *

 * This function allocates an skb.  It then populates it with the page

 * data from the current receive descriptor, taking care to set up the

 * skb correctly.

 prefetch first cache line of first page */

	/* Note, we get here by enabling legacy-rx via:

	 *

	 *    ethtool --set-priv-flags <dev> legacy-rx on

	 *

	 * In this mode, we currently get 0 extra XDP headroom as

	 * opposed to having legacy-rx off, where we process XDP

	 * packets going to stack via i40e_build_skb(). The latter

	 * provides us currently with 192 bytes of headroom.

	 *

	 * For i40e_construct_skb() mode it means that the

	 * xdp->data_meta will always point to xdp->data, since

	 * the helper cannot expand the head. Should this ever

	 * change in future for legacy-rx mode on, then lets also

	 * add xdp->data_meta handling here.

 allocate a skb to store the frags */

 Determine available headroom for copy */

 align pull length to size of long to optimize memcpy performance */

 update all of the pointers */

 buffer is used by skb, update page_offset */

 buffer is unused, reset bias back to rx_buffer */

/**

 * i40e_build_skb - Build skb around an existing buffer

 * @rx_ring: Rx descriptor ring to transact packets on

 * @rx_buffer: Rx buffer to pull data from

 * @xdp: xdp_buff pointing to the data

 *

 * This function builds an skb around an existing Rx buffer, taking care

 * to set up the skb correctly and avoid any memcpy overhead.

	/* Prefetch first cache line of first page. If xdp->data_meta

	 * is unused, this points exactly as xdp->data, otherwise we

	 * likely have a consumer accessing first few bytes of meta

	 * data, and then actual data.

 build an skb around the page buffer */

 update pointers within the skb to store the data */

 buffer is used by skb, update page_offset */

/**

 * i40e_put_rx_buffer - Clean up used buffer and either recycle or free

 * @rx_ring: rx descriptor ring to transact packets on

 * @rx_buffer: rx buffer to pull data from

 * @rx_buffer_pgcnt: rx buffer page refcount pre xdp_do_redirect() call

 *

 * This function will clean up the contents of the rx_buffer.  It will

 * either recycle the buffer or unmap it and free the associated resources.

 hand second half of page back to the ring */

 we are not reusing the buffer so unmap it */

 clear contents of buffer_info */

/**

 * i40e_is_non_eop - process handling of non-EOP buffers

 * @rx_ring: Rx ring being processed

 * @rx_desc: Rx descriptor for current buffer

 *

 * If the buffer is an EOP buffer, this function exits returning false,

 * otherwise return true indicating that this is in fact a non-EOP buffer.

 if we are the last buffer then there is nothing else to do */

/**

 * i40e_run_xdp - run an XDP program

 * @rx_ring: Rx ring being processed

 * @xdp: XDP buffer containing the frame

 xdp_frame write */

 handle aborts by dropping packet */

/**

 * i40e_rx_buffer_flip - adjusted rx_buffer to point to an unused region

 * @rx_ring: Rx ring

 * @rx_buffer: Rx buffer to adjust

 * @size: Size of adjustment

/**

 * i40e_xdp_ring_update_tail - Updates the XDP Tx ring tail register

 * @xdp_ring: XDP Tx ring

 *

 * This function updates the XDP Tx ring tail register.

	/* Force memory writes to complete before letting h/w

	 * know there are new descriptors to fetch.

/**

 * i40e_update_rx_stats - Update Rx ring statistics

 * @rx_ring: rx descriptor ring

 * @total_rx_bytes: number of bytes received

 * @total_rx_packets: number of packets received

 *

 * This function updates the Rx ring statistics.

/**

 * i40e_finalize_xdp_rx - Bump XDP Tx tail and/or flush redirect map

 * @rx_ring: Rx ring

 * @xdp_res: Result of the receive batch

 *

 * This function bumps XDP Tx tail and/or flush redirect map, and

 * should be called when a batch of packets has been processed in the

 * napi loop.

/**

 * i40e_inc_ntc: Advance the next_to_clean index

 * @rx_ring: Rx ring

/**

 * i40e_clean_rx_irq - Clean completed descriptors from Rx ring - bounce buf

 * @rx_ring: rx descriptor ring to transact packets on

 * @budget: Total limit on number of packets to process

 *

 * This function provides a "bounce buffer" approach to Rx interrupt

 * processing.  The advantage to this is that on systems that have

 * expensive overhead for IOMMU access this provides a means of avoiding

 * it by maintaining the mapping of the page to the system.

 *

 * Returns amount of work completed

 return some buffers to hardware, one at a time is too slow */

		/* status_error_len will always be zero for unused descriptors

		 * because it's cleared in cleanup, and overlaps with hdr_addr

		 * which is always zero because packet split isn't used, if the

		 * hardware wrote DD then the length will be non-zero

		/* This memory barrier is needed to keep us from reading

		 * any other fields out of the rx_desc until we have

		 * verified the descriptor has been written back.

 retrieve a buffer from the ring */

 At larger PAGE_SIZE, frame_sz depend on len size */

 exit if we failed to retrieve a buffer */

 probably a little skewed due to removing CRC */

 populate checksum, VLAN, and protocol */

 update budget accounting */

 guarantee a trip back through this routine if there was a failure */

	/* We don't bother with setting the CLEARPBA bit as the data sheet

	 * points out doing so is "meaningless since it was already

	 * auto-cleared". The auto-clearing happens when the interrupt is

	 * asserted.

	 *

	 * Hardware errata 28 for also indicates that writing to a

	 * xxINT_DYN_CTLx CSR with INTENA_MSK (bit 31) set to 0 will clear

	 * an event in the PBA anyway so we need to rely on the automask

	 * to hold pending events for us until the interrupt is re-enabled

	 *

	 * The itr value is reported in microseconds, and the register

	 * value is recorded in 2 microsecond units. For this reason we

	 * only need to shift by the interval shift - 1 instead of the

	 * full value.

 a small macro to shorten up some long lines */

/* The act of updating the ITR will cause it to immediately trigger. In order

 * to prevent this from throwing off adaptive update statistics we defer the

 * update so that it can only happen so often. So after either Tx or Rx are

 * updated we make the adaptive scheme wait until either the ITR completely

 * expires via the next_update expiration or we have been through at least

 * 3 interrupts.

/**

 * i40e_update_enable_itr - Update itr and re-enable MSIX interrupt

 * @vsi: the VSI we care about

 * @q_vector: q_vector for which itr is being updated and interrupt enabled

 *

 If we don't have MSIX, then we only need to re-enable icr0 */

 These will do nothing if dynamic updates are not enabled */

	/* This block of logic allows us to get away with only updating

	 * one ITR value with each interrupt. The idea is to perform a

	 * pseudo-lazy update with the following criteria.

	 *

	 * 1. Rx is given higher priority than Tx if both are in same state

	 * 2. If we must reduce an ITR that is given highest priority.

	 * 3. We then give priority to increasing ITR based on amount.

 Rx ITR needs to be reduced, this is highest priority */

		/* Tx ITR needs to be reduced, this is second priority

		 * Tx ITR needs to be increased more than Rx, fourth priority

 Rx ITR needs to be increased, third priority */

 No ITR update, lowest priority */

/**

 * i40e_napi_poll - NAPI polling Rx/Tx cleanup routine

 * @napi: napi struct with our devices info in it

 * @budget: amount of work driver is allowed to do this pass, in packets

 *

 * This function will clean all queues associated with a q_vector.

 *

 * Returns the amount of work done

	/* Since the actual Tx work is minimal, we can give the Tx a larger

	 * budget and be more aggressive about cleaning up the Tx descriptors.

 Handle case where we are called by netpoll with a budget of 0 */

 normally we have 1 Rx ring per q_vector */

		/* We attempt to distribute budget to each Rx queue fairly, but

		 * don't allow the budget to go below 1 because that would exit

		 * polling early.

 Max of 1 Rx ring in this q_vector so give it the budget */

 if we clean as many as budgeted, we must not be done */

 If work not completed, return budget and polling will return */

		/* It is possible that the interrupt affinity has changed but,

		 * if the cpu is pegged at 100%, polling will never exit while

		 * traffic continues and the interrupt will be stuck on this

		 * cpu.  We check to make sure affinity is correct before we

		 * continue to poll, otherwise we must stop polling so the

		 * interrupt can move to the correct cpu.

 Tell napi that we are done polling */

 Force an interrupt */

 Return budget-1 so that polling stops */

	/* Exit the polling mode, but don't re-enable interrupts if stack might

	 * poll us due to busy-polling

/**

 * i40e_atr - Add a Flow Director ATR filter

 * @tx_ring:  ring to add programming descriptor to

 * @skb:      send buffer

 * @tx_flags: send tx flags

 make sure ATR is enabled */

 if sampling is disabled do nothing */

 Currently only IPv4/IPv6 with TCP is supported */

 snag network header to get L4 type and address */

	/* Note: tx_flags gets modified to reflect inner protocols in

	 * tx_enable_csum function if encap is enabled.

 access ihl as u8 to avoid unaligned access on ia64 */

 find the start of the innermost ipv6 header */

 this function updates h_offset to the end of the header */

 hlen will contain our best estimate of the tcp header */

 Due to lack of space, no more new filters can be programmed */

		/* HW ATR eviction will take care of removing filters on FIN

		 * and RST packets.

 sample on all syn/fin/rst packets or once every atr sample rate */

 grab the next descriptor */

/**

 * i40e_tx_prepare_vlan_flags - prepare generic TX VLAN tagging flags for HW

 * @skb:     send buffer

 * @tx_ring: ring to send buffer on

 * @flags:   the tx flags to be set

 *

 * Checks the skb and set up correspondingly several generic transmit flags

 * related to VLAN tagging for the HW, such as VLAN, DCB, etc.

 *

 * Returns error code indicate the frame should be dropped upon error and the

 * otherwise  returns 0 to indicate the flags has been set properly.

		/* When HW VLAN acceleration is turned off by the user the

		 * stack sets the protocol to 8021q so that the driver

		 * can take any steps required to support the SW only

		 * VLAN handling.  In our case the driver doesn't need

		 * to take any further steps so just set the protocol

		 * to the encapsulated ethertype.

 if we have a HW VLAN tag being added, default to the HW one */

 else if it is a SW VLAN, check the next protocol and store the tag */

 Insert 802.1p priority into VLAN header */

/**

 * i40e_tso - set up the tso context descriptor

 * @first:    pointer to first Tx buffer for xmit

 * @hdr_len:  ptr to the size of the packet header

 * @cd_type_cmd_tso_mss: Quad Word 1

 *

 * Returns 0 if no TSO can happen, 1 if tso is going, or error

 initialize outer IP header fields */

 determine offset of outer transport header */

 remove payload length from outer checksum */

 reset pointers to inner headers */

 initialize inner IP header fields */

 determine offset of inner transport header */

 remove payload length from inner checksum */

 compute length of segmentation header */

 compute length of segmentation header */

 pull values out of skb_shinfo */

 update GSO size and bytecount with header size */

 find the field values */

/**

 * i40e_tsyn - set up the tsyn context descriptor

 * @tx_ring:  ptr to the ring to send

 * @skb:      ptr to the skb we're sending

 * @tx_flags: the collected send information

 * @cd_type_cmd_tso_mss: Quad Word 1

 *

 * Returns 0 if no Tx timestamp can happen and 1 if the timestamp will happen

 Tx timestamps cannot be sampled when doing TSO */

	/* only timestamp the outbound packet if the user has requested it and

	 * we are not already transmitting a packet to be timestamped

/**

 * i40e_tx_enable_csum - Enable Tx checksum offloads

 * @skb: send buffer

 * @tx_flags: pointer to Tx flags currently set

 * @td_cmd: Tx descriptor command bits to set

 * @td_offset: Tx descriptor header offsets to set

 * @tx_ring: Tx descriptor ring

 * @cd_tunneling: ptr to context desc bits

 compute outer L2 header size */

 define outer network header type */

 define outer transport */

 compute outer L3 header size */

 switch IP header pointer from outer to inner header */

 compute tunnel header size */

 indicate if we need to offload outer UDP header */

 record tunnel offload values */

 switch L4 header pointer from outer to inner */

 reset type as we transition from outer to inner headers */

 Enable IP checksum offloads */

		/* the stack computes the IP header already, the only time we

		 * need the hardware to recompute it is in the case of TSO.

 compute inner L3 header size */

 Enable L4 checksum offloads */

 enable checksum offloads */

 enable SCTP checksum offload */

 enable UDP checksum offload */

/**

 * i40e_create_tx_ctx - Build the Tx context descriptor

 * @tx_ring:  ring to create the descriptor on

 * @cd_type_cmd_tso_mss: Quad Word 1

 * @cd_tunneling: Quad Word 0 - bits 0-31

 * @cd_l2tag2: Quad Word 0 - bits 32-63

 grab the next descriptor */

 cpu_to_le32 and assign to struct fields */

/**

 * __i40e_maybe_stop_tx - 2nd level check for tx stop conditions

 * @tx_ring: the ring to be checked

 * @size:    the size buffer we want to assure is available

 *

 * Returns -EBUSY if a stop is needed, else 0

 Memory barrier before checking head and tail */

 Check again in a case another CPU has just made room available. */

 A reprieve! - use start_queue because it doesn't call schedule */

/**

 * __i40e_chk_linearize - Check if there are more than 8 buffers per packet

 * @skb:      send buffer

 *

 * Note: Our HW can't DMA more than 8 buffers to build a packet on the wire

 * and so we need to figure out the cases where we need to linearize the skb.

 *

 * For TSO we need to count the TSO header and segment payload separately.

 * As such we need to check cases where we have 7 fragments or more as we

 * can potentially require 9 DMA transactions, 1 for the TSO header, 1 for

 * the segment payload in the first descriptor, and another 7 for the

 * fragments.

 no need to check if number of frags is less than 7 */

	/* We need to walk through the list and validate that each group

	 * of 6 fragments totals at least gso_size.

	/* Initialize size to the negative value of gso_size minus 1.  We

	 * use this as the worst case scenerio in which the frag ahead

	 * of us only provides one byte which is why we are limited to 6

	 * descriptors for a single transmit as the header and previous

	 * fragment are already consuming 2 descriptors.

 Add size of frags 0 through 4 to create our initial sum */

	/* Walk through fragments adding latest fragment, testing it, and

	 * then removing stale fragments from the sum.

		/* The stale fragment may present us with a smaller

		 * descriptor than the actual fragment size. To account

		 * for that we need to remove all the data on the front and

		 * figure out what the remainder would be in the last

		 * descriptor associated with the fragment.

 if sum is negative we failed to make sufficient progress */

/**

 * i40e_tx_map - Build the Tx descriptor

 * @tx_ring:  ring to send buffer on

 * @skb:      send buffer

 * @first:    first buffer info buffer to use

 * @tx_flags: collected send information

 * @hdr_len:  size of the packet header

 * @td_cmd:   the command field in the descriptor

 * @td_offset: offset for checksum or crc

 *

 * Returns 0 on success, -1 on failure to DMA

 record length, and DMA address */

 align size to end of page */

 write last descriptor with EOP bit */

	/* We OR these values together to check both against 4 (WB_STRIDE)

	 * below. This is safe since we don't re-use desc_count afterwards.

 write last descriptor with RS bit set */

	/* Force memory writes to complete before letting h/w know there

	 * are new descriptors to fetch.

	 *

	 * We also use this memory barrier to make certain all of the

	 * status bits have been updated before next_to_watch is written.

 set next_to_watch value indicating a packet is present */

 notify HW of packet */

 clear dma mappings for failed tx_bi map */

 is DCB enabled at all? */

 sanity check */

 select a queue assigned for the given TC */

/**

 * i40e_xmit_xdp_ring - transmits an XDP buffer to an XDP Tx ring

 * @xdpf: data to transmit

 * @xdp_ring: XDP Tx ring

 record length, and DMA address */

	/* Make certain all of the status bits have been updated

	 * before next_to_watch is written.

/**

 * i40e_xmit_frame_ring - Sends buffer on Tx ring

 * @skb:     send buffer

 * @tx_ring: ring to send buffer on

 *

 * Returns NETDEV_TX_OK if sent, else an error code

 prefetch the data, we'll need it later */

	/* need: 1 descriptor per page * PAGE_SIZE/I40E_MAX_DATA_PER_TXD,

	 *       + 1 desc for skb_head_len/I40E_MAX_DATA_PER_TXD,

	 *       + 4 desc gap to avoid the cache line where head is,

	 *       + 1 desc for context descriptor,

	 * otherwise try next time

 record the location of the first descriptor for this packet */

 prepare the xmit flags */

 obtain protocol of skb */

 setup IPv4/IPv6 offloads */

 Always offload the checksum, since it's in the data descriptor */

 always enable CRC insertion offload */

	/* Add Flow Director ATR if it's enabled.

	 *

	 * NOTE: this must always be directly before the data descriptor.

/**

 * i40e_lan_xmit_frame - Selects the correct VSI and Tx queue to send buffer

 * @skb:    send buffer

 * @netdev: network interface device structure

 *

 * Returns NETDEV_TX_OK if sent, else an error code

	/* hardware can't handle really short frames, hardware padding works

	 * beyond this point

/**

 * i40e_xdp_xmit - Implements ndo_xdp_xmit

 * @dev: netdev

 * @n: number of frames

 * @frames: array of XDP buffer pointers

 * @flags: XDP extra info

 *

 * Returns number of frames successfully sent. Failed frames

 * will be free'ed by XDP core.

 *

 * For error cases, a negative errno code is returned and no-frames

 * are transmitted (caller must handle freeing frames).

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2013 - 2021 Intel Corporation. */

 Local includes */

/* All i40e tracepoints are defined by the include below, which

 * must be included exactly once across the whole kernel with

 * CREATE_TRACE_POINTS defined

 a bit of forward declarations */

/* i40e_pci_tbl - PCI Device ID Table

 *

 * Last entry must be all 0s

 *

 * { Vendor ID, Device ID, SubVendor ID, SubDevice ID,

 *   Class, Class Mask, private data (not used) }

 required last entry */

/**

 * i40e_allocate_dma_mem_d - OS specific memory alloc for shared code

 * @hw:   pointer to the HW structure

 * @mem:  ptr to mem struct to fill out

 * @size: size of memory requested

 * @alignment: what to align the allocation to

/**

 * i40e_free_dma_mem_d - OS specific memory free for shared code

 * @hw:   pointer to the HW structure

 * @mem:  ptr to mem struct to free

/**

 * i40e_allocate_virt_mem_d - OS specific memory alloc for shared code

 * @hw:   pointer to the HW structure

 * @mem:  ptr to mem struct to fill out

 * @size: size of memory requested

/**

 * i40e_free_virt_mem_d - OS specific memory free for shared code

 * @hw:   pointer to the HW structure

 * @mem:  ptr to mem struct to free

 it's ok to kfree a NULL pointer */

/**

 * i40e_get_lump - find a lump of free generic resource

 * @pf: board private structure

 * @pile: the pile of resource to search

 * @needed: the number of items needed

 * @id: an owner id to stick on the items assigned

 *

 * Returns the base item index of the lump, or negative for error

 *

 * The search_hint trick and lack of advanced fit-finding only work

 * because we're highly likely to have all the same size lump requests.

 * Linear search time and any fragmentation should be minimal.

 start the linear search with an imperfect hint */

 skip already allocated entries */

 do we have enough in this lump? */

 there was enough, so assign it to the requestor */

 not enough, so skip over it and continue looking */

/**

 * i40e_put_lump - return a lump of generic resource

 * @pile: the pile of resource to search

 * @index: the base item index

 * @id: the owner id of the items assigned

 *

 * Returns the count of items in the lump

/**

 * i40e_find_vsi_from_id - searches for the vsi with the given id

 * @pf: the pf structure to search for the vsi

 * @id: id of the vsi it is searching for

/**

 * i40e_service_event_schedule - Schedule the service task to wake up

 * @pf: board private structure

 *

 * If not already scheduled, this puts the task into the work queue

/**

 * i40e_tx_timeout - Respond to a Tx Hang

 * @netdev: network interface device structure

 * @txqueue: queue number timing out

 *

 * If any port has noticed a Tx timeout, it is likely that the whole

 * device is munged, not just the one netdev port, so go for the full

 * reset.

 with txqueue index, find the tx_ring struct */

 reset after some time */

 don't do any new action before the next timeout */

 don't kick off another recovery if one is already pending */

 Read interrupt register */

/**

 * i40e_get_vsi_stats_struct - Get System Network Statistics

 * @vsi: the VSI we care about

 *

 * Returns the address of the device statistics structure.

 * The statistics are actually updated from the service task.

/**

 * i40e_get_netdev_stats_struct_tx - populate stats from a Tx ring

 * @ring: Tx ring to get statistics from

 * @stats: statistics entry to be updated

/**

 * i40e_get_netdev_stats_struct - Get statistics for netdev interface

 * @netdev: network interface device structure

 * @stats: data structure to store statistics

 *

 * Returns the address of the device statistics structure.

 * The statistics are actually updated from the service task.

 following stats updated by i40e_watchdog_subtask() */

/**

 * i40e_vsi_reset_stats - Resets all stats of the given vsi

 * @vsi: the VSI to have its stats reset

/**

 * i40e_pf_reset_stats - Reset all of the stats for the given PF

 * @pf: the PF to be reset

/**

 * i40e_stat_update48 - read and update a 48 bit stat from the chip

 * @hw: ptr to the hardware info

 * @hireg: the high 32 bit reg to read

 * @loreg: the low 32 bit reg to read

 * @offset_loaded: has the initial offset been loaded yet

 * @offset: ptr to current offset value

 * @stat: ptr to the stat

 *

 * Since the device stats are not reset at PFReset, they likely will not

 * be zeroed when the driver starts.  We'll save the first values read

 * and use them as offsets to be subtracted from the raw values in order

 * to report stats that count from zero.  In the process, we also manage

 * the potential roll-over.

/**

 * i40e_stat_update32 - read and update a 32 bit stat from the chip

 * @hw: ptr to the hardware info

 * @reg: the hw reg to read

 * @offset_loaded: has the initial offset been loaded yet

 * @offset: ptr to current offset value

 * @stat: ptr to the stat

/**

 * i40e_stat_update_and_clear32 - read and clear hw reg, update a 32 bit stat

 * @hw: ptr to the hardware info

 * @reg: the hw reg to read and clear

 * @stat: ptr to the stat

 must write a nonzero value to clear register */

/**

 * i40e_update_eth_stats - Update VSI-specific ethernet statistics counters.

 * @vsi: the VSI to be updated

 device's eth stats */

 Gather up the stats that the hw collects */

/**

 * i40e_update_veb_stats - Update Switch component statistics

 * @veb: the VEB being updated

 device's eth stats */

 Gather up the stats that the hw collects */

/**

 * i40e_update_vsi_stats - Update the vsi statistics counters.

 * @vsi: the VSI to be updated

 *

 * There are a few instances where we store the same stat in a

 * couple of different structs.  This is partly because we have

 * the netdev stats that need to be filled out, which is slightly

 * different from the "eth_stats" defined by the chip and used in

 * VF communications.  We sort it out here.

 netdev stats */

 device's eth stats */

	/* Gather up the netdev and vsi stats that the driver collects

	 * on the fly during packet processing

 locate Tx ring */

 locate Rx ring */

 locate XDP ring */

 update netdev stats from eth stats */

 pull in a couple PF stats if this is the main vsi */

/**

 * i40e_update_pf_stats - Update the PF statistics counters.

 * @pf: the PF to be updated

 FDIR stats */

/**

 * i40e_update_stats - Update the various statistics counters.

 * @vsi: the VSI to be updated

 *

 * Update the various stats for this VSI and its related entities.

/**

 * i40e_count_filters - counts VSI mac filters

 * @vsi: the VSI to be searched

 *

 * Returns count of mac filters

/**

 * i40e_find_filter - Search VSI filter list for specific mac/vlan filter

 * @vsi: the VSI to be searched

 * @macaddr: the MAC address

 * @vlan: the vlan

 *

 * Returns ptr to the filter object or NULL

/**

 * i40e_find_mac - Find a mac addr in the macvlan filters list

 * @vsi: the VSI to be searched

 * @macaddr: the MAC address we are searching for

 *

 * Returns the first filter with the provided MAC address or NULL if

 * MAC address was not found

/**

 * i40e_is_vsi_in_vlan - Check if VSI is in vlan mode

 * @vsi: the VSI to be searched

 *

 * Returns true if VSI is in vlan mode or false otherwise

 If we have a PVID, always operate in VLAN mode */

	/* We need to operate in VLAN mode whenever we have any filters with

	 * a VLAN other than I40E_VLAN_ALL. We could check the table each

	 * time, incurring search cost repeatedly. However, we can notice two

	 * things:

	 *

	 * 1) the only place where we can gain a VLAN filter is in

	 *    i40e_add_filter.

	 *

	 * 2) the only place where filters are actually removed is in

	 *    i40e_sync_filters_subtask.

	 *

	 * Thus, we can simply use a boolean value, has_vlan_filters which we

	 * will set to true when we add a VLAN filter in i40e_add_filter. Then

	 * we have to perform the full search after deleting filters in

	 * i40e_sync_filters_subtask, but we already have to search

	 * filters here and can perform the check at the same time. This

	 * results in avoiding embedding a loop for VLAN mode inside another

	 * loop over all the filters, and should maintain correctness as noted

	 * above.

/**

 * i40e_correct_mac_vlan_filters - Correct non-VLAN filters if necessary

 * @vsi: the VSI to configure

 * @tmp_add_list: list of filters ready to be added

 * @tmp_del_list: list of filters ready to be deleted

 * @vlan_filters: the number of active VLAN filters

 *

 * Update VLAN=0 and VLAN=-1 (I40E_VLAN_ANY) filters properly so that they

 * behave as expected. If we have any active VLAN filters remaining or about

 * to be added then we need to update non-VLAN filters to be marked as VLAN=0

 * so that they only match against untagged traffic. If we no longer have any

 * active VLAN filters, we need to make all non-VLAN filters marked as VLAN=-1

 * so that they match against both tagged and untagged traffic. In this way,

 * we ensure that we correctly receive the desired traffic. This ensures that

 * when we have an active VLAN we will receive only untagged traffic and

 * traffic matching active VLANs. If we have no active VLANs then we will

 * operate in non-VLAN mode and receive all traffic, tagged or untagged.

 *

 * Finally, in a similar fashion, this function also corrects filters when

 * there is an active PVID assigned to this VSI.

 *

 * In case of memory allocation failure return -ENOMEM. Otherwise, return 0.

 *

 * This function is only expected to be called from within

 * i40e_sync_vsi_filters.

 *

 * NOTE: This function expects to be called while under the

 * mac_filter_hash_lock

	/* To determine if a particular filter needs to be replaced we

	 * have the three following conditions:

	 *

	 * a) if we have a PVID assigned, then all filters which are

	 *    not marked as VLAN=PVID must be replaced with filters that

	 *    are.

	 * b) otherwise, if we have any active VLANS, all filters

	 *    which are marked as VLAN=-1 must be replaced with

	 *    filters marked as VLAN=0

	 * c) finally, if we do not have any active VLANS, all filters

	 *    which are marked as VLAN=0 must be replaced with filters

	 *    marked as VLAN=-1

 Update the filters about to be added in place */

 Update the remaining active filters */

		/* Combine the checks for whether a filter needs to be changed

		 * and then determine the new VLAN inside the if block, in

		 * order to avoid duplicating code for adding the new filter

		 * then deleting the old filter.

 Determine the new vlan we will be adding */

 Create the new filter */

 Create a temporary i40e_new_mac_filter */

 Add the new filter to the tmp list */

 Put the original filter into the delete list */

/**

 * i40e_rm_default_mac_filter - Remove the default MAC filter set by NVM

 * @vsi: the PF Main VSI - inappropriate for any other VSI

 * @macaddr: the MAC address

 *

 * Remove whatever filter the firmware set up so the driver can manage

 * its own filtering intelligently.

 Only appropriate for the PF main VSI */

 Ignore error returns, some firmware does it this way... */

 ...and some firmware does it this way. */

/**

 * i40e_add_filter - Add a mac/vlan filter to the VSI

 * @vsi: the VSI to be searched

 * @macaddr: the MAC address

 * @vlan: the vlan

 *

 * Returns ptr to the filter object or NULL when no memory available.

 *

 * NOTE: This function is expected to be called with mac_filter_hash_lock

 * being held.

		/* Update the boolean indicating if we need to function in

		 * VLAN mode.

	/* If we're asked to add a filter that has been marked for removal, it

	 * is safe to simply restore it to active state. __i40e_del_filter

	 * will have simply deleted any filters which were previously marked

	 * NEW or FAILED, so if it is currently marked REMOVE it must have

	 * previously been ACTIVE. Since we haven't yet run the sync filters

	 * task, just restore this filter to the ACTIVE state so that the

	 * sync task leaves it in place

/**

 * __i40e_del_filter - Remove a specific filter from the VSI

 * @vsi: VSI to remove from

 * @f: the filter to remove from the list

 *

 * This function should be called instead of i40e_del_filter only if you know

 * the exact filter you will remove already, such as via i40e_find_filter or

 * i40e_find_mac.

 *

 * NOTE: This function is expected to be called with mac_filter_hash_lock

 * being held.

 * ANOTHER NOTE: This function MUST be called from within the context of

 * the "safe" variants of any list iterators, e.g. list_for_each_entry_safe()

 * instead of list_for_each_entry().

	/* If the filter was never added to firmware then we can just delete it

	 * directly and we don't want to set the status to remove or else an

	 * admin queue command will unnecessarily fire.

/**

 * i40e_del_filter - Remove a MAC/VLAN filter from the VSI

 * @vsi: the VSI to be searched

 * @macaddr: the MAC address

 * @vlan: the VLAN

 *

 * NOTE: This function is expected to be called with mac_filter_hash_lock

 * being held.

 * ANOTHER NOTE: This function MUST be called from within the context of

 * the "safe" variants of any list iterators, e.g. list_for_each_entry_safe()

 * instead of list_for_each_entry().

/**

 * i40e_add_mac_filter - Add a MAC filter for all active VLANs

 * @vsi: the VSI to be searched

 * @macaddr: the mac address to be filtered

 *

 * If we're not in VLAN mode, just add the filter to I40E_VLAN_ANY. Otherwise,

 * go through all the macvlan filters and add a macvlan filter for each

 * unique vlan that already exists. If a PVID has been assigned, instead only

 * add the macaddr to that VLAN.

 *

 * Returns last filter added on success, else NULL

/**

 * i40e_del_mac_filter - Remove a MAC filter from all VLANs

 * @vsi: the VSI to be searched

 * @macaddr: the mac address to be removed

 *

 * Removes a given MAC address from a VSI regardless of what VLAN it has been

 * associated with.

 *

 * Returns 0 for success, or error

/**

 * i40e_set_mac - NDO callback to set mac address

 * @netdev: network interface device structure

 * @p: pointer to an address structure

 *

 * Returns 0 on success, negative on failure

	/* Copy the address first, so that we avoid a possible race with

	 * .set_rx_mode().

	 * - Remove old address from MAC filter

	 * - Copy new address

	 * - Add new address to MAC filter

	/* schedule our worker thread which will take care of

	 * applying the new filter changes

/**

 * i40e_config_rss_aq - Prepare for RSS using AQ commands

 * @vsi: vsi structure

 * @seed: RSS hash seed

 * @lut: pointer to lookup table of lut_size

 * @lut_size: size of the lookup table

/**

 * i40e_vsi_config_rss - Prepare for VSI(VMDq) RSS if used

 * @vsi: VSI structure

	/* Use the user configured hash keys and lookup table if there is one,

	 * otherwise use default

/**

 * i40e_vsi_setup_queue_map_mqprio - Prepares mqprio based tc_config

 * @vsi: the VSI being configured,

 * @ctxt: VSI context structure

 * @enabled_tc: number of traffic classes to enable

 *

 * Prepares VSI tc_config to have queue configurations based on MQPRIO options.

 find the next higher power-of-2 of num queue pairs */

 Setup queue offset/count for all TCs for given VSI */

 See if the given TC is enabled for the given VSI */

			/* TC is not enabled so set the offset to

			 * default queue and allocate one queue

			 * for the given TC.

 Set actual Tx/Rx queue pairs */

 Setup queue TC[0].qmap for given VSI context */

 Reconfigure RSS for main VSI with max queue count */

	/* Find queue count available for channel VSIs and starting offset

	 * for channel VSIs

/**

 * i40e_vsi_setup_queue_map - Setup a VSI queue map based on enabled_tc

 * @vsi: the VSI being setup

 * @ctxt: VSI context structure

 * @enabled_tc: Enabled TCs bitmap

 * @is_add: True if called before Add VSI

 *

 * Setup VSI queue mapping for enabled traffic classes.

 zero out queue mapping, it will get updated on the end of the function */

		/* This code helps add more queue to the VSI if we have

		 * more cores than RSS can support, the higher cores will

		 * be served by ATR or other filters. Furthermore, the

		 * non-zero req_queue_pairs says that user requested a new

		 * queue count via ethtool's set_channels, so use this

		 * value for queues distribution across traffic classes

 Number of queues per enabled TC */

 Find numtc from enabled TC bitmap */

 TC is enabled */

 Do not allow use more TC queue pairs than MSI-X vectors exist */

 Setup queue offset/count for all TCs for given VSI */

 See if the given TC is enabled for the given VSI */

 TC is enabled */

 find the next higher power-of-2 of num queue pairs */

			/* TC is not enabled so set the offset to

			 * default queue and allocate one queue

			 * for the given TC.

 Do not change previously set num_queue_pairs for PFs and VFs*/

 Scheduler section valid can only be set for ADD VSI */

/**

 * i40e_addr_sync - Callback for dev_(mc|uc)_sync to add address

 * @netdev: the netdevice

 * @addr: address to add

 *

 * Called by __dev_(mc|uc)_sync when an address needs to be added. We call

 * __dev_(uc|mc)_sync from .set_rx_mode and guarantee to hold the hash lock.

/**

 * i40e_addr_unsync - Callback for dev_(mc|uc)_sync to remove address

 * @netdev: the netdevice

 * @addr: address to add

 *

 * Called by __dev_(mc|uc)_sync when an address needs to be removed. We call

 * __dev_(uc|mc)_sync from .set_rx_mode and guarantee to hold the hash lock.

	/* Under some circumstances, we might receive a request to delete

	 * our own device address from our uc list. Because we store the

	 * device address in the VSI's MAC/VLAN filter list, we need to ignore

	 * such requests and not delete our device address from this list.

/**

 * i40e_set_rx_mode - NDO callback to set the netdev filters

 * @netdev: network interface device structure

 check for other flag changes */

/**

 * i40e_undo_del_filter_entries - Undo the changes made to MAC filter entries

 * @vsi: Pointer to VSI struct

 * @from: Pointer to list which contains MAC filter entries - changes to

 *        those entries needs to be undone.

 *

 * MAC filter entries from this list were slated for deletion.

 Move the element back into MAC filter list*/

/**

 * i40e_undo_add_filter_entries - Undo the changes made to MAC filter entries

 * @vsi: Pointer to vsi struct

 * @from: Pointer to list which contains MAC filter entries - changes to

 *        those entries needs to be undone.

 *

 * MAC filter entries from this list were slated for addition.

 We can simply free the wrapper structure */

/**

 * i40e_next_filter - Get the next non-broadcast filter from a list

 * @next: pointer to filter in list

 *

 * Returns the next non-broadcast filter in the list. Required so that we

 * ignore broadcast filters within the list, since these are not handled via

 * the normal firmware update path.

/**

 * i40e_update_filter_state - Update filter state based on return data

 * from firmware

 * @count: Number of filters added

 * @add_list: return data from fw

 * @add_head: pointer to first filter in current batch

 *

 * MAC filter entries from list were slated to be added to device. Returns

 * number of successful filters. Note that 0 does NOT mean success!

		/* Always check status of each filter. We don't need to check

		 * the firmware return status because we pre-set the filter

		 * status to I40E_AQC_MM_ERR_NO_RES when sending the filter

		 * request to the adminq. Thus, if it no longer matches then

		 * we know the filter is active.

/**

 * i40e_aqc_del_filters - Request firmware to delete a set of filters

 * @vsi: ptr to the VSI

 * @vsi_name: name to display in messages

 * @list: the list of filters to send to firmware

 * @num_del: the number of filters to delete

 * @retval: Set to -EIO on failure to delete

 *

 * Send a request to firmware via AdminQ to delete a set of filters. Uses

 * *retval instead of a return value so that success does not force ret_val to

 * be set to 0. This ensures that a sequence of calls to this function

 * preserve the previous value of *retval on successful delete.

 Explicitly ignore and do not report when firmware returns ENOENT */

/**

 * i40e_aqc_add_filters - Request firmware to add a set of filters

 * @vsi: ptr to the VSI

 * @vsi_name: name to display in messages

 * @list: the list of filters to send to firmware

 * @add_head: Position in the add hlist

 * @num_add: the number of filters to add

 *

 * Send a request to firmware via AdminQ to add a chunk of filters. Will set

 * __I40E_VSI_OVERFLOW_PROMISC bit in vsi->state if the firmware has run out of

 * space for more filters.

/**

 * i40e_aqc_broadcast_filter - Set promiscuous broadcast flags

 * @vsi: pointer to the VSI

 * @vsi_name: the VSI name

 * @f: filter data

 *

 * This function sets or clears the promiscuous broadcast flags for VLAN

 * filters in order to properly receive broadcast frames. Assumes that only

 * broadcast filters are passed.

 *

 * Returns status indicating success or failure;

/**

 * i40e_set_promiscuous - set promiscuous mode

 * @pf: board private structure

 * @promisc: promisc on or off

 *

 * There are different ways of setting promiscuous mode on a PF depending on

 * what state/environment we're in.  This identifies and sets it appropriately.

 * Returns 0 on success.

		/* set defport ON for Main VSI instead of true promisc

		 * this way we will get all unicast/multicast and VLAN

		 * promisc behavior but will not get VF or VMDq traffic

		 * replicated on the Main VSI.

/**

 * i40e_sync_vsi_filters - Update the VSI filter list to the HW

 * @vsi: ptr to the VSI

 *

 * Push any outstanding VSI filter changes through the AdminQ.

 *

 * Returns 0 or error value

 empty array typed pointers, kcalloc later */

 Create a list of filters to delete. */

 Move the element into temporary del_list */

 Avoid counting removed filters */

 Create a temporary i40e_new_mac_filter */

 Store pointer to the real filter */

 Add it to the hash list */

			/* Count the number of active (current and new) VLAN

			 * filters we have now. Does not count filters which

			 * are marked for deletion.

 Now process 'del_list' outside the lock */

			/* handle broadcast filters by updating the broadcast

			 * promiscuous flag and release filter list.

 add to delete list */

 flush a full buffer */

			/* Release memory for MAC filter entries which were

			 * synced up with HW.

 Do all the adds now. */

			/* handle broadcast filters by updating the broadcast

			 * promiscuous flag instead of adding a MAC filter.

 add to add array */

 set invalid match method for later detection */

 flush a full buffer */

		/* Now move all of the filters from the temp add list back to

		 * the VSI's list.

 Only update the state if we're still NEW */

 Determine the number of active and failed filters. */

	/* Check if we are able to exit overflow promiscuous mode. We can

	 * safely exit if we didn't just enter, we no longer have any failed

	 * filters, and we have reduced filters below the threshold value.

 if the VF is not trusted do not do promisc */

	/* If we are entering overflow promiscuous, we need to calculate a new

	 * threshold for when we are safe to exit

 check for changes in promiscuous modes */

 if something went wrong then set the changed flag so we try again */

 Restore elements on the temporary add and delete lists */

/**

 * i40e_sync_filters_subtask - Sync the VSI filter list with HW

 * @pf: board private structure

 come back and try again later */

/**

 * i40e_max_xdp_frame_size - returns the maximum allowed frame size for XDP

 * @vsi: the vsi

/**

 * i40e_change_mtu - NDO callback to change the Maximum Transfer Unit

 * @netdev: network interface device structure

 * @new_mtu: new value for maximum frame size

 *

 * Returns 0 on success, negative on failure

/**

 * i40e_ioctl - Access the hwtstamp interface

 * @netdev: network interface device structure

 * @ifr: interface request data

 * @cmd: ioctl command

/**

 * i40e_vlan_stripping_enable - Turn on vlan stripping for the VSI

 * @vsi: the vsi being adjusted

 Don't modify stripping options if a port VLAN is active */

 already enabled */

/**

 * i40e_vlan_stripping_disable - Turn off vlan stripping for the VSI

 * @vsi: the vsi being adjusted

 Don't modify stripping options if a port VLAN is active */

 already disabled */

/**

 * i40e_add_vlan_all_mac - Add a MAC/VLAN filter for each existing MAC address

 * @vsi: the vsi being configured

 * @vid: vlan id to be added (0 = untagged only , -1 = any)

 *

 * This is a helper function for adding a new MAC/VLAN filter with the

 * specified VLAN for each existing MAC address already in the hash table.

 * This function does *not* perform any accounting to update filters based on

 * VLAN mode.

 *

 * NOTE: this function expects to be called while under the

 * mac_filter_hash_lock

/**

 * i40e_vsi_add_vlan - Add VSI membership for given VLAN

 * @vsi: the VSI being configured

 * @vid: VLAN id to be added

	/* The network stack will attempt to add VID=0, with the intention to

	 * receive priority tagged packets with a VLAN of 0. Our HW receives

	 * these packets by default when configured to receive untagged

	 * packets, so we don't need to add a filter for this case.

	 * Additionally, HW interprets adding a VID=0 filter as meaning to

	 * receive *only* tagged traffic and stops receiving untagged traffic.

	 * Thus, we do not want to actually add a filter for VID=0

 Locked once because all functions invoked below iterates list*/

	/* schedule our worker thread which will take care of

	 * applying the new filter changes

/**

 * i40e_rm_vlan_all_mac - Remove MAC/VLAN pair for all MAC with the given VLAN

 * @vsi: the vsi being configured

 * @vid: vlan id to be removed (0 = untagged only , -1 = any)

 *

 * This function should be used to remove all VLAN filters which match the

 * given VID. It does not schedule the service event and does not take the

 * mac_filter_hash_lock so it may be combined with other operations under

 * a single invocation of the mac_filter_hash_lock.

 *

 * NOTE: this function expects to be called while under the

 * mac_filter_hash_lock

/**

 * i40e_vsi_kill_vlan - Remove VSI membership for given VLAN

 * @vsi: the VSI being configured

 * @vid: VLAN id to be removed

	/* schedule our worker thread which will take care of

	 * applying the new filter changes

/**

 * i40e_vlan_rx_add_vid - Add a vlan id filter to HW offload

 * @netdev: network interface to be adjusted

 * @proto: unused protocol value

 * @vid: vlan id to be added

 *

 * net_device_ops implementation for adding vlan ids

/**

 * i40e_vlan_rx_add_vid_up - Add a vlan id filter to HW offload in UP path

 * @netdev: network interface to be adjusted

 * @proto: unused protocol value

 * @vid: vlan id to be added

/**

 * i40e_vlan_rx_kill_vid - Remove a vlan id filter from HW offload

 * @netdev: network interface to be adjusted

 * @proto: unused protocol value

 * @vid: vlan id to be removed

 *

 * net_device_ops implementation for removing vlan ids

	/* return code is ignored as there is nothing a user

	 * can do about failure to remove and a log message was

	 * already printed from the other function

/**

 * i40e_restore_vlan - Reinstate vlans when vsi/netdev comes back up

 * @vsi: the vsi being brought back up

/**

 * i40e_vsi_add_pvid - Add pvid for the VSI

 * @vsi: the vsi being adjusted

 * @vid: the vlan id to set as a PVID

/**

 * i40e_vsi_remove_pvid - Remove the pvid from the VSI

 * @vsi: the vsi being adjusted

 *

 * Just use the vlan_rx_register() service to put it back to normal

/**

 * i40e_vsi_setup_tx_resources - Allocate VSI Tx queue resources

 * @vsi: ptr to the VSI

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

/**

 * i40e_vsi_free_tx_resources - Free Tx resources for VSI queues

 * @vsi: ptr to the VSI

 *

 * Free VSI's transmit software resources

/**

 * i40e_vsi_setup_rx_resources - Allocate VSI queues Rx resources

 * @vsi: ptr to the VSI

 *

 * If this function returns with an error, then it's possible one or

 * more of the rings is populated (while the rest are not).  It is the

 * callers duty to clean those orphaned rings.

 *

 * Return 0 on success, negative on failure

/**

 * i40e_vsi_free_rx_resources - Free Rx Resources for VSI queues

 * @vsi: ptr to the VSI

 *

 * Free all receive software resources

/**

 * i40e_config_xps_tx_ring - Configure XPS for a Tx ring

 * @ring: The Tx ring to configure

 *

 * This enables/disables XPS for a given Tx descriptor ring

 * based on the TCs enabled for the VSI that ring belongs to.

 We only initialize XPS once, so as not to overwrite user settings */

/**

 * i40e_xsk_pool - Retrieve the AF_XDP buffer pool if XDP and ZC is enabled

 * @ring: The Tx or Rx ring

 *

 * Returns the AF_XDP buffer pool or NULL.

/**

 * i40e_configure_tx_ring - Configure a transmit ring context and rest

 * @ring: The Tx ring to configure

 *

 * Configure the Tx descriptor ring in the HMC context.

 some ATR related tx ring init */

 configure XPS */

 clear the context structure first */

 FDIR VSI tx ring can still use RS bit and writebacks */

	/* As part of VSI creation/update, FW allocates certain

	 * Tx arbitration queue sets for each TC enabled for

	 * the VSI. The FW returns the handles to these queue

	 * sets as part of the response buffer to Add VSI,

	 * Update VSI, etc. AQ commands. It is expected that

	 * these queue set handles be associated with the Tx

	 * queues by the driver as part of the TX queue context

	 * initialization. This has to be done regardless of

	 * DCB as by default everything is mapped to TC0.

 clear the context in the HMC */

 set the context in the HMC */

 Now associate this queue with this PCI function */

 cache tail off for easier writes later */

/**

 * i40e_rx_offset - Return expected offset into page to access data

 * @rx_ring: Ring we are requesting offset of

 *

 * Returns the offset value for ring into the data buffer.

/**

 * i40e_configure_rx_ring - Configure a receive ring context

 * @ring: The Rx ring to configure

 *

 * Configure the Rx descriptor ring in the HMC context.

 clear the context structure first */

		/* For AF_XDP ZC, we disallow packets to span on

		 * multiple buffers, thus letting us skip that

		 * handling in the fast-path.

 use 16 byte descriptors */

	/* descriptor type is always zero

	 * rx_ctx.dtype = 0;

 this controls whether VLAN is stripped from inner headers */

 set the prefena field to 1 because the manual says to */

 clear the context in the HMC */

 set the context in the HMC */

 configure Rx buffer alignment */

 cache tail for quicker writes, and clear the reg before use */

		/* Log this in case the user has forgotten to give the kernel

		 * any buffers, even later in the application.

/**

 * i40e_vsi_configure_tx - Configure the VSI for Tx

 * @vsi: VSI structure describing this set of rings and resources

 *

 * Configure the Tx VSI for operation.

/**

 * i40e_vsi_configure_rx - Configure the VSI for Rx

 * @vsi: the VSI being configured

 *

 * Configure the Rx VSI for operation.

 set up individual rings */

/**

 * i40e_vsi_config_dcb_rings - Update rings to reflect DCB TC

 * @vsi: ptr to the VSI

 Reset the TC information */

/**

 * i40e_set_vsi_rx_mode - Call set_rx_mode on a VSI

 * @vsi: ptr to the VSI

/**

 * i40e_reset_fdir_filter_cnt - Reset flow director filter counters

 * @pf: Pointer to the targeted PF

 *

 * Set all flow director counters to 0.

/**

 * i40e_fdir_filter_restore - Restore the Sideband Flow Director filters

 * @vsi: Pointer to the targeted VSI

 *

 * This function replays the hlist on the hw where all the SB Flow Director

 * filters were saved.

 Reset FDir counters as we're replaying all existing filters */

/**

 * i40e_vsi_configure - Set up the VSI for action

 * @vsi: the VSI being configured

/**

 * i40e_vsi_configure_msix - MSIX mode Interrupt Config in the HW

 * @vsi: the VSI being configured

	/* The interrupt indexing is offset by 1 in the PFINT_ITRn

	 * and PFINT_LNKLSTn registers, e.g.:

	 *   PFINT_ITRn[0..n-1] gets msix-1..msix-n  (qpair interrupts)

 Linked list for the queuepairs assigned to this vector */

 Terminate the linked list */

/**

 * i40e_enable_misc_int_causes - enable the non-queue interrupts

 * @pf: pointer to private device data structure

 clear things first */

 disable all */

 read to clear */

 SW_ITR_IDX = 0, but don't change INTENA */

 OTHER_ITR_IDX = 0 */

/**

 * i40e_configure_msi_and_legacy - Legacy mode interrupt config in the HW

 * @vsi: the VSI being configured

 set the ITR configuration */

 FIRSTQ_INDX = 0, FIRSTQ_TYPE = 0 (rx) */

 Associate the queue pair to the vector and enable the queue int */

/**

 * i40e_irq_dynamic_disable_icr0 - Disable default interrupt generation for icr0

 * @pf: board private structure

/**

 * i40e_irq_dynamic_enable_icr0 - Enable default interrupt generation for icr0

 * @pf: board private structure

/**

 * i40e_msix_clean_rings - MSIX mode Interrupt Handler

 * @irq: interrupt number

 * @data: pointer to a q_vector

/**

 * i40e_irq_affinity_notify - Callback for affinity changes

 * @notify: context as to what irq was changed

 * @mask: the new affinity mask

 *

 * This is a callback function used by the irq_set_affinity_notifier function

 * so that we may register to receive changes to the irq affinity masks.

/**

 * i40e_irq_affinity_release - Callback for affinity notifier release

 * @ref: internal core kernel usage

 *

 * This is a callback function used by the irq_set_affinity_notifier function

 * to inform the current notification subscriber that they will no longer

 * receive notifications.

/**

 * i40e_vsi_request_irq_msix - Initialize MSI-X interrupts

 * @vsi: the VSI being configured

 * @basename: name for the vector

 *

 * Allocates MSI-X vectors and requests interrupts from the kernel.

 skip this unused q_vector */

 register for affinity change notifications */

		/* Spread affinity hints out across online CPUs.

		 *

		 * get_cpu_mask returns a static constant mask with

		 * a permanent lifetime so it's ok to pass to

		 * irq_set_affinity_hint without making a copy.

/**

 * i40e_vsi_disable_irq - Mask off queue interrupt generation on the VSI

 * @vsi: the VSI being un-configured

 disable interrupt causation from each queue */

 disable each interrupt */

 Legacy and MSI mode - this stops all interrupt handling */

/**

 * i40e_vsi_enable_irq - Enable IRQ for the given VSI

 * @vsi: the VSI being configured

/**

 * i40e_free_misc_vector - Free the vector that handles non-queue events

 * @pf: board private structure

 Disable ICR 0 */

/**

 * i40e_intr - MSI/Legacy and non-queue interrupt handler

 * @irq: interrupt number

 * @data: pointer to a q_vector

 *

 * This is the handler used for all MSI/Legacy interrupts, and deals

 * with both queue and non-queue interrupts.  This is also used in

 * MSIX mode to handle the non-queue interrupts.

 if sharing a legacy IRQ, we might get called w/o an intr pending */

 if interrupt but no bits showing, must be SWINT */

 only q0 is used in MSI/Legacy mode, and none are used in MSIX */

		/* We do not have a way to disarm Queue causes while leaving

		 * interrupt enabled for all other causes, ideally

		 * interrupt should be disabled while we are in NAPI but

		 * this is not a performance path and napi_schedule()

		 * can deal with rescheduling.

 disable any further VFLR event notifications */

	/* If a critical error is pending we have no choice but to reset the

	 * device.

	 * Report and mask out any remaining unexpected interrupts.

 re-enable interrupt causes */

/**

 * i40e_clean_fdir_tx_irq - Reclaim resources after transmit completes

 * @tx_ring:  tx ring to clean

 * @budget:   how many cleans we're allowed

 *

 * Returns true if there's any budget left (e.g. the clean is finished)

 if next_to_watch is not set then there is no work pending */

 prevent any other reads prior to eop_desc */

 if the descriptor isn't done, no work yet to do */

 clear next_to_watch to prevent false hangs */

 move past filter desc */

 unmap skb header data */

 move us past the eop_desc for start of next FD desc */

 update budget accounting */

/**

 * i40e_fdir_clean_ring - Interrupt Handler for FDIR SB ring

 * @irq: interrupt number

 * @data: pointer to a q_vector

/**

 * i40e_map_vector_to_qp - Assigns the queue pair to the vector

 * @vsi: the VSI being configured

 * @v_idx: vector index

 * @qp_idx: queue pair index

 Place XDP Tx ring in the same q_vector ring list as regular Tx */

/**

 * i40e_vsi_map_rings_to_vectors - Maps descriptor rings to vectors

 * @vsi: the VSI being configured

 *

 * This function maps descriptor rings to the queue-specific vectors

 * we were allotted through the MSI-X enabling code.  Ideally, we'd have

 * one vector per queue pair, but on a constrained vector budget, we

 * group the queue pairs as "efficiently" as possible.

	/* If we don't have enough vectors for a 1-to-1 mapping, we'll have to

	 * group them so there are multiple queues per vector.

	 * It is also important to go through all the vectors available to be

	 * sure that if we don't use all the vectors, that the remaining vectors

	 * are cleared. This is especially important when decreasing the

	 * number of queues in use.

/**

 * i40e_vsi_request_irq - Request IRQ from the OS

 * @vsi: the VSI being configured

 * @basename: name for the vector

/**

 * i40e_netpoll - A Polling 'interrupt' handler

 * @netdev: network interface device structure

 *

 * This is used by netconsole to send skbs without having to re-enable

 * interrupts.  It's not called while the normal interrupt routine is executing.

 if interface is down do nothing */

/**

 * i40e_pf_txq_wait - Wait for a PF's Tx queue to be enabled or disabled

 * @pf: the PF being configured

 * @pf_q: the PF queue

 * @enable: enable or disable state of the queue

 *

 * This routine will wait for the given Tx queue of the PF to reach the

 * enabled or disabled state.

 * Returns -ETIMEDOUT in case of failing to reach the requested state after

 * multiple retries; else will return 0 in case of success.

/**

 * i40e_control_tx_q - Start or stop a particular Tx queue

 * @pf: the PF structure

 * @pf_q: the PF queue to configure

 * @enable: start or stop the queue

 *

 * This function enables or disables a single queue. Note that any delay

 * required after the operation is expected to be handled by the caller of

 * this function.

 warn the TX unit of coming changes */

 Skip if the queue is already in the requested state */

 turn on/off the queue */

/**

 * i40e_control_wait_tx_q - Start/stop Tx queue and wait for completion

 * @seid: VSI SEID

 * @pf: the PF structure

 * @pf_q: the PF queue to configure

 * @is_xdp: true if the queue is used for XDP

 * @enable: start or stop the queue

 wait for the change to finish */

/**

 * i40e_vsi_enable_tx - Start a VSI's rings

 * @vsi: the VSI being configured

is xdp*/, true);

is xdp*/, true);

/**

 * i40e_pf_rxq_wait - Wait for a PF's Rx queue to be enabled or disabled

 * @pf: the PF being configured

 * @pf_q: the PF queue

 * @enable: enable or disable state of the queue

 *

 * This routine will wait for the given Rx queue of the PF to reach the

 * enabled or disabled state.

 * Returns -ETIMEDOUT in case of failing to reach the requested state after

 * multiple retries; else will return 0 in case of success.

/**

 * i40e_control_rx_q - Start or stop a particular Rx queue

 * @pf: the PF structure

 * @pf_q: the PF queue to configure

 * @enable: start or stop the queue

 *

 * This function enables or disables a single queue. Note that

 * any delay required after the operation is expected to be

 * handled by the caller of this function.

 Skip if the queue is already in the requested state */

 turn on/off the queue */

/**

 * i40e_control_wait_rx_q

 * @pf: the PF structure

 * @pf_q: queue being configured

 * @enable: start or stop the rings

 *

 * This function enables or disables a single queue along with waiting

 * for the change to finish. The caller of this function should handle

 * the delays needed in the case of disabling queues.

 wait for the change to finish */

/**

 * i40e_vsi_enable_rx - Start a VSI's rings

 * @vsi: the VSI being configured

/**

 * i40e_vsi_start_rings - Start a VSI's rings

 * @vsi: the VSI being configured

 do rx first for enable and last for disable */

/**

 * i40e_vsi_stop_rings - Stop a VSI's rings

 * @vsi: the VSI being configured

 When port TX is suspended, don't wait */

/**

 * i40e_vsi_stop_rings_no_wait - Stop a VSI's rings and do not delay

 * @vsi: the VSI being shutdown

 *

 * This function stops all the rings for a VSI but does not delay to verify

 * that rings have been disabled. It is expected that the caller is shutting

 * down multiple VSIs at once and will delay together for all the VSIs after

 * initiating the shutdown. This is particularly useful for shutting down lots

 * of VFs together. Otherwise, a large delay can be incurred while configuring

 * each VSI in serial.

/**

 * i40e_vsi_free_irq - Free the irq association with the OS

 * @vsi: the VSI being configured

 free only the irqs that were actually requested */

 clear the affinity notifier in the IRQ descriptor */

 remove our suggested affinity mask for this IRQ */

			/* Tear down the interrupt queue link list

			 *

			 * We know that they come in pairs and always

			 * the Rx first, then the Tx.  To clear the

			 * link list, stick the EOL value into the

			 * next_q field of the registers.

/**

 * i40e_free_q_vector - Free memory allocated for specific interrupt vector

 * @vsi: the VSI being configured

 * @v_idx: Index of vector to be freed

 *

 * This function frees the memory allocated to the q_vector.  In addition if

 * NAPI is enabled it will delete any references to the NAPI struct prior

 * to freeing the q_vector.

 disassociate q_vector from rings */

 only VSI w/ an associated netdev is set up w/ NAPI */

/**

 * i40e_vsi_free_q_vectors - Free memory allocated for interrupt vectors

 * @vsi: the VSI being un-configured

 *

 * This frees the memory allocated to the q_vectors and

 * deletes references to the NAPI struct.

/**

 * i40e_reset_interrupt_capability - Disable interrupt setup in OS

 * @pf: board private structure

 If we're in Legacy mode, the interrupt was cleaned in vsi_close */

/**

 * i40e_clear_interrupt_scheme - Clear the current interrupt scheme settings

 * @pf: board private structure

 *

 * We go through and clear interrupt specific resources and reset the structure

 * to pre-load conditions

/**

 * i40e_napi_enable_all - Enable NAPI for all q_vectors in the VSI

 * @vsi: the VSI being configured

/**

 * i40e_napi_disable_all - Disable NAPI for all q_vectors in the VSI

 * @vsi: the VSI being configured

/**

 * i40e_vsi_close - Shut down a VSI

 * @vsi: the vsi to be quelled

/**

 * i40e_quiesce_vsi - Pause a given VSI

 * @vsi: the VSI being paused

/**

 * i40e_unquiesce_vsi - Resume a given VSI

 * @vsi: the VSI being resumed

 this clears the DOWN bit */

/**

 * i40e_pf_quiesce_all_vsi - Pause all VSIs on a PF

 * @pf: the PF

/**

 * i40e_pf_unquiesce_all_vsi - Resume all VSIs on a PF

 * @pf: the PF

/**

 * i40e_vsi_wait_queues_disabled - Wait for VSI's queues to be disabled

 * @vsi: the VSI being configured

 *

 * Wait until all queues on a given VSI have been disabled.

 Check and wait for the Tx queue */

 Check and wait for the XDP Tx queue */

 Check and wait for the Rx queue */

/**

 * i40e_pf_wait_queues_disabled - Wait for all queues of PF VSIs to be disabled

 * @pf: the PF

 *

 * This function waits for the queues to be in disabled state for all the

 * VSIs that are managed by this PF.

/**

 * i40e_get_iscsi_tc_map - Return TC map for iSCSI APP

 * @pf: pointer to PF

 *

 * Get TC map for ISCSI PF type that will include iSCSI TC

 * and LAN TC.

 TC0 is always enabled */

 Get the iSCSI APP TLV */

/**

 * i40e_dcb_get_num_tc -  Get the number of TCs from DCBx config

 * @dcbcfg: the corresponding DCBx configuration structure

 *

 * Return the number of TCs from given DCBx configuration

	/* Scan the ETS Config Priority Table to find

	 * traffic class enabled for a given priority

	 * and create a bitmask of enabled TCs

	/* Now scan the bitmask to check for

	 * contiguous TCs starting with TC0

 There is always at least TC0 */

/**

 * i40e_dcb_get_enabled_tc - Get enabled traffic classes

 * @dcbcfg: the corresponding DCBx configuration structure

 *

 * Query the current DCB configuration and return the number of

 * traffic classes enabled from the given DCBX config

/**

 * i40e_mqprio_get_enabled_tc - Get enabled traffic classes

 * @pf: PF being queried

 *

 * Query the current MQPRIO configuration and return the number of

 * traffic classes enabled.

/**

 * i40e_pf_get_num_tc - Get enabled traffic classes for PF

 * @pf: PF being queried

 *

 * Return number of traffic classes enabled for the given PF

 If neither MQPRIO nor DCB is enabled, then always use single TC */

 SFP mode will be enabled for all TCs on port */

 MFP mode return count of enabled TCs for this PF */

 Only TC0 */

/**

 * i40e_pf_get_tc_map - Get bitmap for enabled traffic classes

 * @pf: PF being queried

 *

 * Return a bitmap for enabled traffic classes for this PF.

	/* If neither MQPRIO nor DCB is enabled for this PF then just return

	 * default TC

 SFP mode we want PF to be enabled for all TCs */

 MFP enabled and iSCSI PF type */

/**

 * i40e_vsi_get_bw_info - Query VSI BW Information

 * @vsi: the VSI being queried

 *

 * Returns 0 on success, negative value on failure

 Get the VSI level BW configuration */

 Get the VSI level BW configuration per TC */

 Still continuing */

 3 bits out of 4 for each TC */

/**

 * i40e_vsi_configure_bw_alloc - Configure VSI BW allocation per TC

 * @vsi: the VSI being configured

 * @enabled_tc: TC bitmap

 * @bw_share: BW shared credits per TC

 *

 * Returns 0 on success, negative value on failure

 There is no need to reset BW when mqprio mode is on.  */

/**

 * i40e_vsi_config_netdev_tc - Setup the netdev TC configuration

 * @vsi: the VSI being configured

 * @enabled_tc: TC map to be enabled

 *

 Set up actual enabled TCs on the VSI */

 set per TC queues for the VSI */

		/* Only set TC queues for enabled tcs

		 *

		 * e.g. For a VSI that has TC0 and TC3 enabled the

		 * enabled_tc bitmap would be 0x00001001; the driver

		 * will set the numtc for netdev as 2 that will be

		 * referenced by the netdev layer as TC 0 and 1.

 Assign UP2TC map for the VSI */

 Get the actual TC# for the UP */

 Get the mapped netdev TC# for the UP */

/**

 * i40e_vsi_update_queue_map - Update our copy of VSi info with new queue map

 * @vsi: the VSI being configured

 * @ctxt: the ctxt buffer returned from AQ VSI update param command

	/* copy just the sections touched not the entire info

	 * since not all sections are valid as returned by

	 * update vsi params

/**

 * i40e_update_adq_vsi_queues - update queue mapping for ADq VSI

 * @vsi: the VSI being reconfigured

 * @vsi_offset: offset from main VF VSI

 update the local VSI info with updated queue map */

/**

 * i40e_vsi_config_tc - Configure VSI Tx Scheduler for given TC map

 * @vsi: VSI to be configured

 * @enabled_tc: TC bitmap

 *

 * This configures a particular VSI for TCs that are mapped to the

 * given TC bitmap. It uses default bandwidth share for TCs across

 * VSIs to configure TC for a particular VSI.

 *

 * NOTE:

 * It is expected that the VSI queues have been quisced before calling

 * this function.

 Check if enabled_tc is same as existing or new TCs */

 Enable ETS TCs with equal BW Share for now across all VSIs */

 Always enable TC0, no matter what */

 Update Queue Pairs Mapping for currently enabled UPs */

	/* On destroying the qdisc, reset vsi->rss_size, as number of enabled

	 * queues changed.

	/* Update the VSI after updating the VSI queue-mapping

	 * information

 update the local VSI info with updated queue map */

 Update current VSI BW information */

 Update the netdev TC setup */

/**

 * i40e_get_link_speed - Returns link speed for the interface

 * @vsi: VSI to be configured

 *

/**

 * i40e_set_bw_limit - setup BW limit for Tx traffic based on max_tx_rate

 * @vsi: VSI to be configured

 * @seid: seid of the channel/VSI

 * @max_tx_rate: max TX rate to be configured as BW limit

 *

 * Helper function to set BW limit for a given VSI

 Tx rate credits are in values of 50Mbps, 0 is disabled */

/**

 * i40e_remove_queue_channels - Remove queue channels for the TCs

 * @vsi: VSI to be configured

 *

 * Remove queue channels for the TCs

	/* Reset rss size that was stored when reconfiguring rss for

	 * channel VSIs with non-power-of-2 queue count.

 perform cleanup for channels if they exist */

 Reset queue contexts */

 Reset BW configured for this VSI via mqprio */

 delete cloud filters associated with this channel */

 delete VSI from FW */

/**

 * i40e_get_max_queues_for_channel

 * @vsi: ptr to VSI to which channels are associated with

 *

 * Helper function which returns max value among the queue counts set on the

 * channels/TCs created.

/**

 * i40e_validate_num_queues - validate num_queues w.r.t channel

 * @pf: ptr to PF device

 * @num_queues: number of queues

 * @vsi: the parent VSI

 * @reconfig_rss: indicates should the RSS be reconfigured or not

 *

 * This function validates number of queues in the context of new channel

 * which is being established and determines if RSS should be reconfigured

 * or not for parent VSI.

		/* Find the max num_queues configured for channel if channel

		 * exist.

		 * if channel exist, then enforce 'num_queues' to be more than

		 * max ever queues configured for channel.

/**

 * i40e_vsi_reconfig_rss - reconfig RSS based on specified rss_size

 * @vsi: the VSI being setup

 * @rss_size: size of RSS, accordingly LUT gets reprogrammed

 *

 * This function reconfigures RSS by reprogramming LUTs using 'rss_size'

 Ignoring user configured lut if there is one */

	/* Use user configured hash key if there is one, otherwise

	 * use default.

 Do the update w.r.t. storing rss_size */

/**

 * i40e_channel_setup_queue_map - Setup a channel queue map

 * @pf: ptr to PF device

 * @ctxt: VSI context structure

 * @ch: ptr to channel structure

 *

 * Setup queue map for a specific channel

 find the next higher power-of-2 of num queue pairs */

 Setup queue TC[0].qmap for given VSI context */

 TC0 enabled */

/**

 * i40e_add_channel - add a channel by adding VSI

 * @pf: ptr to PF device

 * @uplink_seid: underlying HW switching element (VEB) ID

 * @ch: ptr to channel structure

 *

 * Add a channel (VSI) using add_vsi and queue_map

 TC0 enabled */

 Set queue map for a given VSI context */

 Now time to create VSI */

	/* Success, update channel, set enabled_tc only if the channel

	 * is not a macvlan

	/* copy just the sections touched not the entire info

	 * since not all sections are valid as returned by

	 * update vsi params

/**

 * i40e_channel_config_tx_ring - config TX ring associated with new channel

 * @pf: ptr to PF device

 * @vsi: the VSI being setup

 * @ch: ptr to channel structure

 *

 * Configure TX rings associated with channel (VSI) since queues are being

 * from parent VSI.

 Enable ETS TCs with equal BW Share for now across all VSIs */

 configure BW for new VSI */

		/* Get to TX ring ptr of main VSI, for re-setup TX queue

		 * context

 Get the RX ring ptr */

/**

 * i40e_setup_hw_channel - setup new channel

 * @pf: ptr to PF device

 * @vsi: the VSI being setup

 * @ch: ptr to channel structure

 * @uplink_seid: underlying HW switching element (VEB) ID

 * @type: type of channel to be created (VMDq2/VF)

 *

 * Setup new channel (VSI) based on specified type (VMDq2/VF)

 * and configures TX rings accordingly

 Proceed with creation of channel (VMDq2) VSI */

 Mark the successful creation of channel */

 Reconfigure TX queues using QTX_CTL register */

 update 'next_base_queue' */

/**

 * i40e_setup_channel - setup new channel using uplink element

 * @pf: ptr to PF device

 * @vsi: pointer to the VSI to set up the channel within

 * @ch: ptr to channel structure

 *

 * Setup new channel (VSI) based on specified type (VMDq2/VF)

 * and uplink switching element (uplink_seid)

 underlying switching element */

 create channel (VSI), configure TX rings */

/**

 * i40e_validate_and_set_switch_mode - sets up switch mode correctly

 * @vsi: ptr to VSI which has PF backing

 *

 * Sets up switch mode correctly if it needs to be changed and perform

 * what are allowed modes.

		/* if switch mode is set, support mode2 (non-tunneled for

		 * cloud filter) for now

 Set Bit 7 to be valid */

 Set L4type for TCP support */

 Set cloud filter mode */

 Prep mode field for set_switch_config */

/**

 * i40e_create_queue_channel - function to create channel

 * @vsi: VSI to be configured

 * @ch: ptr to channel (it contains channel specific params)

 *

 * This function creates channel (VSI) using num_queues specified by user,

 * reconfigs RSS if needed.

 validate user requested num_queues for channel */

	/* By default we are in VEPA mode, if this is the first VF/VMDq

	 * VSI to be added switch to VEB mode.

		/* now onwards for main VSI, number of queues will be value

		 * of TC0's queue count

	/* By this time, vsi->cnt_q_avail shall be set to non-zero and

	 * it should be more than num_queues

 reconfig_rss only if vsi type is MAIN_VSI */

 configure VSI for BW limit */

 in case of VF, this will be main SRIOV VSI */

 and update main_vsi's count for queue_available to use */

/**

 * i40e_configure_queue_channels - Add queue channel for the given TCs

 * @vsi: VSI to be configured

 *

 * Configures queue channel mapping to the given TCs

 Create app vsi with the TCs. Main VSI with TC0 is already set up */

			/* Bandwidth limit through tc interface is in bytes/s,

			 * change to Mbit/s

/**

 * i40e_veb_config_tc - Configure TCs for given VEB

 * @veb: given VEB

 * @enabled_tc: TC bitmap

 *

 * Configures given TC bitmap for VEB (switching) element

 No TCs or already enabled TCs just return */

 bw_data.absolute_credits is not set (relative) */

 Enable ETS TCs with equal BW Share for now */

 Update the BW information */

/**

 * i40e_dcb_reconfigure - Reconfigure all VEBs and VSIs

 * @pf: PF struct

 *

 * Reconfigure VEB/VSIs on a given PF; it is assumed that

 * the caller would've quiesce all the VSIs before calling

 * this function

 Enable the TCs available on PF to all VEBs */

 Will try to configure as many components */

 Update each VSI */

		/* - Enable all TCs for the LAN VSI

		 * - For all others keep them at TC0 for now

 Will try to configure as many components */

 Re-configure VSI vectors based on updated TC map */

/**

 * i40e_resume_port_tx - Resume port Tx

 * @pf: PF struct

 *

 * Resume a port's Tx and issue a PF reset in case of failure to

 * resume.

 Schedule PF reset to recover */

/**

 * i40e_suspend_port_tx - Suspend port Tx

 * @pf: PF struct

 *

 * Suspend a port's Tx and issue a PF reset in case of failure.

 Schedule PF reset to recover */

/**

 * i40e_hw_set_dcb_config - Program new DCBX settings into HW

 * @pf: PF being configured

 * @new_cfg: New DCBX configuration

 *

 * Program DCB settings into HW and reconfigure VEB/VSIs on

 * given PF. Uses "Set LLDP MIB" AQC to program the hardware.

 Check if need reconfiguration */

 Config change disable all VSIs */

 Copy the new config to the current config */

 Changes in configuration update VEB/VSI */

 In case of reset do not try to resume anything */

 Re-start the VSIs if disabled */

 In case of error no point in resuming VSIs */

/**

 * i40e_hw_dcb_config - Program new DCBX settings into HW

 * @pf: PF being configured

 * @new_cfg: New DCBX configuration

 *

 * Program DCB settings into HW and reconfigure VEB/VSIs on

 * given PF

	/* Un-pack information to Program ETS HW via shared API

	 * numtc, tcmap

	 * LLTC map

	 * ETS/NON-ETS arbiter mode

	 * max exponent (credit refills)

	 * Total number of ports

	 * PFC priority bit-map

	 * Priority Table

	 * BW % per TC

	 * Arbiter mode between UPs sharing same TC

	 * TSA table (ETS or non-ETS)

	 * EEE enabled or not

	 * MFS TC table

 Invalid TSA type */

 Check if need reconfiguration */

	/* If needed, enable/disable frame tagging, disable all VSIs

	 * and suspend port tx

 Enable DCB tagging only when more than one TC */

 Reconfiguration needed quiesce all VSIs */

 Configure Port ETS Tx Scheduler */

 Configure Rx ETS HW */

 Configure Rx Packet Buffers in HW */

 Update the local Rx Packet buffer config */

 Inform the FW about changes to DCB configuration */

 Update the port DCBx configuration */

 Changes in configuration update VEB/VSI */

 Re-start the VSIs if disabled */

 In case of error no point in resuming VSIs */

 Wait for the PF's queues to be disabled */

 Schedule PF reset to recover */

 registers are set, lets apply */

/**

 * i40e_dcb_sw_default_config - Set default DCB configuration when DCB in SW

 * @pf: PF being queried

 *

 * Set default DCB configuration in case DCB is to be done in SW.

 Update the local cached instance with TC0 ETS */

 FW needs one App to configure HW */

 TC0 only */

 ETS */

 100% to TC0 */

 Enable ETS on the Physical port */

 Update the local cached instance with TC0 ETS */

/**

 * i40e_init_pf_dcb - Initialize DCB configuration

 * @pf: PF being configured

 *

 * Query the current DCB configuration and cache it

 * in the hardware structure

	/* Do not enable DCB for SW1 and SW2 images even if the FW is capable

	 * Also do not enable DCBx if FW LLDP agent is disabled

 at init capable but disabled */

 Device/Function is not DCBX capable */

 When status is not DISABLED then DCBX in FW */

			/* Enable DCB tagging only when more than one TC

			 * or explicitly disable if only one TC

 CONFIG_I40E_DCB */

/**

 * i40e_print_link_message - print link up or down

 * @vsi: the VSI for which link needs a message

 * @isup: true of link is up, false otherwise

	/* Warn user if link speed on NPAR enabled partition is not at

	 * least 10GB

		/* 'CL108 RS-FEC' should be displayed when RS is requested, or

		 * both RS and FC are requested

/**

 * i40e_up_complete - Finish the last steps of bringing up a connection

 * @vsi: the VSI being configured

 start rings */

 replay FDIR SB filters */

 reset fd counters */

	/* On the next run of the service_task, notify any clients of the new

	 * opened netdev

/**

 * i40e_vsi_reinit_locked - Reset the VSI

 * @vsi: the VSI being configured

 *

 * Rebuild the ring structs after some configuration

 * has changed, e.g. MTU size.

/**

 * i40e_force_link_state - Force the link status

 * @pf: board private structure

 * @is_up: whether the link state should be forced up or down

	/* Card might've been put in an unstable state by other drivers

	 * and applications, which causes incorrect speed values being

	 * set on startup. In order to clear speed registers, we call

	 * get_phy_capabilities twice, once to get initial state of

	 * available speeds, and once to get current PHY config.

 Get the current phy config */

	/* If link needs to go up, but was not forced to go down,

	 * and its speed values are OK, no need for a flap

	 * if non_zero_phy_type was set, still need to force up

	/* To force link we need to set bits for all supported PHY types,

	 * but there are now more than 32, so we need to split the bitmap

	 * across two fields.

 Copy the old settings, except of phy_type */

 Update the link info */

		/* Wait a little bit (on 40G cards it sometimes takes a really

		 * long time for link to come back from the atomic reset)

		 * and try once more

/**

 * i40e_up - Bring the connection back up after being down

 * @vsi: the VSI being configured

/**

 * i40e_down - Shutdown the connection processing

 * @vsi: the VSI being stopped

	/* It is assumed that the caller of this function

	 * sets the vsi->state __I40E_VSI_DOWN bit.

			/* Make sure that in-progress ndo_xdp_xmit and

			 * ndo_xsk_wakeup calls are completed.

/**

 * i40e_validate_mqprio_qopt- validate queue mapping info

 * @vsi: the VSI being configured

 * @mqprio_qopt: queue parametrs

/**

 * i40e_vsi_set_default_tc_config - set default values for tc configuration

 * @vsi: the VSI being configured

 Only TC0 is enabled */

		/* For the TC that is not enabled set the offset to default

		 * queue and allocate one queue for the given TC.

/**

 * i40e_del_macvlan_filter

 * @hw: pointer to the HW structure

 * @seid: seid of the channel VSI

 * @macaddr: the mac address to apply as a filter

 * @aq_err: store the admin Q error

 *

 * This function deletes a mac filter on the channel VSI which serves as the

 * macvlan. Returns 0 on success.

/**

 * i40e_add_macvlan_filter

 * @hw: pointer to the HW structure

 * @seid: seid of the channel VSI

 * @macaddr: the mac address to apply as a filter

 * @aq_err: store the admin Q error

 *

 * This function adds a mac filter on the channel VSI which serves as the

 * macvlan. Returns 0 on success.

/**

 * i40e_reset_ch_rings - Reset the queue contexts in a channel

 * @vsi: the VSI we want to access

 * @ch: the channel we want to access

/**

 * i40e_free_macvlan_channels

 * @vsi: the VSI we want to access

 *

 * This function frees the Qs of the channel VSI from

 * the stack and also deletes the channel VSIs which

 * serve as macvlans.

 remove the VSI */

/**

 * i40e_fwd_ring_up - bring the macvlan device up

 * @vsi: the VSI we want to access

 * @vdev: macvlan netdevice

 * @fwd: the private fwd structure

 Go through the list and find an available channel */

 record configuration for macvlan interface in vdev */

 Get to TX ring ptr */

 Get the RX ring ptr */

	/* Guarantee all rings are updated before we update the

	 * MAC address filter.

 Add a mac filter */

 if we cannot add the MAC rule then disable the offload */

/**

 * i40e_setup_macvlans - create the channels which will be macvlans

 * @vsi: the VSI we want to access

 * @macvlan_cnt: no. of macvlans to be setup

 * @qcnt: no. of Qs per macvlan

 * @vdev: macvlan netdevice

 find the next higher power-of-2 of num queue pairs */

 Setup context bits for the main VSI */

 Reconfigure RSS for main VSI with new max queue count */

	/* Update the VSI after updating the VSI queue-mapping

	 * information

 update the local VSI info with updated queue map */

 Create channels for macvlans */

/**

 * i40e_fwd_add - configure macvlans

 * @netdev: net device to configure

 * @vdev: macvlan netdevice

	/* The macvlan device has to be a single Q device so that the

	 * tc_to_txq field can be reused to pick the tx queue.

 reserve bit 0 for the pf device */

		/* Try to reserve as many queues as possible for macvlans. First

		 * reserve 3/4th of max vectors, then half, then quarter and

		 * calculate Qs per macvlan as you go

 allocate 4 Qs per macvlan and 32 Qs to the PF*/

 allocate 2 Qs per macvlan and 16 Qs to the PF*/

 allocate 1 Q per macvlan and 16 Qs to the PF*/

 allocate 1 Q per macvlan and 8 Qs to the PF */

 allocate 1 Q per macvlan and 1 Q to the PF */

 Quiesce VSI queues */

 sets up the macvlans but does not "enable" them */

 Unquiesce VSI */

 create the fwd struct */

 Set fwd ring up */

 unbind the queues and drop the subordinate channel config */

/**

 * i40e_del_all_macvlans - Delete all the mac filters on the channels

 * @vsi: the VSI we want to access

 Reset queue contexts */

/**

 * i40e_fwd_del - delete macvlan interfaces

 * @netdev: net device to configure

 * @vdev: macvlan netdevice

 Find the channel associated with the macvlan and del mac filter */

 Reset queue contexts */

/**

 * i40e_setup_tc - configure multiple traffic classes

 * @netdev: net device to configure

 * @type_data: tc offload data

 Check if MFP enabled */

 Check if DCB enabled to continue */

 Check whether tc count is within enabled limit */

 Generate TC map for number of tc requested */

 Requesting same TC configuration as already enabled */

 Quiesce VSI queues */

 Configure VSI for enabled TCs */

 Reset the configuration data to defaults, only TC0 is enabled */

 Unquiesce VSI */

/**

 * i40e_set_cld_element - sets cloud filter element data

 * @filter: cloud filter rule

 * @cld: ptr to cloud filter element data

 *

 * This is helper function to copy data into cloud filter element

	/* tenant_id is not supported by FW now, once the support is enabled

	 * fill the cld->tenant_id with cpu_to_le32(filter->tenant_id)

/**

 * i40e_add_del_cloud_filter - Add/del cloud filter

 * @vsi: pointer to VSI

 * @filter: cloud filter rule

 * @add: if true, add, if false, delete

 *

 * Add or delete a cloud filter for a specific flow spec.

 * Returns 0 if the filter were successfully added.

 copy element needed to add cloud filter from filter */

/**

 * i40e_add_del_cloud_filter_big_buf - Add/del cloud filter using big_buf

 * @vsi: pointer to VSI

 * @filter: cloud filter rule

 * @add: if true, add, if false, delete

 *

 * Add or delete a cloud filter for a specific flow spec using big buffer.

 * Returns 0 if the filter were successfully added.

 Both (src/dst) valid mac_addr are not supported */

	/* Big buffer cloud filter needs 'L4 port' to be non-zero. Also, UDP

	 * ports are not supported via big buffer now.

 adding filter using src_port/src_ip is not supported at this stage */

 copy element needed to add cloud filter from filter */

 MAC + IP : unsupported mode */

		/* since we validated that L4 port must be valid before

		 * we get here, start with respective "flags" value

		 * and update if vlan is present or not

 Now copy L4 port in Byte 6..7 in general fields */

 Validate current device switch mode, change if necessary */

/**

 * i40e_parse_cls_flower - Parse tc flower filters provided by kernel

 * @vsi: Pointer to VSI

 * @f: Pointer to struct flow_cls_offload

 * @filter: Pointer to cloud filter structure

 *

 use is_broadcast and is_zero to check for all 0xf or 0 */

		/* src and dest IPV6 address should not be LOOPBACK

		 * (0:0:0:0:0:0:0:1), which can be represented as ::1

/**

 * i40e_handle_tclass: Forward to a traffic class on the device

 * @vsi: Pointer to VSI

 * @tc: traffic class index on the device

 * @filter: Pointer to cloud filter structure

 *

 direct to a traffic class on the same device */

/**

 * i40e_configure_clsflower - Configure tc flower filters

 * @vsi: Pointer to VSI

 * @cls_flower: Pointer to struct flow_cls_offload

 *

 Add cloud filter */

 add filter to the ordered list */

/**

 * i40e_find_cloud_filter - Find the could filter in the list

 * @vsi: Pointer to VSI

 * @cookie: filter specific cookie

 *

/**

 * i40e_delete_clsflower - Remove tc flower filters

 * @vsi: Pointer to VSI

 * @cls_flower: Pointer to struct flow_cls_offload

 *

/**

 * i40e_setup_tc_cls_flower - flower classifier offloads

 * @np: net device to configure

 * @cls_flower: offload data

/**

 * i40e_open - Called when a network interface is made active

 * @netdev: network interface device structure

 *

 * The open entry point is called when a network interface is made

 * active by the system (IFF_UP).  At this point all resources needed

 * for transmit and receive operations are allocated, the interrupt

 * handler is registered with the OS, the netdev watchdog subtask is

 * enabled, and the stack is notified that the interface is ready.

 *

 * Returns 0 on success, negative value on failure

 disallow open during test or if eeprom is broken */

 configure global TSO hardware offload settings */

/**

 * i40e_vsi_open -

 * @vsi: the VSI to open

 *

 * Finish initialization of the VSI.

 *

 * Returns 0 on success, negative value on failure

 *

 * Note: expects to be called while under rtnl_lock()

 allocate descriptors */

 Notify the stack of the actual queue counts. */

/**

 * i40e_fdir_filter_exit - Cleans up the Flow Director accounting

 * @pf: Pointer to PF

 *

 * This function destroys the hlist where all the Flow Director

 * filters were saved.

 Reprogram the default input set for TCP/IPv4 */

 Reprogram the default input set for TCP/IPv6 */

 Reprogram the default input set for UDP/IPv4 */

 Reprogram the default input set for UDP/IPv6 */

 Reprogram the default input set for SCTP/IPv4 */

 Reprogram the default input set for SCTP/IPv6 */

 Reprogram the default input set for Other/IPv4 */

 Reprogram the default input set for Other/IPv6 */

/**

 * i40e_cloud_filter_exit - Cleans up the cloud filters

 * @pf: Pointer to PF

 *

 * This function destroys the hlist where all the cloud filters

 * were saved.

/**

 * i40e_close - Disables a network interface

 * @netdev: network interface device structure

 *

 * The close entry point is called when an interface is de-activated

 * by the OS.  The hardware is still under the driver's control, but

 * this netdev interface is disabled.

 *

 * Returns 0, this is not allowed to fail

/**

 * i40e_do_reset - Start a PF or Core Reset sequence

 * @pf: board private structure

 * @reset_flags: which reset is requested

 * @lock_acquired: indicates whether or not the lock has been acquired

 * before this function was called.

 *

 * The essential difference in resets is that the PF Reset

 * doesn't clear the packet buffers, doesn't reset the PE

 * firmware, and doesn't bother the other PFs on the chip.

 do the biggest reset indicated */

		/* Request a Global Reset

		 *

		 * This will start the chip's countdown to the actual full

		 * chip reset event, and a warning interrupt to be sent

		 * to all PFs, including the requestor.  Our handler

		 * for the warning interrupt will deal with the shutdown

		 * and recovery of the switch setup.

		/* Request a Core Reset

		 *

		 * Same as Global Reset, except does *not* include the MAC/PHY

		/* Request a PF Reset

		 *

		 * Resets only the PF-specific registers

		 *

		 * This goes directly to the tear-down and rebuild of

		 * the switch, since we need to do all the recovery as

		 * for the Core Reset.

		/* Request a PF Reset

		 *

		 * Resets PF and reinitializes PFs VSI.

 Find the VSI(s) that requested a re-init */

 Find the VSI(s) that needs to be brought down */

/**

 * i40e_dcb_need_reconfig - Check if DCB needs reconfig

 * @pf: board private structure

 * @old_cfg: current DCB config

 * @new_cfg: new DCB config

 Check if ETS configuration has changed */

 If Priority Table has changed reconfig is needed */

 Check if PFC configuration has changed */

 Check if APP Table has changed */

/**

 * i40e_handle_lldp_event - Handle LLDP Change MIB event

 * @pf: board private structure

 * @e: event info posted on ARQ

 X710-T*L 2.5G and 5G speeds don't support DCB */

 let firmware decide if the DCB should be disabled */

 Not DCB capable or capability disabled */

 Ignore if event is not for Nearest Bridge */

 Check MIB Type and return if event for Remote MIB update */

 Update the remote cached instance and return */

 Store the old configuration */

 Reset the old DCBx configuration data */

 Get updated DCBX data from firmware */

 X710-T*L 2.5G and 5G speeds don't support DCB */

 No change detected in DCBX configs */

 Enable DCB tagging only when more than one TC */

 Reconfiguration needed quiesce all VSIs */

 Changes in configuration update VEB/VSI */

 In case of error no point in resuming VSIs */

 Wait for the PF's queues to be disabled */

 Schedule PF reset to recover */

 CONFIG_I40E_DCB */

/**

 * i40e_do_reset_safe - Protected reset path for userland calls.

 * @pf: board private structure

 * @reset_flags: which reset is requested

 *

/**

 * i40e_handle_lan_overflow_event - Handler for LAN queue overflow event

 * @pf: board private structure

 * @e: event info posted on ARQ

 *

 * Handler for LAN Queue Overflow Event generated by the firmware for PF

 * and VF queues

 Queue belongs to VF, find the VF and issue VF reset */

 Allow VF to process pending reset notification */

/**

 * i40e_get_cur_guaranteed_fd_count - Get the consumed guaranteed FD filters

 * @pf: board private structure

/**

 * i40e_get_current_fd_count - Get total FD filters programmed for this PF

 * @pf: board private structure

/**

 * i40e_get_global_fd_count - Get total FD filters programmed on device

 * @pf: board private structure

/**

 * i40e_reenable_fdir_sb - Restore FDir SB capability

 * @pf: board private structure

/**

 * i40e_reenable_fdir_atr - Restore FDir ATR capability

 * @pf: board private structure

		/* ATR uses the same filtering logic as SB rules. It only

		 * functions properly if the input set mask is at the default

		 * settings. It is safe to restore the default input set

		 * because there are no active TCPv4 filter rules.

/**

 * i40e_delete_invalid_filter - Delete an invalid FDIR filter

 * @pf: board private structure

 * @filter: FDir filter to remove

 Update counters */

 Remove the filter from the list and free memory */

/**

 * i40e_fdir_check_and_reenable - Function to reenabe FD ATR or SB if disabled

 * @pf: board private structure

 Check if we have enough room to re-enable FDir SB capability. */

	/* We should wait for even more space before re-enabling ATR.

	 * Additionally, we cannot enable ATR as long as we still have TCP SB

	 * rules active.

 if hw had a problem adding a filter, delete it */

/**

 * i40e_fdir_flush_and_replay - Function to flush all FD filters and replay SB

 * @pf: board private structure

	/* If the flush is happening too quick and we have mostly SB rules we

	 * should not re-enable ATR for some time.

 flush all filters */

 Check FD flush status every 5-6msec */

 replay sideband filters */

/**

 * i40e_get_current_atr_cnt - Get the count of total FD ATR filters programmed

 * @pf: board private structure

/**

 * i40e_fdir_reinit_subtask - Worker thread to reinit FDIR filter table

 * @pf: board private structure

 if interface is down do nothing */

/**

 * i40e_vsi_link_event - notify VSI of a link event

 * @vsi: vsi to be notified

 * @link_up: link up or down

 there is no notification for other VSIs */

/**

 * i40e_veb_link_event - notify elements on the veb of a link event

 * @veb: veb to be notified

 * @link_up: link up or down

 depth first... */

 ... now the local VSIs */

/**

 * i40e_link_event - Update netif_carrier status

 * @pf: board private structure

 CONFIG_I40E_DCB */

 set this to force the get_link_status call to refresh state */

 On success, disable temp link polling */

		/* Enable link polling temporarily until i40e_get_link_status

		 * returns I40E_SUCCESS

	/* Notify the base of the switch tree connected to

	 * the link.  Floating VEBs are not notified.

 Not SW DCB so firmware will take care of default settings */

	/* We cover here only link down, as after link up in case of SW DCB

	 * SW LLDP agent will take care of setting it up

 CONFIG_I40E_DCB */

/**

 * i40e_watchdog_subtask - periodic checks not using event driven response

 * @pf: board private structure

 if interface is down do nothing */

 make sure we don't do these things too often */

	/* Update the stats for active netdevs so the network stack

	 * can look at updated numbers whenever it cares to

 Update the stats for the active switching components */

/**

 * i40e_reset_subtask - Set up for resetting the device and driver

 * @pf: board private structure

	/* If there's a recovery already waiting, it takes

	 * precedence before starting a new reset sequence.

 If we're already down or resetting, just bail */

/**

 * i40e_handle_link_event - Handle link event

 * @pf: board private structure

 * @e: event info posted on ARQ

	/* Do a new status request to re-enable LSE reporting

	 * and load new status information into the hw struct

	 * This completely ignores any state information

	 * in the ARQ event info, instead choosing to always

	 * issue the AQ update link status command.

 Check if module meets thermal requirements */

		/* check for unqualified module, if link is down, suppress

		 * the message if link was forced to be down.

/**

 * i40e_clean_adminq_subtask - Clean the AdminQ rings

 * @pf: board private structure

 Do not run clean AQ when PF reset fails */

 check for error indications */

 CONFIG_I40E_DCB */

 re-enable Admin queue interrupt cause */

/**

 * i40e_verify_eeprom - make sure eeprom is good to use

 * @pf: board private structure

 retry in case of garbage read */

/**

 * i40e_enable_pf_switch_lb

 * @pf: pointer to the PF structure

 *

 * enable switch loop back or die - no point in a return value

/**

 * i40e_disable_pf_switch_lb

 * @pf: pointer to the PF structure

 *

 * disable switch loop back or die - no point in a return value

/**

 * i40e_config_bridge_mode - Configure the HW bridge mode

 * @veb: pointer to the bridge instance

 *

 * Configure the loop back mode for the LAN VSI that is downlink to the

 * specified HW bridge instance. It is expected this function is called

 * when a new HW bridge is instantiated.

/**

 * i40e_reconstitute_veb - rebuild the VEB and anything connected to it

 * @veb: pointer to the VEB instance

 *

 * This is a recursive function that first builds the attached VSIs then

 * recurses in to build the next layer of VEB.  We track the connections

 * through our own index numbers because the seid's from the HW could

 * change across the reset.

 build VSI that owns this VEB, temporarily attached to base VEB */

 create the VEB in the switch and move the VSI onto the VEB */

 create the remaining VSIs attached to this VEB */

 create any VEBs attached to this VEB - RECURSION */

/**

 * i40e_get_capabilities - get info about the HW

 * @pf: the PF struct

 * @list_type: AQ capability to be queried

 this loads the data into the hw struct for us */

 data loaded, buffer no longer needed */

 retry with a larger buffer */

/**

 * i40e_fdir_sb_setup - initialize the Flow Director resources for Sideband

 * @pf: board private structure

	/* quick workaround for an NVM issue that leaves a critical register

	 * uninitialized

 find existing VSI and see if it needs configuring */

 create a new VSI if none exists */

/**

 * i40e_fdir_teardown - release the Flow Director resources

 * @pf: board private structure

/**

 * i40e_rebuild_cloud_filters - Rebuilds cloud filters for VSIs

 * @vsi: PF main vsi

 * @seid: seid of main or channel VSIs

 *

 * Rebuilds cloud filters associated with main VSI and channel VSIs if they

 * existed before reset

 Add cloud filters back if they exist */

/**

 * i40e_rebuild_channels - Rebuilds channel VSIs if they existed before reset

 * @vsi: PF main vsi

 *

 * Rebuilds channel VSIs if they existed before reset

 Proceed with creation of channel (VMDq2) VSI */

 Reconfigure TX queues using QTX_CTL register */

 update 'next_base_queue' */

/**

 * i40e_prep_for_reset - prep for the core to reset

 * @pf: board private structure

 *

 * Close up the VFs and other things in prep for PF Reset.

 quiesce the VSIs and their queues that are not already DOWN */

 call shutdown HMC */

	/* Save the current PTP time so that we can restore the time after the

	 * reset completes.

/**

 * i40e_send_version - update firmware with driver version

 * @pf: PF struct

/**

 * i40e_get_oem_version - get OEM specific version information

 * @hw: pointer to the hardware structure

 Check if pointer to OEM version block is valid. */

 Check if OEM version block has correct length. */

 Check if OEM version format is as expected. */

/**

 * i40e_reset - wait for core reset to finish reset, reset pf if corer not seen

 * @pf: board private structure

/**

 * i40e_rebuild - rebuild using a saved config

 * @pf: board private structure

 * @reinit: if the Main VSI needs to re-initialized.

 * @lock_acquired: indicates whether or not the lock has been acquired

 * before this function was called.

 rebuild the basics for the AdminQ, HMC, and initial HW switch */

		/* The following delay is necessary for 4.33 firmware and older

		 * to recover after EMP reset. 200 ms should suffice but we

		 * put here 300 ms to be sure that FW is ready to operate

		 * after reset.

 re-verify the eeprom if we just had an EMP reset */

	/* if we are going out of or into recovery mode we have to act

	 * accordingly with regard to resources initialization

	 * and deinitialization

			/* we're staying in recovery mode so we'll reinitialize

			 * misc vector here

			/* we're going out of recovery mode so we'll free

			 * the IRQ allocated specifically for recovery mode

			 * and restore the interrupt scheme

 tell the firmware that we're starting */

		/* bail out in case recovery mode was detected, as there is

		 * no need for further configuration.

	/* Enable FW to write a default DCB config on link-up

	 * unless I40E_FLAG_TC_MQPRIO was enabled or DCB

	 * is not supported with new link speed

 Continue without DCB enabled */

 CONFIG_I40E_DCB */

	/* The driver only wants link up/down and module qualification

	 * reports from firmware.  Note the negative logic.

	/* Rebuild the VSIs and VEBs that existed before reset.

	 * They are still in our local switch element arrays, so only

	 * need to rebuild the switch model in the HW.

	 *

	 * If there were VEBs but the reconstitution failed, we'll try

	 * to recover minimal use by getting the basic PF VSI working.

 find the one VEB connected to the MAC, and find orphans */

				/* If Main VEB failed, we're in deep doodoo,

				 * so give up rebuilding the switch and set up

				 * for minimal rebuild of PF VSI.

				 * If orphan failed, we'll report the error

				 * but try to keep going.

 no VEB, so rebuild only the Main VSI */

	/* PF Main VSI is rebuild by now, go ahead and rebuild channel VSIs

	 * for this main VSI if they exist

	/* Reconfigure hardware for allowing smaller MSS in the case

	 * of TSO, so that we avoid the MDD being fired and causing

	 * a reset in the case of small MSS+TSO.

 reinit the misc interrupt */

	/* Add a filter to drop all Flow control frames from any VSI from being

	 * transmitted. By doing so we stop a malicious VF from sending out

	 * PAUSE or PFC frames and potentially controlling traffic for other

	 * PF/VF VSIs.

	 * The FW can still send Flow control frames if enabled.

 restart the VSIs that were rebuilt and running before the reset */

 Release the RTNL lock before we start resetting VFs */

 Restore promiscuous settings */

 tell the firmware that we're starting */

 We've already released the lock, so don't do it again */

/**

 * i40e_reset_and_rebuild - reset and rebuild using a saved config

 * @pf: board private structure

 * @reinit: if the Main VSI needs to re-initialized.

 * @lock_acquired: indicates whether or not the lock has been acquired

 * before this function was called.

	/* Now we wait for GRST to settle out.

	 * We don't have to delete the VEBs or VSIs from the hw switch

	 * because the reset will make them disappear.

/**

 * i40e_handle_reset_warning - prep for the PF to reset, reset and rebuild

 * @pf: board private structure

 *

 * Close up the VFs and other things in prep for a Core Reset,

 * then get ready to rebuild the world.

 * @lock_acquired: indicates whether or not the lock has been acquired

 * before this function was called.

/**

 * i40e_handle_mdd_event

 * @pf: pointer to the PF structure

 *

 * Called from the MDD irq handler to identify possibly malicious vfs

 find what triggered the MDD event */

 see if one of the VFs needs its hand slapped */

 re-enable mdd interrupt cause */

/**

 * i40e_service_task - Run the driver's async subtasks

 * @work: pointer to work_struct containing our data

 don't bother with service tasks if a reset is in progress */

 Client subtask will reopen next time through. */

 flush memory to make sure state is correct before next watchdog */

	/* If the tasks have taken longer than one timer cycle or there

	 * is more work to be done, reschedule the service task now

	 * rather than wait for the timer to tick again.

/**

 * i40e_service_timer - timer callback

 * @t: timer list pointer

/**

 * i40e_set_num_rings_in_vsi - Determine number of rings in the VSI

 * @vsi: the VSI being configured

/**

 * i40e_vsi_alloc_arrays - Allocate queue and vector pointer arrays for the vsi

 * @vsi: VSI pointer

 * @alloc_qvectors: a bool to specify if q_vectors need to be allocated.

 *

 * On error: returns error code (negative)

 * On success: returns 0

 allocate memory for both Tx, XDP Tx and Rx ring pointers */

 allocate memory for q_vector pointers */

/**

 * i40e_vsi_mem_alloc - Allocates the next available struct vsi in the PF

 * @pf: board private structure

 * @type: type of VSI

 *

 * On error: returns error code (negative)

 * On success: returns vsi index in PF (positive)

 Need to protect the allocation of the VSIs at the PF level */

	/* VSI list may be fragmented if VSI creation/destruction has

	 * been happening.  We can afford to do a quick scan to look

	 * for any free VSIs in the list.

	 *

	 * find next empty vsi slot, looping back around if necessary

 Found one! */

 out of VSI slots! */

 Setup default MSIX irq handler for VSI */

 Initialize VSI lock */

/**

 * i40e_vsi_free_arrays - Free queue and vector pointer arrays for the VSI

 * @vsi: VSI pointer

 * @free_qvectors: a bool to specify if q_vectors need to be freed.

 *

 * On error: returns error code (negative)

 * On success: returns 0

 free the ring and vector containers */

/**

 * i40e_clear_rss_config_user - clear the user configured RSS hash keys

 * and lookup table

 * @vsi: Pointer to VSI structure

/**

 * i40e_vsi_clear - Deallocate the VSI provided

 * @vsi: the VSI being un-configured

 updates the PF for this cleared vsi */

/**

 * i40e_vsi_clear_rings - Deallocates the Rx and Tx rings for the provided VSI

 * @vsi: the VSI being cleaned

/**

 * i40e_alloc_rings - Allocates the Rx and Tx rings for the provided VSI

 * @vsi: the VSI being configured

 Set basic values in the rings to be used later during open() */

 allocate space for both Tx and Rx in one shot */

/**

 * i40e_reserve_msix_vectors - Reserve MSI-X vectors in the kernel

 * @pf: board private structure

 * @vectors: the number of MSI-X vectors to request

 *

 * Returns the number of vectors reserved, or error

/**

 * i40e_init_msix - Setup the MSIX capability

 * @pf: board private structure

 *

 * Work with the OS to set up the MSIX vectors needed.

 *

 * Returns the number of vectors reserved or negative on failure

	/* The number of vectors we'll request will be comprised of:

	 *   - Add 1 for "other" cause for Admin Queue events, etc.

	 *   - The number of LAN queue pairs

	 *	- Queues being used for RSS.

	 *		We don't need as many as max_rss_size vectors.

	 *		use rss_size instead in the calculation since that

	 *		is governed by number of cpus in the system.

	 *	- assumes symmetric Tx/Rx pairing

	 *   - The number of VMDq pairs

	 *   - The CPU count within the NUMA node if iWARP is enabled

	 * Once we count this up, try the request.

	 *

	 * If we can't get what we want, we'll simplify to nearly nothing

	 * and try again.  If that still fails, we punt.

 reserve one vector for miscellaneous handler */

	/* reserve some vectors for the main PF traffic queues. Initially we

	 * only reserve at most 50% of the available vectors, in the case that

	 * the number of online CPUs is large. This ensures that we can enable

	 * extra features as well. Once we've enabled the other features, we

	 * will use any remaining vectors to reach as close as we can to the

	 * number of online CPUs.

 reserve one vector for sideband flow director */

 can we reserve enough for iWARP? */

 any vectors left over go for VMDq support */

			/* if we're short on vectors for what's desired, we limit

			 * the queues per vmdq.  If this is still more than are

			 * available, the user will need to change the number of

			 * queues/vectors used by the PF later with the ethtool

			 * channels command

	/* On systems with a large number of SMP cores, we previously limited

	 * the number of vectors for num_lan_msix to be at most 50% of the

	 * available vectors, to allow for other features. Now, we add back

	 * the remaining vectors. However, we ensure that the total

	 * num_lan_msix will not exceed num_online_cpus(). To do this, we

	 * calculate the number of vectors we can add without going over the

	 * cap of CPUs. For systems with a small number of CPUs this will be

	 * zero.

 Adjust for minimal MSIX use */

		/* If we have limited resources, we will start with no vectors

		 * for the special features and then allocate vectors to some

		 * of these features based on the policy and at the end disable

		 * the features that did not get any vectors.

 reserve the misc vector */

 Scale vector usage down */

 force VMDqs to only one vector */

 partition out the remaining vectors */

/**

 * i40e_vsi_alloc_q_vector - Allocate memory for a single interrupt vector

 * @vsi: the VSI being configured

 * @v_idx: index of the vector in the vsi struct

 *

 * We allocate one q_vector.  If allocation fails we return -ENOMEM.

 allocate q_vector */

 tie q_vector and vsi together */

/**

 * i40e_vsi_alloc_q_vectors - Allocate memory for interrupt vectors

 * @vsi: the VSI being configured

 *

 * We allocate one q_vector per queue interrupt.  If allocation fails we

 * return -ENOMEM.

 if not MSIX, give the one vector only to the LAN VSI */

/**

 * i40e_init_interrupt_scheme - Determine proper interrupt scheme

 * @pf: board private structure to initialize

 rework the queue expectations without MSIX */

 one MSI or Legacy vector */

 set up vector assignment tracking */

 track first vector for misc interrupts, ignore return */

/**

 * i40e_restore_interrupt_scheme - Restore the interrupt scheme

 * @pf: private board data structure

 *

 * Restore the interrupt scheme that was cleared when we suspended the

 * device. This should be called during resume to re-allocate the q_vectors

 * and reacquire IRQs.

	/* We cleared the MSI and MSI-X flags when disabling the old interrupt

	 * scheme. We need to re-enabled them here in order to attempt to

	 * re-acquire the MSI or MSI-X vectors

	/* Now that we've re-acquired IRQs, we need to remap the vectors and

	 * rings together again.

/**

 * i40e_setup_misc_vector_for_recovery_mode - Setup the misc vector to handle

 * non queue events in recovery mode

 * @pf: board private structure

 *

 * This sets up the handler for MSIX 0 or MSI/legacy, which is used to manage

 * the non-queue interrupts, e.g. AdminQ and errors in recovery mode.

 * This is handled differently than in recovery mode since no Tx/Rx resources

 * are being allocated.

/**

 * i40e_setup_misc_vector - Setup the misc vector to handle non queue events

 * @pf: board private structure

 *

 * This sets up the handler for MSIX 0, which is used to manage the

 * non-queue interrupts, e.g. AdminQ and errors.  This is not used

 * when in MSI or Legacy interrupt mode.

 Only request the IRQ once, the first time through. */

 associate no queues to the misc vector */

/**

 * i40e_get_rss_aq - Get RSS keys and lut by using AQ commands

 * @vsi: Pointer to vsi structure

 * @seed: Buffter to store the hash keys

 * @lut: Buffer to store the lookup table entries

 * @lut_size: Size of buffer to store the lookup table entries

 *

 * Return 0 on success, negative on failure

/**

 * i40e_config_rss_reg - Configure RSS keys and lut by writing registers

 * @vsi: Pointer to vsi structure

 * @seed: RSS hash seed

 * @lut: Lookup table

 * @lut_size: Lookup table size

 *

 * Returns 0 on success, negative on failure

 Fill out hash function seed */

/**

 * i40e_get_rss_reg - Get the RSS keys and lut by reading registers

 * @vsi: Pointer to VSI structure

 * @seed: Buffer to store the keys

 * @lut: Buffer to store the lookup table entries

 * @lut_size: Size of buffer to store the lookup table entries

 *

 * Returns 0 on success, negative on failure

/**

 * i40e_config_rss - Configure RSS keys and lut

 * @vsi: Pointer to VSI structure

 * @seed: RSS hash seed

 * @lut: Lookup table

 * @lut_size: Lookup table size

 *

 * Returns 0 on success, negative on failure

/**

 * i40e_get_rss - Get RSS keys and lut

 * @vsi: Pointer to VSI structure

 * @seed: Buffer to store the keys

 * @lut: Buffer to store the lookup table entries

 * @lut_size: Size of buffer to store the lookup table entries

 *

 * Returns 0 on success, negative on failure

/**

 * i40e_fill_rss_lut - Fill the RSS lookup table with default values

 * @pf: Pointer to board private structure

 * @lut: Lookup table

 * @rss_table_size: Lookup table size

 * @rss_size: Range of queue number for hashing

/**

 * i40e_pf_config_rss - Prepare for RSS if used

 * @pf: board private structure

 By default we enable TCP/UDP with IPv4/IPv6 ptypes */

 Determine the RSS table size based on the hardware capabilities */

 Determine the RSS size of the VSI */

		/* If the firmware does something weird during VSI init, we

		 * could end up with zero TCs. Check for that to avoid

		 * divide-by-zero. It probably won't pass traffic, but it also

		 * won't panic.

 Use user configured lut if there is one, otherwise use default */

	/* Use user configured hash key if there is one, otherwise

	 * use default.

/**

 * i40e_reconfig_rss_queues - change number of queues for rss and rebuild

 * @pf: board private structure

 * @queue_count: the requested queue count for rss.

 *

 * returns 0 if rss is not enabled, if enabled returns the final rss queue

 * count which may be different from the requested queue count.

 * Note: expects to be called while under rtnl_lock()

		/* Discard the user configured hash keys and lut, if less

		 * queues are enabled.

 Reset vsi->rss_size, as number of enabled queues changed */

/**

 * i40e_get_partition_bw_setting - Retrieve BW settings for this PF partition

 * @pf: board private structure

/**

 * i40e_set_partition_bw_setting - Set BW settings for this PF partition

 * @pf: board private structure

 Set the valid bit for this PF */

 Set the new bandwidths */

/**

 * i40e_commit_partition_bw_setting - Commit BW settings for this PF partition

 * @pf: board private structure

 Commit temporary BW setting to permanent NVM image */

 Acquire NVM for read access */

 Read word 0x10 of NVM - SW compatibility word 1 */

	/* Save off last admin queue command status before releasing

	 * the NVM

 Wait a bit for NVM release to complete */

 Acquire NVM for write access */

	/* Write it back out unchanged to initiate update NVM,

	 * which will force a write of the shadow (alt) RAM to

	 * the NVM - thus storing the bandwidth values permanently.

	/* Save off last admin queue command status before releasing

	 * the NVM

/**

 * i40e_is_total_port_shutdown_enabled - read NVM and return value

 * if total port shutdown feature is enabled for this PF

 * @pf: board private structure

/**

 * i40e_sw_init - Initialize general software structures (struct i40e_pf)

 * @pf: board private structure to initialize

 *

 * i40e_sw_init initializes the Adapter private data structure.

 * Fields are initialized based on PCI device information and

 * OS network device settings (MTU size).

 Set default capability flags */

 Set default ITR */

	/* Depending on PF configurations, it is possible that the RSS

	 * maximum might end up larger than the available queues

 find the next higher power-of-2 of num cpus */

 MFP mode enabled */

 nudge the Tx scheduler */

 Supported in FW API version higher than 1.4 */

 Enable HW ATR eviction if possible */

 No DCB support  for FW < v4.33 */

 Disable FW LLDP if FW < v4.3 */

 Use the FW Set LLDP MIB API if FW > v4.40 */

 Enable PTP L4 if FW > v6.0 */

 IWARP needs one extra vector for CQP just like MISC.*/

	/* Stopping FW LLDP engine is supported on XL710 and X722

	 * starting from FW versions determined in i40e_init_adminq.

	 * Stopping the FW LLDP engine is not supported on XL710

	 * if NPAR is functioning so unset this hw flag in this case.

 CONFIG_PCI_IOV */

 By default FW has this off for performance reasons */

 set up queue assignment tracking */

		/* Link down on close must be on when total port shutdown

		 * is enabled for a given port

/**

 * i40e_set_ntuple - set the ntuple feature flag and take action

 * @pf: board private structure to initialize

 * @features: the feature set that the stack is suggesting

 *

 * returns a bool to indicate if reset needs to happen

	/* Check if Flow Director n-tuple support was enabled or disabled.  If

	 * the state changed, we need to reset.

 Enable filters and mark for reset */

		/* enable FD_SB only if there is MSI-X vector and no cloud

		 * filters exist

 turn off filters, mark for reset and clear SW filter list */

 reset fd counters */

 if ATR was auto disabled it can be re-enabled. */

/**

 * i40e_clear_rss_lut - clear the rx hash lookup table

 * @vsi: the VSI being configured

/**

 * i40e_set_features - set the netdev feature flags

 * @netdev: ptr to the netdev being adjusted

 * @features: the feature set that the stack is suggesting

 * Note: expects to be called while under rtnl_lock()

/**

 * i40e_ndo_fdb_add - add an entry to the hardware database

 * @ndm: the input from the stack

 * @tb: pointer to array of nladdr (unused)

 * @dev: the net device pointer

 * @addr: the MAC address entry being added

 * @vid: VLAN ID

 * @flags: instructions from stack about fdb operation

 * @extack: netlink extended ack, unused currently

	/* Hardware does not support aging addresses so if a

	 * ndm_state is given only allow permanent addresses

 Only return duplicate errors if NLM_F_EXCL is set */

/**

 * i40e_ndo_bridge_setlink - Set the hardware bridge mode

 * @dev: the netdev being configured

 * @nlh: RTNL message

 * @flags: bridge flags

 * @extack: netlink extended ack

 *

 * Inserts a new hardware bridge if not already created and

 * enables the bridging mode requested (VEB or VEPA). If the

 * hardware bridge has already been inserted and the request

 * is to change the mode then that requires a PF reset to

 * allow rebuild of the components with required hardware

 * bridge mode enabled.

 *

 * Note: expects to be called while under rtnl_lock()

 Only for PF VSI for now */

 Find the HW bridge for PF VSI */

 Insert a new HW bridge */

 No Bridge HW offload available */

 Existing HW bridge but different mode needs reset */

 TODO: If no VFs or VMDq VSIs, disallow VEB mode */

/**

 * i40e_ndo_bridge_getlink - Get the hardware bridge mode

 * @skb: skb buff

 * @pid: process id

 * @seq: RTNL message seq #

 * @dev: the netdev being configured

 * @filter_mask: unused

 * @nlflags: netlink flags passed in

 *

 * Return the mode in which the hardware bridge is operating in

 * i.e VEB or VEPA.

 Only for PF VSI for now */

 Find the HW bridge for the PF VSI */

/**

 * i40e_features_check - Validate encapsulated packet conforms to limits

 * @skb: skb buff

 * @dev: This physical port's netdev

 * @features: Offload features that the stack believes apply

	/* No point in doing any of this if neither checksum nor GSO are

	 * being requested for this frame.  We can rule out both by just

	 * checking for CHECKSUM_PARTIAL

	/* We cannot support GSO if the MSS is going to be less than

	 * 64 bytes.  If it is then we need to drop support for GSO.

 MACLEN can support at most 63 words */

 IPLEN and EIPLEN can support at most 127 dwords */

 L4TUNLEN can support 127 words */

 IPLEN can support at most 127 dwords */

	/* No need to validate L4LEN as TCP is the only protocol with a

	 * a flexible value and we support all possible values supported

	 * by TCP, which is at most 15 dwords

/**

 * i40e_xdp_setup - add/remove an XDP program

 * @vsi: VSI to changed

 * @prog: XDP program

 * @extack: netlink extended ack

 Don't allow frames that span over multiple buffers */

 When turning XDP on->off/off->on we reset and rebuild the rings. */

 Wait until ndo_xsk_wakeup completes. */

	/* Kick start the NAPI context if there is an AF_XDP socket open

	 * on that queue id. This so that receiving will start.

/**

 * i40e_enter_busy_conf - Enters busy config state

 * @vsi: vsi

 *

 * Returns 0 on success, <0 for failure.

/**

 * i40e_exit_busy_conf - Exits busy config state

 * @vsi: vsi

/**

 * i40e_queue_pair_reset_stats - Resets all statistics for a queue pair

 * @vsi: vsi

 * @queue_pair: queue pair

/**

 * i40e_queue_pair_clean_rings - Cleans all the rings of a queue pair

 * @vsi: vsi

 * @queue_pair: queue pair

		/* Make sure that in-progress ndo_xdp_xmit calls are

		 * completed.

/**

 * i40e_queue_pair_toggle_napi - Enables/disables NAPI for a queue pair

 * @vsi: vsi

 * @queue_pair: queue pair

 * @enable: true for enable, false for disable

 All rings in a qp belong to the same qvector. */

/**

 * i40e_queue_pair_toggle_rings - Enables/disables all rings for a queue pair

 * @vsi: vsi

 * @queue_pair: queue pair

 * @enable: true for enable, false for disable

 *

 * Returns 0 on success, <0 on failure.

is xdp*/, enable);

	/* Due to HW errata, on Rx disable only, the register can

	 * indicate done before it really is. Needs 50ms to be sure

is xdp*/, enable);

/**

 * i40e_queue_pair_enable_irq - Enables interrupts for a queue pair

 * @vsi: vsi

 * @queue_pair: queue_pair

 All rings in a qp belong to the same qvector. */

/**

 * i40e_queue_pair_disable_irq - Disables interrupts for a queue pair

 * @vsi: vsi

 * @queue_pair: queue_pair

	/* For simplicity, instead of removing the qp interrupt causes

	 * from the interrupt linked list, we simply disable the interrupt, and

	 * leave the list intact.

	 *

	 * All rings in a qp belong to the same qvector.

 Legacy and MSI mode - this stops all interrupt handling */

/**

 * i40e_queue_pair_disable - Disables a queue pair

 * @vsi: vsi

 * @queue_pair: queue pair

 *

 * Returns 0 on success, <0 on failure.

 off */);

 off */);

/**

 * i40e_queue_pair_enable - Enables a queue pair

 * @vsi: vsi

 * @queue_pair: queue pair

 *

 * Returns 0 on success, <0 on failure.

 on */);

 on */);

/**

 * i40e_xdp - implements ndo_bpf for i40e

 * @dev: netdevice

 * @xdp: XDP command

/**

 * i40e_config_netdev - Setup the netdev flags

 * @vsi: the VSI being configured

 *

 * Returns 0 on success, negative value on failure

 record features VLANs can make use of */

 enable macvlan offloads */

		/* The following steps are necessary for two reasons. First,

		 * some older NVM configurations load a default MAC-VLAN

		 * filter that will accept any tagged packet, and we want to

		 * replace this with a normal filter. Additionally, it is

		 * possible our MAC address was provided by the platform using

		 * Open Firmware or similar.

		 *

		 * Thus, we need to remove the default filter and install one

		 * specific to the MAC address.

		/* Relate the VSI_VMDQ name to the VSI_MAIN name. Note that we

		 * are still limited by IFNAMSIZ, but we're adding 'v%d\0' to

		 * the end, which is 4 bytes long, so force truncation of the

		 * original name by IFNAMSIZ - 4

	/* Add the broadcast filter so that we initially will receive

	 * broadcast packets. Note that when a new VLAN is first added the

	 * driver will convert all filters marked I40E_VLAN_ANY into VLAN

	 * specific filters as part of transitioning into "vlan" operation.

	 * When more VLANs are added, the driver will copy each existing MAC

	 * filter and add it for the new VLAN.

	 *

	 * Broadcast filters are handled specially by

	 * i40e_sync_filters_subtask, as the driver must to set the broadcast

	 * promiscuous bit instead of adding this directly as a MAC/VLAN

	 * filter. The subtask will update the correct broadcast promiscuous

	 * bits as VLANs become active or inactive.

 i40iw_net_event() reads 16 bytes from neigh->primary_key */

 Setup netdev TC information */

 MTU range: 68 - 9706 */

/**

 * i40e_vsi_delete - Delete a VSI from the switch

 * @vsi: the VSI being removed

 *

 * Returns 0 on success, negative value on failure

 remove default VSI is not allowed */

/**

 * i40e_is_vsi_uplink_mode_veb - Check if the VSI's uplink bridge mode is VEB

 * @vsi: the VSI being queried

 *

 * Returns 1 if HW bridge mode is VEB and return 0 in case of VEPA mode

 Uplink is not a bridge so default to VEB */

 Uplink is a bridge in VEPA mode */

 Uplink is a bridge in VEB mode */

 VEPA is now default bridge, so return 0 */

/**

 * i40e_add_vsi - Add a VSI to the switch

 * @vsi: the VSI being configured

 *

 * This initializes a VSI context depending on the VSI type to be added and

 * passes it down to the add_vsi aq command.

 TC0 enabled */

		/* The PF's main VSI is already setup as part of the

		 * device initialization, so we'll not bother with

		 * the add_vsi call, but we will retrieve the current

		 * VSI context.

		/* Source pruning is enabled by default, so the flag is

		 * negative logic - if it's set, we need to fiddle with

		 * the VSI to disable source pruning.

 MFP mode setup queue map and update VSI */

 NIC type PF */

 update the local VSI info queue map */

			/* Default/Main VSI is only enabled for TC0

			 * reconfigure it to enable all TCs that are

			 * available on the port in SFP mode.

			 * For MFP case the iSCSI PF would use this

			 * flow to enable LAN+iSCSI TC.

				/* Single TC condition is not fatal,

				 * message and continue

		/* This VSI is connected to VEB so the switch_id

		 * should be set to zero by default.

 Setup the VSI tx/rx queue map for TC0 only for now */

		/* This VSI is connected to VEB so the switch_id

		 * should be set to zero by default.

 Setup the VSI tx/rx queue map for TC0 only for now */

 send down message to iWARP */

 If macvlan filters already exist, force them to get loaded */

 Update VSI BW information */

 VSI is already added so not tearing that up */

/**

 * i40e_vsi_release - Delete a VSI and free its resources

 * @vsi: the VSI being removed

 *

 * Returns 0 on success or < 0 on error

 release of a VEB-owner or last VSI is not allowed */

 results in a call to i40e_close() */

 clear the sync flag on all filters */

 make sure any remaining filters are marked for deletion */

	/* If this was the last thing on the VEB, except for the

	 * controlling VSI, remove the VEB, which puts the controlling

	 * VSI onto the next level down in the switch.

	 *

	 * Well, okay, there's one more exception here: don't remove

	 * the orphan VEBs yet.  We'll wait for an explicit remove request

	 * from up the network stack.

 count the VSIs */

 count the VEBs */

/**

 * i40e_vsi_setup_vectors - Set up the q_vectors for the given VSI

 * @vsi: ptr to the VSI

 *

 * This should only be called after i40e_vsi_mem_alloc() which allocates the

 * corresponding SW VSI structure and initializes num_queue_pairs for the

 * newly allocated VSI.

 *

 * Returns 0 on success or negative on failure

	/* In Legacy mode, we do not have to get any other vector since we

	 * piggyback on the misc/ICR0 for queue interrupts.

/**

 * i40e_vsi_reinit_setup - return and reallocate resources for a VSI

 * @vsi: pointer to the vsi.

 *

 * This re-allocates a vsi's queue resources.

 *

 * Returns pointer to the successfully allocated and configured VSI sw struct

 * on success, otherwise returns NULL on failure.

	/* Update the FW view of the VSI. Force a reset of TC and queue

	 * layout configurations.

 assign it some queues */

 map all of the rings to the q_vectors */

/**

 * i40e_vsi_setup - Set up a VSI by a given type

 * @pf: board private structure

 * @type: VSI type

 * @uplink_seid: the switch element to link to

 * @param1: usage depends upon VSI type. For VF types, indicates VF id

 *

 * This allocates the sw VSI structure and its queue resources, then add a VSI

 * to the identified VEB.

 *

 * Returns pointer to the successfully allocated and configure VSI sw struct on

 * success, otherwise returns NULL on failure.

	/* The requested uplink_seid must be either

	 *     - the PF's port seid

	 *              no VEB is needed because this is the PF

	 *              or this is a Flow Director special case VSI

	 *     - seid of an existing VEB

	 *     - seid of a VSI that owns an existing VEB

	 *     - seid of a VSI that doesn't own a VEB

	 *              a new VEB is created and the VSI becomes the owner

	 *     - seid of the PF VSI, which is what creates the first VEB

	 *              this is a special case of the previous

	 *

	 * Find which uplink_seid we were given and create a new VEB if needed

			/* We come up by default in VEPA mode if SRIOV is not

			 * already enabled, in which case we can't force VEPA

			 * mode.

 get vsi sw struct */

 assign it some queues */

 get a VSI from the hardware */

 setup the netdev if needed */

 Setup DCB netlink interface */

 CONFIG_I40E_DCB */

 set up vectors and rings if needed */

 map all of the rings to the q_vectors */

 no netdev or rings for the other VSI types */

/**

 * i40e_veb_get_bw_info - Query VEB BW information

 * @veb: the veb to query

 *

 * Query the Tx scheduler BW configuration data for given VEB

/**

 * i40e_veb_mem_alloc - Allocates the next available struct veb in the PF

 * @pf: board private structure

 *

 * On error: returns error code (negative)

 * On success: returns vsi index in PF (positive)

 Need to protect the allocation of switch elements at the PF level */

	/* VEB list may be fragmented if VEB creation/destruction has

	 * been happening.  We can afford to do a quick scan to look

	 * for any free slots in the list.

	 *

	 * find next empty veb slot, looping back around if necessary

 out of VEB slots! */

/**

 * i40e_switch_branch_release - Delete a branch of the switch tree

 * @branch: where to start deleting

 *

 * This uses recursion to find the tips of the branch to be

 * removed, deleting until we get back to and can delete this VEB.

 release any VEBs on this VEB - RECURSION */

	/* Release the VSIs on this VEB, but not the owner VSI.

	 *

	 * NOTE: Removing the last VSI on a VEB has the SIDE EFFECT of removing

	 *       the VEB itself, so don't use (*branch) after this loop.

	/* There's one corner case where the VEB might not have been

	 * removed, so double check it here and remove it if needed.

	 * This case happens if the veb was created from the debugfs

	 * commands and no VSIs were added to it.

/**

 * i40e_veb_clear - remove veb struct

 * @veb: the veb to remove

/**

 * i40e_veb_release - Delete a VEB and free its resources

 * @veb: the VEB being removed

 find the remaining VSI and check for extras */

 move the remaining VSI to uplink veb */

 floating VEB */

/**

 * i40e_add_veb - create the VEB in the switch

 * @veb: the VEB to be instantiated

 * @vsi: the controlling VSI

 get a VEB from the hardware */

 get statistics counter */

/**

 * i40e_veb_setup - Set up a VEB

 * @pf: board private structure

 * @flags: VEB setup flags

 * @uplink_seid: the switch element to link to

 * @vsi_seid: the initial VSI seid

 * @enabled_tc: Enabled TC bit-map

 *

 * This allocates the sw VEB structure and links it into the switch

 * It is possible and legal for this to be a duplicate of an already

 * existing VEB.  It is also possible for both uplink and vsi seids

 * to be zero, in order to create a floating VEB.

 *

 * Returns pointer to the successfully allocated VEB sw struct on

 * success, otherwise returns NULL on failure.

 if one seid is 0, the other must be 0 to create a floating relay */

 make sure there is such a vsi and uplink */

 get veb sw struct */

 create the VEB in the switch */

/**

 * i40e_setup_pf_switch_element - set PF vars based on switch type

 * @pf: board private structure

 * @ele: element we are building info from

 * @num_reported: total number of elements

 * @printconfig: should we print the contents

 *

 * helper function to assist in extracting a few useful SEID values.

 Main VEB? */

 find existing or else empty VEB */

		/* This is immediately after a reset so we can assume this is

		 * the PF's VSI

 ignore these for now */

/**

 * i40e_fetch_switch_configuration - Get switch config from firmware

 * @pf: board private structure

 * @printconfig: should we print the contents

 *

 * Get the current switch configuration from the device and

 * extract a few useful SEID values.

/**

 * i40e_setup_pf_switch - Setup the HW switch on startup or after reset

 * @pf: board private structure

 * @reinit: if the Main VSI needs to re-initialized.

 * @lock_acquired: indicates whether or not the lock has been acquired

 *

 * Returns 0 on success, negative value on failure

 find out what's out there already */

	/* set the switch config bit for the whole device to

	 * support limited promisc or true promisc

	 * when user requests promisc. The default is limited

	 * promisc.

 not a fatal problem, just keep going */

 first time setup */

		/* Set up the PF VSI associated with the PF's main VSI

		 * that is already in the HW switch

 force a reset of TC and queue layout configurations */

 Setup static PF queue filter control settings */

 Failure here should not stop continuing other steps */

	/* enable RSS in the HW, even for only one queue, as the stack can use

	 * the hash

 fill in link information and enable LSE reporting */

 Initialize user-specific link properties */

 repopulate tunnel port filters */

/**

 * i40e_determine_queue_usage - Work out queue distribution

 * @pf: board private structure

	/* Find the max queues to be put into basic use.  We'll always be

	 * using TC0, whether or not DCB is running, and TC0 will get the

	 * big RSS set.

 one qp for PF, no queues for anything else */

 make sure all the fancies are disabled */

 one qp for PF */

 Not enough queues for all TCs */

 limit lan qps to the smaller of qps, cpus or msix */

 save 1 queue for FD */

/**

 * i40e_setup_pf_filter_control - Setup PF static filter control

 * @pf: PF to be setup

 *

 * i40e_setup_pf_filter_control sets up a PF's initial filter control

 * settings. If PE/FCoE are enabled then it will also set the per PF

 * based filter sizes required for them. It also enables Flow director,

 * ethertype and macvlan type filter settings for the pf.

 *

 * Returns 0 on success, negative on failure

 Flow Director is enabled */

 Ethtype and MACVLAN filters enabled for PF */

/**

 * i40e_get_platform_mac_addr - get platform-specific MAC address

 * @pdev: PCI device information struct

 * @pf: board private structure

 *

 * Look up the MAC address for the device. First we'll try

 * eth_platform_get_mac_address, which will check Open Firmware, or arch

 * specific fallback. Otherwise, we'll default to the stored value in

 * firmware.

/**

 * i40e_set_fec_in_flags - helper function for setting FEC options in flags

 * @fec_cfg: FEC option to set in flags

 * @flags: ptr to flags in which we set FEC option

/**

 * i40e_check_recovery_mode - check if we are running transition firmware

 * @pf: board private structure

 *

 * Check registers indicating the firmware runs in recovery mode. Sets the

 * appropriate driver state.

 *

 * Returns true if the recovery mode was detected, false otherwise

/**

 * i40e_pf_loop_reset - perform reset in a loop.

 * @pf: board private structure

 *

 * This function is useful when a NIC is about to enter recovery mode.

 * When a NIC's internal data structures are corrupted the NIC's

 * firmware is going to enter recovery mode.

 * Right after a POR it takes about 7 minutes for firmware to enter

 * recovery mode. Until that time a NIC is in some kind of intermediate

 * state. After that time period the NIC almost surely enters

 * recovery mode. The only way for a driver to detect intermediate

 * state is to issue a series of pf-resets and check a return value.

 * If a PF reset returns success then the firmware could be in recovery

 * mode so the caller of this code needs to check for recovery mode

 * if this function returns success. There is a little chance that

 * firmware will hang in intermediate state forever.

 * Since waiting 7 minutes is quite a lot of time this function waits

 * 10 seconds and then gives up by returning an error.

 *

 * Return 0 on success, negative on failure.

 wait max 10 seconds for PF reset to succeed */

/**

 * i40e_check_fw_empr - check if FW issued unexpected EMP Reset

 * @pf: board private structure

 *

 * Check FW registers to determine if FW issued unexpected EMP Reset.

 * Every time when unexpected EMP Reset occurs the FW increments

 * a counter of unexpected EMP Resets. When the counter reaches 10

 * the FW should enter the Recovery mode

 *

 * Returns true if FW issued unexpected EMP Reset

/**

 * i40e_handle_resets - handle EMP resets and PF resets

 * @pf: board private structure

 *

 * Handle both EMP resets and PF resets and conclude whether there are

 * any issues regarding these resets. If there are any issues then

 * generate log entry.

 *

 * Return 0 if NIC is healthy or negative value when there are issues

 * with resets

/**

 * i40e_init_recovery_mode - initialize subsystems needed in recovery mode

 * @pf: board private structure

 * @hw: ptr to the hardware info

 *

 * This function does a minimal setup of all subsystems needed for running

 * recovery mode.

 *

 * Returns 0 on success, negative on failure

 set up periodic task facility */

	/* The number of VSIs reported by the FW is the minimum guaranteed

	 * to us; HW supports far more and we share the remaining pool with

	 * the other PFs. We allocate space for more than the guarantee with

	 * the understanding that we might not get them all later.

 Set up the vsi struct and our local tracking of the MAIN PF vsi. */

	/* We allocate one VSI which is needed as absolute minimum

	 * in order to register the netdev

 tell the firmware that we're starting */

 since everything's happy, start the service_task timer */

/**

 * i40e_set_subsystem_device_id - set subsystem device id

 * @hw: pointer to the hardware info

 *

 * Set PCI subsystem device id either from a pci_dev structure or

 * a specific FW register.

/**

 * i40e_probe - Device initialization routine

 * @pdev: PCI device information struct

 * @ent: entry in i40e_pci_tbl

 *

 * i40e_probe initializes a PF identified by a pci_dev structure.

 * The OS initialization, configuring of the PF private structure,

 * and a hardware reset occur.

 *

 * Returns 0 on success, negative on failure

 CONFIG_I40E_DCB */

 set up for high or low dma */

 set up pci connections */

	/* Now that we have a PCI connection, we need to do the

	 * low level device setup.  This is primarily setting up

	 * the Admin Queue structures and then querying for the

	 * device's current profile information.

	/* We believe that the highest register to read is

	 * I40E_GLGEN_STAT_CLEAR, so we check if the BAR size

	 * is not less than that before mapping to prevent a

	 * kernel panic.

	/* Select something other than the 802.1ad ethertype for the

	 * switch to use internally and drop on ingress.

	/* set up the locks for the AQ, do this only once in probe

	 * and destroy them only once in remove

 do a special CORER for clearing PXE mode once at init */

 Reset here to make sure all is clean and to define PF 'n' */

 set up a default setting for link flow control */

 provide nvm, fw, api versions, vendor:device id, subsys vendor:device id */

 Rev 0 hardware was never productized */

	/* Disable LLDP for NICs that have firmware versions lower than v4.3.

	 * Ignore error return codes because if it was already disabled via

	 * hardware settings this will fail

 allow a platform config to override the HW addr */

 Enable FW to write default DCB config on link-up */

 Continue without DCB enabled */

 CONFIG_I40E_DCB */

 set up periodic task facility */

 NVM bit on means WoL disabled for the port */

 set up the main switch operations */

	/* Reduce Tx and Rx pairs for kdump

	 * When MSI-X is enabled, it's not allowed to use more TC queue

	 * pairs than MSI-X vectors (pf->num_lan_msix) exist. Thus

	 * vsi->num_queue_pairs will be equal to pf->num_lan_msix, i.e., 1.

	/* The number of VSIs reported by the FW is the minimum guaranteed

	 * to us; HW supports far more and we share the remaining pool with

	 * the other PFs. We allocate space for more than the guarantee with

	 * the understanding that we might not get them all later.

 Set up the *vsi struct and our local tracking of the MAIN PF vsi. */

 prep for VF support */

 if FDIR VSI was set up, start it now */

	/* The driver only wants link up/down and module qualification

	 * reports from firmware.  Note the negative logic.

	/* Reconfigure hardware for allowing smaller MSS in the case

	 * of TSO, so that we avoid the MDD being fired and causing

	 * a reset in the case of small MSS+TSO.

	/* The main driver is (mostly) up and happy. We need to set this state

	 * before setting up the misc vector or we get a race and the vector

	 * ends up disabled forever.

	/* In case of MSIX we are going to setup the misc vector right here

	 * to handle admin queue events etc. In case of legacy and MSI

	 * the misc functionality and queue processing is combined in

	 * the same vector and that gets setup at open.

 prep for VF support */

 disable link interrupts for VFs */

 CONFIG_PCI_IOV */

 tell the firmware that we're starting */

 since everything's happy, start the service_task timer */

 add this PF to client device list and launch a client service task */

	/* Devices on the IOSF bus do not have this information

	 * and will report PCI Gen 1 x 1 by default so don't bother

	 * checking them.

		/* Get the negotiated link width and speed from PCI config

		 * space

 get the requested speeds from the fw */

 set the FEC config due to the board capabilities */

 get the supported phy types from the fw */

 make sure the MFS hasn't been set lower than the default */

	/* Add a filter to drop all Flow control frames from any VSI from being

	 * transmitted. By doing so we stop a malicious VF from sending out

	 * PAUSE or PFC frames and potentially controlling traffic for other

	 * PF/VF VSIs.

	 * The FW can still send Flow control frames if enabled.

 print a string summarizing features */

 Unwind what we've done if something failed in the setup */

/**

 * i40e_remove - Device removal routine

 * @pdev: PCI device information struct

 *

 * i40e_remove is called by the PCI subsystem to alert the driver

 * that is should release a PCI device.  This could be caused by a

 * Hot-Plug event, or because the driver is going to be removed from

 * memory.

 Disable RSS in hw */

 no more scheduling of any task */

		/* We know that we have allocated only one vsi for this PF,

		 * it was just for registering netdevice, so the interface

		 * could be visible in the 'ifconfig' output

	/* Client close must be called explicitly here because the timer

	 * has been stopped.

	/* If there is a switch structure or any orphans, remove them.

	 * This will leave only the PF's VSI remaining.

	/* Now we can shutdown the PF's VSI, just before we kill

	 * adminq and hmc.

 remove attached clients */

 shutdown and destroy the HMC */

 Free MSI/legacy interrupt 0 when in recovery mode. */

 shutdown the adminq */

 destroy the locks only once, here */

 Clear all dynamic memory lists of rings, q_vectors, and VSIs */

/**

 * i40e_pci_error_detected - warning that something funky happened in PCI land

 * @pdev: PCI device information struct

 * @error: the type of PCI error

 *

 * Called to warn that something happened and the error handling steps

 * are in progress.  Allows the driver to quiesce things, be ready for

 * remediation.

 shutdown all operations */

 Request a slot reset */

/**

 * i40e_pci_error_slot_reset - a PCI slot reset just happened

 * @pdev: PCI device information struct

 *

 * Called to find if the driver can work with the device now that

 * the pci slot has been reset.  If a basic connection seems good

 * (registers are readable and have sane content) then return a

 * happy little PCI_ERS_RESULT_xxx.

/**

 * i40e_pci_error_reset_prepare - prepare device driver for pci reset

 * @pdev: PCI device information struct

/**

 * i40e_pci_error_reset_done - pci reset done, device driver reset can begin

 * @pdev: PCI device information struct

/**

 * i40e_pci_error_resume - restart operations after PCI error recovery

 * @pdev: PCI device information struct

 *

 * Called to allow the driver to bring things back up after PCI error

 * and/or reset recovery has finished.

/**

 * i40e_enable_mc_magic_wake - enable multicast magic packet wake up

 * using the mac_address_write admin q function

 * @pf: pointer to i40e_pf struct

 Get current MAC address in case it's an LAA */

	/* The FW expects the mac address write cmd to first be called with

	 * one of these flags before calling it again with the multicast

	 * enable flags.

/**

 * i40e_shutdown - PCI callback for shutting down

 * @pdev: PCI device information struct

	/* Client close must be called explicitly here because the timer

	 * has been stopped.

 Free MSI/legacy interrupt 0 when in recovery mode. */

	/* Since we're going to destroy queues during the

	 * i40e_clear_interrupt_scheme() we should hold the RTNL lock for this

	 * whole section

/**

 * i40e_suspend - PM callback for moving to D3

 * @dev: generic device information structure

 If we're already suspended, then there is nothing to do */

 Ensure service task will not be running */

	/* Client close must be called explicitly here because the timer

	 * has been stopped.

	/* Since we're going to destroy queues during the

	 * i40e_clear_interrupt_scheme() we should hold the RTNL lock for this

	 * whole section

	/* Clear the interrupt scheme and release our IRQs so that the system

	 * can safely hibernate even when there are a large number of CPUs.

	 * Otherwise hibernation might fail when mapping all the vectors back

	 * to CPU0.

/**

 * i40e_resume - PM callback for waking up from D3

 * @dev: generic device information structure

 If we're not suspended, then there is nothing to do */

	/* We need to hold the RTNL lock prior to restoring interrupt schemes,

	 * since we're going to be restoring queues

	/* We cleared the interrupt scheme when we suspended, so we need to

	 * restore it now to resume device functionality.

 Clear suspended state last after everything is recovered */

 Restart the service task */

/**

 * i40e_init_module - Driver registration routine

 *

 * i40e_init_module is the first routine called when the driver is

 * loaded. All it does is register with the PCI subsystem.

	/* There is no need to throttle the number of active tasks because

	 * each device limits its own task using a state bit for scheduling

	 * the service task, and the device tasks do not interfere with each

	 * other, so we don't set a max task limit. We must set WQ_MEM_RECLAIM

	 * since we need to be able to guarantee forward progress even under

	 * memory pressure.

/**

 * i40e_exit_module - Driver exit cleanup routine

 *

 * i40e_exit_module is called just before the driver is removed

 * from memory.

