/* SPDX-License-Identifier: GPL-2.0

 *

 * IO cost model based controller.

 *

 * Copyright (C) 2019 Tejun Heo <tj@kernel.org>

 * Copyright (C) 2019 Andy Newell <newella@fb.com>

 * Copyright (C) 2019 Facebook

 *

 * One challenge of controlling IO resources is the lack of trivially

 * observable cost metric.  This is distinguished from CPU and memory where

 * wallclock time and the number of bytes can serve as accurate enough

 * approximations.

 *

 * Bandwidth and iops are the most commonly used metrics for IO devices but

 * depending on the type and specifics of the device, different IO patterns

 * easily lead to multiple orders of magnitude variations rendering them

 * useless for the purpose of IO capacity distribution.  While on-device

 * time, with a lot of clutches, could serve as a useful approximation for

 * non-queued rotational devices, this is no longer viable with modern

 * devices, even the rotational ones.

 *

 * While there is no cost metric we can trivially observe, it isn't a

 * complete mystery.  For example, on a rotational device, seek cost

 * dominates while a contiguous transfer contributes a smaller amount

 * proportional to the size.  If we can characterize at least the relative

 * costs of these different types of IOs, it should be possible to

 * implement a reasonable work-conserving proportional IO resource

 * distribution.

 *

 * 1. IO Cost Model

 *

 * IO cost model estimates the cost of an IO given its basic parameters and

 * history (e.g. the end sector of the last IO).  The cost is measured in

 * device time.  If a given IO is estimated to cost 10ms, the device should

 * be able to process ~100 of those IOs in a second.

 *

 * Currently, there's only one builtin cost model - linear.  Each IO is

 * classified as sequential or random and given a base cost accordingly.

 * On top of that, a size cost proportional to the length of the IO is

 * added.  While simple, this model captures the operational

 * characteristics of a wide varienty of devices well enough.  Default

 * parameters for several different classes of devices are provided and the

 * parameters can be configured from userspace via

 * /sys/fs/cgroup/io.cost.model.

 *

 * If needed, tools/cgroup/iocost_coef_gen.py can be used to generate

 * device-specific coefficients.

 *

 * 2. Control Strategy

 *

 * The device virtual time (vtime) is used as the primary control metric.

 * The control strategy is composed of the following three parts.

 *

 * 2-1. Vtime Distribution

 *

 * When a cgroup becomes active in terms of IOs, its hierarchical share is

 * calculated.  Please consider the following hierarchy where the numbers

 * inside parentheses denote the configured weights.

 *

 *           root

 *         /       \

 *      A (w:100)  B (w:300)

 *      /       \

 *  A0 (w:100)  A1 (w:100)

 *

 * If B is idle and only A0 and A1 are actively issuing IOs, as the two are

 * of equal weight, each gets 50% share.  If then B starts issuing IOs, B

 * gets 300/(100+300) or 75% share, and A0 and A1 equally splits the rest,

 * 12.5% each.  The distribution mechanism only cares about these flattened

 * shares.  They're called hweights (hierarchical weights) and always add

 * upto 1 (WEIGHT_ONE).

 *

 * A given cgroup's vtime runs slower in inverse proportion to its hweight.

 * For example, with 12.5% weight, A0's time runs 8 times slower (100/12.5)

 * against the device vtime - an IO which takes 10ms on the underlying

 * device is considered to take 80ms on A0.

 *

 * This constitutes the basis of IO capacity distribution.  Each cgroup's

 * vtime is running at a rate determined by its hweight.  A cgroup tracks

 * the vtime consumed by past IOs and can issue a new IO if doing so

 * wouldn't outrun the current device vtime.  Otherwise, the IO is

 * suspended until the vtime has progressed enough to cover it.

 *

 * 2-2. Vrate Adjustment

 *

 * It's unrealistic to expect the cost model to be perfect.  There are too

 * many devices and even on the same device the overall performance

 * fluctuates depending on numerous factors such as IO mixture and device

 * internal garbage collection.  The controller needs to adapt dynamically.

 *

 * This is achieved by adjusting the overall IO rate according to how busy

 * the device is.  If the device becomes overloaded, we're sending down too

 * many IOs and should generally slow down.  If there are waiting issuers

 * but the device isn't saturated, we're issuing too few and should

 * generally speed up.

 *

 * To slow down, we lower the vrate - the rate at which the device vtime

 * passes compared to the wall clock.  For example, if the vtime is running

 * at the vrate of 75%, all cgroups added up would only be able to issue

 * 750ms worth of IOs per second, and vice-versa for speeding up.

 *

 * Device business is determined using two criteria - rq wait and

 * completion latencies.

 *

 * When a device gets saturated, the on-device and then the request queues

 * fill up and a bio which is ready to be issued has to wait for a request

 * to become available.  When this delay becomes noticeable, it's a clear

 * indication that the device is saturated and we lower the vrate.  This

 * saturation signal is fairly conservative as it only triggers when both

 * hardware and software queues are filled up, and is used as the default

 * busy signal.

 *

 * As devices can have deep queues and be unfair in how the queued commands

 * are executed, soley depending on rq wait may not result in satisfactory

 * control quality.  For a better control quality, completion latency QoS

 * parameters can be configured so that the device is considered saturated

 * if N'th percentile completion latency rises above the set point.

 *

 * The completion latency requirements are a function of both the

 * underlying device characteristics and the desired IO latency quality of

 * service.  There is an inherent trade-off - the tighter the latency QoS,

 * the higher the bandwidth lossage.  Latency QoS is disabled by default

 * and can be set through /sys/fs/cgroup/io.cost.qos.

 *

 * 2-3. Work Conservation

 *

 * Imagine two cgroups A and B with equal weights.  A is issuing a small IO

 * periodically while B is sending out enough parallel IOs to saturate the

 * device on its own.  Let's say A's usage amounts to 100ms worth of IO

 * cost per second, i.e., 10% of the device capacity.  The naive

 * distribution of half and half would lead to 60% utilization of the

 * device, a significant reduction in the total amount of work done

 * compared to free-for-all competition.  This is too high a cost to pay

 * for IO control.

 *

 * To conserve the total amount of work done, we keep track of how much

 * each active cgroup is actually using and yield part of its weight if

 * there are other cgroups which can make use of it.  In the above case,

 * A's weight will be lowered so that it hovers above the actual usage and

 * B would be able to use the rest.

 *

 * As we don't want to penalize a cgroup for donating its weight, the

 * surplus weight adjustment factors in a margin and has an immediate

 * snapback mechanism in case the cgroup needs more IO vtime for itself.

 *

 * Note that adjusting down surplus weights has the same effects as

 * accelerating vtime for other cgroups and work conservation can also be

 * implemented by adjusting vrate dynamically.  However, squaring who can

 * donate and should take back how much requires hweight propagations

 * anyway making it easier to implement and understand as a separate

 * mechanism.

 *

 * 3. Monitoring

 *

 * Instead of debugfs or other clumsy monitoring mechanisms, this

 * controller uses a drgn based monitoring script -

 * tools/cgroup/iocost_monitor.py.  For details on drgn, please see

 * https://github.com/osandov/drgn.  The output looks like the following.

 *

 *  sdb RUN   per=300ms cur_per=234.218:v203.695 busy= +1 vrate= 62.12%

 *                 active      weight      hweight% inflt% dbt  delay usages%

 *  test/a              *    50/   50  33.33/ 33.33  27.65   2  0*041 033:033:033

 *  test/b              *   100/  100  66.67/ 66.67  17.56   0  0*000 066:079:077

 *

 * - per	: Timer period

 * - cur_per	: Internal wall and device vtime clock

 * - vrate	: Device virtual time rate against wall clock

 * - weight	: Surplus-adjusted and configured weights

 * - hweight	: Surplus-adjusted and configured hierarchical weights

 * - inflt	: The percentage of in-flight IO cost at the end of last period

 * - del_ms	: Deferred issuer delay induction level and duration

 * - usages	: Usage history

 copied from TRACE_CGROUP_PATH, see cgroup-internal.h */

 CONFIG_TRACE_POINTS */

 CONFIG_TRACE_POINTS */

 timer period is calculated from latency requirements, bound it */

	/*

	 * iocg->vtime is targeted at 50% behind the device vtime, which

	 * serves as its IO credit buffer.  Surplus weight adjustment is

	 * immediately canceled if the vtime margin runs below 10%.

 Have some play in timer operations */

 1/64k is granular enough and can easily be handled w/ u32 */

	/*

	 * As vtime is used to calculate the cost of each IO, it needs to

	 * be fairly high precision.  For example, it should be able to

	 * represent the cost of a single page worth of discard with

	 * suffificient accuracy.  At the same time, it should be able to

	 * represent reasonably long enough durations to be useful and

	 * convenient during operation.

	 *

	 * 1s worth of vtime is 2^37.  This gives us both sub-nanosecond

	 * granularity and days of wrap-around time even at extreme vrates.

 bound vrate adjustments within two orders of magnitude */

 1% */

 10000% */

 if IOs end up waiting for requests, issue less */

 unbusy hysterisis */

	/*

	 * The effect of delay is indirect and non-linear and a huge amount of

	 * future debt can accumulate abruptly while unthrottled. Linearly scale

	 * up delay as debt is going up and then let it decay exponentially.

	 * This gives us quick ramp ups while delay is accumulating and long

	 * tails which can help reducing the frequency of debt explosions on

	 * unthrottle. The parameters are experimentally determined.

	 *

	 * The delay mechanism provides adequate protection and behavior in many

	 * cases. However, this is far from ideal and falls shorts on both

	 * fronts. The debtors are often throttled too harshly costing a

	 * significant level of fairness and possibly total work while the

	 * protection against their impacts on the system can be choppy and

	 * unreliable.

	 *

	 * The shortcoming primarily stems from the fact that, unlike for page

	 * cache, the kernel doesn't have well-defined back-pressure propagation

	 * mechanism and policies for anonymous memory. Fully addressing this

	 * issue will likely require substantial improvements in the area.

 halve debts if avg usage over 100ms is under 50% */

 don't let cmds which take a very long time pin lagging for too long */

 switch iff the conditions are met for longer than this */

	/*

	 * Count IO size in 4k pages.  The 12bit shift helps keeping

	 * size-proportional components of cost calculation in closer

	 * numbers of digits to per-IO cost components.

 if apart further than 16M, consider randio for linear model */

 io.cost.qos controls including per-dev enable of the whole controller */

 io.cost.qos params */

 io.cost.model controls */

 builtin linear cost model coefficients */

 per device */

 active cgroups */

 wallclock starttime */

 vtime starttime */

 inc'd each period */

 saturation history */

 for lazy hweights */

 debt forgivness */

 per device-cgroup pair */

	/*

	 * A iocg can get its weight from two sources - an explicit

	 * per-device-cgroup configuration or the default weight of the

	 * cgroup.  `cfg_weight` is the explicit per-device-cgroup

	 * configuration.  `weight` is the effective considering both

	 * sources.

	 *

	 * When an idle cgroup becomes active its `active` goes from 0 to

	 * `weight`.  `inuse` is the surplus adjusted active weight.

	 * `active` and `inuse` are used to calculate `hweight_active` and

	 * `hweight_inuse`.

	 *

	 * `last_inuse` remembers `inuse` while an iocg is idle to persist

	 * surplus adjustments.

	 *

	 * `inuse` may be adjusted dynamically during period. `saved_*` are used

	 * to determine and track adjustments.

 to detect randio */

	/*

	 * `vtime` is this iocg's vtime cursor which progresses as IOs are

	 * issued.  If lagging behind device vtime, the delta represents

	 * the currently available IO budget.  If running ahead, the

	 * overage.

	 *

	 * `vtime_done` is the same but progressed on completion rather

	 * than issue.  The delta behind `vtime` represents the cost of

	 * currently in-flight IOs.

 current delay in effect and when it started */

	/*

	 * The period this iocg was last active in.  Used for deactivation

	 * and invalidating `vtime`.

 see __propagate_weights() and current_hweight() for details */

 timestamp at the latest activation */

 statistics */

 this iocg's depth in the hierarchy and ancestors including self */

 per cgroup */

 250ms */

 25ms */

 25ms */

 5ms */

/*

 * vrate adjust percentages indexed by ioc->busy_level.  We adjust up on

 * vtime credit shortage and down on device saturation.

 accessors and helpers */

/*

 * Scale @abs_cost to the inverse of @hw_inuse.  The lower the hierarchical

 * weight, the more expensive each IO.  Must round up.

/*

 * The inverse of abs_cost_to_cost().  Must round up.

 latency Qos params changed, update period_us and all the dependent params */

 pick the higher latency target */

	/*

	 * We want the period to be long enough to contain a healthy number

	 * of IOs while short enough for granular control.  Define it as a

	 * multiple of the latency target.  Ideally, the multiplier should

	 * be scaled according to the percentile so that it would nominally

	 * contain a certain number of requests.  Let's be simpler and

	 * scale it linearly so that it's 2x >= pct(90) and 10x at pct(50).

 calculate dependent params */

 rotational? */

 handle SATA SSDs w/ broken NCQ */

 use one of the normal ssd sets */

 if user is overriding anything, maintain what was there */

 step up/down based on the vrate */

/*

 * Take the followings as input

 *

 *  @bps	maximum sequential throughput

 *  @seqiops	maximum sequential 4k iops

 *  @randiops	maximum random 4k iops

 *

 * and calculate the linear model cost coefficients.

 *

 *  *@page	per-page cost		1s / (@bps / 4096)

 *  *@seqio	base cost of a seq IO	max((1s / @seqiops) - *@page, 0)

 *  @randiops	base cost of a rand IO	max((1s / @randiops) - *@page, 0)

/*

 * When an iocg accumulates too much vtime or gets deactivated, we throw away

 * some vtime, which lowers the overall device utilization. As the exact amount

 * which is being thrown away is known, we can compensate by accelerating the

 * vrate accordingly so that the extra vtime generated in the current period

 * matches what got lost.

 we need some time left in this period */

	/*

	 * Calculate how much vrate should be adjusted to offset the error.

	 * Limit the amount of adjustment and deduct the adjusted amount from

	 * the error.

 bound how much error can accumulate */

	/*

	 * If vrate is out of bounds, apply clamp gradually as the

	 * bounds can change abruptly.  Otherwise, apply busy_level

	 * based adjustment.

 take a snapshot of the current [v]time and vrate */

	/*

	 * The current vtime is

	 *

	 *   vtime at period start + (wallclock time since the start) * vrate

	 *

	 * As a consistent snapshot of `period_at_vtime` and `period_at` is

	 * needed, they're seqcount protected.

/*

 * Update @iocg's `active` and `inuse` to @active and @inuse, update level

 * weight sums and propagate upwards accordingly. If @save, the current margin

 * is saved to be used as reference for later inuse in-period adjustments.

	/*

	 * For an active leaf node, its inuse shouldn't be zero or exceed

	 * @active. An active internal node's inuse is solely determined by the

	 * inuse to active ratio of its children regardless of @inuse.

 update the level sums */

 apply the updates */

		/*

		 * The delta between inuse and active sums indicates that

		 * much of weight is being given away.  Parent's inuse

		 * and active should reflect the ratio.

 do we need to keep walking up? */

 paired with rmb in current_hweight(), see there */

 hot path - if uptodate, use cached */

	/*

	 * Paired with wmb in commit_weights(). If we saw the updated

	 * hweight_gen, all the weight updates from __propagate_weights() are

	 * visible too.

	 *

	 * We can race with weight updates during calculation and get it

	 * wrong.  However, hweight_gen would have changed and a future

	 * reader will recalculate and we're guaranteed to discard the

	 * wrong result soon.

 we can race with deactivations and either may read as zero */

/*

 * Calculate the hweight_inuse @iocg would get with max @inuse assuming all the

 * other weights stay unchanged.

	/*

	 * If seem to be already active, just update the stamp to tell the

	 * timer that we're still active.  We don't mind occassional races.

 racy check on internal node IOs, treat as root level IOs */

 update period */

 already activated or breaking leaf-only constraint? */

	/*

	 * Always start with the target budget. On deactivation, we throw away

	 * anything above it.

	/*

	 * Activate, propagate weight and start period timer if not

	 * running.  Reset hweight_gen to avoid accidental match from

	 * wrapping.

 calculate the current delay in effect - 1/2 every second */

 calculate the new delay from the debt amount */

 pick the higher one and apply */

	/*

	 * Once in debt, debt handling owns inuse. @iocg stays at the minimum

	 * inuse donating all of it share to others until its debt is paid off.

 make sure that nobody messed with @iocg */

 if debt is paid in full, restore inuse */

	/*

	 * autoremove_wake_function() removes the wait entry only when it

	 * actually changed the task state. We want the wait always removed.

	 * Remove explicitly and use default_wake_function(). Note that the

	 * order of operations is important as finish_wait() tests whether

	 * @wq_entry is removed without grabbing the lock.

/*

 * Calculate the accumulated budget, pay debt if @pay_debt and wake up waiters

 * accordingly. When @pay_debt is %true, the caller must be holding ioc->lock in

 * addition to iocg->waitq.lock.

 pay off debt */

	/*

	 * Debt can still be outstanding if we haven't paid all yet or the

	 * caller raced and called without @pay_debt. Shouldn't wake up waiters

	 * under debt. Make sure @vbudget reflects the outstanding amount and is

	 * not positive.

	/*

	 * Wake up the ones which are due and see how much vtime we'll need for

	 * the next one. As paying off debt restores hw_inuse, it must be read

	 * after the above debt payment.

 determine next wakeup, add a timer margin to guarantee chunking */

 if already active and close enough, don't bother */

 was iocg idle this period? */

 did something get issued this period? */

 is something in flight? */

/*

 * Call this function on the target leaf @iocg's to build pre-order traversal

 * list of all the ancestors in @inner_walk. The inner nodes are linked through

 * ->walk_list and the caller is responsible for dissolving the list after use.

 find the first ancestor which hasn't been visited yet */

 walk down and visit the inner nodes to get pre-order traversal */

 record traversal order */

 collect per-cpu counters and propagate the deltas to the parent */

 collect per-cpu counters */

 propagate upwards */

 propagate the deltas to the parent */

 get stat counters ready for reading on all active iocgs */

 flush leaves and build inner node walk list */

 keep flushing upwards by walking the inner list backwards */

/*

 * Determine what @iocg's hweight_inuse should be after donating unused

 * capacity. @hwm is the upper bound and used to signal no donation. This

 * function also throws away @iocg's excess budget.

 debt handling owns inuse for debtors */

 see whether minimum margin requirement is met */

 throw away excess above target */

	/*

	 * Let's say the distance between iocg's and device's vtimes as a

	 * fraction of period duration is delta. Assuming that the iocg will

	 * consume the usage determined above, we want to determine new_hwi so

	 * that delta equals MARGIN_TARGET at the end of the next period.

	 *

	 * We need to execute usage worth of IOs while spending the sum of the

	 * new budget (1 - MARGIN_TARGET) and the leftover from the last period

	 * (delta):

	 *

	 *   usage = (1 - MARGIN_TARGET + delta) * new_hwi

	 *

	 * Therefore, the new_hwi is:

	 *

	 *   new_hwi = usage / (1 - MARGIN_TARGET + delta)

/*

 * For work-conservation, an iocg which isn't using all of its share should

 * donate the leftover to other iocgs. There are two ways to achieve this - 1.

 * bumping up vrate accordingly 2. lowering the donating iocg's inuse weight.

 *

 * #1 is mathematically simpler but has the drawback of requiring synchronous

 * global hweight_inuse updates when idle iocg's get activated or inuse weights

 * change due to donation snapbacks as it has the possibility of grossly

 * overshooting what's allowed by the model and vrate.

 *

 * #2 is inherently safe with local operations. The donating iocg can easily

 * snap back to higher weights when needed without worrying about impacts on

 * other nodes as the impacts will be inherently correct. This also makes idle

 * iocg activations safe. The only effect activations have is decreasing

 * hweight_inuse of others, the right solution to which is for those iocgs to

 * snap back to higher weights.

 *

 * So, we go with #2. The challenge is calculating how each donating iocg's

 * inuse should be adjusted to achieve the target donation amounts. This is done

 * using Andy's method described in the following pdf.

 *

 *   https://drive.google.com/file/d/1PsJwxPFtjUnwOY1QJ5AeICCcsL7BM3bo

 *

 * Given the weights and target after-donation hweight_inuse values, Andy's

 * method determines how the proportional distribution should look like at each

 * sibling level to maintain the relative relationship between all non-donating

 * pairs. To roughly summarize, it divides the tree into donating and

 * non-donating parts, calculates global donation rate which is used to

 * determine the target hweight_inuse for each node, and then derives per-level

 * proportions.

 *

 * The following pdf shows that global distribution calculated this way can be

 * achieved by scaling inuse weights of donating leaves and propagating the

 * adjustments upwards proportionally.

 *

 *   https://drive.google.com/file/d/1vONz1-fzVO7oY5DXXsLjSxEtYYQbOvsE

 *

 * Combining the above two, we can determine how each leaf iocg's inuse should

 * be adjusted to achieve the target donation.

 *

 *   https://drive.google.com/file/d/1WcrltBOSPN0qXVdBgnKm4mdp9FhuEFQN

 *

 * The inline comments use symbols from the last pdf.

 *

 *   b is the sum of the absolute budgets in the subtree. 1 for the root node.

 *   f is the sum of the absolute budgets of non-donating nodes in the subtree.

 *   t is the sum of the absolute budgets of donating nodes in the subtree.

 *   w is the weight of the node. w = w_f + w_t

 *   w_f is the non-donating portion of w. w_f = w * f / b

 *   w_b is the donating portion of w. w_t = w * t / b

 *   s is the sum of all sibling weights. s = Sum(w) for siblings

 *   s_f and s_t are the non-donating and donating portions of s.

 *

 * Subscript p denotes the parent's counterpart and ' the adjusted value - e.g.

 * w_pt is the donating portion of the parent's weight and w'_pt the same value

 * after adjustments. Subscript r denotes the root node's values.

	/*

	 * It's pretty unlikely but possible for the total sum of

	 * hweight_after_donation's to be higher than WEIGHT_ONE, which will

	 * confuse the following calculations. If such condition is detected,

	 * scale down everyone over its full share equally to keep the sum below

	 * WEIGHT_ONE.

		/*

		 * The delta should be deducted from the over_sum, calculate

		 * target over_sum value.

	/*

	 * Build pre-order inner node walk list and prepare for donation

	 * adjustment calculations.

	/*

	 * Propagate the donating budget (b_t) and after donation budget (b'_t)

	 * up the hierarchy.

	/*

	 * Calculate inner hwa's (b) and make sure the donation values are

	 * within the accepted ranges as we're doing low res calculations with

	 * roundups.

	/*

	 * Calculate the global donation rate (gamma) - the rate to adjust

	 * non-donating budgets by.

	 *

	 * No need to use 64bit multiplication here as the first operand is

	 * guaranteed to be smaller than WEIGHT_ONE (1<<16).

	 *

	 * We know that there are beneficiary nodes and the sum of the donating

	 * hweights can't be whole; however, due to the round-ups during hweight

	 * calculations, root_iocg->hweight_donating might still end up equal to

	 * or greater than whole. Limit the range when calculating the divider.

	 *

	 * gamma = (1 - t_r') / (1 - t_r)

	/*

	 * Calculate adjusted hwi, child_adjusted_sum and inuse for the inner

	 * nodes.

 adjusted weight sum for 1st level: s' = s * b_pf / b'_pf */

 b' = gamma * b_f + b_t' */

 w' = s' * b' / b'_p */

 adjusted weight sum for children: s' = s_f + s_t * w'_pt / w_pt */

	/*

	 * All inner nodes now have ->hweight_inuse and ->child_adjusted_sum and

	 * we can finally determine leaf adjustments.

		/*

		 * In-debt iocgs participated in the donation calculation with

		 * the minimum target hweight_inuse. Configuring inuse

		 * accordingly would work fine but debt handling expects

		 * @iocg->inuse stay at the minimum and we don't wanna

		 * interfere.

 w' = s' * b' / b'_p, note that b' == b'_t for donating leaves */

 walk list should be dissolved after use */

/*

 * A low weight iocg can amass a large amount of debt, for example, when

 * anonymous memory gets reclaimed aggressively. If the system has a lot of

 * memory paired with a slow IO device, the debt can span multiple seconds or

 * more. If there are no other subsequent IO issuers, the in-debt iocg may end

 * up blocked paying its debt while the IO device is idle.

 *

 * The following protects against such cases. If the device has been

 * sufficiently idle for a while, the debts are halved and delays are

 * recalculated.

 if no debtor, reset the cycle */

	/*

	 * Debtors can pass through a lot of writes choking the device and we

	 * don't want to be forgiving debts while the device is struggling from

	 * write bursts. If we're missing latency targets, consider the device

	 * fully utilized.

	/*

	 * At least DFGV_PERIOD has passed since the last period. Calculate the

	 * average usage and reset the period counters.

 if was too busy, reset everything */

	/*

	 * Usage is lower than threshold. Let's forgive some debts. Debt

	 * forgiveness runs off of the usual ioc timer but its period usually

	 * doesn't match ioc's. Compensate the difference by performing the

	 * reduction as many times as would fit in the duration since the last

	 * run and carrying over the left-over duration in @ioc->dfgv_period_rem

	 * - if ioc period is 75% of DFGV_PERIOD, one out of three consecutive

	 * reductions is doubled.

/*

 * Check the active iocgs' state to avoid oversleeping and deactive

 * idle iocgs.

 *

 * Since waiters determine the sleep durations based on the vrate

 * they saw at the time of sleep, if vrate has increased, some

 * waiters could be sleeping for too long. Wake up tardy waiters

 * which should have woken up in the last period and expire idle

 * iocgs.

 flush wait and indebt stat deltas */

 might be oversleeping vtime / hweight changes, kick */

 no waiter and idle, deactivate */

			/*

			 * @iocg has been inactive for a full duration and will

			 * have a high budget. Account anything above target as

			 * error and throw away. On reactivation, it'll start

			 * with the target budget.

 how were the latencies during the period? */

 take care of active iocgs */

	/*

	 * Wait and indebt stat are flushed above and the donation calculation

	 * below needs updated usage stat. Let's bring stat up-to-date.

 calc usage and see whether some weights need to be moved around */

		/*

		 * Collect unused and wind vtime closer to vnow to prevent

		 * iocgs from accumulating a large amount of budget.

		/*

		 * Latency QoS detection doesn't account for IOs which are

		 * in-flight for longer than a period.  Detect them by

		 * comparing vdone against period start.  If lagging behind

		 * IOs from past periods, don't increase vrate.

		/*

		 * Determine absolute usage factoring in in-flight IOs to avoid

		 * high-latency completions appearing as idle.

 see whether there's surplus vtime */

 convert to hweight based usage ratio */

			/*

			 * Already donating or accumulated enough to start.

			 * Determine the donation amount.

 genuinely short on vtime */

 surplus list should be dissolved after use */

	/*

	 * If q is getting clogged or we're missing too much, we're issuing

	 * too much IO and should lower vtime rate.  If we're not missing

	 * and experiencing shortages but not surpluses, we're too stingy

	 * and should increase vtime rate.

 clearly missing QoS targets, slow down vrate */

 QoS targets are being met with >25% margin */

			/*

			 * We're throttling while the device has spare

			 * capacity.  If vrate was being slowed down, stop.

			/*

			 * If there are IOs spanning multiple periods, wait

			 * them out before pushing the device harder.

			/*

			 * Nobody is being throttled and the users aren't

			 * issuing enough IOs to saturate the device.  We

			 * simply don't know how close the device is to

			 * saturation.  Coast.

 inside the hysterisis margin, we're good */

	/*

	 * This period is done.  Move onto the next one.  If nothing's

	 * going on with the device, stop the timer.

 debt handling owns inuse for debtors */

	/*

	 * We only increase inuse during period and do so if the margin has

	 * deteriorated since the previous adjustment.

 we own inuse only when @iocg is in the normal active state */

	/*

	 * Bump up inuse till @abs_cost fits in the existing budget.

	 * adj_step must be determined after acquiring ioc->lock - we might

	 * have raced and lost to another thread for activation and could

	 * be reading 0 iocg->active before ioc->lock which will lead to

	 * infinite loop.

 bypass IOs if disabled, still initializing, or for root cgroup */

 calculate the absolute vtime cost */

	/*

	 * If no one's waiting and within budget, issue right away.  The

	 * tests are racy but the races aren't systemic - we only miss once

	 * in a while which is fine.

	/*

	 * We're over budget. This can be handled in two ways. IOs which may

	 * cause priority inversions are punted to @ioc->aux_iocg and charged as

	 * debt. Otherwise, the issuer is blocked on @iocg->waitq. Debt handling

	 * requires @ioc->lock, waitq handling @iocg->waitq.lock. Determine

	 * whether debt handling is needed and acquire locks accordingly.

	/*

	 * @iocg must stay activated for debt and waitq handling. Deactivation

	 * is synchronized against both ioc->lock and waitq.lock and we won't

	 * get deactivated as long as we're waiting or has debt, so we're good

	 * if we're activated here. In the unlikely cases that we aren't, just

	 * issue the IO.

	/*

	 * We're over budget. If @bio has to be issued regardless, remember

	 * the abs_cost instead of advancing vtime. iocg_kick_waitq() will pay

	 * off the debt before waking more IOs.

	 *

	 * This way, the debt is continuously paid off each period with the

	 * actual budget available to the cgroup. If we just wound vtime, we

	 * would incorrectly use the current hw_inuse for the entire amount

	 * which, for example, can lead to the cgroup staying blocked for a

	 * long time even with substantially raised hw_inuse.

	 *

	 * An iocg with vdebt should stay online so that the timer can keep

	 * deducting its vdebt and [de]activate use_delay mechanism

	 * accordingly. We don't want to race against the timer trying to

	 * clear them and leave @iocg inactive w/ dangling use_delay heavily

	 * penalizing the cgroup and its descendants.

 guarantee that iocgs w/ waiters have maximum inuse */

	/*

	 * Append self to the waitq and schedule the wakeup timer if we're

	 * the first waiter.  The timer duration is calculated based on the

	 * current vrate.  vtime and hweight changes can make it too short

	 * or too long.  Each wait entry records the absolute cost it's

	 * waiting for to allow re-evaluation using a custom wait entry.

	 *

	 * If too short, the timer simply reschedules itself.  If too long,

	 * the period timer will notice and trigger wakeups.

	 *

	 * All waiters are on iocg->waitq and the wait states are

	 * synchronized using waitq.lock.

 will be set true by waker */

 waker already committed us, proceed */

 bypass if disabled, still initializing, or for root cgroup */

 update cursor if backmerging into the request at the cursor */

	/*

	 * Charge if there's enough vtime budget and the existing request has

	 * cost assigned.

	/*

	 * Otherwise, account it as debt if @iocg is online, which it should

	 * be for the vast majority of cases. See debt handling in

	 * ioc_rqos_throttle() for details.

	/*

	 * rqos must be added before activation to allow iocg_pd_init() to

	 * lookup the ioc from q. This means that the rqos methods may get

	 * called before policy activation completion, can't assume that the

	 * target bio has an iocg associated and need to test for NULL iocg.

 SPDX-License-Identifier: GPL-2.0

/*

 * Zoned block device handling

 *

 * Copyright (c) 2015, Hannes Reinecke

 * Copyright (c) 2015, SUSE Linux GmbH

 *

 * Copyright (c) 2016, Damien Le Moal

 * Copyright (c) 2016, Western Digital

/**

 * blk_zone_cond_str - Return string XXX in BLK_ZONE_COND_XXX.

 * @zone_cond: BLK_ZONE_COND_XXX.

 *

 * Description: Centralize block layer function to convert BLK_ZONE_COND_XXX

 * into string format. Useful in the debugging and tracing zone conditions. For

 * invalid BLK_ZONE_COND_XXX it returns string "UNKNOWN".

/*

 * Return true if a request is a write requests that needs zone write locking.

/**

 * blkdev_nr_zones - Get number of zones

 * @disk:	Target gendisk

 *

 * Return the total number of zones of a zoned block device.  For a block

 * device without zone capabilities, the number of zones is always 0.

/**

 * blkdev_report_zones - Get zones information

 * @bdev:	Target block device

 * @sector:	Sector from which to report zones

 * @nr_zones:	Maximum number of zones to report

 * @cb:		Callback function called for each reported zone

 * @data:	Private data for the callback

 *

 * Description:

 *    Get zone information starting from the zone containing @sector for at most

 *    @nr_zones, and call @cb for each zone reported by the device.

 *    To report all zones in a device starting from @sector, the BLK_ALL_ZONES

 *    constant can be passed to @nr_zones.

 *    Returns the number of zones reported by the device, or a negative errno

 *    value in case of failure.

 *

 *    Note: The caller must use memalloc_noXX_save/restore() calls to control

 *    memory allocations done within this function.

	/*

	 * For an all-zones reset, ignore conventional, empty, read-only

	 * and offline zones.

 This may take a while, so be nice to others */

/**

 * blkdev_zone_mgmt - Execute a zone management operation on a range of zones

 * @bdev:	Target block device

 * @op:		Operation to be performed on the zones

 * @sector:	Start sector of the first zone to operate on

 * @nr_sectors:	Number of sectors, should be at least the length of one zone and

 *		must be zone size aligned.

 * @gfp_mask:	Memory allocation flags (for bio_alloc)

 *

 * Description:

 *    Perform the specified operation on the range of zones specified by

 *    @sector..@sector+@nr_sectors. Specifying the entire disk sector range

 *    is valid, but the specified range should not contain conventional zones.

 *    The operation to execute on each zone can be a zone reset, open, close

 *    or finish request.

 Out of range */

 Check alignment (handle eventual smaller last zone) */

	/*

	 * In the case of a zone reset operation over all zones,

	 * REQ_OP_ZONE_RESET_ALL can be used with devices supporting this

	 * command. For other devices, we emulate this command behavior by

	 * identifying the zones needing a reset.

 This may take a while, so be nice to others */

/*

 * BLKREPORTZONE ioctl processing.

 * Called from blkdev_ioctl.

 Out of range */

/*

 * BLKRESETZONE, BLKOPENZONE, BLKCLOSEZONE and BLKFINISHZONE ioctl processing.

 * Called from blkdev_ioctl.

 Invalidate the page cache, including dirty pages. */

/*

 * Helper function to check the validity of zones of a zoned block device.

	/*

	 * All zones must have the same size, with the exception on an eventual

	 * smaller last zone.

 Check for holes in the zone report */

 Check zone type */

/**

 * blk_revalidate_disk_zones - (re)allocate and initialize zone bitmaps

 * @disk:	Target disk

 * @update_driver_data:	Callback to update driver data on the frozen disk

 *

 * Helper function for low-level device drivers to (re) allocate and initialize

 * a disk request queue zone bitmaps. This functions should normally be called

 * within the disk ->revalidate method for blk-mq based drivers.  For BIO based

 * drivers only q->nr_zones needs to be updated so that the sysfs exposed value

 * is correct.

 * If the @update_driver_data callback function is not NULL, the callback is

 * executed with the device request queue frozen after all zones have been

 * checked.

	/*

	 * Ensure that all memory allocations in this context are done as if

	 * GFP_NOIO was specified.

	/*

	 * If zones where reported, make sure that the entire disk capacity

	 * has been checked.

	/*

	 * Install the new bitmaps and update nr_zones only once the queue is

	 * stopped and all I/Os are completed (i.e. a scheduler is not

	 * referencing the bitmaps).

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2001 Jens Axboe <axboe@kernel.dk>

 smaller bios use inline vecs */

/*

 * fs_bio_set is the bio_set containing bio and iovec memory pools used by

 * IO code that does not need private memory pools.

/*

 * Our slab pool management

/*

 * Make the first allocation restricted and don't dump info on allocation

 * failures, since we'll fall back to the mempool in case of failure.

	/*

	 * Upgrade the nr_vecs request to take full advantage of the allocation.

	 * We also rely on this in the bvec_free path.

	/*

	 * Try a slab allocation first for all smaller allocations.  If that

	 * fails and __GFP_DIRECT_RECLAIM is set retry with the mempool.

	 * The mempool is sized to handle up to BIO_MAX_VECS entries.

		/*

		 * If we have front padding, adjust the bio pointer before freeing

 Bio was allocated by bio_kmalloc() */

/*

 * Users of this function have their own bio allocation. Subsequently,

 * they must remember to pair any call to bio_init() with bio_uninit()

 * when IO has completed, or when the bio is released.

/**

 * bio_reset - reinitialize a bio

 * @bio:	bio to reset

 *

 * Description:

 *   After calling bio_reset(), @bio will be in the same state as a freshly

 *   allocated bio returned bio bio_alloc_bioset() - the only fields that are

 *   preserved are the ones that are initialized by bio_alloc_bioset(). See

 *   comment in struct bio.

/**

 * bio_chain - chain bio completions

 * @bio: the target bio

 * @parent: the parent bio of @bio

 *

 * The caller won't have a bi_end_io called when @bio completes - instead,

 * @parent's bi_end_io won't be called until both @parent and @bio have

 * completed; the chained bio will also be freed when it completes.

 *

 * The caller must not set bi_private or bi_end_io in @bio.

	/*

	 * In order to guarantee forward progress we must punt only bios that

	 * were allocated from this bio_set; otherwise, if there was a bio on

	 * there for a stacking driver higher up in the stack, processing it

	 * could require allocating bios from this bio_set, and doing that from

	 * our own rescuer would be bad.

	 *

	 * Since bio lists are singly linked, pop them all instead of trying to

	 * remove from the middle of the list:

/**

 * bio_alloc_bioset - allocate a bio for I/O

 * @gfp_mask:   the GFP_* mask given to the slab allocator

 * @nr_iovecs:	number of iovecs to pre-allocate

 * @bs:		the bio_set to allocate from.

 *

 * Allocate a bio from the mempools in @bs.

 *

 * If %__GFP_DIRECT_RECLAIM is set then bio_alloc will always be able to

 * allocate a bio.  This is due to the mempool guarantees.  To make this work,

 * callers must never allocate more than 1 bio at a time from the general pool.

 * Callers that need to allocate more than 1 bio must always submit the

 * previously allocated bio for IO before attempting to allocate a new one.

 * Failure to do so can cause deadlocks under memory pressure.

 *

 * Note that when running under submit_bio_noacct() (i.e. any block driver),

 * bios are not submitted until after you return - see the code in

 * submit_bio_noacct() that converts recursion into iteration, to prevent

 * stack overflows.

 *

 * This would normally mean allocating multiple bios under submit_bio_noacct()

 * would be susceptible to deadlocks, but we have

 * deadlock avoidance code that resubmits any blocked bios from a rescuer

 * thread.

 *

 * However, we do not guarantee forward progress for allocations from other

 * mempools. Doing multiple allocations from the same mempool under

 * submit_bio_noacct() should be avoided - instead, use bio_set's front_pad

 * for per bio allocations.

 *

 * Returns: Pointer to new bio on success, NULL on failure.

 should not use nobvec bioset for nr_iovecs > 0 */

	/*

	 * submit_bio_noacct() converts recursion to iteration; this means if

	 * we're running beneath it, any bios we allocate and submit will not be

	 * submitted (and thus freed) until after we return.

	 *

	 * This exposes us to a potential deadlock if we allocate multiple bios

	 * from the same bio_set() while running underneath submit_bio_noacct().

	 * If we were to allocate multiple bios (say a stacking block driver

	 * that was splitting bios), we would deadlock if we exhausted the

	 * mempool's reserve.

	 *

	 * We solve this, and guarantee forward progress, with a rescuer

	 * workqueue per bio_set. If we go to allocate and there are bios on

	 * current->bio_list, we first try the allocation without

	 * __GFP_DIRECT_RECLAIM; if that fails, we punt those bios we would be

	 * blocking to the rescuer workqueue before we retry with the original

	 * gfp_flags.

/**

 * bio_kmalloc - kmalloc a bio for I/O

 * @gfp_mask:   the GFP_* mask given to the slab allocator

 * @nr_iovecs:	number of iovecs to pre-allocate

 *

 * Use kmalloc to allocate and initialize a bio.

 *

 * Returns: Pointer to new bio on success, NULL on failure.

/**

 * bio_truncate - truncate the bio to small size of @new_size

 * @bio:	the bio to be truncated

 * @new_size:	new size for truncating the bio

 *

 * Description:

 *   Truncate the bio to new size of @new_size. If bio_op(bio) is

 *   REQ_OP_READ, zero the truncated part. This function should only

 *   be used for handling corner cases, such as bio eod.

	/*

	 * Don't touch bvec table here and make it really immutable, since

	 * fs bio user has to retrieve all pages via bio_for_each_segment_all

	 * in its .end_bio() callback.

	 *

	 * It is enough to truncate bio by updating .bi_size since we can make

	 * correct bvec with the updated .bi_size for drivers.

/**

 * guard_bio_eod - truncate a BIO to fit the block device

 * @bio:	bio to truncate

 *

 * This allows us to do IO even on the odd last sectors of a device, even if the

 * block size is some multiple of the physical sector size.

 *

 * We'll just truncate the bio to the size of the device, and clear the end of

 * the buffer head manually.  Truly out-of-range accesses will turn into actual

 * I/O errors, this only handles the "we need to be able to do I/O at the final

 * sector" case.

	/*

	 * If the *whole* IO is past the end of the device,

	 * let it through, and the IO layer will turn it into

	 * an EIO.

/**

 * bio_put - release a reference to a bio

 * @bio:   bio to release reference to

 *

 * Description:

 *   Put a reference to a &struct bio, either one you have gotten with

 *   bio_alloc, bio_get or bio_clone_*. The last put of a bio will free it.

/**

 * 	__bio_clone_fast - clone a bio that shares the original bio's biovec

 * 	@bio: destination bio

 * 	@bio_src: bio to clone

 *

 *	Clone a &bio. Caller will own the returned bio, but not

 *	the actual data it points to. Reference count of returned

 * 	bio will be one.

 *

 * 	Caller must ensure that @bio_src is not freed before @bio.

	/*

	 * most users will be overriding ->bi_bdev with a new target,

	 * so we don't set nor calculate new physical/hw segment counts here

/**

 *	bio_clone_fast - clone a bio that shares the original bio's biovec

 *	@bio: bio to clone

 *	@gfp_mask: allocation priority

 *	@bs: bio_set to allocate from

 *

 * 	Like __bio_clone_fast, only also allocates the returned bio

/**

 * bio_full - check if the bio is full

 * @bio:	bio to check

 * @len:	length of one segment to be added

 *

 * Return true if @bio is full and one segment with @len bytes can't be

 * added to the bio, otherwise return false

/**

 * __bio_try_merge_page - try appending data to an existing bvec.

 * @bio: destination bio

 * @page: start page to add

 * @len: length of the data to add

 * @off: offset of the data relative to @page

 * @same_page: return if the segment has been merged inside the same page

 *

 * Try to add the data at @page + @off to the last bvec of @bio.  This is a

 * useful optimisation for file systems with a block size smaller than the

 * page size.

 *

 * Warn if (@len, @off) crosses pages in case that @same_page is true.

 *

 * Return %true on success or %false on failure.

/*

 * Try to merge a page into a segment, while obeying the hardware segment

 * size limit.  This is not for normal read/write bios, but for passthrough

 * or Zone Append operations that we can't split.

/**

 * bio_add_hw_page - attempt to add a page to a bio with hw constraints

 * @q: the target queue

 * @bio: destination bio

 * @page: page to add

 * @len: vec entry length

 * @offset: vec entry offset

 * @max_sectors: maximum number of sectors that can be added

 * @same_page: return if the segment has been merged inside the same page

 *

 * Add a page to a bio while respecting the hardware max_sectors, max_segment

 * and gap limitations.

		/*

		 * If the queue doesn't support SG gaps and adding this segment

		 * would create a gap, disallow it.

/**

 * bio_add_pc_page	- attempt to add page to passthrough bio

 * @q: the target queue

 * @bio: destination bio

 * @page: page to add

 * @len: vec entry length

 * @offset: vec entry offset

 *

 * Attempt to add a page to the bio_vec maplist. This can fail for a

 * number of reasons, such as the bio being full or target block device

 * limitations. The target block device must allow bio's up to PAGE_SIZE,

 * so it is always possible to add a single page to an empty bio.

 *

 * This should only be used by passthrough bios.

/**

 * bio_add_zone_append_page - attempt to add page to zone-append bio

 * @bio: destination bio

 * @page: page to add

 * @len: vec entry length

 * @offset: vec entry offset

 *

 * Attempt to add a page to the bio_vec maplist of a bio that will be submitted

 * for a zone-append request. This can fail for a number of reasons, such as the

 * bio being full or the target block device is not a zoned block device or

 * other limitations of the target block device. The target block device must

 * allow bio's up to PAGE_SIZE, so it is always possible to add a single page

 * to an empty bio.

 *

 * Returns: number of bytes added to the bio, or 0 in case of a failure.

/**

 * __bio_add_page - add page(s) to a bio in a new segment

 * @bio: destination bio

 * @page: start page to add

 * @len: length of the data to add, may cross pages

 * @off: offset of the data relative to @page, may cross pages

 *

 * Add the data at @page + @off to @bio as a new bvec.  The caller must ensure

 * that @bio has space for another bvec.

/**

 *	bio_add_page	-	attempt to add page(s) to bio

 *	@bio: destination bio

 *	@page: start page to add

 *	@len: vec entry length, may cross pages

 *	@offset: vec entry offset relative to @page, may cross pages

 *

 *	Attempt to add page(s) to the bio_vec maplist. This will only fail

 *	if either bio->bi_vcnt == bio->bi_max_vecs or it's a cloned bio.

/**

 * __bio_iov_iter_get_pages - pin user or kernel pages and add them to a bio

 * @bio: bio to add pages to

 * @iter: iov iterator describing the region to be mapped

 *

 * Pins pages from *iter and appends them to @bio's bvec array. The

 * pages will have to be released using put_page() when done.

 * For multi-segment *iter, this function only adds pages from the

 * next non-empty segment of the iov iterator.

	/*

	 * Move page array up in the allocated memory for the bio vecs as far as

	 * possible so that we can start filling biovecs from the beginning

	 * without overwriting the temporary page array.

	/*

	 * Move page array up in the allocated memory for the bio vecs as far as

	 * possible so that we can start filling biovecs from the beginning

	 * without overwriting the temporary page array.

/**

 * bio_iov_iter_get_pages - add user or kernel pages to a bio

 * @bio: bio to add pages to

 * @iter: iov iterator describing the region to be added

 *

 * This takes either an iterator pointing to user memory, or one pointing to

 * kernel pages (BVEC iterator). If we're adding user pages, we pin them and

 * map them into the kernel. On IO completion, the caller should put those

 * pages. For bvec based iterators bio_iov_iter_get_pages() uses the provided

 * bvecs rather than copying them. Hence anyone issuing kiocb based IO needs

 * to ensure the bvecs and pages stay referenced until the submitted I/O is

 * completed by a call to ->ki_complete() or returns with an error other than

 * -EIOCBQUEUED. The caller needs to check if the bio is flagged BIO_NO_PAGE_REF

 * on IO completion. If it isn't, then pages should be released.

 *

 * The function tries, but does not guarantee, to pin as many pages as

 * fit into the bio, or are requested in @iter, whatever is smaller. If

 * MM encounters an error pinning the requested pages, it stops. Error

 * is returned only if 0 pages could be pinned.

 *

 * It's intended for direct IO, so doesn't do PSI tracking, the caller is

 * responsible for setting BIO_WORKINGSET if necessary.

 don't account direct I/O as memory stall */

/**

 * submit_bio_wait - submit a bio, and wait until it completes

 * @bio: The &struct bio which describes the I/O

 *

 * Simple wrapper around submit_bio(). Returns 0 on success, or the error from

 * bio_endio() on failure.

 *

 * WARNING: Unlike to how submit_bio() is usually used, this function does not

 * result in bio reference to be consumed. The caller must drop the reference

 * on his own.

 Prevent hang_check timer from firing at us during very long I/O */

/**

 * bio_copy_data - copy contents of data buffers from one bio to another

 * @src: source bio

 * @dst: destination bio

 *

 * Stops when it reaches the end of either @src or @dst - that is, copies

 * min(src->bi_size, dst->bi_size) bytes (or the equivalent for lists of bios).

/*

 * bio_set_pages_dirty() and bio_check_pages_dirty() are support functions

 * for performing direct-IO in BIOs.

 *

 * The problem is that we cannot run set_page_dirty() from interrupt context

 * because the required locks are not interrupt-safe.  So what we can do is to

 * mark the pages dirty _before_ performing IO.  And in interrupt context,

 * check that the pages are still dirty.   If so, fine.  If not, redirty them

 * in process context.

 *

 * We special-case compound pages here: normally this means reads into hugetlb

 * pages.  The logic in here doesn't really work right for compound pages

 * because the VM does not uniformly chase down the head page in all cases.

 * But dirtiness of compound pages is pretty meaningless anyway: the VM doesn't

 * handle them at all.  So we skip compound pages here at an early stage.

 *

 * Note that this code is very hard to test under normal circumstances because

 * direct-io pins the pages with get_user_pages().  This makes

 * is_page_cache_freeable return false, and the VM will not clean the pages.

 * But other code (eg, flusher threads) could clean the pages if they are mapped

 * pagecache.

 *

 * Simply disabling the call to bio_set_pages_dirty() is a good way to test the

 * deferred bio dirtying paths.

/*

 * bio_set_pages_dirty() will mark all the bio's pages as dirty.

/*

 * bio_check_pages_dirty() will check that all the BIO's pages are still dirty.

 * If they are, then fine.  If, however, some pages are clean then they must

 * have been written out during the direct-IO read.  So we take another ref on

 * the BIO and re-dirty the pages in process context.

 *

 * It is expected that bio_check_pages_dirty() will wholly own the BIO from

 * here on.  It will run one put_page() against each page and will run one

 * bio_put() against the BIO.

/*

 * This runs in process context

	/*

	 * If we're not chaining, then ->__bi_remaining is always 1 and

	 * we always end io on the first invocation.

/**

 * bio_endio - end I/O on a bio

 * @bio:	bio

 *

 * Description:

 *   bio_endio() will end I/O on the whole bio. bio_endio() is the preferred

 *   way to end I/O on a bio. No one should call bi_end_io() directly on a

 *   bio unless they own it and thus know that it has an end_io function.

 *

 *   bio_endio() can be called several times on a bio that has been chained

 *   using bio_chain().  The ->bi_end_io() function will only be called the

 *   last time.

	/*

	 * Need to have a real endio function for chained bios, otherwise

	 * various corner cases will break (like stacking block devices that

	 * save/restore bi_end_io) - however, we want to avoid unbounded

	 * recursion and blowing the stack. Tail call optimization would

	 * handle this, but compiling with frame pointers also disables

	 * gcc's sibling call optimization.

 release cgroup info */

/**

 * bio_split - split a bio

 * @bio:	bio to split

 * @sectors:	number of sectors to split from the front of @bio

 * @gfp:	gfp mask

 * @bs:		bio set to allocate from

 *

 * Allocates and returns a new bio which represents @sectors from the start of

 * @bio, and updates @bio to represent the remaining sectors.

 *

 * Unless this is a discard request the newly allocated bio will point

 * to @bio's bi_io_vec. It is the caller's responsibility to ensure that

 * neither @bio nor @bs are freed before the split bio.

 Zone append commands cannot be split */

/**

 * bio_trim - trim a bio

 * @bio:	bio to trim

 * @offset:	number of sectors to trim from the front of @bio

 * @size:	size we want to trim @bio to, in sectors

 *

 * This function is typically used for bios that are cloned and submitted

 * to the underlying device in parts.

/*

 * create memory pools for biovec's in a bio_set.

 * use the global biovec slabs created for general use.

/*

 * bioset_exit - exit a bioset initialized with bioset_init()

 *

 * May be called on a zeroed but uninitialized bioset (i.e. allocated with

 * kzalloc()).

/**

 * bioset_init - Initialize a bio_set

 * @bs:		pool to initialize

 * @pool_size:	Number of bio and bio_vecs to cache in the mempool

 * @front_pad:	Number of bytes to allocate in front of the returned bio

 * @flags:	Flags to modify behavior, currently %BIOSET_NEED_BVECS

 *              and %BIOSET_NEED_RESCUER

 *

 * Description:

 *    Set up a bio_set to be used with @bio_alloc_bioset. Allows the caller

 *    to ask for a number of bytes to be allocated in front of the bio.

 *    Front pad allocation is useful for embedding the bio inside

 *    another structure, to avoid allocating extra data to go with the bio.

 *    Note that the bio must be embedded at the END of that structure always,

 *    or things will break badly.

 *    If %BIOSET_NEED_BVECS is set in @flags, a separate pool will be allocated

 *    for allocating iovecs.  This pool is not needed e.g. for bio_clone_fast().

 *    If %BIOSET_NEED_RESCUER is set, a workqueue is created which can be used to

 *    dispatch queued requests when the mempool runs out of space.

 *

/*

 * Initialize and setup a new bio_set, based on the settings from

 * another bio_set.

/**

 * bio_alloc_kiocb - Allocate a bio from bio_set based on kiocb

 * @kiocb:	kiocb describing the IO

 * @nr_vecs:	number of iovecs to pre-allocate

 * @bs:		bio_set to allocate from

 *

 * Description:

 *    Like @bio_alloc_bioset, but pass in the kiocb. The kiocb is only

 *    used to check if we should dip into the per-cpu bio_set allocation

 *    cache. The allocation uses GFP_KERNEL internally. On return, the

 *    bio is marked BIO_PERCPU_CACHEABLE, and the final put of the bio

 *    MUST be done from process context, not hard/soft IRQ.

 *

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright  2016 Intel Corporation

 *

 * Authors:

 *    Scott  Bauer      <scott.bauer@intel.com>

 *    Rafael Antognolli <rafael.antognolli@intel.com>

 Number of bytes needed by cmd_finalize. */

/*

 * On the parsed response, we don't store again the toks that are already

 * stored in the response buffer. Instead, for each token, we just store a

 * pointer to the position in the buffer where the token starts, and the size

 * of the token in bytes.

/*

 * From the response header it's not possible to know how many tokens there are

 * on the payload. So we hardcode that the maximum will be MAX_TOKS, and later

 * if we start dealing with messages that have more than that, we can increase

 * this number. This is done to avoid having to make two passes through the

 * response, the first one counting how many tokens we have and the second one

 * actually storing the positions.

 users */

 tables */

 C_PIN_TABLE object ID's */

 half UID's (only first 4 bytes used) */

 special value for omitted optional parameter */

/*

 * TCG Storage SSC Methods.

 * Derived from: TCG_Storage_Architecture_Core_Spec_v2.01_r1.00

 * Section: 6.3 Assigned UIDs

/*

 * Derived from:

 * TCG_Storage_Architecture_Core_Spec_v2.01_r1.00

 * Section: 5.1.5 Method Status Codes

 first do a discovery0 */

	/*

	 * For each OPAL command the first step in steps starts some sort of

	 * session. If an error occurred in the initial discovery0 or if an

	 * error occurred in the first step (and thus stopping the loop with

	 * state == 0) then there was an error before or during the attempt to

	 * start a session. Therefore we shouldn't attempt to terminate a

	 * session, as one has not yet been created.

 end of buffer */

 current position on buffer */

 some ignored properties */

 vendor specific, just ignore */

	/*

	 * Close the parameter list opened from cmd_start.

	 * The number of bytes added must be equal to

	 * CMD_FINALIZE_BYTES_NEEDED.

 tiny atom */

 short atom */

 medium atom */

 long atom */

 TOKEN */

 Parses and checks for errors */

	/*

	 * Every method call is followed by its parameters enclosed within

	 * OPAL_STARTLIST and OPAL_ENDLIST tokens. We automatically open the

	 * parameter list here and close it later in cmd_finalize.

/*

 * request @column from table @table on device @dev. On success, the column

 * data will be available in dev->resp->tok[4]

/*

 * see TCG SAS 5.3.2.3 for a description of the available columns

 *

 * the result is provided in dev->resp->tok[4]

	/* sed-opal UIDs can be split in two halves:

	 *  first:  actual table index

	 *  second: relative index in the table

	 * so we have to get the first half of the OPAL_TABLE_TABLE and use the

	 * first part of the target table as relative index into that table

 do we fit in the available space? */

 do the actual transmission(s) */

		/*

		 * The bytestring header is either 1 or 2 bytes, so assume 2.

		 * There also needs to be enough space to accommodate the

		 * trailing OPAL_ENDNAME (1 byte) and tokens added by

		 * cmd_finalize.

 HostChallenge */

 HostSignAuth */

 Enabled */

 Done T or F */

 vars are initialized to locked */

 vars are initialized to locked */

 Determine if we're in the Manufactured Inactive or Active state */

 0x08 is Manufactured Inactive */

 0x09 is Manufactured */

/*

 * IO_BUFFER_LENGTH = 2048

 * sizeof(header) = 56

 * No. of Token Bytes in the Response = 11

 * MAX size of data that can be carried in response buffer

 * at a time is : 2048 - (56 + 11) = 1981 = 0x7BD.

 Check if the user is trying to read from the table limits */

 start row value */

		add_token_u64(&err, dev, offset + off + len); /* end row value

 len+1: This includes the NULL terminator at the end*/

 controller will terminate session */

	/*

	 * If we successfully reverted lets clean

	 * any saved locking ranges.

 We can't activate Admin1 it's active as manufactured */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  BSG helper library

 *

 *  Copyright (C) 2008   James Smart, Emulex Corporation

 *  Copyright (C) 2011   Red Hat, Inc.  All rights reserved.

 *  Copyright (C) 2011   Mike Christie

	/*

	 * The assignments below don't make much sense, but are kept for

	 * bug by bug backwards compatibility:

 we're only returning the result field in the reply */

 we assume all request payload was transferred, residual == 0 */

/**

 * bsg_teardown_job - routine to teardown a bsg job

 * @kref: kref inside bsg_job that is to be torn down

 release reference for the request */

/**

 * bsg_job_done - completion routine for bsg requests

 * @job: bsg_job that is complete

 * @result: job reply result

 * @reply_payload_rcv_len: length of payload recvd

 *

 * The LLD should call this when the bsg job has completed.

/**

 * bsg_complete - softirq done routine for destroying the bsg requests

 * @rq: BSG request that holds the job to be destroyed

/**

 * bsg_prepare_job - create the bsg_job structure for the bsg request

 * @dev: device that is being sent the bsg request

 * @req: BSG request that needs a job structure

 take a reference for the request */

/**

 * bsg_queue_rq - generic handler for bsg requests

 * @hctx: hardware queue

 * @bd: queue data

 *

 * On error the create_bsg_job function should return a -Exyz error value

 * that will be set to ->result.

 *

 * Drivers/subsys should pass this to the queue init function.

 called right after the request is allocated for the request_queue */

/**

 * bsg_setup_queue - Create and add the bsg hooks so we can receive requests

 * @dev: device to attach bsg device to

 * @name: device to give bsg device

 * @job_fn: bsg job handler

 * @timeout: timeout handler function pointer

 * @dd_job_size: size of LLD data needed for each job

 SPDX-License-Identifier: GPL-2.0

/*

 *  MQ Deadline i/o scheduler - adaptation of the legacy deadline scheduler,

 *  for the blk-mq scheduling framework

 *

 *  Copyright (C) 2016 Jens Axboe <axboe@kernel.dk>

/*

 * See Documentation/block/deadline-iosched.rst

 max time before a read is submitted. */

 ditto for writes, these limits are SOFT! */

/*

 * Time after which to dispatch lower priority requests even if higher

 * priority requests are pending.

 max times reads can starve a write */

static const int fifo_batch = 16;       /* # of sequential requests treated as one

/*

 * I/O statistics per I/O priority. It is fine if these counters overflow.

 * What matters is that these counters are at least as wide as

 * log2(max_outstanding_requests).

/*

 * Deadline scheduler data per I/O priority (enum dd_prio). Requests are

 * present on both sort_list[] and fifo_list[].

 Next request in FIFO order. Read, write or both are NULL. */

	/*

	 * run time data

 Data direction of latest dispatched request. */

 number of sequential requests made */

 times reads have starved writes */

	/*

	 * settings that change how the i/o scheduler behaves

 Maps an I/O priority class to a deadline scheduler priority. */

/*

 * Returns the I/O priority class (IOPRIO_CLASS_*) that has been assigned to a

 * request.

/*

 * get the request after `rq' in sector-sorted order

/*

 * remove rq from rbtree and fifo.

	/*

	 * We might not be on the rbtree, if we are doing an insert merge

	/*

	 * if the merge was a front merge, we need to reposition request

/*

 * Callback function that is invoked after @next has been merged into @req.

	/*

	 * if next expires before rq, assign its expire time to rq

	 * and move into next position (next will be deleted) in fifo

	/*

	 * kill knowledge of next, this one is a goner

/*

 * move an entry to dispatch queue

	/*

	 * take it off the sort and fifo list

 Number of requests queued for a given priority level. */

/*

 * deadline_check_fifo returns 0 if there are no expired requests on the fifo,

 * 1 otherwise. Requires !list_empty(&dd->fifo_list[data_dir])

	/*

	 * rq is expired!

/*

 * For the specified data direction, return the next request to

 * dispatch using arrival ordered lists.

	/*

	 * Look for a write request that can be dispatched, that is one with

	 * an unlocked target zone.

/*

 * For the specified data direction, return the next request to

 * dispatch using sector position sorted lists.

	/*

	 * Look for a write request that can be dispatched, that is one with

	 * an unlocked target zone.

/*

 * Returns true if and only if @rq started after @latest_start where

 * @latest_start is in jiffies.

/*

 * deadline_dispatch_requests selects the best request according to

 * read/write expire, fifo_batch, etc and with a start time <= @latest_start.

	/*

	 * batches are currently reads XOR writes

 we have a next request are still entitled to batch */

	/*

	 * at this point we are not running a batch. select the appropriate

	 * data direction (read / write)

	/*

	 * there are either no reads or writes have been starved

	/*

	 * we are not running a batch, find best request for selected data_dir

		/*

		 * A deadline has expired, the last request was in the other

		 * direction, or we have run out of higher-sectored requests.

		 * Start again from the request with the earliest expiry time.

		/*

		 * The last req was the same dir and we have a next request in

		 * sort order. No expired requests so continue on from here.

	/*

	 * For a zoned block device, if we only have writes queued and none of

	 * them can be dispatched, rq will be NULL.

	/*

	 * rq is the selected appropriate request.

	/*

	 * If the request needs its target zone locked, do it.

/*

 * Check whether there are any requests with priority other than DD_RT_PRIO

 * that were inserted more than prio_aging_expire jiffies ago.

/*

 * Called from blk_mq_run_hw_queue() -> __blk_mq_sched_dispatch_requests().

 *

 * One confusing aspect here is that we get called for a specific

 * hardware queue, but we may return a request that is for a

 * different hardware queue. This is because mq-deadline has shared

 * state for all hardware queues, in terms of sorting, FIFOs, etc.

	/*

	 * Next, dispatch requests in priority order. Ignore lower priority

	 * requests if any higher priority requests are pending.

/*

 * Called by __blk_mq_alloc_request(). The shallow_depth value set by this

 * function is used by __blk_mq_get_tag().

 Do not throttle synchronous reads. */

	/*

	 * Throttle asynchronous requests and writes such that these requests

	 * do not block the allocation of synchronous requests.

 Called by blk_mq_update_nr_requests(). */

 Called by blk_mq_init_hctx() and blk_mq_init_sched(). */

/*

 * initialize elevator private data (deadline_data).

/*

 * Try to merge @bio into an existing request. If @bio has been merged into

 * an existing request, store the pointer to that request into *@rq.

/*

 * Attempt to merge a bio into an existing request. This function is called

 * before @bio is associated with a request.

/*

 * add rq to rbtree and fifo

	/*

	 * This may be a requeue of a write request that has locked its

	 * target zone. If it is the case, this releases the zone lock.

		/*

		 * set expire time and add to fifo list

/*

 * Called from blk_mq_sched_insert_request() or blk_mq_sched_insert_requests().

 Callback from inside blk_mq_rq_ctx_init(). */

/*

 * Callback from inside blk_mq_free_request().

 *

 * For zoned block devices, write unlock the target zone of

 * completed write requests. Do this while holding the zone lock

 * spinlock so that the zone is never unlocked while deadline_fifo_request()

 * or deadline_next_request() are executing. This function is called for

 * all requests, whether or not these requests complete successfully.

 *

 * For a zoned block device, __dd_dispatch_request() may have stopped

 * dispatching requests if all the queued requests are write requests directed

 * at zones that are already locked due to on-going write requests. To ensure

 * write request dispatch progress in this case, mark the queue as needing a

 * restart to ensure that the queue is run again after completion of the

 * request and zones being unlocked.

	/*

	 * The block layer core may call dd_finish_request() without having

	 * called dd_insert_requests(). Skip requests that bypassed I/O

	 * scheduling. See also blk_mq_request_bypass_insert().

/*

 * sysfs parts below

 Number of requests owned by the block driver for a given priority. */

 SPDX-License-Identifier: GPL-2.0

/*

 * bsg.c - block layer implementation of the sg v4 interface

	/*

	 * Our own ioctls

	/*

	 * SCSI/sg ioctls

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 Google LLC

/*

 * Refer to Documentation/block/inline-encryption.rst for detailed explanation.

	/*

	 * Copy of the bvec_iter when this bio was submitted.

	 * We only want to en/decrypt the part of the bio as described by the

	 * bvec_iter upon submission because bio might be split before being

	 * resubmitted

/*

 * Allocating a crypto tfm during I/O can deadlock, so we have to preallocate

 * all of a mode's tfms when that mode starts being used. Since each mode may

 * need all the keyslots at some point, each mode needs its own tfm for each

 * keyslot; thus, a keyslot may contain tfms for multiple modes.  However, to

 * match the behavior of real inline encryption hardware (which only supports a

 * single encryption context per keyslot), we only allow one tfm per keyslot to

 * be used at a time - the rest of the unused tfms have their keys cleared.

/*

 * This is the key we set when evicting a keyslot. This *should* be the all 0's

 * key, but AES-XTS rejects that key, so we use some random bytes instead.

 Clear the key in the skcipher */

/*

 * The crypto API fallback's encryption routine.

 * Allocate a bounce bio for encryption, encrypt the input bio using crypto API,

 * and replace *bio_ptr with the bounce bio. May split input bio if it's too

 * large. Returns true on success. Returns false and sets bio->bi_status on

 * error.

 Split the bio if it's too big for single page bvec */

 Allocate bounce bio for encryption */

	/*

	 * Get a blk-crypto-fallback keyslot that contains a crypto_skcipher for

	 * this bio's algorithm and key.

 and then allocate an skcipher_request for it */

 Encrypt each page in the bounce bio */

 Encrypt each data unit in this page */

/*

 * The crypto API fallback's main decryption routine.

 * Decrypts input bio in place, and calls bio_endio on the bio.

	/*

	 * Get a blk-crypto-fallback keyslot that contains a crypto_skcipher for

	 * this bio's algorithm and key.

 and then allocate an skcipher_request for it */

 Decrypt each segment in the bio */

 Decrypt each data unit in the segment */

/**

 * blk_crypto_fallback_decrypt_endio - queue bio for fallback decryption

 *

 * @bio: the bio to queue

 *

 * Restore bi_private and bi_end_io, and queue the bio for decryption into a

 * workqueue, since this function will be called from an atomic context.

 If there was an IO error, don't queue for decrypt. */

/**

 * blk_crypto_fallback_bio_prep - Prepare a bio to use fallback en/decryption

 *

 * @bio_ptr: pointer to the bio to prepare

 *

 * If bio is doing a WRITE operation, this splits the bio into two parts if it's

 * too big (see blk_crypto_fallback_split_bio_if_needed()). It then allocates a

 * bounce bio for the first part, encrypts it, and updates bio_ptr to point to

 * the bounce bio.

 *

 * For a READ operation, we mark the bio for decryption by using bi_private and

 * bi_end_io.

 *

 * In either case, this function will make the bio look like a regular bio (i.e.

 * as if no encryption context was ever specified) for the purposes of the rest

 * of the stack except for blk-integrity (blk-integrity and blk-crypto are not

 * currently supported together).

 *

 * Return: true on success. Sets bio->bi_status and returns false on error.

 User didn't call blk_crypto_start_using_key() first */

	/*

	 * bio READ case: Set up a f_ctx in the bio's bi_private and set the

	 * bi_end_io appropriately to trigger decryption when the bio is ended.

 All blk-crypto modes have a crypto API fallback. */

/*

 * Prepare blk-crypto-fallback for the specified crypto mode.

 * Returns -ENOPKG if the needed crypto API support is missing.

	/*

	 * Fast path

	 * Ensure that updates to blk_crypto_keyslots[i].tfms[mode_num]

	 * for each i are visible before we try to access them.

	/*

	 * Ensure that updates to blk_crypto_keyslots[i].tfms[mode_num]

	 * for each i are visible before we set tfms_inited[mode_num].

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions to sequence PREFLUSH and FUA writes.

 *

 * Copyright (C) 2011		Max Planck Institute for Gravitational Physics

 * Copyright (C) 2011		Tejun Heo <tj@kernel.org>

 *

 * REQ_{PREFLUSH|FUA} requests are decomposed to sequences consisted of three

 * optional steps - PREFLUSH, DATA and POSTFLUSH - according to the request

 * properties and hardware capability.

 *

 * If a request doesn't have data, only REQ_PREFLUSH makes sense, which

 * indicates a simple flush request.  If there is data, REQ_PREFLUSH indicates

 * that the device cache should be flushed before the data is executed, and

 * REQ_FUA means that the data must be on non-volatile media on request

 * completion.

 *

 * If the device doesn't have writeback cache, PREFLUSH and FUA don't make any

 * difference.  The requests are either completed immediately if there's no data

 * or executed as normal requests otherwise.

 *

 * If the device has writeback cache and supports FUA, REQ_PREFLUSH is

 * translated to PREFLUSH but REQ_FUA is passed down directly with DATA.

 *

 * If the device has writeback cache and doesn't support FUA, REQ_PREFLUSH

 * is translated to PREFLUSH and REQ_FUA to POSTFLUSH.

 *

 * The actual execution of flush is double buffered.  Whenever a request

 * needs to execute PRE or POSTFLUSH, it queues at

 * fq->flush_queue[fq->flush_pending_idx].  Once certain criteria are met, a

 * REQ_OP_FLUSH is issued and the pending_idx is toggled.  When the flush

 * completes, all the requests which were pending are proceeded to the next

 * step.  This allows arbitrary merging of different types of PREFLUSH/FUA

 * requests.

 *

 * Currently, the following conditions are used to determine when to issue

 * flush.

 *

 * C1. At any given time, only one flush shall be in progress.  This makes

 *     double buffering sufficient.

 *

 * C2. Flush is deferred if any request is executing DATA of its sequence.

 *     This avoids issuing separate POSTFLUSHes for requests which shared

 *     PREFLUSH.

 *

 * C3. The second condition is ignored if there is a request which has

 *     waited longer than FLUSH_PENDING_TIMEOUT.  This is to avoid

 *     starvation in the unlikely case where there are continuous stream of

 *     FUA (without PREFLUSH) requests.

 *

 * For devices which support FUA, it isn't clear whether C2 (and thus C3)

 * is beneficial.

 *

 * Note that a sequenced PREFLUSH/FUA request with DATA is completed twice.

 * Once while executing DATA and again after the whole sequence is

 * complete.  The first completion updates the contained bio but doesn't

 * finish it so that the bio submitter is notified only after the whole

 * sequence is complete.  This is implemented by testing RQF_FLUSH_SEQ in

 * req_bio_endio().

 *

 * The above peculiarity requires that each PREFLUSH/FUA request has only one

 * bio attached to it, which is guaranteed as they aren't allowed to be

 * merged in the usual way.

 PREFLUSH/FUA sequences */

 pre-flushing in progress */

 data write in progress */

 post-flushing in progress */

	/*

	 * If flush has been pending longer than the following timeout,

	 * it's issued even if flush_data requests are still in flight.

	/*

	 * After flush data completion, @rq->bio is %NULL but we need to

	 * complete the bio again.  @rq->biotail is guaranteed to equal the

	 * original @rq->bio.  Restore it.

 make @rq a normal request */

/**

 * blk_flush_complete_seq - complete flush sequence

 * @rq: PREFLUSH/FUA request being sequenced

 * @fq: flush queue

 * @seq: sequences to complete (mask of %REQ_FSEQ_*, can be zero)

 * @error: whether an error occurred

 *

 * @rq just completed @seq part of its flush sequence, record the

 * completion and trigger the next step.

 *

 * CONTEXT:

 * spin_lock_irq(fq->mq_flush_lock)

 queue for flush */

		/*

		 * @rq was previously adjusted by blk_insert_flush() for

		 * flush sequencing and may already have gone through the

		 * flush data request completion path.  Restore @rq for

		 * normal completion and end it.

 release the tag's ownership to the req cloned from */

	/*

	 * Flush request has to be marked as IDLE when it is really ended

	 * because its .end_io() is called from timeout code path too for

	 * avoiding use-after-free.

 account completion of the flush request */

 and push the waiting requests to the next stage */

/**

 * blk_kick_flush - consider issuing flush request

 * @q: request_queue being kicked

 * @fq: flush queue

 * @flags: cmd_flags of the original request

 *

 * Flush related states of @q have changed, consider issuing flush request.

 * Please read the comment at the top of this file for more info.

 *

 * CONTEXT:

 * spin_lock_irq(fq->mq_flush_lock)

 *

 C1 described at the top of this file */

 C2 and C3 */

	/*

	 * Issue flush and toggle pending_idx.  This makes pending_idx

	 * different from running_idx, which means flush is in flight.

	/*

	 * In case of none scheduler, borrow tag from the first request

	 * since they can't be in flight at the same time. And acquire

	 * the tag's ownership for flush req.

	 *

	 * In case of IO scheduler, flush rq need to borrow scheduler tag

	 * just for cheating put/get driver tag.

		/*

		 * We borrow data request's driver tag, so have to mark

		 * this flush request as INFLIGHT for avoiding double

		 * account of this driver tag

	/*

	 * Order WRITE ->end_io and WRITE rq->ref, and its pair is the one

	 * implied in refcount_inc_not_zero() called from

	 * blk_mq_find_and_get_req(), which orders WRITE/READ flush_rq->ref

	 * and READ flush_rq->end_io

	/*

	 * After populating an empty queue, kick it to avoid stall.  Read

	 * the comment in flush_end_io().

/**

 * blk_insert_flush - insert a new PREFLUSH/FUA request

 * @rq: request to insert

 *

 * To be called from __elv_add_request() for %ELEVATOR_INSERT_FLUSH insertions.

 * or __blk_mq_run_hw_queue() to dispatch request.

 * @rq is being submitted.  Analyze what needs to be done and put it on the

 * right queue.

 may change, cache */

	/*

	 * @policy now records what operations need to be done.  Adjust

	 * REQ_PREFLUSH and FUA for the driver.

	/*

	 * REQ_PREFLUSH|REQ_FUA implies REQ_SYNC, so if we clear any

	 * of those flags, we have to set REQ_SYNC to avoid skewing

	 * the request accounting.

	/*

	 * An empty flush handed down from a stacking driver may

	 * translate into nothing if the underlying device does not

	 * advertise a write-back cache.  In this case, simply

	 * complete the request.

assumes zero or single bio rq */

	/*

	 * If there's data but flush is not necessary, the request can be

	 * processed directly without going through flush machinery.  Queue

	 * for normal execution.

	/*

	 * @rq should go through flush machinery.  Mark it part of flush

	 * sequence and submit for further processing.

 Usually NULL */

/**

 * blkdev_issue_flush - queue a flush

 * @bdev:	blockdev to issue flush for

 *

 * Description:

 *    Issue a flush for the block device in question.

 bio based request queue hasn't flush queue */

/*

 * Allow driver to set its own lock class to fq->mq_flush_lock for

 * avoiding lockdep complaint.

 *

 * flush_end_io() may be called recursively from some driver, such as

 * nvme-loop, so lockdep may complain 'possible recursive locking' because

 * all 'struct blk_flush_queue' instance share same mq_flush_lock lock class

 * key. We need to assign different lock class for these driver's

 * fq->mq_flush_lock for avoiding the lockdep warning.

 *

 * Use dynamically allocated lock class key for each 'blk_flush_queue'

 * instance is over-kill, and more worse it introduces horrible boot delay

 * issue because synchronize_rcu() is implied in lockdep_unregister_key which

 * is called for each hctx release. SCSI probing may synchronously create and

 * destroy lots of MQ request_queues for non-existent devices, and some robot

 * test kernel always enable lockdep option. It is observed that more than half

 * an hour is taken during SCSI MQ probe with per-fq lock class.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2016 Christoph Hellwig.

/**

 * blk_mq_virtio_map_queues - provide a default queue mapping for virtio device

 * @qmap:	CPU to hardware queue map.

 * @vdev:	virtio device to provide a mapping for.

 * @first_vec:	first interrupt vectors to use for queues (usually 0)

 *

 * This function assumes the virtio device @vdev has at least as many available

 * interrupt vectors as @set has queues.  It will then query the vector

 * corresponding to each queue for it's affinity mask and built queue mapping

 * that maps a queue to the CPUs that have irq affinity for the corresponding

 * vector.

 SPDX-License-Identifier: GPL-2.0-only

/**

 * bd_link_disk_holder - create symlinks between holding disk and slave bdev

 * @bdev: the claimed slave bdev

 * @disk: the holding disk

 *

 * DON'T USE THIS UNLESS YOU'RE ALREADY USING IT.

 *

 * This functions creates the following sysfs symlinks.

 *

 * - from "slaves" directory of the holder @disk to the claimed @bdev

 * - from "holders" directory of the @bdev to the holder @disk

 *

 * For example, if /dev/dm-0 maps to /dev/sda and disk for dm-0 is

 * passed to bd_link_disk_holder(), then:

 *

 *   /sys/block/dm-0/slaves/sda --> /sys/block/sda

 *   /sys/block/sda/holders/dm-0 --> /sys/block/dm-0

 *

 * The caller must have claimed @bdev before calling this function and

 * ensure that both @bdev and @disk are valid during the creation and

 * lifetime of these symlinks.

 *

 * CONTEXT:

 * Might sleep.

 *

 * RETURNS:

 * 0 on success, -errno on failure.

 FIXME: remove the following once add_disk() handles errors */

	/*

	 * del_gendisk drops the initial reference to bd_holder_dir, so we need

	 * to keep our own here to allow for cleanup past that point.

/**

 * bd_unlink_disk_holder - destroy symlinks created by bd_link_disk_holder()

 * @bdev: the calimed slave bdev

 * @disk: the holding disk

 *

 * DON'T USE THIS UNLESS YOU'RE ALREADY USING IT.

 *

 * CONTEXT:

 * Might sleep.

 SPDX-License-Identifier: GPL-2.0

/*

 * t10_pi.c - Functions for generating and verifying T10 Protection

 *	      Information.

/*

 * Type 1 and Type 2 protection use the same format: 16 bit guard tag,

 * 16 bit app tag, 32 bit reference tag. Type 3 does not define the ref

 * tag.

/**

 * t10_pi_type1_prepare - prepare PI prior submitting request to device

 * @rq:              request with PI that should be prepared

 *

 * For Type 1/Type 2, the virtual start sector is the one that was

 * originally submitted by the block layer for the ref_tag usage. Due to

 * partitioning, MD/DM cloning, etc. the actual physical start sector is

 * likely to be different. Remap protection information to match the

 * physical LBA.

 Already remapped? */

/**

 * t10_pi_type1_complete - prepare PI prior returning request to the blk layer

 * @rq:              request with PI that should be prepared

 * @nr_bytes:        total bytes to prepare

 *

 * For Type 1/Type 2, the virtual start sector is the one that was

 * originally submitted by the block layer for the ref_tag usage. Due to

 * partitioning, MD/DM cloning, etc. the actual physical start sector is

 * likely to be different. Since the physical start sector was submitted

 * to the device, we should remap it back to virtual values expected by the

 * block layer.

 Type 3 does not have a reference tag so no remapping is required. */

 Type 3 does not have a reference tag so no remapping is required. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2016 Christoph Hellwig.

/**

 * blk_mq_pci_map_queues - provide a default queue mapping for PCI device

 * @qmap:	CPU to hardware queue map.

 * @pdev:	PCI device associated with @set.

 * @offset:	Offset to use for the pci irq vector

 *

 * This function assumes the PCI device @pdev has at least as many available

 * interrupt vectors as @set has queues.  It will then query the vector

 * corresponding to each queue for it's affinity mask and built queue mapping

 * that maps a queue to the CPUs that have irq affinity for the corresponding

 * vector.

 SPDX-License-Identifier: GPL-2.0

/*

 * The Kyber I/O scheduler. Controls latency by throttling queue depths using

 * scalable techniques.

 *

 * Copyright (C) 2017 Facebook

/*

 * Scheduling domains: the device is divided into multiple domains based on the

 * request type.

	/*

	 * In order to prevent starvation of synchronous requests by a flood of

	 * asynchronous requests, we reserve 25% of requests for synchronous

	 * operations.

/*

 * Maximum device-wide depth for each scheduling domain.

 *

 * Even for fast devices with lots of tags like NVMe, you can saturate the

 * device with only a fraction of the maximum possible queue depth. So, we cap

 * these to a reasonable value.

/*

 * Default latency targets for each scheduling domain.

/*

 * Batch size (number of requests we'll dispatch in a row) for each scheduling

 * domain.

/*

 * Requests latencies are recorded in a histogram with buckets defined relative

 * to the target latency:

 *

 * <= 1/4 * target latency

 * <= 1/2 * target latency

 * <= 3/4 * target latency

 * <= target latency

 * <= 1 1/4 * target latency

 * <= 1 1/2 * target latency

 * <= 1 3/4 * target latency

 * > 1 3/4 * target latency

	/*

	 * The width of the latency histogram buckets is

	 * 1 / (1 << KYBER_LATENCY_SHIFT) * target latency.

	/*

	 * The first (1 << KYBER_LATENCY_SHIFT) buckets are <= target latency,

	 * thus, "good".

 There are also (1 << KYBER_LATENCY_SHIFT) "bad" buckets. */

/*

 * We measure both the total latency and the I/O latency (i.e., latency after

 * submitting to the device).

/*

 * Per-cpu latency histograms: total latency and I/O latency for each scheduling

 * domain except for KYBER_OTHER.

/*

 * There is a same mapping between ctx & hctx and kcq & khd,

 * we use request->mq_ctx->index_hw to index the kcq in khd.

	/*

	 * Used to ensure operations on rq_list and kcq_map to be an atmoic one.

	 * Also protect the rqs on rq_list when merge.

	/*

	 * Each scheduling domain has a limited number of in-flight requests

	 * device-wide, limited by these tokens.

	/*

	 * Async request percentage, converted to per-word depth for

	 * sbitmap_get_shallow().

 Timer for stats aggregation and adjusting domain tokens. */

 Target latencies in nanoseconds. */

/*

 * Calculate the histogram bucket with the given percentile rank, or -1 if there

 * aren't enough samples yet.

	/*

	 * We do the calculation once we have 500 samples or one second passes

	 * since the first sample was recorded, whichever comes first.

 Sum all of the per-cpu latency histograms. */

	/*

	 * Check if any domains have a high I/O latency, which might indicate

	 * congestion in the device. Note that we use the p90; we don't want to

	 * be too sensitive to outliers here.

	/*

	 * Adjust the scheduling domain depths. If we determined that there was

	 * congestion, we throttle all domains with good latencies. Either way,

	 * we ease up on throttling domains with bad latencies.

		/*

		 * This is kind of subtle: different domains will not

		 * necessarily have enough samples to calculate the latency

		 * percentiles during the same window, so we have to remember

		 * the p99 for the next time we observe congestion; once we do,

		 * we don't want to throttle again until we get more data, so we

		 * reset it to -1.

		/*

		 * If this domain has bad latency, throttle less. Otherwise,

		 * throttle more iff we determined that there is congestion.

		 *

		 * The new depth is scaled linearly with the p99 latency vs the

		 * latency target. E.g., if the p99 is 3/4 of the target, then

		 * we throttle down to 3/4 of the current depth, and if the p99

		 * is 2x the target, then we double the depth.

	/*

	 * We use the scheduler tags as per-hardware queue queueing tokens.

	 * Async requests can be limited at this stage.

	/*

	 * If we failed to get a domain token, make sure the hardware queue is

	 * run when one becomes available. Note that this is serialized on

	 * khd->lock, but we still need to be careful about the waker.

		/*

		 * Try again in case a token was freed before we got on the wait

		 * queue.

	/*

	 * If we got a token while we were on the wait queue, remove ourselves

	 * from the wait queue to ensure that all wake ups make forward

	 * progress. It's possible that the waker already deleted the entry

	 * between the !list_empty_careful() check and us grabbing the lock, but

	 * list_del_init() is okay with that.

	/*

	 * If we already have a flushed request, then we just need to get a

	 * token for it. Otherwise, if there are pending requests in the kcqs,

	 * flush the kcqs, but only if we can get a token. If not, we should

	 * leave the requests in the kcqs so that they can be merged. Note that

	 * khd->lock serializes the flushes, so if we observed any bit set in

	 * the kcq_map, we will always get a request.

 There were either no pending requests or no tokens. */

	/*

	 * First, if we are still entitled to batch, try to dispatch a request

	 * from the batch.

	/*

	 * Either,

	 * 1. We were no longer entitled to a batch.

	 * 2. The domain we were batching didn't have any requests.

	 * 3. The domain we were batching was out of tokens.

	 *

	 * Start another batch. Note that this wraps back around to the original

	 * domain if no other domains have requests or tokens.

 SPDX-License-Identifier: GPL-2.0

/*

 * Block multiqueue core code

 *

 * Copyright (C) 2013-2014 Jens Axboe

 * Copyright (C) 2013-2014 Christoph Hellwig

/*

 * Check if any of the ctx, dispatch list or elevator

 * have pending work in this hardware queue.

/*

 * Mark this ctx as having pending work in this hardware queue

/*

 * Guarantee no request is in use, so we can change any data structure of

 * the queue afterward.

	/*

	 * In the !blk_mq case we are only calling this to kill the

	 * q_usage_counter, otherwise this increases the freeze depth

	 * and waits for it to return to zero.  For this reason there is

	 * no blk_unfreeze_queue(), and blk_freeze_queue() is not

	 * exported to drivers as the only user for unfreeze is blk_mq.

	/*

	 * ...just an alias to keep freeze and unfreeze actions balanced

	 * in the blk_mq_* namespace

/*

 * FIXME: replace the scsi_internal_device_*block_nowait() calls in the

 * mpt3sas driver such that this function can be removed.

/**

 * blk_mq_wait_quiesce_done() - wait until in-progress quiesce is done

 * @q: request queue.

 *

 * Note: it is driver's responsibility for making sure that quiesce has

 * been started.

/**

 * blk_mq_quiesce_queue() - wait until all ongoing dispatches have finished

 * @q: request queue.

 *

 * Note: this function does not prevent that the struct request end_io()

 * callback function is invoked. Once this function is returned, we make

 * sure no dispatch can happen until the queue is unquiesced via

 * blk_mq_unquiesce_queue().

/*

 * blk_mq_unquiesce_queue() - counterpart of blk_mq_quiesce_queue()

 * @q: request queue.

 *

 * This function recovers queue into the state before quiescing

 * which is done by blk_mq_quiesce_queue.

 dispatch requests which are inserted during quiescing */

 tag was already set */

 caller already holds a reference, add for remainder */

 alloc_time includes depth and tag waits */

		/*

		 * Flush/passthrough requests are special and go directly to the

		 * dispatch list. Don't include reserved tags in the

		 * limiting, as it isn't useful.

	/*

	 * Try batched alloc if we want more than 1 tag.

	/*

	 * Waiting allocations only fail because of an inactive hctx.  In that

	 * case just retry the hctx assignment and tag allocation as CPU hotplug

	 * should have migrated us to an online CPU by now.

		/*

		 * Give up the CPU and sleep for a random short time to

		 * ensure that thread using a realtime scheduling class

		 * are migrated off the CPU, and thus off the hctx that

		 * is going away.

 alloc_time includes depth and tag waits */

	/*

	 * If the tag allocator sleeps we could get an allocation for a

	 * different hardware context.  No need to complicate the low level

	 * allocator for this for the rare use case of a command tied to

	 * a specific queue.

	/*

	 * Check if the hardware context is actually mapped to anything.

	 * If not tell the caller that it should skip this queue.

		/*

		 * Partial zone append completions cannot be supported as the

		 * BIO fragments may end up not being written sequentially.

 don't actually finish bio if it's part of flush sequence */

/**

 * blk_update_request - Complete multiple bytes without completing the request

 * @req:      the request being processed

 * @error:    block status code

 * @nr_bytes: number of bytes to complete for @req

 *

 * Description:

 *     Ends I/O on a number of bytes attached to @req, but doesn't complete

 *     the request structure even if @req doesn't have leftover.

 *     If @req has leftover, sets it up for the next range of segments.

 *

 *     Passing the result of blk_rq_bytes() as @nr_bytes guarantees

 *     %false return from this function.

 *

 * Note:

 *	The RQF_SPECIAL_PAYLOAD flag is ignored on purpose in this function

 *      except in the consistency check at the end of this function.

 *

 * Return:

 *     %false - this request doesn't have any more data

 *     %true  - this request has more data

 Completion has already been traced */

	/*

	 * completely done

		/*

		 * Reset counters so that the request stacking driver

		 * can find how many bytes remain in the request

		 * later.

 update sector only for requests with clear definition of sector */

 mixed attributes always follow the first bio */

		/*

		 * If total number of sectors is less than the first segment

		 * size, something has gone terribly wrong.

 recalculate the number of segments */

	/*

	 * All requests should have been marked as RQF_MQ_INFLIGHT, so

	 * update hctx->nr_active in batch

	/*

	 * With force threaded interrupts enabled, raising softirq from an SMP

	 * function call will always result in waking the ksoftirqd thread.

	 * This is probably worse than completing the request on a different

	 * cache domain.

 same CPU or cache domain?  Complete locally */

 don't try to IPI to an offline CPU */

	/*

	 * For a polled request, always complete locallly, it's pointless

	 * to redirect the completion.

/**

 * blk_mq_complete_request - end I/O on a request

 * @rq:		the request being processed

 *

 * Description:

 *	Complete a request by scheduling the ->complete_rq operation.

 shut up gcc false positive */

/**

 * blk_mq_start_request - Start processing a request

 * @rq: Pointer to request to be started

 *

 * Function used by device drivers to notify the block layer that a request

 * is going to be processed now, so blk layer can do proper initializations

 * such as starting the timeout timer.

 this request will be re-inserted to io scheduler queue */

		/*

		 * If RQF_DONTPREP, rq has contained some driver specific

		 * data, so insert it to hctx dispatch list to avoid any

		 * merge.

	/*

	 * We abuse this flag that is otherwise used by the I/O scheduler to

	 * request head insertion from the workqueue.

	/*

	 * If we find a request that isn't idle and the queue matches,

	 * we know the queue is busy. Return false to stop the iteration.

	/*

	 * blk_mq_queue_tag_busy_iter() has locked the request, so it cannot

	 * be reallocated underneath the timeout handler's processing, then

	 * the expire check is reliable. If the request is not expired, then

	 * it was completed and reallocated as a new request after returning

	 * from blk_mq_check_expired().

	/* A deadlock might occur if a request is stuck requiring a

	 * timeout at the same time a queue freeze is waiting

	 * completion, since the timeout code would not be able to

	 * acquire the queue reference here.

	 *

	 * That's why we don't use blk_queue_enter here; instead, we use

	 * percpu_ref_tryget directly, because we need to be able to

	 * obtain a reference even in the short window between the queue

	 * starting to freeze, by dropping the first reference in

	 * blk_freeze_queue_start, and the moment the last request is

	 * consumed, marked by the instant q_usage_counter reaches

	 * zero.

		/*

		 * Request timeouts are handled as a forward rolling timer. If

		 * we end up here it means that no requests are pending and

		 * also that no request has been pending for a while. Mark

		 * each hctx as idle.

 the hctx may be unmapped, so check it here */

/*

 * Process software queues that have been marked busy, splicing them

 * to the for-dispatch

/*

 * Mark us waiting for a tag. For shared tags, this involves hooking us into

 * the tag wakeups. For non-shared tags, we can simply mark us needing a

 * restart. For both cases, take care to check the condition again after

 * marking us as waiting.

		/*

		 * It's possible that a tag was freed in the window between the

		 * allocation failure and adding the hardware queue to the wait

		 * queue.

		 *

		 * Don't clear RESTART here, someone else could have set it.

		 * At most this will cost an extra queue run.

	/*

	 * It's possible that a tag was freed in the window between the

	 * allocation failure and adding the hardware queue to the wait

	 * queue.

	/*

	 * We got a tag, remove ourselves from the wait queue to ensure

	 * someone else gets the wakeup.

/*

 * Update dispatch busy with the Exponential Weighted Moving Average(EWMA):

 * - EWMA is one simple way to compute running average value

 * - weight(7/8 and 1/8) is applied so that it can decrease exponentially

 * - take 4 as factor for avoiding to get too small(0) result, and this

 *   factor doesn't matter because EWMA decreases exponentially

 ms units */

	/*

	 * If an I/O scheduler has been configured and we got a driver tag for

	 * the next request already, free it.

	/*

	 * If we end up here it is because we cannot dispatch a request to a

	 * specific zone due to LLD level zone-write locking or other zone

	 * related resource not being available. In this case, set the request

	 * aside in zone_list for retrying it later.

		/*

		 * The initial allocation attempt failed, so we need to

		 * rerun the hardware queue when a tag is freed. The

		 * waitqueue takes care of that. If the queue is run

		 * before we add this entry back on the dispatch list,

		 * we'll re-run it below.

			/*

			 * All budgets not got from this function will be put

			 * together during handling partial dispatch

 release all allocated budgets before calling to blk_mq_dispatch_rq_list */

/*

 * Returns true if we did some work AND can potentially do more.

	/*

	 * Now process all the entries, sending them to the driver.

		/*

		 * Flag last if we have no more requests, or if we have more

		 * but can't assign a driver tag to it.

		/*

		 * once the request is queued to lld, no need to cover the

		 * budget any more

			/*

			 * Move the request to zone_list and keep going through

			 * the dispatch list to find more requests the drive can

			 * accept.

	/* If we didn't flush the entire list, we could have told the driver

	 * there was more coming, but that turned out to be a lie.

	/*

	 * Any items that need requeuing? Stuff them into hctx->dispatch,

	 * that is where we will continue on next queue run.

 For non-shared tags, the RESTART check will suffice */

		/*

		 * Order adding requests to hctx->dispatch and checking

		 * SCHED_RESTART flag. The pair of this smp_mb() is the one

		 * in blk_mq_sched_restart(). Avoid restart code path to

		 * miss the new added requests to hctx->dispatch, meantime

		 * SCHED_RESTART is observed here.

		/*

		 * If SCHED_RESTART was set by the caller of this function and

		 * it is no longer set that means that it was cleared by another

		 * thread and hence that a queue rerun is needed.

		 *

		 * If 'no_tag' is set, that means that we failed getting

		 * a driver tag with an I/O scheduler attached. If our dispatch

		 * waitqueue is no longer active, ensure that we run the queue

		 * AFTER adding our entries back to the list.

		 *

		 * If no I/O scheduler has been configured it is possible that

		 * the hardware queue got stopped and restarted before requests

		 * were pushed back onto the dispatch list. Rerun the queue to

		 * avoid starvation. Notes:

		 * - blk_mq_run_hw_queue() checks whether or not a queue has

		 *   been stopped before rerunning a queue.

		 * - Some but not all block drivers stop a queue before

		 *   returning BLK_STS_RESOURCE. Two exceptions are scsi-mq

		 *   and dm-rq.

		 *

		 * If driver returns BLK_STS_RESOURCE and SCHED_RESTART

		 * bit is set, run queue after a delay to avoid IO stalls

		 * that could otherwise occur if the queue is idle.  We'll do

		 * similar if we couldn't get budget or couldn't lock a zone

		 * and SCHED_RESTART is set.

/**

 * __blk_mq_run_hw_queue - Run a hardware queue.

 * @hctx: Pointer to the hardware queue to run.

 *

 * Send pending requests to the hardware.

	/*

	 * We can't run the queue inline with ints disabled. Ensure that

	 * we catch bad users of this early.

/*

 * It'd be great if the workqueue API had a way to pass

 * in a mask and had some smarts for more clever placement.

 * For now we just round-robin here, switching for every

 * BLK_MQ_CPU_WORK_BATCH queued items.

	/*

	 * Do unbound schedule if we can't find a online CPU for this hctx,

	 * and it should only happen in the path of handling CPU DEAD.

		/*

		 * Make sure to re-select CPU next time once after CPUs

		 * in hctx->cpumask become online again.

/**

 * __blk_mq_delay_run_hw_queue - Run (or schedule to run) a hardware queue.

 * @hctx: Pointer to the hardware queue to run.

 * @async: If we want to run the queue asynchronously.

 * @msecs: Milliseconds of delay to wait before running the queue.

 *

 * If !@async, try to run the queue now. Else, run the queue asynchronously and

 * with a delay of @msecs.

/**

 * blk_mq_delay_run_hw_queue - Run a hardware queue asynchronously.

 * @hctx: Pointer to the hardware queue to run.

 * @msecs: Milliseconds of delay to wait before running the queue.

 *

 * Run a hardware queue asynchronously with a delay of @msecs.

/**

 * blk_mq_run_hw_queue - Start to run a hardware queue.

 * @hctx: Pointer to the hardware queue to run.

 * @async: If we want to run the queue asynchronously.

 *

 * Check if the request queue is not in a quiesced state and if there are

 * pending requests to be sent. If this is true, run the queue to send requests

 * to hardware.

	/*

	 * When queue is quiesced, we may be switching io scheduler, or

	 * updating nr_hw_queues, or other things, and we can't run queue

	 * any more, even __blk_mq_hctx_has_pending() can't be called safely.

	 *

	 * And queue will be rerun in blk_mq_unquiesce_queue() if it is

	 * quiesced.

/*

 * Is the request queue handled by an IO scheduler that does not respect

 * hardware queues when dispatching?

/*

 * Return prefered queue to dispatch from (if any) for non-mq aware IO

 * scheduler.

	/*

	 * If the IO scheduler does not respect hardware queues when

	 * dispatching, we just don't bother with multiple HW queues and

	 * dispatch from hctx for the current CPU since running multiple queues

	 * just causes lock contention inside the scheduler and pointless cache

	 * bouncing.

/**

 * blk_mq_run_hw_queues - Run all hardware queues in a request queue.

 * @q: Pointer to the request queue to run.

 * @async: If we want to run the queue asynchronously.

		/*

		 * Dispatch from this hctx either if there's no hctx preferred

		 * by IO scheduler or if it has requests that bypass the

		 * scheduler.

/**

 * blk_mq_delay_run_hw_queues - Run all hardware queues asynchronously.

 * @q: Pointer to the request queue to run.

 * @msecs: Milliseconds of delay to wait before running the queues.

		/*

		 * Dispatch from this hctx either if there's no hctx preferred

		 * by IO scheduler or if it has requests that bypass the

		 * scheduler.

/**

 * blk_mq_queue_stopped() - check whether one or more hctxs have been stopped

 * @q: request queue.

 *

 * The caller is responsible for serializing this function against

 * blk_mq_{start,stop}_hw_queue().

/*

 * This function is often used for pausing .queue_rq() by driver when

 * there isn't enough resource or some conditions aren't satisfied, and

 * BLK_STS_RESOURCE is usually returned.

 *

 * We do not guarantee that dispatch can be drained or blocked

 * after blk_mq_stop_hw_queue() returns. Please use

 * blk_mq_quiesce_queue() for that requirement.

/*

 * This function is often used for pausing .queue_rq() by driver when

 * there isn't enough resource or some conditions aren't satisfied, and

 * BLK_STS_RESOURCE is usually returned.

 *

 * We do not guarantee that dispatch can be drained or blocked

 * after blk_mq_stop_hw_queues() returns. Please use

 * blk_mq_quiesce_queue() for that requirement.

	/*

	 * If we are stopped, don't run the queue.

/**

 * blk_mq_request_bypass_insert - Insert a request at dispatch list.

 * @rq: Pointer to request to be inserted.

 * @at_head: true if the request should be inserted at the head of the list.

 * @run_queue: If we should run the hardware queue after inserting the request.

 *

 * Should only be used carefully, when the caller knows we want to

 * bypass a potential IO scheduler on the target device.

	/*

	 * preemption doesn't flush plug list, so it's possible ctx->cpu is

	 * offline now

	/*

	 * If we didn't flush the entire list, we could have told the driver

	 * there was more coming, but that turned out to be a lie.

 This can't fail, since GFP_NOIO includes __GFP_DIRECT_RECLAIM. */

	/*

	 * For OK queue, we are done. For error, caller may kill it.

	 * Any other error (busy), just add it to our list as we

	 * previously would have done.

	/*

	 * RCU or SRCU read lock is needed before checking quiesced flag.

	 *

	 * When queue is stopped or quiesced, ignore 'bypass_insert' from

	 * blk_mq_request_issue_directly(), and return BLK_STS_OK to caller,

	 * and avoid driver to try to dispatch again.

/**

 * blk_mq_try_issue_directly - Try to send a request directly to device driver.

 * @hctx: Pointer of the associated hardware queue.

 * @rq: Pointer to request to be sent.

 *

 * If the device has enough resources to accept a new request now, send the

 * request directly to device driver. Else, insert at hctx->dispatch queue, so

 * we can try send it another time in the future. Requests inserted at this

 * queue have higher priority.

	/*

	 * If we didn't flush the entire list, we could have told

	 * the driver there was more coming, but that turned out to

	 * be a lie.

/*

 * Allow 2x BLK_MAX_REQUEST_COUNT requests on plug queue for multiple

 * queues. This is important for md arrays to benefit from merging

 * requests.

/**

 * blk_mq_submit_bio - Create and send a request to block device.

 * @bio: Bio pointer.

 *

 * Builds up a request structure from @q and @bio and send to the device. The

 * request may not be queued directly to hardware if:

 * * This request can be merged with another one

 * * We want to place request at plug queue for possible future merging

 * * There is an IO scheduler active at this queue

 *

 * It will not queue the request if there is an error with the bio, or at the

 * request creation.

		/*

		 * Use plugging if we have a ->commit_rqs() hook as well, as

		 * we know the driver uses bd->last in a smart fashion.

		 *

		 * Use normal plugging if this disk is slow HDD, as sequential

		 * IO may benefit a lot from plug merging.

 Insert the request at the IO scheduler queue */

		/*

		 * We do limited plugging. If the bio can be merged, do that.

		 * Otherwise the existing request in the plug list will be

		 * issued. So the plug list will have one request at most

		 * The plug list might get flushed before this. If that happens,

		 * the plug list is empty, and same_queue_rq is invalid.

		/*

		 * There is no scheduler and we can try to send directly

		 * to the hardware.

 Default case. */

 called before freeing request pool in @tags */

 There is no need to clear a driver tags own mapping */

	/*

	 * Wait until all pending iteration is done.

	 *

	 * Request reference is cleared and it is guaranteed to be observed

	 * after the ->lock is released.

		/*

		 * Remove kmemleak object previously allocated in

		 * blk_mq_alloc_rqs().

	/*

	 * rq_size is the size of the request plus driver payload, rounded

	 * to the cacheline size

		/*

		 * Allow kmemleak to scan these pages as they contain pointers

		 * to additional allocations like via ops->init_request().

	/*

	 * Prevent new request from being allocated on the current hctx.

	 *

	 * The smp_mb__after_atomic() Pairs with the implied barrier in

	 * test_and_set_bit_lock in sbitmap_get().  Ensures the inactive flag is

	 * seen once we return from the tag allocator.

	/*

	 * Try to grab a reference to the queue and wait for any outstanding

	 * requests.  If we could not grab a reference the queue has been

	 * frozen and there are no requests.

/*

 * 'cpu' is going away. splice any existing rq_list entries from this

 * software queue to the hw queue dispatch list, and ensure that it

 * gets run.

/*

 * Before freeing hw queue, clearing the flush request reference in

 * tags->rqs[] for avoiding potential UAF.

 The hw queue may not be mapped yet */

	/*

	 * Wait until all pending iteration is done.

	 *

	 * Request reference is cleared and it is guaranteed to be observed

	 * after the ->lock is released.

 hctx->ctxs will be freed in queue's release handler */

	/*

	 * Allocate space for all possible cpus to avoid allocation at

	 * runtime

		/*

		 * Set local node, IFF we have more than one hw queue. If

		 * not, we remain on the home node of the device

	/*

	 * Map software to hardware queues.

	 *

	 * If the cpu isn't present, the cpu is mapped to first hctx.

 unmapped hw queue can be remapped after CPU topo changed */

				/*

				 * If tags initialization fail for some hctx,

				 * that hctx won't be brought online.  In this

				 * case, remap the current ctx to hctx[0] which

				 * is guaranteed to always have tags allocated

			/*

			 * If the CPU is already set in the mask, then we've

			 * mapped this one already. This can happen if

			 * devices share queues across queue maps.

			/*

			 * If the nr_ctx type overflows, we have exceeded the

			 * amount of sw queues we can support.

		/*

		 * If no software queues are mapped to this hardware queue,

		 * disable it and free the request entries.

			/* Never unmap queue 0.  We need it as a

			 * fallback in case of a new remap fails

			 * allocation

		/*

		 * Set the map size to the number of mapped software queues.

		 * This is more accurate and more efficient than looping

		 * over all possibly mapped software queues.

		/*

		 * Initialize batch roundrobin counts

/*

 * Caller needs to ensure that we're either frozen/quiesced, or that

 * the queue isn't live yet.

 just transitioned to unshared */

 update existing queue */

	/*

	 * Check to see if we're transitioning to shared (from 1 to 2 queues).

 update existing queue */

 All allocations will be freed in release handler of q->mq_kobj */

/*

 * It is the actual release handler for mq, but we do it from

 * request queue's release handler for avoiding use-after-free

 * and headache because q->mq_kobj shouldn't have been introduced,

 * but we can't group ctx/kctx kobj without it.

 all hctx are in .unused_hctx_list now */

	/*

	 * release .mq_kobj and sw queue's kobject now because

	 * both share lifetime with request queue.

 reuse dead hctx first */

 protect against switching io scheduler  */

		/*

		 * If the hw queue has been mapped to another numa node,

		 * we need to realloc the hctx. If allocation fails, fallback

		 * to use the previous one.

	/*

	 * Increasing nr_hw_queues fails. Free the newly allocated

	 * hctxs and keep the previous q->nr_hw_queues.

 mark the queue as mq asap */

 init q->mq_kobj and sw queues' kobjects */

	/*

	 * Default to classic polling

 tags can _not_ be used after returning from blk_mq_exit_queue */

 Checks hctx->flags & BLK_MQ_F_TAG_QUEUE_SHARED. */

 May clear BLK_MQ_F_TAG_QUEUE_SHARED in hctx->flags. */

/*

 * Allocate the request maps associated with this tag_set. Note that this

 * may reduce the depth asked for, if memory is tight. set->queue_depth

 * will be updated to reflect the allocated depth.

	/*

	 * blk_mq_map_queues() and multiple .map_queues() implementations

	 * expect that set->map[HCTX_TYPE_DEFAULT].nr_queues is set to the

	 * number of hardware queues.

		/*

		 * transport .map_queues is usually done in the following

		 * way:

		 *

		 * for (queue = 0; queue < set->nr_hw_queues; queue++) {

		 * 	mask = get_cpu_mask(queue)

		 * 	for_each_cpu(cpu, mask)

		 * 		set->map[x].mq_map[cpu] = queue;

		 * }

		 *

		 * When we need to remap, the table has to be cleared for

		 * killing stale mapping since one CPU may not be mapped

		 * to any hw queue.

/*

 * Alloc a tag set to be associated with one or more request queues.

 * May fail with EINVAL for various error conditions. May adjust the

 * requested depth down, if it's too large. In that case, the set

 * value will be stored in set->queue_depth.

	/*

	 * If a crashdump is active, then we are potentially in a very

	 * memory constrained environment. Limit us to 1 queue and

	 * 64 tags to prevent using too much memory.

	/*

	 * There is no use for more h/w queues than cpus if we just have

	 * a single map

 allocate and initialize a tagset for a simple single-queue device */

		/*

		 * If we're using an MQ scheduler, just update the scheduler

		 * queue depth. This is similar to what the old code would do.

/*

 * request_queue and elevator_type pair.

 * It is just used by __blk_mq_update_nr_hw_queues to cache

 * the elevator_type associated with a request_queue.

/*

 * Cache the elevator_type in qe pair list and switch the

 * io scheduler to 'none'

	/*

	 * After elevator_switch_mq, the previous elevator_queue will be

	 * released by elevator_release. The reference of the io scheduler

	 * module get by elevator_get will also be put. So we need to get

	 * a reference of the io scheduler module here to prevent it to be

	 * removed.

	/*

	 * Switch IO scheduler to 'none', cleaning up the data associated

	 * with the previous scheduler. We will switch back once we are done

	 * updating the new sw to hw queue mappings.

 Enable polling stats and return whether they were already enabled. */

	/*

	 * We don't arm the callback if polling stats are not enabled or the

	 * callback is already active.

	/*

	 * If stats collection isn't on, don't sleep but turn it on for

	 * future users

	/*

	 * As an optimistic guess, use half of the mean service time

	 * for this type of request. We can (and should) make this smarter.

	 * For instance, if the completion latencies are tight, we can

	 * get closer than just half the mean. This is especially

	 * important on devices where the completion latencies are longer

	 * than ~10 usec. We do use the stats for the relevant IO size

	 * if available which does lead to better estimates.

	/*

	 * If a request has completed on queue that uses an I/O scheduler, we

	 * won't get back a request from blk_qc_to_rq.

	/*

	 * If we get here, hybrid polling is enabled. Hence poll_nsec can be:

	 *

	 *  0:	use half of prev avg

	 * >0:	use this specific value

	/*

	 * This will be replaced with the stats tracking code, using

	 * 'avg_completion_time / 2' as the pre-sleep target.

	/*

	 * If we sleep, have the caller restart the poll loop to reset the

	 * state.  Like for the other success return cases, the caller is

	 * responsible for checking if the IO completed.  If the IO isn't

	 * complete, we'll get called again and will go straight to the busy

	 * poll loop.

 SPDX-License-Identifier: GPL-2.0

/*

 * blk-integrity.c - Block layer data integrity extensions

 *

 * Copyright (C) 2007, 2008 Oracle Corporation

 * Written by: Martin K. Petersen <martin.petersen@oracle.com>

/**

 * blk_rq_count_integrity_sg - Count number of integrity scatterlist elements

 * @q:		request queue

 * @bio:	bio with integrity metadata attached

 *

 * Description: Returns the number of elements required in a

 * scatterlist corresponding to the integrity metadata in a bio.

/**

 * blk_rq_map_integrity_sg - Map integrity metadata into a scatterlist

 * @q:		request queue

 * @bio:	bio with integrity metadata attached

 * @sglist:	target scatterlist

 *

 * Description: Map the integrity vectors in request into a

 * scatterlist.  The scatterlist must be big enough to hold all

 * elements.  I.e. sized using blk_rq_count_integrity_sg().

/**

 * blk_integrity_compare - Compare integrity profile of two disks

 * @gd1:	Disk to compare

 * @gd2:	Disk to compare

 *

 * Description: Meta-devices like DM and MD need to verify that all

 * sub-devices use the same integrity format before advertising to

 * upper layers that they can send/receive integrity metadata.  This

 * function can be used to check whether two gendisk devices have

 * compatible integrity formats.

/**

 * blk_integrity_register - Register a gendisk as being integrity-capable

 * @disk:	struct gendisk pointer to make integrity-aware

 * @template:	block integrity profile to register

 *

 * Description: When a device needs to advertise itself as being able to

 * send/receive integrity metadata it must use this function to register

 * the capability with the block layer. The template is a blk_integrity

 * struct with values appropriate for the underlying hardware. See

 * Documentation/block/data-integrity.rst.

/**

 * blk_integrity_unregister - Unregister block integrity profile

 * @disk:	disk whose integrity profile to unregister

 *

 * Description: This function unregisters the integrity capability from

 * a block device.

 ensure all bios are off the integrity workqueue */

 SPDX-License-Identifier: GPL-2.0-or-later

/************************************************************

 * EFI GUID Partition Table handling

 *

 * http://www.uefi.org/specs/

 * http://www.intel.com/technology/efi/

 *

 * efi.[ch] by Matt Domsch <Matt_Domsch@dell.com>

 *   Copyright 2000,2001,2002,2004 Dell Inc.

 *

 * TODO:

 *

 * Changelog:

 * Mon August 5th, 2013 Davidlohr Bueso <davidlohr@hp.com>

 * - detect hybrid MBRs, tighter pMBR checking & cleanups.

 *

 * Mon Nov 09 2004 Matt Domsch <Matt_Domsch@dell.com>

 * - test for valid PMBR and valid PGPT before ever reading

 *   AGPT, allow override with 'gpt' kernel command line option.

 * - check for first/last_usable_lba outside of size of disk

 *

 * Tue  Mar 26 2002 Matt Domsch <Matt_Domsch@dell.com>

 * - Ported to 2.5.7-pre1 and 2.5.7-dj2

 * - Applied patch to avoid fault in alternate header handling

 * - cleaned up find_valid_gpt

 * - On-disk structure and copy in memory is *always* LE now - 

 *   swab fields as needed

 * - remove print_gpt_header()

 * - only use first max_p partition entries, to keep the kernel minor number

 *   and partition numbers tied.

 *

 * Mon  Feb 04 2002 Matt Domsch <Matt_Domsch@dell.com>

 * - Removed __PRIPTR_PREFIX - not being used

 *

 * Mon  Jan 14 2002 Matt Domsch <Matt_Domsch@dell.com>

 * - Ported to 2.5.2-pre11 + library crc32 patch Linus applied

 *

 * Thu Dec 6 2001 Matt Domsch <Matt_Domsch@dell.com>

 * - Added compare_gpts().

 * - moved le_efi_guid_to_cpus() back into this file.  GPT is the only

 *   thing that keeps EFI GUIDs on disk.

 * - Changed gpt structure names and members to be simpler and more Linux-like.

 * 

 * Wed Oct 17 2001 Matt Domsch <Matt_Domsch@dell.com>

 * - Removed CONFIG_DEVFS_VOLUMES_UUID code entirely per Martin Wilck

 *

 * Wed Oct 10 2001 Matt Domsch <Matt_Domsch@dell.com>

 * - Changed function comments to DocBook style per Andreas Dilger suggestion.

 *

 * Mon Oct 08 2001 Matt Domsch <Matt_Domsch@dell.com>

 * - Change read_lba() to use the page cache per Al Viro's work.

 * - print u64s properly on all architectures

 * - fixed debug_printk(), now Dprintk()

 *

 * Mon Oct 01 2001 Matt Domsch <Matt_Domsch@dell.com>

 * - Style cleanups

 * - made most functions static

 * - Endianness addition

 * - remove test for second alternate header, as it's not per spec,

 *   and is unnecessary.  There's now a method to read/write the last

 *   sector of an odd-sized disk from user space.  No tools have ever

 *   been released which used this code, so it's effectively dead.

 * - Per Asit Mallick of Intel, added a test for a valid PMBR.

 * - Added kernel command line option 'gpt' to override valid PMBR test.

 *

 * Wed Jun  6 2001 Martin Wilck <Martin.Wilck@Fujitsu-Siemens.com>

 * - added devfs volume UUID support (/dev/volumes/uuids) for

 *   mounting file systems by the partition GUID. 

 *

 * Tue Dec  5 2000 Matt Domsch <Matt_Domsch@dell.com>

 * - Moved crc32() to linux/lib, added efi_crc32().

 *

 * Thu Nov 30 2000 Matt Domsch <Matt_Domsch@dell.com>

 * - Replaced Intel's CRC32 function with an equivalent

 *   non-license-restricted version.

 *

 * Wed Oct 25 2000 Matt Domsch <Matt_Domsch@dell.com>

 * - Fixed the last_lba() call to return the proper last block

 *

 * Thu Oct 12 2000 Matt Domsch <Matt_Domsch@dell.com>

 * - Thanks to Andries Brouwer for his debugging assistance.

 * - Code works, detects all the partitions.

 *

/* This allows a kernel command line option 'gpt' to override

 * the test for invalid PMBR.  Not __initdata because reloading

 * the partition tables happens after init too.

/**

 * efi_crc32() - EFI version of crc32 function

 * @buf: buffer to calculate crc32 of

 * @len: length of buf

 *

 * Description: Returns EFI-style CRC32 value for @buf

 * 

 * This function uses the little endian Ethernet polynomial

 * but seeds the function with ~0, and xor's with ~0 at the end.

 * Note, the EFI Specification, v1.02, has a reference to

 * Dr. Dobbs Journal, May 1994 (actually it's in May 1992).

/**

 * last_lba(): return number of last logical block of device

 * @disk: block device

 * 

 * Description: Returns last LBA value on success, 0 on error.

 * This is stored (by sd and ide-geometry) in

 *  the part[0] entry for this disk, and is the number of

 *  physical sectors available on the disk.

 set to 0x00000001 (i.e., the LBA of the GPT Partition Header) */

/**

 * is_pmbr_valid(): test Protective MBR for validity

 * @mbr: pointer to a legacy mbr structure

 * @total_sectors: amount of sectors in the device

 *

 * Description: Checks for a valid protective or hybrid

 * master boot record (MBR). The validity of a pMBR depends

 * on all of the following properties:

 *  1) MSDOS signature is in the last two bytes of the MBR

 *  2) One partition of type 0xEE is found

 *

 * In addition, a hybrid MBR will have up to three additional

 * primary partitions, which point to the same space that's

 * marked out by up to three GPT partitions.

 *

 * Returns 0 upon invalid MBR, or GPT_MBR_PROTECTIVE or

 * GPT_MBR_HYBRID depending on the device layout.

 invalid by default */

			/*

			 * Ok, we at least know that there's a protective MBR,

			 * now check if there are other partition types for

			 * hybrid MBR.

	/*

	 * Protective MBRs take up the lesser of the whole disk

	 * or 2 TiB (32bit LBA), ignoring the rest of the disk.

	 * Some partitioning programs, nonetheless, choose to set

	 * the size to the maximum 32-bit limitation, disregarding

	 * the disk size.

	 *

	 * Hybrid MBRs do not necessarily comply with this.

	 *

	 * Consider a bad value here to be a warning to support dd'ing

	 * an image from a smaller disk to a larger disk.

/**

 * read_lba(): Read bytes from disk, starting at given LBA

 * @state: disk parsed partitions

 * @lba: the Logical Block Address of the partition table

 * @buffer: destination buffer

 * @count: bytes to read

 *

 * Description: Reads @count bytes from @state->disk into @buffer.

 * Returns number of bytes read on success, 0 on error.

/**

 * alloc_read_gpt_entries(): reads partition entries from disk

 * @state: disk parsed partitions

 * @gpt: GPT header

 * 

 * Description: Returns ptes on success,  NULL on error.

 * Allocates space for PTEs based on information found in @gpt.

 * Notes: remember to free pte when you're done!

/**

 * alloc_read_gpt_header(): Allocates GPT header, reads into it from disk

 * @state: disk parsed partitions

 * @lba: the Logical Block Address of the partition table

 * 

 * Description: returns GPT header on success, NULL on error.   Allocates

 * and fills a GPT header starting at @ from @state->disk.

 * Note: remember to free gpt when finished with it.

/**

 * is_gpt_valid() - tests one GPT header and PTEs for validity

 * @state: disk parsed partitions

 * @lba: logical block address of the GPT header to test

 * @gpt: GPT header ptr, filled on return.

 * @ptes: PTEs ptr, filled on return.

 *

 * Description: returns 1 if valid,  0 on error.

 * If valid, returns pointers to newly allocated GPT header and PTEs.

 Check the GUID Partition Table signature */

 Check the GUID Partition Table header size is too big */

 Check the GUID Partition Table header size is too small */

 Check the GUID Partition Table CRC */

	/* Check that the my_lba entry points to the LBA that contains

	/* Check the first_usable_lba and last_usable_lba are

	 * within the disk.

 Check that sizeof_partition_entry has the correct value */

 Sanity check partition table size */

 Check the GUID Partition Entry Array CRC */

 We're done, all's well */

/**

 * is_pte_valid() - tests one PTE for validity

 * @pte:pte to check

 * @lastlba: last lba of the disk

 *

 * Description: returns 1 if valid,  0 on error.

/**

 * compare_gpts() - Search disk for valid GPT headers and PTEs

 * @pgpt: primary GPT header

 * @agpt: alternate GPT header

 * @lastlba: last LBA number

 *

 * Description: Returns nothing.  Sanity checks pgpt and agpt fields

 * and prints warnings on discrepancies.

 * 

/**

 * find_valid_gpt() - Search disk for valid GPT headers and PTEs

 * @state: disk parsed partitions

 * @gpt: GPT header ptr, filled on return.

 * @ptes: PTEs ptr, filled on return.

 *

 * Description: Returns 1 if valid, 0 on error.

 * If valid, returns pointers to newly allocated GPT header and PTEs.

 * Validity depends on PMBR being valid (or being overridden by the

 * 'gpt' kernel command line option) and finding either the Primary

 * GPT header and PTEs valid, or the Alternate GPT header and PTEs

 * valid.  If the Primary GPT header is not valid, the Alternate GPT header

 * is not checked unless the 'gpt' kernel command line option is passed.

 * This protects against devices which misreport their size, and forces

 * the user to decide to use the Alternate GPT.

 This will be added to the EFI Spec. per Intel after v1.02. */

 The obviously unsuccessful case */

 The good cases */

/**

 * utf16_le_to_7bit(): Naively converts a UTF-16LE string to 7-bit ASCII characters

 * @in: input UTF-16LE string

 * @size: size of the input string

 * @out: output string ptr, should be capable to store @size+1 characters

 *

 * Description: Converts @size UTF16-LE symbols from @in string to 7-bit

 * ASCII characters and stores them to @out. Adds trailing zero to @out array.

/**

 * efi_partition - scan for GPT partitions

 * @state: disk parsed partitions

 *

 * Description: called from check.c, if the disk contains GPT

 * partitions, sets up partition entries in the kernel.

 *

 * If the first block on the disk is a legacy MBR,

 * it will get handled by msdos_partition().

 * If it's a Protective MBR, we'll handle it here.

 *

 * We do not create a Linux partition for GPT, but

 * only for the actual data partitions.

 * Returns:

 * -1 if unable to read the partition table

 *  0 if this isn't our partition table

 *  1 if successful

 *

 If this is a RAID volume, tell md */

 Naively convert UTF16-LE to 7 bits. */

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/atari.c

 *

 *  Code extracted from drivers/block/genhd.c

 *

 *  Copyright (C) 1991-1998  Linus Torvalds

 *  Re-organised Feb 1998 Russell King

/* ++guenther: this should be settable by the user ("make config")?.

/* check if a partition entry looks valid -- Atari format is assumed if at

 0:unknown, 1:AHDI, 2:ICD/Supra */

	/*

	 * ATARI partition scheme supports 512 lba only.  If this is not

	 * the case, bail early to avoid miscalculating hd_size.

 Verify this is an Atari rootsector: */

		/*

		 * if there's no valid primary partition, assume that no Atari

		 * format partition table (there's no reliable magic or the like

	         * :-()

 active partition */

 we don't care about other id's */

 extension partition */

 ++roman: sanity check: bit 0 of flg field must be set */

 end of linked partition list */

 no extended partitions -> test ICD-format */

 sanity check: no ICD format if first partition invalid */

 accept only GEM,BGM,RAW,LNX,SWP partitions */

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/amiga.c

 *

 *  Code extracted from drivers/block/genhd.c

 *

 *  Copyright (C) 1991-1998  Linus Torvalds

 *  Re-organised Feb 1998 Russell King

 Multiplier for disk block size */

		/* Try again with 0xdc..0xdf zeroed, Windows might have

		 * trashed it.

 blksize is blocks per 512 byte standard block */

 Be more informative */

 Read in terms partition table understands */

 Tell Kernel about it */

 Be even more informative to aid mounting */

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/karma.c

 *  Rio Karma partition info.

 *

 *  Copyright (C) 2006 Bob Copeland (me@bobcopeland.com)

 *  based on osf.c

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/mac.c

 *

 *  Code extracted from drivers/block/genhd.c

 *  Copyright (C) 1991-1998  Linus Torvalds

 *  Re-organised Feb 1998 Russell King

/*

 * Code to understand MacOS partition tables.

 Get 0th block and look at the first partition map entry. */

 not a MacOS disk */

		/*

		 * If this is the first bootable partition, tell the

		 * setup code, in case it wants to make this the root.

 CONFIG_PPC_PMAC */

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/msdos.c

 *

 *  Code extracted from drivers/block/genhd.c

 *  Copyright (C) 1991-1998  Linus Torvalds

 *

 *  Thanks to Branko Lankester, lankeste@fwi.uva.nl, who found a bug

 *  in the early extended-partition checks and added DM partitions

 *

 *  Support for DiskManager v6.0x added by Mark Lord,

 *  with information provided by OnTrack.  This now works for linux fdisk

 *  and LILO, as well as loadlin and bootln.  Note that disks other than

 *  /dev/hda *must* have a "DOS" type 0x51 partition in the first slot (hda1).

 *

 *  More flexible handling of extended partitions - aeb, 950831

 *

 *  Check partition table on IDE disks for common CHS translations

 *

 *  Re-organised Feb 1998 Russell King

 *

 *  BSD disklabel support by Yossi Gottlieb <yogo@math.tau.ac.il>

 *  updated by Marc Espie <Marc.Espie@openbsd.org>

 *

 *  Unixware slices support by Andrzej Krzysztofowicz <ankry@mif.pg.gda.pl>

 *  and Krzysztof G. Baranowski <kgb@knm.org.pl>

/*

 * Many architectures don't like unaligned accesses, while

 * the nr_sects and start_sect partition table entries are

 * at a 2 (mod 4) address.

 Value is EBCDIC 'IBMA' */

	/*

	 * Assume the partition table is valid if Linux partitions exists.

	 * Note that old Solaris/x86 partitions use the same indicator as

	 * Linux swap partitions, so we consider that a Linux partition as

	 * well.

/*

 * Create devices for each logical partition in an extended partition.

 * The logical partitions form a linked list, with each entry being

 * a partition table with two entries.  The first entry

 * is the real data partition (with a start relative to the partition

 * table start).  The second is a pointer to the next logical partition

 * (with a start relative to the entire extended partition).

 * We do not create a Linux partition for the partition tables, but

 * only for the actual data partitions.

	int loopct = 0;		/* number of links followed

		/*

		 * Usually, the first entry is the real data partition,

		 * the 2nd entry is the next extended partition, or empty,

		 * and the 3rd and 4th entries are unused.

		 * However, DRDOS sometimes has the extended partition as

		 * the first entry (when the data partition is empty),

		 * and OS/2 seems to use all four entries.

		/*

		 * First process the data partition(s)

			/* Check the 3rd and 4th entries -

		/*

		 * Next, process the (first) extended partition, if present.

		 * (So far, there seems to be no reason to make

		 *  parse_extended()  recursive and allow a tree

		 *  of extended partitions.)

		 * It should be a link to the next logical partition.

 nothing left to do */

 ID tag of partition */

 permission flags */

 start sector no of partition */

 # of blocks in partition */

 info needed by mboot */

 to verify vtoc sanity */

 layout version */

 volume name */

 sector size in bytes */

 number of partitions */

 free space */

 slice headers */

 timestamp */

 for compatibility */

/* james@bpgc.com: Solaris has a nasty indicator: 0x82 which also

 Ensure we can handle previous case of VTOC with 8 entries gracefully */

		/* solaris partitions are relative to current MS-DOS

 check against BSD src/sys/sys/disklabel.h for consistency */

 The disk magic number */

 disklabel unused partition entry ID */

 the magic number */

 drive type */

 controller/d_type specific */

 type name, e.g. "eagle" */

 pack identifier */

 # of bytes per sector */

 # of data sectors per track */

 # of tracks per cylinder */

 # of data cylinders per unit */

 # of data sectors per cylinder */

 # of data sectors per unit */

 # of spare sectors per track */

 # of spare sectors per cylinder */

 # of alt. cylinders per unit */

 rotational speed */

 hardware sector interleave */

 sector 0 skew, per track */

 sector 0 skew, per cylinder */

 head switch time, usec */

 track-to-track seek, usec */

 generic flags */

 drive-type specific information */

 reserved for future use */

 the magic number (again) */

 xor of data incl. partitions */

 filesystem and partition information: */

 number of partitions in following */

 size of boot area at sn0, bytes */

 max size of fs superblock, bytes */

 the partition table */

 number of sectors in partition */

 starting sector */

 filesystem basic fragment size */

 filesystem type, see below */

 filesystem fragments per block */

 filesystem cylinders per group */

 actually may be more */

/*

 * Create devices for BSD partitions listed in a disklabel, under a

 * dos-like partition. See parse_extended() for more information.

 FreeBSD has relative offset if C partition offset is zero */

 full parent partition, we have it already */

 The disk magic number */

 The slice table magic nr */

 Unused slice entry ID */

 label */

 permission flags */

 starting sector */

 number of sectors in slice */

 drive type */

 the magic number */

 version number */

 serial number of the device */

 # of data cylinders per device */

 # of tracks per cylinder */

 # of data sectors per track */

 # of bytes per sector */

 # of first sector of this partition*/

 ? */

 byte offset of alternate table */

 byte length of alternate table */

 # of physical cylinders per device */

 # of physical tracks per cylinder */

 # of physical sectors per track */

 # of physical bytes per sector */

 ? */

 ? */

 pad */

 the magic number */

 version number */

 volume name */

 # of slices */

 ? */

 reserved */

 slice headers */

 408 */

/*

 * Create devices for Unixware partitions listed in a disklabel, under a

 * dos-like partition. See parse_extended() for more information.

 I omit the 0th slice as it is the same as whole disk. */

/*

 * Minix 2.0.0/2.0.2 subpartition support.

 * Anand Krishnamurthy <anandk@wiproge.med.ge.com>

 * Rajeev V. Pillai    <rajeevvp@yahoo.com>

	/* The first sector of a Minix partition can have either

	 * a secondary MBR describing its subpartitions, or

 subpartition table present */

 add each partition in use */

 CONFIG_MINIX_SUBPARTITION */

	/*

	 * Note order! (some AIX disks, e.g. unbootable kind,

	 * have no MSDOS 55aa)

	/*

	 * Now that the 55aa signature is present, this is probably

	 * either the boot sector of a FAT filesystem or a DOS-type

	 * partition table. Reject this in case the boot indicator

	 * is not 0 or 0x80.

			/*

			 * Even without a valid boot indicator value

			 * its still possible this is valid FAT filesystem

			 * without a partition table.

 If this is an EFI GPT disk, msdos should ignore it. */

	/*

	 * Look for partitions in two passes:

	 * First find the primary and DOS-type extended partitions.

	 * On the second pass look inside *BSD, Unixware and Solaris partitions.

			/*

			 * prevent someone doing mkfs or mkswap on an

			 * extended partition, but leave room for LILO

			 * FIXME: this uses one logical sector for > 512b

			 * sector, although it may not be enough/proper.

 second pass - output for each on a separate line */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2013 HUAWEI

 * Author: Cai Zhiyong <caizhiyong@huawei.com>

 *

 * Read block device partition table from the command line.

 * Typically used for fixed block (eMMC) embedded devices.

 * It has no MBR, so saves storage space. Bootloader can be easily accessed

 * by absolute address of data on the block device.

 * Users can easily change the partition.

 *

 * The format for the command line is just like mtdparts.

 *

 * For further information, see "Documentation/block/cmdline-partition.rst"

 *

 partition flags */

 Device is read only */

 Always locked after reset */

 partition name, such as 'rootfs' */

 block device, such as 'mmcblk0' */

/*

 * Purpose: allocate cmdline partitions.

 * Returns:

 * -1 if unable to read the partition table

 *  0 if this isn't our partition table

 *  1 if successful

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ldm - Support for Windows Logical Disk Manager (Dynamic Disks)

 *

 * Copyright (C) 2001,2002 Richard Russon <ldm@flatcap.org>

 * Copyright (c) 2001-2012 Anton Altaparmakov

 * Copyright (C) 2001,2002 Jakob Kemi <jakob.kemi@telia.com>

 *

 * Documentation is available at http://www.linux-ntfs.org/doku.php?id=downloads 

/*

 * ldm_debug/info/error/crit - Output an error message

 * @f:    A printf format string containing the message

 * @...:  Variables to substitute into @f

 *

 * ldm_debug() writes a DEBUG level message to the syslog but only if the

 * driver was compiled with debug enabled. Otherwise, the call turns into a NOP.

/**

 * ldm_parse_privhead - Read the LDM Database PRIVHEAD structure

 * @data:  Raw database PRIVHEAD structure loaded from the device

 * @ph:    In-memory privhead structure in which to return parsed information

 *

 * This parses the LDM database PRIVHEAD structure supplied in @data and

 * sets up the in-memory privhead structure @ph with the obtained information.

 *

 * Return:  'true'   @ph contains the PRIVHEAD data

 *          'false'  @ph contents are undefined

 Version 2.11 is Win2k/XP and version 2.12 is Vista. */

 1 MiB in sectors. */

 Warn the user and continue, carefully. */

/**

 * ldm_parse_tocblock - Read the LDM Database TOCBLOCK structure

 * @data:  Raw database TOCBLOCK structure loaded from the device

 * @toc:   In-memory toc structure in which to return parsed information

 *

 * This parses the LDM Database TOCBLOCK (table of contents) structure supplied

 * in @data and sets up the in-memory tocblock structure @toc with the obtained

 * information.

 *

 * N.B.  The *_start and *_size values returned in @toc are not range-checked.

 *

 * Return:  'true'   @toc contains the TOCBLOCK data

 *          'false'  @toc contents are undefined

/**

 * ldm_parse_vmdb - Read the LDM Database VMDB structure

 * @data:  Raw database VMDB structure loaded from the device

 * @vm:    In-memory vmdb structure in which to return parsed information

 *

 * This parses the LDM Database VMDB structure supplied in @data and sets up

 * the in-memory vmdb structure @vm with the obtained information.

 *

 * N.B.  The *_start, *_size and *_seq values will be range-checked later.

 *

 * Return:  'true'   @vm contains VMDB info

 *          'false'  @vm contents are undefined

/**

 * ldm_compare_privheads - Compare two privhead objects

 * @ph1:  First privhead

 * @ph2:  Second privhead

 *

 * This compares the two privhead structures @ph1 and @ph2.

 *

 * Return:  'true'   Identical

 *          'false'  Different

/**

 * ldm_compare_tocblocks - Compare two tocblock objects

 * @toc1:  First toc

 * @toc2:  Second toc

 *

 * This compares the two tocblock structures @toc1 and @toc2.

 *

 * Return:  'true'   Identical

 *          'false'  Different

/**

 * ldm_validate_privheads - Compare the primary privhead with its backups

 * @state: Partition check state including device holding the LDM Database

 * @ph1:   Memory struct to fill with ph contents

 *

 * Read and compare all three privheads from disk.

 *

 * The privheads on disk show the size and location of the main disk area and

 * the configuration area (the database).  The values are range-checked against

 * @hd, which contains the real size of the disk.

 *

 * Return:  'true'   Success

 *          'false'  Error

 off[1 & 2] are relative to ph[0]->config_start */

 Read and parse privheads */

 Log again */

 Already logged */

 FIXME ignore for now, 3rd PH can fail on odd-sized disks */

	/* FIXME ignore this for now

	if (!ldm_compare_privheads (ph[0], ph[2])) {

		ldm_crit ("Primary and backup PRIVHEADs don't match.");

		goto out;

/**

 * ldm_validate_tocblocks - Validate the table of contents and its backups

 * @state: Partition check state including device holding the LDM Database

 * @base:  Offset, into @state->disk, of the database

 * @ldb:   Cache of the database structures

 *

 * Find and compare the four tables of contents of the LDM Database stored on

 * @state->disk and return the parsed information into @toc1.

 *

 * The offsets and sizes of the configs are range-checked against a privhead.

 *

 * Return:  'true'   @toc1 contains validated TOCBLOCK info

 *          'false'  @toc1 contents are undefined

	/*

	 * Try to read and parse all four TOCBLOCKs.

	 *

	 * Windows Vista LDM v2.12 does not always have all four TOCBLOCKs so

	 * skip any that fail as long as we get at least one valid TOCBLOCK.

 Range check the TOCBLOCK against a privhead. */

 Compare all loaded TOCBLOCKs. */

/**

 * ldm_validate_vmdb - Read the VMDB and validate it

 * @state: Partition check state including device holding the LDM Database

 * @base:  Offset, into @bdev, of the database

 * @ldb:   Cache of the database structures

 *

 * Find the vmdb of the LDM Database stored on @bdev and return the parsed

 * information in @ldb.

 *

 * Return:  'true'   @ldb contains validated VBDB info

 *          'false'  @ldb contents are undefined

 Already logged */

 Are there uncommitted transactions? */

	/*

	 * The last_vblkd_seq can be before the end of the vmdb, just make sure

	 * it is not out of bounds.

/**

 * ldm_validate_partition_table - Determine whether bdev might be a dynamic disk

 * @state: Partition check state including device holding the LDM Database

 *

 * This function provides a weak test to decide whether the device is a dynamic

 * disk or not.  It looks for an MS-DOS-style partition table containing at

 * least one partition of type 0x42 (formerly SFS, now used by Windows for

 * dynamic disks).

 *

 * N.B.  The only possible error can come from the read_part_sector and that is

 *       only likely to happen if the underlying device is strange.  If that IS

 *       the case we should return zero to let someone else try.

 *

 * Return:  'true'   @state->disk is a dynamic disk

 *          'false'  @state->disk is not a dynamic disk, or an error occurred

/**

 * ldm_get_disk_objid - Search a linked list of vblk's for a given Disk Id

 * @ldb:  Cache of the database structures

 *

 * The LDM Database contains a list of all partitions on all dynamic disks.

 * The primary PRIVHEAD, at the beginning of the physical disk, tells us

 * the GUID of this disk.  This function searches for the GUID in a linked

 * list of vblk's.

 *

 * Return:  Pointer, A matching vblk was found

 *          NULL,    No match, or an error

/**

 * ldm_create_data_partitions - Create data partitions for this device

 * @pp:   List of the partitions parsed so far

 * @ldb:  Cache of the database structures

 *

 * The database contains ALL the partitions for ALL disk groups, so we need to

 * filter out this specific disk. Using the disk's object id, we can find all

 * the partitions in the database that belong to this disk.

 *

 * Add each partition in our database, to the parsed_partitions structure.

 *

 * N.B.  This function creates the partitions in the order it finds partition

 *       objects in the linked list.

 *

 * Return:  'true'   Partition created

 *          'false'  Error, probably a range checking problem

 Create the data partitions */

/**

 * ldm_relative - Calculate the next relative offset

 * @buffer:  Block of data being worked on

 * @buflen:  Size of the block of data

 * @base:    Size of the previous fixed width fields

 * @offset:  Cumulative size of the previous variable-width fields

 *

 * Because many of the VBLK fields are variable-width, it's necessary

 * to calculate each offset based on the previous one and the length

 * of the field it pointed to.

 *

 * Return:  -1 Error, the calculated offset exceeded the size of the buffer

 *           n OK, a range-checked offset into buffer

/**

 * ldm_get_vnum - Convert a variable-width, big endian number, into cpu order

 * @block:  Pointer to the variable-width number to convert

 *

 * Large numbers in the LDM Database are often stored in a packed format.  Each

 * number is prefixed by a one byte width marker.  All numbers in the database

 * are stored in big-endian byte order.  This function reads one of these

 * numbers and returns the result

 *

 * N.B.  This function DOES NOT perform any range checking, though the most

 *       it will read is eight bytes.

 *

 * Return:  n A number

 *          0 Zero, or an error occurred

/**

 * ldm_get_vstr - Read a length-prefixed string into a buffer

 * @block:   Pointer to the length marker

 * @buffer:  Location to copy string to

 * @buflen:  Size of the output buffer

 *

 * Many of the strings in the LDM Database are not NULL terminated.  Instead

 * they are prefixed by a one byte length marker.  This function copies one of

 * these strings into a buffer.

 *

 * N.B.  This function DOES NOT perform any range checking on the input.

 *       If the buffer is too small, the output will be truncated.

 *

 * Return:  0, Error and @buffer contents are undefined

 *          n, String length in characters (excluding NULL)

 *          buflen-1, String was truncated.

/**

 * ldm_parse_cmp3 - Read a raw VBLK Component object into a vblk structure

 * @buffer:  Block of data being worked on

 * @buflen:  Size of the block of data

 * @vb:      In-memory vblk in which to return information

 *

 * Read a raw VBLK Component object (version 3) into a vblk structure.

 *

 * Return:  'true'   @vb contains a Component VBLK

 *          'false'  @vb contents are not defined

/**

 * ldm_parse_dgr3 - Read a raw VBLK Disk Group object into a vblk structure

 * @buffer:  Block of data being worked on

 * @buflen:  Size of the block of data

 * @vb:      In-memory vblk in which to return information

 *

 * Read a raw VBLK Disk Group object (version 3) into a vblk structure.

 *

 * Return:  'true'   @vb contains a Disk Group VBLK

 *          'false'  @vb contents are not defined

/**

 * ldm_parse_dgr4 - Read a raw VBLK Disk Group object into a vblk structure

 * @buffer:  Block of data being worked on

 * @buflen:  Size of the block of data

 * @vb:      In-memory vblk in which to return information

 *

 * Read a raw VBLK Disk Group object (version 4) into a vblk structure.

 *

 * Return:  'true'   @vb contains a Disk Group VBLK

 *          'false'  @vb contents are not defined

/**

 * ldm_parse_dsk3 - Read a raw VBLK Disk object into a vblk structure

 * @buffer:  Block of data being worked on

 * @buflen:  Size of the block of data

 * @vb:      In-memory vblk in which to return information

 *

 * Read a raw VBLK Disk object (version 3) into a vblk structure.

 *

 * Return:  'true'   @vb contains a Disk VBLK

 *          'false'  @vb contents are not defined

/**

 * ldm_parse_dsk4 - Read a raw VBLK Disk object into a vblk structure

 * @buffer:  Block of data being worked on

 * @buflen:  Size of the block of data

 * @vb:      In-memory vblk in which to return information

 *

 * Read a raw VBLK Disk object (version 4) into a vblk structure.

 *

 * Return:  'true'   @vb contains a Disk VBLK

 *          'false'  @vb contents are not defined

/**

 * ldm_parse_prt3 - Read a raw VBLK Partition object into a vblk structure

 * @buffer:  Block of data being worked on

 * @buflen:  Size of the block of data

 * @vb:      In-memory vblk in which to return information

 *

 * Read a raw VBLK Partition object (version 3) into a vblk structure.

 *

 * Return:  'true'   @vb contains a Partition VBLK

 *          'false'  @vb contents are not defined

/**

 * ldm_parse_vol5 - Read a raw VBLK Volume object into a vblk structure

 * @buffer:  Block of data being worked on

 * @buflen:  Size of the block of data

 * @vb:      In-memory vblk in which to return information

 *

 * Read a raw VBLK Volume object (version 5) into a vblk structure.

 *

 * Return:  'true'   @vb contains a Volume VBLK

 *          'false'  @vb contents are not defined

/**

 * ldm_parse_vblk - Read a raw VBLK object into a vblk structure

 * @buf:  Block of data being worked on

 * @len:  Size of the block of data

 * @vb:   In-memory vblk in which to return information

 *

 * Read a raw VBLK object into a vblk structure.  This function just reads the

 * information common to all VBLK types, then delegates the rest of the work to

 * helper functions: ldm_parse_*.

 *

 * Return:  'true'   @vb contains a VBLK

 *          'false'  @vb contents are not defined

/**

 * ldm_ldmdb_add - Adds a raw VBLK entry to the ldmdb database

 * @data:  Raw VBLK to add to the database

 * @len:   Size of the raw VBLK

 * @ldb:   Cache of the database structures

 *

 * The VBLKs are sorted into categories.  Partitions are also sorted by offset.

 *

 * N.B.  This function does not check the validity of the VBLKs.

 *

 * Return:  'true'   The VBLK was added

 *          'false'  An error occurred

 Already logged */

 Put vblk into the correct list. */

 Sort by the partition's start sector. */

/**

 * ldm_frag_add - Add a VBLK fragment to a list

 * @data:   Raw fragment to be added to the list

 * @size:   Size of the raw fragment

 * @frags:  Linked list of VBLK fragments

 *

 * Fragmented VBLKs may not be consecutive in the database, so they are placed

 * in a list so they can be pieced together later.

 *

 * Return:  'true'   Success, the VBLK was added to the list

 *          'false'  Error, a problem occurred

 Mark the group as broken */

/**

 * ldm_frag_free - Free a linked list of VBLK fragments

 * @list:  Linked list of fragments

 *

 * Free a linked list of VBLK fragments

 *

 * Return:  none

/**

 * ldm_frag_commit - Validate fragmented VBLKs and add them to the database

 * @frags:  Linked list of VBLK fragments

 * @ldb:    Cache of the database structures

 *

 * Now that all the fragmented VBLKs have been collected, they must be added to

 * the database for later use.

 *

 * Return:  'true'   All the fragments we added successfully

 *          'false'  One or more of the fragments we invalid

 Already logged */

/**

 * ldm_get_vblks - Read the on-disk database of VBLKs into memory

 * @state: Partition check state including device holding the LDM Database

 * @base:  Offset, into @state->disk, of the database

 * @ldb:   Cache of the database structures

 *

 * To use the information from the VBLKs, they need to be read from the disk,

 * unpacked and validated.  We cache them in @ldb according to their type.

 *

 * Return:  'true'   All the VBLKs were read successfully

 *          'false'  An error occurred

 Bytes to sectors */

 For each sector */

 For each vblk */

 Number of records */

 Already logged */

 Already logged */

 else Record is not in use, ignore it. */

 Failures, already logged */

/**

 * ldm_free_vblks - Free a linked list of vblk's

 * @lh:  Head of a linked list of struct vblk

 *

 * Free a list of vblk's and free the memory used to maintain the list.

 *

 * Return:  none

/**

 * ldm_partition - Find out whether a device is a dynamic disk and handle it

 * @state: Partition check state including device holding the LDM Database

 *

 * This determines whether the device @bdev is a dynamic disk and if so creates

 * the partitions necessary in the gendisk structure pointed to by @hd.

 *

 * We create a dummy device 1, which contains the LDM database, and then create

 * each partition described by the LDM database in sequence as devices 2+. For

 * example, if the device is hda, we would have: hda1: LDM database, hda2, hda3,

 * and so on: the actual data containing partitions.

 *

 * Return:  1 Success, @state->disk is a dynamic disk and we handled it

 *          0 Success, @state->disk is not a dynamic disk

 *         -1 An error occurred before enough information had been read

 *            Or @state->disk is a dynamic disk, but it may be corrupted

 Look for signs of a Dynamic Disk */

 Parse and check privheads. */

 Already logged */

 All further references are relative to base (database start). */

 Parse and check tocs and vmdb. */

 Already logged */

 Initialize vblk lists in ldmdb struct */

 Finally, create the data partition devices. */

 else Already logged */

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/sgi.c

 *

 *  Code extracted from drivers/block/genhd.c

 autodetect RAID partition */

 Big fat spliff... */

 Root partition number */

 Swap partition number */

 Name of boot file for ARCS */

 Device parameter useless crapola.. */

 Name of volume */

 Logical block number */

 How big, in bytes */

 Size in logical blocks */

 First logical block */

 Type of this partition */

 Disk label checksum */

 Padding */

		/*printk("Dev %s SGI disklabel: bad magic %08x\n",

	/* All SGI disk labels have 16 partitions, disks under Linux only

	 * have 15 minor's.  Luckily there are always a few zero length

	 * partitions which we don't care about so we never overflow the

	 * current_minor.

 SPDX-License-Identifier: GPL-2.0

/*

 *  Copyright (c) 1996-2000 Russell King.

 *

 *  Scan ADFS partitions on hard disk drives.  Unfortunately, there

 *  isn't a standard for partitioning drives on Acorn machines, so

 *  every single manufacturer of SCSI and IDE cards created their own

 *  method.

/*

 * Partition types. (Oh for reusability)

	/*

	 * Try Cumana style partitions - sector 6 contains ADFS boot block

	 * with pointer to next 'drive'.

	 *

	 * There are unknowns in this code - is the 'cylinder number' of the

	 * next partition relative to the start of this one - I'm assuming

	 * it is.

	 *

	 * Also, which ID did Cumana use?

	 *

	 * This is totally unfinished, and will require more work to get it

	 * going. Hence it is totally untested.

 hmm - should be partition size */

 No partition / ADFS? */

 RISCiX - we don't know how to find the next one. */

/*

 * Purpose: allocate ADFS partitions.

 *

 * Params : hd		- pointer to gendisk structure to store partition info.

 *	    dev		- device number to access.

 *

 * Returns: -1 on error, 0 for no ADFS boot sector, 1 for ok.

 *

 * Alloc  : hda  = whole drive

 *	    hda1 = ADFS partition on first drive.

 *	    hda2 = non-ADFS partition.

	/*

	 * Work out start of non-adfs partition.

/*

 * Check for a valid ICS partition using the checksum.

/*

 * Purpose: allocate ICS partitions.

 * Params : hd		- pointer to gendisk structure to store partition info.

 *	    dev		- device number to access.

 * Returns: -1 on error, 0 for no ICS table, 1 for partitions ok.

 * Alloc  : hda  = whole drive

 *	    hda1 = ADFS partition 0 on first drive.

 *	    hda2 = ADFS partition 1 on first drive.

 *		..etc..

	/*

	 * Try ICS style partitions - sector 0 contains partition info.

 yes, it's signed. */

		/*

		 * Negative sizes tell the RISC OS ICS driver to ignore

		 * this partition - in effect it says that this does not

		 * contain an ADFS filesystem.

			/*

			 * Our own extension - We use the first sector

			 * of the partition to identify what type this

			 * partition is.  We must not make this visible

			 * to the filesystem.

	/*

	 * If it looks like a PC/BIOS partition, then it

	 * probably isn't PowerTec.

/*

 * Purpose: allocate ICS partitions.

 * Params : hd		- pointer to gendisk structure to store partition info.

 *	    dev		- device number to access.

 * Returns: -1 on error, 0 for no ICS table, 1 for partitions ok.

 * Alloc  : hda  = whole drive

 *	    hda1 = ADFS partition 0 on first drive.

 *	    hda2 = ADFS partition 1 on first drive.

 *		..etc..

/*

 * Guess who created this format?

/*

 * EESOX SCSI partition format.

 *

 * This is a goddamned awful partition format.  We don't seem to store

 * the size of the partition in this table, only the start addresses.

 *

 * There are two possibilities where the size comes from:

 *  1. The individual ADFS boot block entries that are placed on the disk.

 *  2. The start address of the next entry.

	/*

	 * "Decrypt" the partition table.  God knows why...

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 *                  Volker Sameske <sameske@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999, 2012

/*

 * compute the block number from a

 * cyl-cyl-head-head structure

 decode cylinder and heads for large volumes */

/*

 * compute the block number from a

 * cyl-cyl-head-head-block structure

 decode cylinder and heads for large volumes */

	/* There a three places where we may find a valid label:

	 * - on an ECKD disk it's block 2

	 * - on an FBA disk it's block 1

	 * - on an CMS formatted FBA disk it is sector 1, even if the block size

	 *   is larger than 512 bytes (possible if the DIAG discipline is used)

	 * If we have a valid info structure, then we know exactly which case we

	 * have, otherwise we just search through all possebilities.

	/*

	 * get start of VTOC from the disk label and then search for format1

	 * and format8 labels

 skip FMT4 / FMT5 / FMT7 labels */

 only FMT1 and 8 labels valid at this point */

 OK, we got valid partition data */

		/*

		 * Formated w/o large volume support. If the sanity check

		 * 'size based on geo == size based on nr_sectors' is true, then

		 * we can safely assume that we know the formatted size of

		 * the disk, otherwise we need additional information

		 * that we can only get from a real DASD device.

 else keep size based on nr_sectors */

 first and only partition starts in the first block after the label */

	/*

	 * VM style CMS1 labeled disk

 disk is reserved minidisk */

		/*

		 * Special case for FBA devices:

		 * If an FBA device is CMS formatted with blocksize > 512 byte

		 * and the DIAG discipline is used, then the CMS label is found

		 * in sector 1 instead of block 1. However, the partition is

		 * still supposed to start in block 2.

/*

 * This is the main function, called by check.c

 set start if not filled by getgeo function e.g. virtblk */

		/*

		 * ugly but needed for backward compatibility:

		 * If the block device is a DASD (i.e. BIODASDINFO2 works),

		 * then we claim it in any case, even though it has no valid

		 * label. If it has the LDL format, then we simply define a

		 * partition as if it had an LNX1 label.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 1991-1998  Linus Torvalds

 * Re-organised Feb 1998 Russell King

 * Copyright (C) 2020 Christoph Hellwig

	/*

	 * Probe partition formats with tables at disk address 0

	 * that also have an ADFS boot block at 0xdc0.

	/*

	 * Now move on to formats that only have partition info at

	 * disk address 0xdc0.  Since these may also have stale

	 * PC/BIOS partition tables, they need to come before

	 * the msdos entry.

 this must come before msdos */

 this must come before msdos */

			/*

			 * We have hit an I/O error which we don't report now.

			 * But record it, and let the others do their job.

	/*

	 * The partition is unrecognized. So report I/O errors if there were any

	/*

	 * Remove the block device from the inode hash, so that it cannot be

	 * looked up any more even when openers still hold references.

/*

 * Must be called either with open_mutex held, before a disk can be opened or

 * after all disk users are gone.

	/*

	 * Partitions are not supported on zoned block devices that are used as

	 * such.

 ensure we always have a reference to the whole disk */

 in consecutive minor range? */

 delay uevent until 'holders' subdir is created */

 everything is up and running, commence */

 suppress uevent if the disk suppresses it */

		/*

		 * We can not ignore partitions of broken tables created by for

		 * example camera firmware, but we limit them to the end of the

		 * disk to avoid creating invalid block devices.

		/*

		 * I/O error reading the partition table.  If we tried to read

		 * beyond EOD, retry after unlocking the native capacity.

	/*

	 * Partitions are not supported on host managed zoned block devices.

	/*

	 * If we read beyond EOD, try unlocking native capacity even if the

	 * partition table was successfully read as we could be missing some

	 * partitions.

 tell userspace that the media / partition table may have changed */

	/*

	 * Historically we only set the capacity to zero for devices that

	 * support partitions (independ of actually having partitions created).

	 * Doing that is rather inconsistent, but changing it broke legacy

	 * udisks polling for legacy ide-cdrom devices.  Use the crude check

	 * below to get the sane behavior for most device while not breaking

	 * userspace for this particular setup.

		/*

		 * Tell userspace that the media / partition table may have

		 * changed.

/*

 * Only exported for loop and dasd for historic reasons.  Don't use in new

 * code!

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/sysv68.c

 *

 *  Copyright (C) 2007 Philippe De Muyter <phdm@macqel.be>

/*

 *	Volume ID structure: on first 256-bytes sector of disk

 ASCII string "MOTOROLA" */

/*

 *	config block: second 256-bytes sector on disk

 Slice table block number */

 Number of entries in slice table */

/*

 *	combined volumeid and dkconfig block

/*

 *	Slice Table Structure

 slice size (in blocks) */

 block offset of slice */

 last slice is the whole disk */

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/sun.c

 *

 *  Code extracted from drivers/block/genhd.c

 *

 *  Copyright (C) 1991-1998  Linus Torvalds

 *  Re-organised Feb 1998 Russell King

 autodetect RAID partition */

 Informative text string */

 Layout version */

 Volume name */

 Number of partitions */

 Partition hdrs, sec 2 */

 Alignment padding */

 Info needed by mboot */

 To verify vtoc sanity */

 Free space */

 Partition timestamp */

 sectors to skip, writes */

 sectors to skip, reads */

 Padding */

 Disk rotational speed */

 Physical cylinder count */

 extra sects per cylinder */

 gap1 */

 gap2 */

 Interleave factor */

 Data cylinder count */

 Alt. cylinder count */

 Tracks per cylinder */

 Sectors per track */

 bhead - Label head offset */

 ppart - Physical Partition */

 Magic number */

 Label xor'd checksum */

/*		printk(KERN_INFO "Dev %s Sun disklabel: bad magic %04x\n",

 Look at the checksum */

 Check to see if we can use the VTOC table */

 Use 8 partition entries if not specified in validated VTOC */

	/*

	 * So that old Linux-Sun partitions continue to work,

	 * alow the VTOC to be used under the additional condition ...

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/osf.c

 *

 *  Code extracted from drivers/block/genhd.c

 *

 *  Copyright (C) 1991-1998  Linus Torvalds

 *  Re-organised Feb 1998 Russell King

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/ultrix.c

 *

 *  Code extracted from drivers/block/genhd.c

 *

 *  Re-organised Jul 1999 Russell King

 magic no. indicating part. info exits */

 set by driver if pt is current */

 no. of sectors */

 block offset for start */

 Partition magic number */

 Indicates if struct is valid */

 SPDX-License-Identifier: GPL-2.0

/*

 *  fs/partitions/aix.c

 *

 *  Copyright (C) 2012-2013 Philippe De Muyter <phdm@macqel.be>

 "_LVM" */

 log2(pp_size) */

/**

 * read_lba(): Read bytes from disk, starting at given LBA

 * @state

 * @lba

 * @buffer

 * @count

 *

 * Description:  Reads @count bytes from @state->disk into @buffer.

 * Returns number of bytes read on success, 0 on error.

/**

 * alloc_pvd(): reads physical volume descriptor

 * @state

 * @lba

 *

 * Description: Returns pvd on success,  NULL on error.

 * Allocates space for pvd and fill it with disk blocks at @lba

 * Notes: remember to free pvd when you're done!

/**

 * alloc_lvn(): reads logical volume names

 * @state

 * @lba

 *

 * Description: Returns lvn on success,  NULL on error.

 * Allocates space for lvn and fill it with disk blocks at @lba

 * Notes: remember to free lvn when you're done!

 pvd loops depend on n[].name and lvip[].pps_per_lv */

 null char

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Crypto API wrapper for the generic SHA256 code from lib/crypto/sha256.c

 *

 * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>

 * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 * SHA224 Support Copyright 2007 Intel Corporation <jonathan.lynch@intel.com>

/*

 * Copyright (c) 2013, 2014 Kenneth MacKay. All rights reserved.

 * Copyright (c) 2019 Vitaly Chikunov <vt@altlinux.org>

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are

 * met:

 *  * Redistributions of source code must retain the above copyright

 *   notice, this list of conditions and the following disclaimer.

 *  * Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 Returns curv25519 curve param */

 In FIPS mode only allow P256 and higher */

 Returns true if vli == 0, false otherwise. */

 Returns nonzero if bit of vli is set. */

 Counts the number of 64-bit "digits" in vli. */

	/* Search from the end until we find a non-zero digit.

	 * We do it in reverse because we expect that most digits will

	 * be nonzero.

 Counts the number of bits required for vli. */

 Set dest from unaligned bit string src. */

 Sets dest = src. */

 Returns sign of left - right. */

/* Computes result = in << c, returning carry. Can modify in place

 * (if result == in). 0 < shift < 64.

 Computes vli = vli >> 1. */

 Computes result = left + right, returning carry. Can modify in place. */

 Computes result = left + right, returning carry. Can modify in place. */

 Computes result = left - right, returning borrow. Can modify in place. */

 Computes result = left - right, returning borrow. Can modify in place. */

 Overflow */

	/* Compute each digit of result in sequence, maintaining the

	 * carries.

 Compute product = left * right, for a small right value. */

 no carry */

/* Computes result = (left + right) % mod.

 * Assumes that left < mod and right < mod, result != mod.

	/* result > mod (result = mod + remainder), so subtract mod to

	 * get remainder.

/* Computes result = (left - right) % mod.

 * Assumes that left < mod and right < mod, result != mod.

	/* In this case, p_result == -diff == (max int) - diff.

	 * Since -x % d == d - x, we can get the correct result from

	 * result + mod (with overflow).

/*

 * Computes result = product % mod

 * for special form moduli: p = 2^k-c, for small c (note the minus sign)

 *

 * References:

 * R. Crandall, C. Pomerance. Prime Numbers: A Computational Perspective.

 * 9 Fast Algorithms for Large-Integer Arithmetic. 9.2.3 Moduli of special form

 * Algorithm 9.2.13 (Fast mod operation for special-form moduli).

/*

 * Computes result = product % mod

 * for special form moduli: p = 2^{k-1}+c, for small c (note the plus sign)

 * where k-1 does not fit into qword boundary by -1 bit (such as 255).



 * References (loosely based on):

 * A. Menezes, P. van Oorschot, S. Vanstone. Handbook of Applied Cryptography.

 * 14.3.4 Reduction methods for moduli of special form. Algorithm 14.47.

 * URL: http://cacr.uwaterloo.ca/hac/about/chap14.pdf

 *

 * H. Cohen, G. Frey, R. Avanzi, C. Doche, T. Lange, K. Nguyen, F. Vercauteren.

 * Handbook of Elliptic and Hyperelliptic Curve Cryptography.

 * Algorithm 10.25 Fast reduction for special form moduli

 expanded mod */

 last bit that doesn't fit into q */

 q and carry are top bits */

/*

 * Computes result = product % mod, where product is 2N words long.

 * Reference: Ken MacKay's micro-ecc.

 * Currently only designed to work for curve_p or curve_n.

 Shift mod so its highest set bit is at the maximum position. */

 Swap the index if there was no borrow */

/* Computes result = product % mod using Barrett's reduction with precomputed

 * value mu appended to the mod after ndigits, mu = (2^{2w} / mod) and have

 * length ndigits + 1, where mu * (2^w - 1) should not overflow ndigits

 * boundary.

 *

 * Reference:

 * R. Brent, P. Zimmermann. Modern Computer Arithmetic. 2010.

 * 2.4.1 Barrett's algorithm. Algorithm 2.5.

/* Computes p_result = p_product % curve_p.

 * See algorithm 5 and 6 from

 * http://www.isys.uni-klu.ac.at/PDF/2001-0126-MT.pdf

/* Computes result = product % curve_prime

 * from http://www.nsa.gov/ia/_files/nist-routines.pdf

 t */

 s1 */

 s2 */

 s3 */

 s4 */

 d1 */

 d2 */

 d3 */

 d4 */

/* Computes result = product % curve_prime

 * from "Mathematical routines for the NIST prime elliptic curves"

 t */

 s1 */

 0 || 0

 0 || 0

a22||a21

 0 ||a23

 0 || 0

 0 || 0

 s2 */

a13||a12

a15||a14

a17||a16

a19||a18

a21||a20

a23||a22

 s3 */

a22||a21

a12||a23

a14||a13

a16||a15

a18||a17

a20||a19

 s4 */

a23|| 0

a20|| 0

a13||a12

a15||a14

a17||a16

a19||a18

 s5 */

  0|| 0

  0|| 0

a21||a20

a23||a22

  0|| 0

  0|| 0

 s6 */

 0 ||a20

a21|| 0

a23||a22

 0 || 0

 0 || 0

 0 || 0

 d1 */

a12||a23

a14||a13

a16||a15

a18||a17

a20||a19

a22||a21

 d2 */

a20|| 0

a22||a21

 0 ||a23

 0 || 0

 0 || 0

 0 || 0

 d3 */

 0 || 0

a23|| 0

 0 ||a23

 0 || 0

 0 || 0

 0 || 0

/* Computes result = product % curve_prime for different curve_primes.

 *

 * Note that curve_primes are distinguished just by heuristic check and

 * not by complete conformance check.

 All NIST curves have name prefix 'nist_' */

 Try to handle Pseudo-Marsenne primes. */

/* Computes result = (left * right) % mod.

 * Assumes that mod is big enough curve order.

 Computes result = (left * right) % curve_prime. */

 Computes result = left^2 % curve_prime. */

/* Computes result = (1 / p_input) % mod. All VLIs are the same size.

 * See "From Euclid's GCD to Montgomery Multiplication to the Great Divide"

 * https://labs.oracle.com/techrep/2001/smli_tr-2001-95.pdf

 ------ Point operations ------ */

 Returns true if p_point is the point at infinity, false otherwise. */

/* Point multiplication algorithm using Montgomery's ladder with co-Z

 * coordinates. From https://eprint.iacr.org/2011/338.pdf

 Double in place */

 t1 = x, t2 = y, t3 = z */

 t4 = y1^2 */

 t5 = x1*y1^2 = A */

 t4 = y1^4 */

 t2 = y1*z1 = z3 */

 t3 = z1^2 */

 t1 = x1 + z1^2 */

 t3 = 2*z1^2 */

 t3 = x1 - z1^2 */

 t1 = x1^2 - z1^4 */

 t3 = 2*(x1^2 - z1^4) */

 t1 = 3*(x1^2 - z1^4) */

 t1 = 3/2*(x1^2 - z1^4) = B */

 t3 = B^2 */

 t3 = B^2 - A */

 t3 = B^2 - 2A = x3 */

 t5 = A - x3 */

 t1 = B * (A - x3) */

 t4 = B * (A - x3) - y1^4 = y3 */

 Modify (x1, y1) => (x1 * z^2, y1 * z^3) */

 z^2 */

 x1 * z^2 */

 z^3 */

 y1 * z^3 */

 P = (x1, y1) => 2P, (x2, y2) => P' */

/* Input P = (x1, y1, Z), Q = (x2, y2, Z)

 * Output P' = (x1', y1', Z3), P + Q = (x3, y3, Z3)

 * or P => P', Q => P + Q

 t1 = X1, t2 = Y1, t3 = X2, t4 = Y2 */

 t5 = x2 - x1 */

 t5 = (x2 - x1)^2 = A */

 t1 = x1*A = B */

 t3 = x2*A = C */

 t4 = y2 - y1 */

 t5 = (y2 - y1)^2 = D */

 t5 = D - B */

 t5 = D - B - C = x3 */

 t3 = C - B */

 t2 = y1*(C - B) */

 t3 = B - x3 */

 t4 = (y2 - y1)*(B - x3) */

 t4 = y3 */

/* Input P = (x1, y1, Z), Q = (x2, y2, Z)

 * Output P + Q = (x3, y3, Z3), P - Q = (x3', y3', Z3)

 * or P => P - Q, Q => P + Q

 t1 = X1, t2 = Y1, t3 = X2, t4 = Y2 */

 t5 = x2 - x1 */

 t5 = (x2 - x1)^2 = A */

 t1 = x1*A = B */

 t3 = x2*A = C */

 t4 = y2 + y1 */

 t4 = y2 - y1 */

 t6 = C - B */

 t2 = y1 * (C - B) */

 t6 = B + C */

 t3 = (y2 - y1)^2 */

 t3 = x3 */

 t7 = B - x3 */

 t4 = (y2 - y1)*(B - x3) */

 t4 = y3 */

 t7 = (y2 + y1)^2 = F */

 t7 = x3' */

 t6 = x3' - B */

 t6 = (y2 + y1)*(x3' - B) */

 t2 = y3' */

 R0 and R1 */

 Find final 1/Z value. */

 X1 - X0 */

 Yb * (X1 - X0) */

 xP * Yb * (X1 - X0) */

 1 / (xP * Yb * (X1 - X0)) */

 yP / (xP * Yb * (X1 - X0)) */

 Xb * yP / (xP * Yb * (X1 - X0)) */

 End 1/Z calculation */

 Computes R = P + Q mod p */

/* Computes R = u1P + u2Q mod p using Shamir's trick.

 * Based on: Kenneth MacKay's micro-ecc (2014).

 Make sure the private key is in the range [2, n-3]. */

/*

 * ECC private keys are generated using the method of extra random bits,

 * equivalent to that described in FIPS 186-4, Appendix B.4.1.

 *

 * d = (c mod(n1)) + 1    where c is a string of random bits, 64 bits longer

 *                         than requested

 * 0 <= c mod(n-1) <= n-2  and implies that

 * 1 <= d <= n-1

 *

 * This method generates a private key uniformly distributed in the range

 * [1, n-1].

 Check that N is included in Table 1 of FIPS 186-4, section 6.1.1 */

	/*

	 * FIPS 186-4 recommends that the private key should be obtained from a

	 * RBG with a security strength equal to or greater than the security

	 * strength associated with N.

	 *

	 * The maximum security strength identified by NIST SP800-57pt1r4 for

	 * ECC is 256 (N >= 512).

	 *

	 * This condition is met by the default RNG because it selects a favored

	 * DRBG with a security strength of 256.

 Make sure the private key is in the valid range. */

 SP800-56A rev 3 5.6.2.1.3 key check */

 SP800-56A section 5.6.2.3.4 partial verification: ephemeral keys only */

 Check 1: Verify key is not the zero point. */

 Check 2: Verify key is in the range [1, p-1]. */

 Check 3: Verify that y^2 == (x^3 + ax + b) mod p */

 y^2 */

 x^2 */

 x^3 */

 ax */

 ax + b */

 x^3 + ax + b */

 Equation */

 SP800-56A section 5.6.2.3.3 full verification */

 Checks 1 through 3 */

 Check 4: Verify that nQ is the zero point. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * CBC: Cipher Block Chaining mode

 *

 * Copyright (c) 2006-2016 Herbert Xu <herbert@gondor.apana.org.au>

 Start of the last block. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * xor.c : Multiple Devices driver for Linux

 *

 * Copyright (C) 1996, 1997, 1998, 1999, 2000,

 * Ingo Molnar, Matti Aarnio, Jakub Jelinek, Richard Henderson.

 *

 * Dispatch optimized RAID-5 checksumming functions.

 The xor routines to use.  */

 Set of all registered templates.  */

 register all the templates and pick the first as the default

 prevent loop optimization */

 bytes/ns == GB/s, multiply by 1000 to get MB/s [not MiB/s]

	/*

	 * If this arch/cpu has a short-circuited selection, don't loop through

	 * all the possible functions, just test the best one

 when built-in xor.o must initialize before drivers/md/md.o */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * seqiv: Sequence Number IV Generator

 *

 * This generator generates an IV based on a sequence number by xoring it

 * with a salt.  This algorithm is mainly useful for CTR and similar modes.

 *

 * Copyright (c) 2007 Herbert Xu <herbert@gondor.apana.org.au>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * af_alg: User-space algorithm interface

 *

 * This file provides the user-space API for algorithms.

 *

 * Copyright (c) 2010 Herbert Xu <herbert@gondor.apana.org.au>

 If caller uses non-allowed flag, return error. */

	/*

	 * newsock->ops assigned here to allow type->accept call to override

	 * them when required.

 Add one extra for linking */

/**

 * af_alg_alloc_tsgl - allocate the TX SGL

 *

 * @sk: socket of connection to user space

 * Return: 0 upon success, < 0 upon error

/**

 * af_alg_count_tsgl - Count number of TX SG entries

 *

 * The counting starts from the beginning of the SGL to @bytes. If

 * an @offset is provided, the counting of the SG entries starts at the @offset.

 *

 * @sk: socket of connection to user space

 * @bytes: Count the number of SG entries holding given number of bytes.

 * @offset: Start the counting of SG entries from the given offset.

 * Return: Number of TX SG entries found given the constraints

 Skip offset */

 If we have seen requested number of bytes, stop */

/**

 * af_alg_pull_tsgl - Release the specified buffers from TX SGL

 *

 * If @dst is non-null, reassign the pages to @dst. The caller must release

 * the pages. If @dst_offset is given only reassign the pages to @dst starting

 * at the @dst_offset (byte). The caller must ensure that @dst is large

 * enough (e.g. by using af_alg_count_tsgl with the same offset).

 *

 * @sk: socket of connection to user space

 * @used: Number of bytes to pull from TX SGL

 * @dst: If non-NULL, buffer is reassigned to dst SGL instead of releasing. The

 *	 caller must release the buffers in dst.

 * @dst_offset: Reassign the TX SGL from given offset. All buffers before

 *	        reaching the offset is released.

			/*

			 * Assumption: caller created af_alg_count_tsgl(len)

			 * SG entries in dst.

 discard page before offset */

 reassign page to dst after offset */

/**

 * af_alg_free_areq_sgls - Release TX and RX SGLs of the request

 *

 * @areq: Request holding the TX and RX SGL

/**

 * af_alg_wait_for_wmem - wait for availability of writable memory

 *

 * @sk: socket of connection to user space

 * @flags: If MSG_DONTWAIT is set, then only report if function would sleep

 * Return: 0 when writable memory is available, < 0 upon error

/**

 * af_alg_wmem_wakeup - wakeup caller when writable memory is available

 *

 * @sk: socket of connection to user space

/**

 * af_alg_wait_for_data - wait for availability of TX data

 *

 * @sk: socket of connection to user space

 * @flags: If MSG_DONTWAIT is set, then only report if function would sleep

 * @min: Set to minimum request size if partial requests are allowed.

 * Return: 0 when writable memory is available, < 0 upon error

/**

 * af_alg_data_wakeup - wakeup caller when new data can be sent to kernel

 *

 * @sk: socket of connection to user space

/**

 * af_alg_sendmsg - implementation of sendmsg system call handler

 *

 * The sendmsg system call handler obtains the user data and stores it

 * in ctx->tsgl_list. This implies allocation of the required numbers of

 * struct af_alg_tsgl.

 *

 * In addition, the ctx is filled with the information sent via CMSG.

 *

 * @sock: socket of connection to user space

 * @msg: message from user space

 * @size: size of message from user space

 * @ivsize: the size of the IV for the cipher operation to verify that the

 *	   user-space-provided IV has the right size

 * Return: the number of copied data upon success, < 0 upon error

 use the existing memory in an allocated page */

 allocate a new page */

/**

 * af_alg_sendpage - sendpage system call handler

 * @sock: socket of connection to user space to write to

 * @page: data to send

 * @offset: offset into page to begin sending

 * @size: length of data

 * @flags: message send/receive flags

 *

 * This is a generic implementation of sendpage to fill ctx->tsgl_list.

/**

 * af_alg_free_resources - release resources required for crypto request

 * @areq: Request holding the TX and RX SGL

/**

 * af_alg_async_cb - AIO callback handler

 * @_req: async request info

 * @err: if non-zero, error result to be returned via ki_complete();

 *       otherwise return the AIO output length via ki_complete().

 *

 * This handler cleans up the struct af_alg_async_req upon completion of the

 * AIO operation.

 *

 * The number of bytes to be generated with the AIO operation must be set

 * in areq->outlen before the AIO callback handler is invoked.

 Buffer size written by crypto operation. */

/**

 * af_alg_poll - poll system call handler

 * @file: file pointer

 * @sock: socket to poll

 * @wait: poll_table

/**

 * af_alg_alloc_areq - allocate struct af_alg_async_req

 *

 * @sk: socket of connection to user space

 * @areqlen: size of struct af_alg_async_req + crypto_*_reqsize

 * Return: allocated data structure or ERR_PTR upon error

/**

 * af_alg_get_rsgl - create the RX SGL for the output data from the crypto

 *		     operation

 *

 * @sk: socket of connection to user space

 * @msg: user space message

 * @flags: flags used to invoke recvmsg with

 * @areq: instance of the cryptographic request that will hold the RX SGL

 * @maxsize: maximum number of bytes to be pulled from user space

 * @outlen: number of bytes in the RX SGL

 * Return: 0 on success, < 0 upon error

 limit the amount of readable buffers */

 make one iovec available as scatterlist */

 chain the new scatterlist with previous one */

 SPDX-License-Identifier: GPL-2.0-or-later

/* 

 * Cryptographic API.

 *

 * TEA, XTEA, and XETA crypto alogrithms

 *

 * The TEA and Xtended TEA algorithms were developed by David Wheeler 

 * and Roger Needham at the Computer Laboratory of Cambridge University.

 *

 * Due to the order of evaluation in XTEA many people have incorrectly

 * implemented it.  XETA (XTEA in the wrong order), exists for

 * compatibility with these implementations.

 *

 * Copyright (c) 2004 Aaron Grothe ajgrothe@yahoo.com

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API for algorithms (i.e., low-level API).

 *

 * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>

 General maximums for all algs. */

 Lower maximums for specific alg types. */

/*

 * This function adds a spawn to the list secondary_spawns which

 * will be used at the end of crypto_remove_spawns to unregister

 * instances, unless the spawn happens to be one that is depended

 * on by the new algorithm (nalg in crypto_remove_spawns).

 *

 * This function is also responsible for resurrecting any algorithms

 * in the dependency chain of nalg by unsetting n->dead.

/*

 * Given an algorithm alg, remove all algorithms that depend on it

 * through spawns.  If nalg is not null, then exempt any algorithms

 * that is depended on by nalg.  This is useful when nalg itself

 * depends on alg.

	/*

	 * Perform a depth-first walk starting from alg through

	 * the cra_users tree.  The list stack records the path

	 * from alg to the current spawn.

			/*

			 * Even if spawn->registered is true, the

			 * instance itself may still be unregistered.

			 * This is because it may have failed during

			 * registration.  Therefore we still need to

			 * make the following test.

			 *

			 * We may encounter an unregistered instance here, since

			 * an instance's spawns are set up prior to the instance

			 * being registered.  An unregistered instance will have

			 * NULL ->cra_users.next, since ->cra_users isn't

			 * properly initialized until registration.  But an

			 * unregistered instance cannot have any users, so treat

			 * it the same as ->cra_users being empty.

	/*

	 * Remove all instances that are marked as dead.  Also

	 * complete the resurrection of the others by moving them

	 * back to the cra_users list.

 No cheating! */

 Only satisfy larval waiters if we are the best. */

			/*

			 * Check to see if either our generic name or

			 * specific name can satisfy the name requested

			 * by the larval entry q.

 Allow the result of crypto_attr_alg_name() to be passed directly */

 not yet initialized? */

/**

 * crypto_check_attr_type() - check algorithm type and compute inherited mask

 * @tb: the template parameters

 * @type: the algorithm type the template would be instantiated as

 * @mask_ret: (output) the mask that should be passed to crypto_grab_*()

 *	      to restrict the flags of any inner algorithms

 *

 * Validate that the algorithm type the user requested is compatible with the

 * one the template would actually be instantiated as.  E.g., if the user is

 * doing crypto_alloc_shash("cbc(aes)", ...), this would return an error because

 * the "cbc" template creates an "skcipher" algorithm, not an "shash" algorithm.

 *

 * Also compute the mask to use to restrict the flags of any inner algorithms.

 *

 * Return: 0 on success; -errno on failure

		/*

		 * If we care about alignment, process as many bytes as

		 * needed to advance dst and src to values whose alignments

		 * equal their relative alignment. This will allow us to

		 * process the remainder of the input using optimal strides.

/*

 * We run this at late_initcall so that all the built-in algorithms

 * have had a chance to register themselves first.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Scatterlist Cryptographic API.

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 * Copyright (c) 2002 David S. Miller (davem@redhat.com)

 * Copyright (c) 2005 Herbert Xu <herbert@gondor.apana.org.au>

 *

 * Portions derived from Cryptoapi, by Alexander Kjeldaas <astor@fast.no>

 * and Nettle, by Niels Mller.

 Test failed */

	/*

	 * If the internal flag is set for a cipher, require a caller to

	 * to invoke the cipher with the internal flag to use that cipher.

	 * Also, if a caller wants to allocate a cipher that may or may

	 * not be an internal cipher, use type | CRYPTO_ALG_INTERNAL and

	 * !(mask & CRYPTO_ALG_INTERNAL).

/*

 *	crypto_alloc_base - Locate algorithm and allocate transform

 *	@alg_name: Name of algorithm

 *	@type: Type of algorithm

 *	@mask: Mask for type comparison

 *

 *	This function should not be used by new algorithm types.

 *	Please use crypto_alloc_tfm instead.

 *

 *	crypto_alloc_base() will first attempt to locate an already loaded

 *	algorithm.  If that fails and the kernel supports dynamically loadable

 *	modules, it will then attempt to load a module of the same name or

 *	alias.  If that fails it will send a query to any loaded crypto manager

 *	to construct an algorithm on the fly.  A refcount is grabbed on the

 *	algorithm which is then associated with the new transform.

 *

 *	The returned transform is of a non-determinate type.  Most people

 *	should use one of the more specific allocation functions such as

 *	crypto_alloc_skcipher().

 *

 *	In case of error the return value is an error pointer.

/*

 *	crypto_alloc_tfm_node - Locate algorithm and allocate transform

 *	@alg_name: Name of algorithm

 *	@frontend: Frontend algorithm type

 *	@type: Type of algorithm

 *	@mask: Mask for type comparison

 *	@node: NUMA node in which users desire to put requests, if node is

 *		NUMA_NO_NODE, it means users have no special requirement.

 *

 *	crypto_alloc_tfm() will first attempt to locate an already loaded

 *	algorithm.  If that fails and the kernel supports dynamically loadable

 *	modules, it will then attempt to load a module of the same name or

 *	alias.  If that fails it will send a query to any loaded crypto manager

 *	to construct an algorithm on the fly.  A refcount is grabbed on the

 *	algorithm which is then associated with the new transform.

 *

 *	The returned transform is of a non-determinate type.  Most people

 *	should use one of the more specific allocation functions such as

 *	crypto_alloc_skcipher().

 *

 *	In case of error the return value is an error pointer.

/*

 *	crypto_destroy_tfm - Free crypto transform

 *	@mem: Start of tfm slab

 *	@tfm: Transform to free

 *

 *	This function frees up the transform and any associated resources,

 *	then drops the refcount on the associated algorithm.

 SPDX-License-Identifier: GPL-2.0

/*

 * ESSIV skcipher and aead template for block encryption

 *

 * This template encapsulates the ESSIV IV generation algorithm used by

 * dm-crypt and fscrypt, which converts the initial vector for the skcipher

 * used for block encryption, by encrypting it using the hash of the

 * skcipher key as encryption key. Usually, the input IV is a 64-bit sector

 * number in LE representation zero-padded to the size of the IV, but this

 * is not assumed by this driver.

 *

 * The typical use of this template is to instantiate the skcipher

 * 'essiv(cbc(aes),sha256)', which is the only instantiation used by

 * fscrypt, and the most relevant one for dm-crypt. However, dm-crypt

 * also permits ESSIV to be used in combination with the authenc template,

 * e.g., 'essiv(authenc(hmac(sha256),cbc(aes)),sha256)', in which case

 * we need to instantiate an aead that accepts the same special key format

 * as the authenc template, and deals with the way the encrypted IV is

 * embedded into the AAD area of the aead request. This means the AEAD

 * flavor produced by this template is tightly coupled to the way dm-crypt

 * happens to use it.

 *

 * Copyright (c) 2019 Linaro, Ltd. <ard.biesheuvel@linaro.org>

 *

 * Heavily based on:

 * adiantum length-preserving encryption mode

 *

 * Copyright 2018 Google LLC

	/*

	 * dm-crypt embeds the sector number and the IV in the AAD region, so

	 * we have to copy the converted IV into the right scatterlist before

	 * we pass it on.

			/*

			 * This is a case that rarely occurs in practice, but

			 * for correctness, we have to deal with it nonetheless.

 find the last opening parens */

 find the first closing parens in the tail of the string */

 Symmetric cipher, e.g., "cbc(aes)" */

 AEAD cipher, e.g., "authenc(hmac(sha256),cbc(aes))" */

 Synchronous hash, e.g., "sha256" */

 Check the set of algorithms */

 record the driver name so we can instantiate this exact algo later */

 Instance fields */

	/*

	 * hash_alg wasn't gotten via crypto_grab*(), so we need to inherit its

	 * flags manually.

 essiv(cipher_name, shash_name) */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * SEED Cipher Algorithm.

 *

 * Documentation of SEED can be found in RFC 4269.

 * Copyright (C) 2007 Korea Information Security Agency (KISA).

/*

 * #define byte(x, nr) ((unsigned char)((x) >> (nr*8)))

 encrypt a block of text */

 decrypt a block of text */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * SHA-3, as specified in

 * https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.202.pdf

 *

 * SHA-3 code by Jeff Garzik <jeff@garzik.org>

 *               Ard Biesheuvel <ard.biesheuvel@linaro.org>

/*

 * On some 32-bit architectures (h8300), GCC ends up using

 * over 1 KB of stack if we inline the round calculation into the loop

 * in keccakf(). On the other hand, on 64-bit architectures with plenty

 * of [64-bit wide] general purpose registers, not inlining it severely

 * hurts performance. So let's use 64-bitness as a heuristic to decide

 * whether to inline or not.

 update the state with given number of rounds */

 Theta */

 Rho Pi */

 Chi */

 Iota */

/* 

 * Cryptographic API.

 *

 * MD4 Message Digest Algorithm (RFC1320).

 *

 * Implementation derived from Andrew Tridgell and Steve French's

 * CIFS MD4 implementation, and the cryptoapi implementation

 * originally based on the public domain implementation written

 * by Colin Plumb in 1993.

 *

 * Copyright (c) Andrew Tridgell 1997-1998.

 * Modified by Steve French (sfrench@us.ibm.com) 2002

 * Copyright (c) Cryptoapi developers.

 * Copyright (c) 2002 David S. Miller (davem@redhat.com)

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; either version 2 of the License, or

 * (at your option) any later version.

 *

/*

 * CTS: Cipher Text Stealing mode

 *

 * COPYRIGHT (c) 2008

 * The Regents of the University of Michigan

 * ALL RIGHTS RESERVED

 *

 * Permission is granted to use, copy, create derivative works

 * and redistribute this software and such derivative works

 * for any purpose, so long as the name of The University of

 * Michigan is not used in any advertising or publicity

 * pertaining to the use of distribution of this software

 * without specific, written prior authorization.  If the

 * above copyright notice or any other identification of the

 * University of Michigan is included in any copy of any

 * portion of this software, then the disclaimer below must

 * also be included.

 *

 * THIS SOFTWARE IS PROVIDED AS IS, WITHOUT REPRESENTATION

 * FROM THE UNIVERSITY OF MICHIGAN AS TO ITS FITNESS FOR ANY

 * PURPOSE, AND WITHOUT WARRANTY BY THE UNIVERSITY OF

 * MICHIGAN OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING

 * WITHOUT LIMITATION THE IMPLIED WARRANTIES OF

 * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE

 * REGENTS OF THE UNIVERSITY OF MICHIGAN SHALL NOT BE LIABLE

 * FOR ANY DAMAGES, INCLUDING SPECIAL, INDIRECT, INCIDENTAL, OR

 * CONSEQUENTIAL DAMAGES, WITH RESPECT TO ANY CLAIM ARISING

 * OUT OF OR IN CONNECTION WITH THE USE OF THE SOFTWARE, EVEN

 * IF IT HAS BEEN OR IS HEREAFTER ADVISED OF THE POSSIBILITY OF

 * SUCH DAMAGES.

/* Derived from various:

 *	Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>

/*

 * This is the Cipher Text Stealing mode as described by

 * Section 8 of rfc2040 and referenced by rfc3962.

 * rfc3962 includes errata information in its Appendix A.

 1. Decrypt Cn-1 (s) to create Dn */

 2. Pad Cn with zeros at the end to create C of length BB */

 3. Exclusive-or Dn with C to create Xn */

 4. Select the first Ln bytes of Xn to create Pn */

 5. Append the tail (BB - Ln) bytes of Xn to Cn to create En */

 6. Decrypt En to create Pn-1 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ChaCha and XChaCha stream ciphers, including ChaCha20 (RFC7539)

 *

 * Copyright (C) 2015 Martin Willi

 * Copyright (C) 2018 Google LLC

 Compute the subkey given the original key and first 128 nonce bits */

 Build the real IV */

 stream position */

 remaining 64 nonce bits */

 Generate the stream and XOR it with the data */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Kernel cryptographic api.

* cast5.c - Cast5 cipher algorithm (rfc2144).

*

* Derived from GnuPG implementation of cast5.

*

* Major Changes.

*	Complete conformance to rfc2144.

*	Supports key size from 40 to 128 bits.

*

* Copyright (C) 1998, 1999, 2000, 2001 Free Software Foundation, Inc.

* Copyright (C) 2003 Kartikey Mahendra Bhatt <kartik_me@hotmail.com>.

 used by the Fx macros */

	/* (L0,R0) <-- (m1...m64).  (Split the plaintext into left and

	 * right 32-bit halves L0 = m1...m32 and R0 = m33...m64.)

	/* (16 rounds) for i from 1 to 16, compute Li and Ri as follows:

	 *  Li = Ri-1;

	 *  Ri = Li-1 ^ f(Ri-1,Kmi,Kri), where f is defined in Section 2.2

	 * Rounds 1, 4, 7, 10, 13, and 16 use f function Type 1.

	 * Rounds 2, 5, 8, 11, and 14 use f function Type 2.

	 * Rounds 3, 6, 9, 12, and 15 use f function Type 3.

	/* c1...c64 <-- (R16,L16).  (Exchange final blocks L16, R16 and

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 *

 * Copyright (c) 2017-present, Facebook, Inc.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * Null algorithms, aka Much Ado About Nothing.

 *

 * These are needed for IPsec, and may be useful in general for

 * testing & debugging.

 *

 * The null cipher is compliant with RFC2410.

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * CCM: Counter with CBC-MAC

 *

 * (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>

	/* format control info per RFC 3610 and

	 * NIST Special Publication 800-38C

	/* add control info for associated data

	 * RFC 3610 and NIST Special Publication 800-38C

 format control data for input */

 format associated data and compute into mac */

 we need to pad the MAC input to a round multiple of the block size */

 2 <= L <= 8, so 1 <= L' <= 7. */

	 /* Note: rfc 3610 and NIST 800-38C require counter of

	 * zero to encrypt auth tag.

 copy authtag to end of dst */

 verify */

 The skcipher algorithm must be CTR mode, using 16-byte blocks. */

 ctr and cbcmac must use the same underlying block cipher. */

 L' */

 We only support 16-byte blocks. */

 Not a stream cipher? */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2012 Xyratex Technology Limited

/*

 * This is crypto api shash wrappers to crc32_le.

* No default init with ~0 */

/*

 * Setting the seed allows arbitrary accumulators and flexible XOR policy

 * If your algorithm starts with ~0, then XOR with ~0 before you set

 * the seed.

 No final XOR 0xFFFFFFFF, like crc32_le */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * algif_hash: User-space interface for hash algorithms

 *

 * This file provides the user-space API for hash algorithms.

 *

 * Copyright (c) 2010 Herbert Xu <herbert@gondor.apana.org.au>

/*

 * Cryptographic API.

 *

 * Khazad Algorithm

 *

 * The Khazad algorithm was developed by Paulo S. L. M. Barreto and

 * Vincent Rijmen.  It was a finalist in the NESSIE encryption contest.

 *

 * The original authors have disclaimed all copyright interest in this

 * code and thus put it in the public domain. The subsequent authors

 * have put this under the GNU General Public License.

 *

 * By Aaron Grothe ajgrothe@yahoo.com, August 1, 2004

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; either version 2 of the License, or

 * (at your option) any later version.

 *

 key is supposed to be 32-bit aligned */

 setup the encrypt key */

 Setup the decrypt key */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Twofish for CryptoAPI

 *

 * Originally Twofish for GPG

 * By Matthew Skala <mskala@ansuz.sooke.bc.ca>, July 26, 1998

 * 256-bit key length added March 20, 1999

 * Some modifications to reduce the text size by Werner Koch, April, 1998

 * Ported to the kerneli patch by Marc Mutz <Marc@Mutz.com>

 * Ported to CryptoAPI by Colin Slater <hoho@tacomeat.net>

 *

 * The original author has disclaimed all copyright interest in this

 * code and thus put it in the public domain. The subsequent authors 

 * have put this under the GNU General Public License.

 *

 * This code is a "clean room" implementation, written from the paper

 * _Twofish: A 128-Bit Block Cipher_ by Bruce Schneier, John Kelsey,

 * Doug Whiting, David Wagner, Chris Hall, and Niels Ferguson, available

 * through http://www.counterpane.com/twofish.html

 *

 * For background information on multiplication in finite fields, used for

 * the matrix operations in the key schedule, see the book _Contemporary

 * Abstract Algebra_ by Joseph A. Gallian, especially chapter 22 in the

 * Third Edition.

/* Macros to compute the g() function in the encryption and decryption

 * rounds.  G1 is the straight g() function; G2 includes the 8-bit

/* Encryption and decryption Feistel rounds.  Each one calls the two g()

 * macros, does the PHT, and performs the XOR and the appropriate bit

 * rotations.  The parameters are the round number (used to select subkeys),

/* Encryption and decryption cycles; each one is simply two Feistel rounds

/* Macros to convert the input and output bytes into 32-bit words,

 * and simultaneously perform the whitening step.  INPACK packs word

 * number n into the variable named by x, using whitening subkey number m.

 * OUTUNPACK unpacks word number n from the variable named by x, using

 Encrypt one block.  in and out may be the same. */

 The four 32-bit chunks of the text. */

 Temporaries used by the round function. */

 Input whitening and packing. */

 Encryption Feistel cycles. */

 Output whitening and unpacking. */

 Decrypt one block.  in and out may be the same. */

 The four 32-bit chunks of the text. */

 Temporaries used by the round function. */

 Input whitening and packing. */

 Encryption Feistel cycles. */

 Output whitening and unpacking. */

/*

 * Cryptographic API.

 *

 * T10 Data Integrity Field CRC16 Crypto Transform

 *

 * Copyright (c) 2007 Oracle Corporation.  All rights reserved.

 * Written by Martin K. Petersen <martin.petersen@oracle.com>

 * Copyright (C) 2013 Intel Corporation

 * Author: Tim Chen <tim.c.chen@linux.intel.com>

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the Free

 * Software Foundation; either version 2 of the License, or (at your option)

 * any later version.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

/*

 * Steps through buffer one byte at a time, calculates reflected

 * crc using table.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * pcrypt - Parallel crypto wrapper.

 *

 * Copyright (C) 2009 secunet Security Networks AG

 * Copyright (C) 2009 Steffen Klassert <steffen.klassert@secunet.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * Compression operations.

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Synchronous Compression operations

 *

 * Copyright 2015 LG Electronics Inc.

 * Copyright (c) 2016, Intel Corporation

 * Author: Giovanni Cabiddu <giovanni.cabiddu@intel.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Key-agreement Protocol Primitives (KPP)

 *

 * Copyright (c) 2016, Intel Corporation

 * Authors: Salvatore Benedetto <salvatore.benedetto@intel.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * RNG operations.

 *

 * Copyright (c) 2008 Neil Horman <nhorman@tuxdriver.com>

 * Copyright (c) 2015 Herbert Xu <herbert@gondor.apana.org.au>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API

 *

 * ARC4 Cipher Algorithm

 *

 * Jon Oberheide <jon@oberheide.org>

	/*

	 * For legacy reasons, this is named "ecb(arc4)", not "arc4".

	 * Nevertheless it's actually a stream cipher, not a block cipher.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Common lookup tables for CAST-128 (cast5) and CAST-256 (cast6)

 *

 * Copyright  1998, 1999, 2000, 2001 Free Software Foundation, Inc.

 * Copyright  2003 Kartikey Mahendra Bhatt <kartik_me@hotmail.com>

 * Copyright  2012 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2016, Intel Corporation

 * Authors: Salvatore Benedetto <salvatore.benedetto@intel.com>

	/*

	 * Don't permit the buffer for 'key' or 'g' to be larger than 'p', since

	 * some drivers assume otherwise.

	/* Don't allocate memory. Set pointers to data within

	 * the given buffer

	/*

	 * Don't permit 'p' to be 0.  It's not a prime number, and it's subject

	 * to corner cases such as 'mod 0' being undefined or

	 * crypto_kpp_maxsize() returning 0.

 It is permissible to not provide Q. */

SPDX-License-Identifier: GPL-2.0

/*

 * CFB: Cipher FeedBack mode

 *

 * Copyright (c) 2018 James.Bottomley@HansenPartnership.com

 *

 * CFB is a stream cipher mode which is layered on to a block

 * encryption scheme.  It works very much like a one time pad where

 * the pad is generated initially from the encrypted IV and then

 * subsequently from the encrypted previous block of ciphertext.  The

 * pad is XOR'd into the plain text to get the final ciphertext.

 *

 * The scheme of CFB is best described by wikipedia:

 *

 * https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#CFB

 *

 * Note that since the pad for both encryption and decryption is

 * generated by an encryption operation, CFB never uses the block

 * decryption function.

 final encrypt and decrypt is the same */

 CFB mode is a stream cipher. */

	/*

	 * To simplify the implementation, configure the skcipher walk to only

	 * give a partial block at the very end, never earlier.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * PRNG: Pseudo Random Number Generator

 *       Based on NIST Recommended PRNG From ANSI X9.31 Appendix A.2.4 using

 *       AES 128 cipher

 *

 *  (C) Neil Horman <nhorman@tuxdriver.com>

/*

 * Flags for the prng_context flags field

/*

 * Note: DT is our counter value

 *	 I is our intermediate value

 *	 V is our seed vector

 * See http://csrc.nist.gov/groups/STM/cavp/documents/rng/931rngext.pdf

 * for implementation details

/*

 * Returns DEFAULT_BLK_SZ bytes of random data per call

 * returns 0 if generation succeeded, <0 if something went wrong

	/*

	 * This algorithm is a 3 stage state machine

			/*

			 * Start by encrypting the counter value

			 * This gives us an intermediate value I

			/*

			 * Next xor I with our secret vector V

			 * encrypt that result to obtain our

			 * pseudo random data which we output

			/*

			 * First check that we didn't produce the same

			 * random data that we did last time around through this

			/*

			 * Lastly xor the random data with I

			 * and encrypt that to obtain a new secret vector V

 do the encryption */

	/*

	 * Now update our DT value

 Our exported functions */

	/*

	 * If the FIXED_SIZE flag is on, only return whole blocks of

	 * pseudo random data

	/*

	 * Return 0 in case of success as mandated by the kernel

	 * crypto API interface definition.

	/*

	 * Copy any data less than an entire block

	/*

	 * Now copy whole blocks

	/*

	 * Now go back and get any remaining partial block

	/*

	 * after allocation, we should always force the user to reset

	 * so they don't inadvertently use the insecure default values

	 * without specifying them intentially

/*

 *  This is the cprng_registered reset method the seed value is

 *  interpreted as the tuple { V KEY DT}

 *  V and KEY are required during reset, and DT is optional, detected

 *  as being present by testing the length of the seed

 fips strictly requires seed != key */

 this primes our continuity test */

 Module initalization */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Common Twofish algorithm parts shared between the c and assembler

 * implementations

 *

 * Originally Twofish for GPG

 * By Matthew Skala <mskala@ansuz.sooke.bc.ca>, July 26, 1998

 * 256-bit key length added March 20, 1999

 * Some modifications to reduce the text size by Werner Koch, April, 1998

 * Ported to the kerneli patch by Marc Mutz <Marc@Mutz.com>

 * Ported to CryptoAPI by Colin Slater <hoho@tacomeat.net>

 *

 * The original author has disclaimed all copyright interest in this

 * code and thus put it in the public domain. The subsequent authors

 * have put this under the GNU General Public License.

 *

 * This code is a "clean room" implementation, written from the paper

 * _Twofish: A 128-Bit Block Cipher_ by Bruce Schneier, John Kelsey,

 * Doug Whiting, David Wagner, Chris Hall, and Niels Ferguson, available

 * through http://www.counterpane.com/twofish.html

 *

 * For background information on multiplication in finite fields, used for

 * the matrix operations in the key schedule, see the book _Contemporary

 * Abstract Algebra_ by Joseph A. Gallian, especially chapter 22 in the

 * Third Edition.

/* The large precomputed tables for the Twofish cipher (twofish.c)

 * Taken from the same source as twofish.c

 * Marc Mutz <Marc@Mutz.com>

/* These two tables are the q0 and q1 permutations, exactly as described in

/* These MDS tables are actually tables of MDS composed with q0 and q1,

 * because it is only ever used that way and we can save some time by

 * precomputing.  Of course the main saving comes from precomputing the

 * GF(2^8) multiplication involved in the MDS matrix multiply; by looking

 * things up in these tables we reduce the matrix multiply to four lookups

 * and three XORs.  Semi-formally, the definition of these tables is:

 * mds[0][i] = MDS (q1[i] 0 0 0)^T  mds[1][i] = MDS (0 q0[i] 0 0)^T

 * mds[2][i] = MDS (0 0 q1[i] 0)^T  mds[3][i] = MDS (0 0 0 q0[i])^T

 * where ^T means "transpose", the matrix multiply is performed in GF(2^8)

 * represented as GF(2)[x]/v(x) where v(x)=x^8+x^6+x^5+x^3+1 as described

 * by Schneier et al, and I'm casually glossing over the byte/word

/* The exp_to_poly and poly_to_exp tables are used to perform efficient

 * operations in GF(2^8) represented as GF(2)[x]/w(x) where

 * w(x)=x^8+x^6+x^3+x^2+1.  We care about doing that because it's part of the

 * definition of the RS matrix in the key schedule.  Elements of that field

 * are polynomials of degree not greater than 7 and all coefficients 0 or 1,

 * which can be represented naturally by bytes (just substitute x=2).  In that

 * form, GF(2^8) addition is the same as bitwise XOR, but GF(2^8)

 * multiplication is inefficient without hardware support.  To multiply

 * faster, I make use of the fact x is a generator for the nonzero elements,

 * so that every element p of GF(2)[x]/w(x) is either 0 or equal to (x)^n for

 * some n in 0..254.  Note that that caret is exponentiation in GF(2^8),

 * *not* polynomial notation.  So if I want to compute pq where p and q are

 * in GF(2^8), I can just say:

 *    1. if p=0 or q=0 then pq=0

 *    2. otherwise, find m and n such that p=x^m and q=x^n

 *    3. pq=(x^m)(x^n)=x^(m+n), so add m and n and find pq

 * The translations in steps 2 and 3 are looked up in the tables

 * poly_to_exp (for step 2) and exp_to_poly (for step 3).  To see this

 * in action, look at the CALC_S macro.  As additional wrinkles, note that

 * one of my operands is always a constant, so the poly_to_exp lookup on it

 * is done in advance; I included the original values in the comments so

 * readers can have some chance of recognizing that this *is* the RS matrix

 * from the Twofish paper.  I've only included the table entries I actually

 * need; I never do a lookup on a variable input of zero and the biggest

 * exponents I'll ever see are 254 (variable) and 237 (constant), so they'll

 * never sum to more than 491.	I'm repeating part of the exp_to_poly table

 * so that I don't have to do mod-255 reduction in the exponent arithmetic.

 * Since I know my constant operands are never zero, I only have to worry

 * about zero values in the variable operand, and I do it with a simple

 * conditional branch.	I know conditionals are expensive, but I couldn't

 * see a non-horrible way of avoiding them, and I did manage to group the

/* The table constants are indices of

/* Macro to perform one column of the RS matrix multiplication.  The

 * parameters a, b, c, and d are the four bytes of output; i is the index

 * of the key bytes, and w, x, y, and z, are the column of constants from

/* Macros to calculate the key-dependent S-boxes for a 128-bit key using

 * the S vector from CALC_S.  CALC_SB_2 computes a single entry in all

 * four S-boxes, where i is the index of the entry to compute, and a and b

 * are the index numbers preprocessed through the q0 and q1 tables

 Macro exactly like CALC_SB_2, but for 192-bit keys. */

 Macro exactly like CALC_SB_2, but for 256-bit keys. */

/* Macros to calculate the whitening and round subkeys.  CALC_K_2 computes the

 * last two stages of the h() function for a given index (either 2i or 2i+1).

 * a, b, c, and d are the four bytes going into the last two stages.  For

 * 128-bit keys, this is the entire h() function and a and c are the index

 * preprocessed through q0 and q1 respectively; for longer keys they are the

 * output of previous stages.  j is the index of the first key byte to use.

 * CALC_K computes a pair of subkeys for 128-bit Twofish, by calling CALC_K_2

 * twice, doing the Pseudo-Hadamard Transform, and doing the necessary

 * rotations.  Its parameters are: a, the array to write the results into,

 * j, the index of the first output entry, k and l, the preprocessed indices

 * for index 2i, and m and n, the preprocessed indices for index 2i+1.

 * CALC_K192_2 expands CALC_K_2 to handle 192-bit keys, by doing an

 * additional lookup-and-XOR stage.  The parameters a, b, c and d are the

 * four bytes going into the last three stages.  For 192-bit keys, c = d

 * are the index preprocessed through q0, and a = b are the index

 * preprocessed through q1; j is the index of the first key byte to use.

 * CALC_K192 is identical to CALC_K but for using the CALC_K192_2 macro

 * instead of CALC_K_2.

 * CALC_K256_2 expands CALC_K192_2 to handle 256-bit keys, by doing an

 * additional lookup-and-XOR stage.  The parameters a and b are the index

 * preprocessed through q0 and q1 respectively; j is the index of the first

 * key byte to use.  CALC_K256 is identical to CALC_K but for using the

 Perform the key setup. */

 Temporaries for CALC_K. */

	/* The S vector used to key the S-boxes, split up into individual bytes.

 Temporary for CALC_S. */

 Check key length. */

 unsupported key length */

	/* Compute the first two words of the S vector.  The magic numbers are

	 * the entries of the RS matrix, preprocessed through poly_to_exp. The

	 * numbers in the comments are the original (polynomial form) matrix

 01 A4 02 A4 */

 A4 56 A1 55 */

 55 82 FC 87 */

 87 F3 C1 5A */

 5A 1E 47 58 */

 58 C6 AE DB */

 DB 68 3D 9E */

 9E E5 19 03 */

 01 A4 02 A4 */

 A4 56 A1 55 */

 55 82 FC 87 */

 87 F3 C1 5A */

 5A 1E 47 58 */

 58 C6 AE DB */

 DB 68 3D 9E */

 9E E5 19 03 */

 192- or 256-bit key */

 Calculate the third word of the S vector */

 01 A4 02 A4 */

 A4 56 A1 55 */

 55 82 FC 87 */

 87 F3 C1 5A */

 5A 1E 47 58 */

 58 C6 AE DB */

 DB 68 3D 9E */

 9E E5 19 03 */

 256-bit key */

 Calculate the fourth word of the S vector */

 01 A4 02 A4 */

 A4 56 A1 55 */

 55 82 FC 87 */

 87 F3 C1 5A */

 5A 1E 47 58 */

 58 C6 AE DB */

 DB 68 3D 9E */

 9E E5 19 03 */

 Compute the S-boxes. */

		/* CALC_K256/CALC_K192/CALC_K loops were unrolled.

		 * Unrolling produced x2.5 more code (+18k on i386),

		 * and speeded up key setup by 7%:

		 * unrolled: twofish_setkey/sec: 41128

		 *     loop: twofish_setkey/sec: 38148

		 * CALC_K256: ~100 insns each

		 * CALC_K192: ~90 insns

		 *    CALC_K: ~70 insns

 Calculate whitening and round subkeys */

 192-bit key */

 Compute the S-boxes. */

 Calculate whitening and round subkeys */

 128-bit key */

 Compute the S-boxes. */

 Calculate whitening and round subkeys */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * Single-block cipher operations.

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 * Copyright (c) 2005 Herbert Xu <herbert@gondor.apana.org.au>

/* gf128mul.c - GF(2^128) multiplication functions

 *

 * Copyright (c) 2003, Dr Brian Gladman, Worcester, UK.

 * Copyright (c) 2006, Rik Snel <rsnel@cube.dyndns.org>

 *

 * Based on Dr Brian Gladman's (GPL'd) work published at

 * http://gladman.plushost.co.uk/oldsite/cryptography_technology/index.php

 * See the original copyright notice below.

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the Free

 * Software Foundation; either version 2 of the License, or (at your option)

 * any later version.

/*

 ---------------------------------------------------------------------------

 Copyright (c) 2003, Dr Brian Gladman, Worcester, UK.   All rights reserved.



 LICENSE TERMS



 The free distribution and use of this software in both source and binary

 form is allowed (with or without changes) provided that:



   1. distributions of this source code include the above copyright

      notice, this list of conditions and the following disclaimer;



   2. distributions in binary form include the above copyright

      notice, this list of conditions and the following disclaimer

      in the documentation and/or other associated materials;



   3. the copyright holder's name is not used to endorse products

      built using this software without specific written permission.



 ALTERNATIVELY, provided that this notice is retained in full, this product

 may be distributed under the terms of the GNU General Public License (GPL),

 in which case the provisions of the GPL apply INSTEAD OF those given above.



 DISCLAIMER



 This software is provided 'as is' with no explicit or implied warranties

 in respect of its properties, including, but not limited to, correctness

 and/or fitness for purpose.

 ---------------------------------------------------------------------------

 Issue 31/01/2006



 This file provides fast multiplication in GF(2^128) as required by several

 cryptographic authentication modes

/*

 * Given a value i in 0..255 as the byte overflow when a field element

 * in GF(2^128) is multiplied by x^8, the following macro returns the

 * 16-bit value that must be XOR-ed into the low-degree end of the

 * product to reduce it modulo the polynomial x^128 + x^7 + x^2 + x + 1.

 *

 * There are two versions of the macro, and hence two tables: one for

 * the "be" convention where the highest-order bit is the coefficient of

 * the highest-degree polynomial term, and one for the "le" convention

 * where the highest-order bit is the coefficient of the lowest-degree

 * polynomial term.  In both cases the values are stored in CPU byte

 * endianness such that the coefficients are ordered consistently across

 * bytes, i.e. in the "be" table bits 15..0 of the stored value

 * correspond to the coefficients of x^15..x^0, and in the "le" table

 * bits 15..0 correspond to the coefficients of x^0..x^15.

 *

 * Therefore, provided that the appropriate byte endianness conversions

 * are done by the multiplication functions (and these must be in place

 * anyway to support both little endian and big endian CPUs), the "be"

 * table can be used for multiplications of both "bbe" and "ble"

 * elements, and the "le" table can be used for multiplications of both

 * "lle" and "lbe" elements.

/*

 * The following functions multiply a field element by x^8 in

 * the polynomial field representation.  They use 64-bit word operations

 * to gain speed but compensate for machine endianness and hence work

 * correctly on both styles of machine.

/*      This version uses 64k bytes of table space.

    A 16 byte buffer has to be multiplied by a 16 byte key

    value in GF(2^128).  If we consider a GF(2^128) value in

    the buffer's lowest byte, we can construct a table of

    the 256 16 byte values that result from the 256 values

    of this byte.  This requires 4096 bytes. But we also

    need tables for each of the 16 higher bytes in the

    buffer as well, which makes 64 kbytes in total.

/* additional explanation

 * t[0][BYTE] contains g*BYTE

 * t[1][BYTE] contains g*x^8*BYTE

 *  ..

/*      This version uses 4k bytes of table space.

    A 16 byte buffer has to be multiplied by a 16 byte key

    value in GF(2^128).  If we consider a GF(2^128) value in a

    single byte, we can construct a table of the 256 16 byte

    values that result from the 256 values of this byte.

    This requires 4096 bytes. If we take the highest byte in

    the buffer and use this table to get the result, we then

    have to multiply by x^120 to get the final value. For the

    next highest byte the result has to be multiplied by x^112

    and so on. But we can do this by accumulating the result

    in an accumulator starting with the result for the top

    byte.  We repeatedly multiply the accumulator value by

    x^8 and then add in (i.e. xor) the 16 bytes of the next

    lower byte in the buffer, stopping when we reach the

    lowest byte. This requires a 4096 byte table.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * RIPEMD-160 - RACE Integrity Primitives Evaluation Message Digest.

 *

 * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC

 *

 * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>

 XOR */

 x ? y : z */

 z ? x : y */

 Initialize left lane */

 Initialize right lane */

 round 1: left lane */

 round 2: left lane" */

 round 3: left lane" */

 round 4: left lane" */

 round 5: left lane" */

 round 1: right lane */

 round 2: right lane */

 round 3: right lane */

 round 4: right lane */

 round 5: right lane */

 combine results */

 final result for state[0] */

 Enough space in buffer? If so copy and we're done */

 Add padding and return the message digest. */

 Pad out to 56 mod 64 */

 Append length */

 Store state in digest */

 Wipe context */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Hash Info: Hash algorithms information

 *

 * Copyright (c) 2013 Dmitry Kasatkin <d.kasatkin@samsung.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Algorithm testing framework and tests.

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 * Copyright (c) 2002 Jean-Francois Dive <jef@linuxbe.org>

 * Copyright (c) 2007 Nokia Siemens Networks

 * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>

 * Copyright (c) 2019 Google LLC

 *

 * Updated RFC4106 AES-GCM testing.

 *    Authors: Aidan O'Mahony (aidan.o.mahony@intel.com)

 *             Adrian Hoban <adrian.hoban@intel.com>

 *             Gabriele Paoloni <gabriele.paoloni@intel.com>

 *             Tadeusz Struk (tadeusz.struk@intel.com)

 *    Copyright (c) 2010, Intel Corporation.

 a perfect nop */

/*

 * Need slab memory for testing (size in number of pages).

/*

* Used by test_cipher()

	/*

	 * Set if trying to decrypt an inauthentic ciphertext with this

	 * algorithm might result in EINVAL rather than EBADMSG, due to other

	 * validation the algorithm does on the inputs such as length checks.

	/*

	 * Set if this algorithm requires that the IV be located at the end of

	 * the AAD buffer, in addition to being given in the normal way.  The

	 * behavior when the two IV copies differ is implementation-defined.

 set if alg is allowed in fips mode */

 Is the memory region still fully poisoned? */

 flush type for hash algorithms */

 merge with update of previous buffer(s) */

 update with previous buffer(s) before doing this one */

 likewise, but also export and re-import the intermediate state */

 finalization function for hash algorithms */

 use final() */

 use finup() */

 use digest() */

/**

 * struct test_sg_division - description of a scatterlist entry

 *

 * This struct describes one entry of a scatterlist being constructed to check a

 * crypto test vector.

 *

 * @proportion_of_total: length of this chunk relative to the total length,

 *			 given as a proportion out of TEST_SG_TOTAL so that it

 *			 scales to fit any test vector

 * @offset: byte offset into a 2-page buffer at which this chunk will start

 * @offset_relative_to_alignmask: if true, add the algorithm's alignmask to the

 *				  @offset

 * @flush_type: for hashes, whether an update() should be done now vs.

 *		continuing to accumulate data

 * @nosimd: if doing the pending update(), do it with SIMD disabled?

/**

 * struct testvec_config - configuration for testing a crypto test vector

 *

 * This struct describes the data layout and other parameters with which each

 * crypto test vector can be tested.

 *

 * @name: name of this config, logged for debugging purposes if a test fails

 * @inplace: operate on the data in-place, if applicable for the algorithm type?

 * @req_flags: extra request_flags, e.g. CRYPTO_TFM_REQ_MAY_SLEEP

 * @src_divs: description of how to arrange the source scatterlist

 * @dst_divs: description of how to arrange the dst scatterlist, if applicable

 *	      for the algorithm type.  Defaults to @src_divs if unset.

 * @iv_offset: misalignment of the IV in the range [0..MAX_ALGAPI_ALIGNMASK+1],

 *	       where 0 is aligned to a 2*(MAX_ALGAPI_ALIGNMASK+1) byte boundary

 * @iv_offset_relative_to_alignmask: if true, add the algorithm's alignmask to

 *				     the @iv_offset

 * @key_offset: misalignment of the key, where 0 is default alignment

 * @key_offset_relative_to_alignmask: if true, add the algorithm's alignmask to

 *				      the @key_offset

 * @finalization_type: what finalization function to use for hashes

 * @nosimd: execute with SIMD disabled?  Requires !CRYPTO_TFM_REQ_MAY_SLEEP.

/*

 * The following are the lists of testvec_configs to test for each algorithm

 * type when the basic crypto self-tests are enabled, i.e. when

 * CONFIG_CRYPTO_MANAGER_DISABLE_TESTS is unset.  They aim to provide good test

 * coverage, while keeping the test time much shorter than the full fuzz tests

 * so that the basic tests can be enabled in a wider range of circumstances.

 Configs for skciphers and aeads */

/*

 * Check whether the given testvec_config is valid.  This isn't strictly needed

 * since every testvec_config should be valid, but check anyway so that people

 * don't unknowingly add broken configs that don't do what they wanted.

 defaults to dst_divs=src_divs */

 two pages per buffer */);

 two pages per buffer */);

/**

 * build_test_sglist() - build a scatterlist for a crypto test

 *

 * @tsgl: the scatterlist to build.  @tsgl->bufs[] contains an array of 2-page

 *	  buffers which the scatterlist @tsgl->sgl[] will be made to point into.

 * @divs: the layout specification on which the scatterlist will be based

 * @alignmask: the algorithm's alignmask

 * @total_len: the total length of the scatterlist to build in bytes

 * @data: if non-NULL, the buffers will be filled with this data until it ends.

 *	  Otherwise the buffers will be poisoned.  In both cases, some bytes

 *	  past the end of each buffer will be poisoned to help detect overruns.

 * @out_divs: if non-NULL, the test_sg_division to which each scatterlist entry

 *	      corresponds will be returned here.  This will match @divs except

 *	      that divisions resolving to a length of 0 are omitted as they are

 *	      not included in the scatterlist.

 *

 * Return: 0 or a -errno value

 Calculate the (div, length) pairs */

 Set up the sgl entries and fill the data or poison */

/*

 * Verify that a scatterlist crypto operation produced the correct output.

 *

 * @tsgl: scatterlist containing the actual output

 * @expected_output: buffer containing the expected output

 * @len_to_check: length of @expected_output in bytes

 * @unchecked_prefix_len: number of ignored bytes in @tsgl prior to real result

 * @check_poison: verify that the poison bytes after each chunk are intact?

 *

 * Return: 0 if correct, -EINVAL if incorrect, -EOVERFLOW if buffer overrun.

 Build the src and dst scatterlists for an skcipher or AEAD test */

/*

 * Support for testing passing a misaligned key to setkey():

 *

 * If cfg->key_offset is set, copy the key into a new buffer at that offset,

 * optionally adding alignmask.  Else, just use the key directly.

 Like setkey_f(tfm, key, ksize), but sometimes misalign the key */

 Generate a random length in range [0, max_len], but prefer smaller values */

 Flip a random bit in the given nonempty data buffer */

 Flip a random byte in the given nonempty data buffer */

 Sometimes make some random changes to the given nonempty data buffer */

 Sometimes flip some bits */

 Sometimes flip some bytes */

 Randomly generate 'count' bytes, but sometimes make them "interesting" */

 Choose a generation strategy */

 All the same byte, plus optional mutations */

 Ascending or descending bytes, plus optional mutations */

 Fully random bytes */

 for "%u.%u%%" */

 Generate a random testvec_config for fuzz testing */

/*

 * Given an algorithm name, build the name of the generic implementation of that

 * algorithm, assuming the usual naming convention.  Specifically, this appends

 * "-generic" to every part of the name that is not a template name.  Examples:

 *

 *	aes => aes-generic

 *	cbc(aes) => cbc(aes-generic)

 *	cts(cbc(aes)) => cts(cbc(aes-generic))

 *	rfc7539(chacha20,poly1305) => rfc7539(chacha20-generic,poly1305-generic)

 *

 * Return: 0 on success, or -ENAMETOOLONG if the generic name would be too long

 !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */

 !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */

 Test one hash test vector in one configuration, using the shash API */

 Set the key, if specified */

 Build the scatterlist for the source data */

 Do the actual hashing */

 Just using digest() */

 Using init(), zero or more update(), then final() or finup() */

 Test ->export() and ->import() */

 Test one hash test vector in one configuration, using the ahash API */

 Set the key, if specified */

 Build the scatterlist for the source data */

 Do the actual hashing */

 Just using digest() */

 Using init(), zero or more update(), then final() or finup() */

 update() with the pending data */

 Test ->export() and ->import() */

 finish with update() and final() */

 finish with finup() */

	/*

	 * For algorithms implemented as "shash", most bugs will be detected by

	 * both the shash and ahash tests.  Test the shash API first so that the

	 * failures involve less indirection, so are easier to debug.

/*

 * Generate a hash test vector from the given implementation.

 * Assumes the buffers in 'vec' were already allocated.

 Data */

	/*

	 * Key: length in range [1, maxkeysize], but usually choose maxkeysize.

	 * If algorithm is unkeyed, then maxkeysize == 0 and set ksize = 0.

 If the key couldn't be set, no need to continue to digest. */

 Digest */

/*

 * Test the hash algorithm represented by @req against the corresponding generic

 * implementation, if one is available.

 Use default naming convention? */

 Already the generic impl? */

 Check the algorithm properties for consistency. */

	/*

	 * Now generate test vectors using the generic implementation, and test

	 * the other implementation against them.

 !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */

 !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */

			/*

			 * This algorithm is only available through the ahash

			 * API, not the shash API, so skip the shash tests.

	/*

	 * Always test the ahash API.  This works regardless of whether the

	 * algorithm is implemented as ahash or shash.

	/*

	 * If available also test the shash API, to cover corner cases that may

	 * be missed by testing the ahash API only.

	/*

	 * For OPTIONAL_KEY algorithms, we have to do all the unkeyed tests

	 * first, before setting a key on the tfm.  To make this easier, we

	 * require that the unkeyed test vectors (if any) are listed first.

 Set the key */

 Set the authentication tag size */

 The IV must be copied to a buffer, as the algorithm may modify it */

 Build the src/dst scatterlists */

 Do the actual encryption or decryption */

 Check that the algorithm didn't overwrite things it shouldn't have */

 Check for unexpected success or failure, or wrong error code */

 Expectedly failed. */

 Check for the correct output (ciphertext or plaintext) */

/*

 * Make at least one random change to a (ciphertext, AAD) pair.  "Ciphertext"

 * here means the full ciphertext including the authentication tag.  The

 * authentication tag (and hence also the ciphertext) is assumed to be nonempty.

 Mutate the AAD */

 Mutate auth tag (assuming it's at the end of ciphertext) */

 Mutate any part of the ciphertext */

/*

 * Minimum authentication tag size in bytes at which we assume that we can

 * reliably generate inauthentic messages, i.e. not generate an authentic

 * message by chance.

 Generate the AAD. */

 Avoid implementation-defined behavior. */

 Generate a random ciphertext. */

 Generate a random plaintext and encrypt it. */

 If encryption failed, we're done. */

		/*

		 * Mutate the authentic (ciphertext, AAD) pair to get an

		 * inauthentic one.

/*

 * Generate an AEAD test vector 'vec' using the implementation specified by

 * 'req'.  The buffers in 'vec' must already be allocated.

 *

 * If 'prefer_inauthentic' is true, then this function will generate inauthentic

 * test vectors (i.e. vectors with 'vec->novrfy=1') more often.

 Key: length in [0, maxkeysize], but usually choose maxkeysize */

 IV */

 Tag length: in [0, maxauthsize], but usually choose maxauthsize */

 AAD, plaintext, and ciphertext lengths */

	/*

	 * Generate the AAD, plaintext, and ciphertext.  Not applicable if the

	 * key or the authentication tag size couldn't be set.

/*

 * Generate inauthentic test vectors (i.e. ciphertext, AAD pairs that aren't the

 * result of an encryption with the key) and verify that decryption fails.

		/*

		 * Since this part of the tests isn't comparing the

		 * implementation to another, there's no point in testing any

		 * test vectors other than inauthentic ones (vec.novrfy=1) here.

		 *

		 * If we're having trouble generating such a test vector, e.g.

		 * if the algorithm keeps rejecting the generated keys, don't

		 * retry forever; just continue on.

/*

 * Test the AEAD algorithm against the corresponding generic implementation, if

 * one is available.

 Use default naming convention? */

 Already the generic impl? */

 Check the algorithm properties for consistency. */

	/*

	 * Now generate test vectors using the generic implementation, and test

	 * the other implementation against them.

 !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */

 !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */

 Set the key */

 The IV must be copied to a buffer, as the algorithm may modify it */

 Build the src/dst scatterlists */

 Do the actual encryption or decryption */

 Check that the algorithm didn't overwrite things it shouldn't have */

 Check for success or failure */

 Check for the correct output (ciphertext or plaintext) */

 If applicable, check that the algorithm generated the correct IV */

/*

 * Generate a symmetric cipher test vector from the given implementation.

 * Assumes the buffers in 'vec' were already allocated.

 Key: length in [0, maxkeysize], but usually choose maxkeysize */

 IV */

 Plaintext */

 If the key couldn't be set, no need to continue to encrypt. */

 Ciphertext */

		/*

		 * The only acceptable error here is for an invalid length, so

		 * skcipher decryption should fail with the same error too.

		 * We'll test for this.  But to keep the API usage well-defined,

		 * explicitly initialize the ciphertext buffer too.

/*

 * Test the skcipher algorithm represented by @req against the corresponding

 * generic implementation, if one is available.

 Keywrap isn't supported here yet as it handles its IV differently. */

 Use default naming convention? */

 Already the generic impl? */

 Check the algorithm properties for consistency. */

	/*

	 * Now generate test vectors using the generic implementation, and test

	 * the other implementation against them.

 !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */

 !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */

			/*

			 * This crc32c implementation is only available through

			 * ahash API, not the shash API, so the remaining part

			 * of the test is not applicable to it.

 Use appropriate parameter as base */

 Compute party A's public key */

 Save party A's public key */

 Verify calculated public key */

 Calculate shared secret key by using counter part (b) public key. */

 Save the shared secret obtained by party A */

		/*

		 * Calculate party B's shared secret by using party A's

		 * public key.

	/*

	 * verify shared secret from which the user will derive

	 * secret key by executing whatever hash it has chosen

	/*

	 * First run test which do not require a private key, such as

	 * encrypt or verify.

		/* Swap args so we could keep plaintext (digest)

		 * in vecs->m, and cooked signature in vecs->c.

 signature */

 digest */

 Run asymmetric signature verification */

 Run asymmetric encrypt */

 verify that encrypted message is equal to expected */

	/*

	 * Don't invoke (decrypt or sign) test which require a private key

	 * for vectors with only a public key.

 Run asymmetric signature generation */

 Run asymmetric decrypt */

 verify that decrypted message is equal to the original msg */

 Please keep this list sorted by algorithm name. */

		/* Same as cbc(aes) except the key is stored in

		 * hardware secure memory which we reference by index

		/* Same as cbc(sm4) except the key is stored in

		 * hardware secure memory which we reference by index

		/* Same as ctr(aes) except the key is stored in

		 * hardware secure memory which we reference by index

		/* Same as ctr(sm4) except the key is stored in

		 * hardware secure memory which we reference by index

		/* Same as cts(cbc((aes)) except the key is stored in

		 * hardware secure memory which we reference by index

		/*

		 * There is no need to specifically test the DRBG with every

		 * backend cipher -- covered by drbg_nopr_hmac_sha256 test

 covered by drbg_nopr_hmac_sha256 test */

 covered by drbg_nopr_sha256 test */

 covered by drbg_pr_ctr_aes128 test */

 covered by drbg_pr_hmac_sha256 test */

 covered by drbg_pr_sha256 test */

		/* Same as ecb(aes) except the key is stored in

		 * hardware secure memory which we reference by index

		/* Same as ofb(aes) except the key is stored in

		 * hardware secure memory which we reference by index

		/* Same as xts(aes) except the key is stored in

		 * hardware secure memory which we reference by index

 CONFIG_CRYPTO_MANAGER_DISABLE_TESTS */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * algif_aead: User-space interface for AEAD algorithms

 *

 * Copyright (C) 2014, Stephan Mueller <smueller@chronox.de>

 *

 * This file provides the user-space API for AEAD ciphers.

 *

 * The following concept of the memory management is used:

 *

 * The kernel maintains two SGLs, the TX SGL and the RX SGL. The TX SGL is

 * filled by user space with the data submitted via sendpage/sendmsg. Filling

 * up the TX SGL does not cause a crypto operation -- the data will only be

 * tracked by the kernel. Upon receipt of one recvmsg call, the caller must

 * provide a buffer which is tracked with the RX SGL.

 *

 * During the processing of the recvmsg operation, the cipher request is

 * allocated and prepared. As part of the recvmsg operation, the processed

 * TX buffers are extracted from the TX SGL into a separate SGL.

 *

 * After the completion of the crypto operation, the RX SGL and the cipher

 * request is released. The extracted TX SGL parts are released together with

 * the RX SGL release.

	/*

	 * The minimum amount of memory needed for an AEAD cipher is

	 * the AAD and in case of decryption the tag.

 [in]  TX bufs to be en/decrypted */

 [out] RX bufs produced by kernel */

 [in]  RX bufs to be used from user */

 [in]  TX bufs to be consumed */

	/*

	 * Data length provided by caller via sendmsg/sendpage that has not

	 * yet been processed.

	/*

	 * Make sure sufficient data is present -- note, the same check is

	 * also present in sendmsg/sendpage. The checks in sendpage/sendmsg

	 * shall provide an information to the data sender that something is

	 * wrong, but they are irrelevant to maintain the kernel integrity.

	 * We need this check here too in case user space decides to not honor

	 * the error message in sendmsg/sendpage and still call recvmsg. This

	 * check here protects the kernel integrity.

	/*

	 * Calculate the minimum output buffer size holding the result of the

	 * cipher operation. When encrypting data, the receiving buffer is

	 * larger by the tag length compared to the input buffer as the

	 * encryption operation generates the tag. For decryption, the input

	 * buffer provides the tag which is consumed resulting in only the

	 * plaintext without a buffer for the tag returned to the caller.

	/*

	 * The cipher operation input data is reduced by the associated data

	 * length as this data is processed separately later on.

 Allocate cipher request for current operation. */

 convert iovecs of output buffers into RX SGL */

	/*

	 * Ensure output buffer is sufficiently large. If the caller provides

	 * less buffer space, only use the relative required input size. This

	 * allows AIO operation where the caller sent all data to be processed

	 * and the AIO operation performs the operation on the different chunks

	 * of the input data.

	/*

	 * Copy of AAD from source to destination

	 *

	 * The AAD is copied to the destination buffer without change. Even

	 * when user space uses an in-place cipher operation, the kernel

	 * will copy the data as it does not see whether such in-place operation

	 * is initiated.

	 *

	 * To ensure efficiency, the following implementation ensure that the

	 * ciphers are invoked to perform a crypto operation in-place. This

	 * is achieved by memory management specified as follows.

 Use the RX SGL as source (and destination) for crypto op. */

		/*

		 * Encryption operation - The in-place cipher operation is

		 * achieved by the following operation:

		 *

		 * TX SGL: AAD || PT

		 *	    |	   |

		 *	    | copy |

		 *	    v	   v

		 * RX SGL: AAD || PT || Tag

		/*

		 * Decryption operation - To achieve an in-place cipher

		 * operation, the following  SGL structure is used:

		 *

		 * TX SGL: AAD || CT || Tag

		 *	    |	   |	 ^

		 *	    | copy |	 | Create SGL link.

		 *	    v	   v	 |

		 * RX SGL: AAD || CT ----+

 Copy AAD || CT to RX SGL buffer for in-place operation. */

 Create TX SGL for tag and chain it to RX SGL. */

 Release TX SGL, except for tag data and reassign tag data. */

 chain the areq TX SGL holding the tag with RX SGL */

 RX SGL present */

 no RX SGL present (e.g. authentication only) */

 Initialize the crypto operation */

 AIO operation */

 Remember output size that will be generated. */

 AIO operation in progress */

 Synchronous operation */

		/*

		 * This error covers -EIOCBQUEUED which implies that we can

		 * only handle one AIO request. If the caller wants to have

		 * multiple AIO requests in parallel, he must make multiple

		 * separate AIO calls.

		 *

		 * Also return the error if no data has been processed so far.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * Common Blowfish algorithm parts shared between the c and assembler

 * implementations.

 *

 * Blowfish Cipher Algorithm, by Bruce Schneier.

 * http://www.counterpane.com/blowfish.html

 *

 * Adapted from Kerneli implementation.

 *

 * Copyright (c) Herbert Valerio Riedel <hvr@hvrlab.org>

 * Copyright (c) Kyle McMartin <kyle@debian.org>

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

/*

 * Round loop unrolling macros, S is a pointer to a S-Box array

 * organized in 4 unsigned longs at a row.

/*

 * The blowfish encipher, processes 64-bit blocks.

 * NOTE: This function MUSTN'T respect endianess

/*

 * Calculates the blowfish S and P boxes for encryption and decryption.

 Copy the initialization s-boxes */

 Set the p-boxes */

 Actual subkey generation */

 Bruce says not to bother with the weak key check. */

/* 

 * Cryptographic API.

 *

 * MD5 Message Digest Algorithm (RFC1321).

 *

 * Derived from cryptoapi implementation, originally based on the

 * public domain implementation written by Colin Plumb in 1993.

 *

 * Copyright (c) Cryptoapi developers.

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 * 

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the Free

 * Software Foundation; either version 2 of the License, or (at your option) 

 * any later version.

 *

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2016, Intel Corporation

 * Authors: Salvatore Benedetto <salvatore.benedetto@intel.com>

	/* Don't allocate memory. Set pointer to data

	 * within the given buffer

 SPDX-License-Identifier: (GPL-2.0-only OR Apache-2.0)

/*

 * Generic implementation of the BLAKE2b digest algorithm.  Based on the BLAKE2b

 * reference implementation, but it has been heavily modified for use in the

 * kernel.  The reference implementation was:

 *

 *	Copyright 2012, Samuel Neves <sneves@dei.uc.pt>.  You may use this under

 *	the terms of the CC0, the OpenSSL Licence, or the Apache Public License

 *	2.0, at your option.  The terms of these licenses can be found at:

 *

 *	- CC0 1.0 Universal : http://creativecommons.org/publicdomain/zero/1.0

 *	- OpenSSL license   : https://www.openssl.org/source/license.html

 *	- Apache 2.0        : https://www.apache.org/licenses/LICENSE-2.0

 *

 * More information about BLAKE2 can be found at https://blake2.net.

bugs.llvm.org/show_bug.cgi?id=45803 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2019 Linaro Ltd <ard.biesheuvel@linaro.org>

/*

 * Poly1305 authenticator algorithm, RFC7539

 *

 * Copyright (C) 2015 Martin Willi

 *

 * Based on public domain code by Andrew Moon and Daniel J. Bernstein.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; either version 2 of the License, or

 * (at your option) any later version.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Authenc: Simple AEAD wrapper for IPsec

 *

 * Copyright (c) 2007-2015 Herbert Xu <herbert@gondor.apana.org.au>

	/*

	 * RTA_OK() didn't align the rtattr's payload when validating that it

	 * fits in the buffer.  Yet, the keys should start on the next 4-byte

	 * aligned boundary.  To avoid confusion, require that the rtattr

	 * payload be exactly the param struct, which has a 4-byte aligned size.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Synchronous Cryptographic Hash operations.

 *

 * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>

/*

 * Check whether an shash algorithm has a setkey function.

 *

 * For CFI compatibility, this must not be an inline function.  This is because

 * when CFI is enabled, modules won't get the same address for shash_no_setkey

 * (if it were exported, which inlining would require) as the core kernel will.

	/*

	 * We cannot count on __aligned() working for large values:

	 * https://patchwork.kernel.org/patch/9507697/

	/*

	 * We cannot count on __aligned() working for large values:

	 * https://patchwork.kernel.org/patch/9507697/

 ->init_tfm() may have increased the descsize. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Kernel cryptographic api.

 * cast6.c - Cast6 cipher algorithm [rfc2612].

 *

 * CAST-256 (*cast6*) is a DES like Substitution-Permutation Network (SPN)

 * cryptosystem built upon the CAST-128 (*cast5*) [rfc2144] encryption

 * algorithm.

 *

 * Copyright (C) 2003 Kartikey Mahendra Bhatt <kartik_me@hotmail.com>.

 forward octave */

 padded key */

 A */

 B */

 C */

 D */

 E */

 F */

 G */

 H */

forward quad round*/

reverse quad round*/

/*

 * algif_rng: User-space interface for random number generators

 *

 * This file provides the user-space API for random number generators.

 *

 * Copyright (C) 2014, Stephan Mueller <smueller@chronox.de>

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, and the entire permission notice in its entirety,

 *    including the disclaimer of warranties.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. The name of the author may not be used to endorse or promote

 *    products derived from this software without specific prior

 *    written permission.

 *

 * ALTERNATIVELY, this product may be distributed under the terms of

 * the GNU General Public License, in which case the provisions of the GPL2

 * are required INSTEAD OF the above restrictions.  (This clause is

 * necessary due to a potential bad interaction between the GPL and

 * the restrictions contained in a BSD-style copyright.)

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES

 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, ALL OF

 * WHICH ARE HEREBY DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT

 * OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF

 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE

 * USE OF THIS SOFTWARE, EVEN IF NOT ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

	/*

	 * although not strictly needed, this is a precaution against coding

	 * errors

	/*

	 * The enforcement of a proper seeding of an RNG is done within an

	 * RNG implementation. Some RNGs (DRBG, krng) do not need specific

	 * seeding as they automatically seed. The X9.31 DRNG will return

	 * an error if it was not seeded properly.

	/*

	 * No seeding done at that point -- if multiple accepts are

	 * done on one RNG instance, each resulting FD points to the same

	 * state of the RNG.

	/*

	 * Non NULL pctx->entropy means that CAVP test has been initiated on

	 * this socket, replace proto_ops algif_rng_ops with algif_rng_test_ops.

	/*

	 * Check whether seedlen is of sufficient size is done in RNG

	 * implementations.

	/*

	 * Since rng doesn't perform any memory management for the entropy

	 * buffer, save kentropy pointer to pctx now to free it after use.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * authencesn.c - AEAD wrapper for IPsec with extended sequence numbers,

 *                 derived from authenc.c

 *

 * Copyright (C) 2010 secunet Security Networks AG

 * Copyright (C) 2010 Steffen Klassert <steffen.klassert@secunet.com>

 * Copyright (c) 2015 Herbert Xu <herbert@gondor.apana.org.au>

 Move high-order bits of sequence number back. */

 Move high-order bits of sequence number to the end. */

 Move high-order bits of sequence number back. */

 Move high-order bits of sequence number to the end. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Asynchronous Cryptographic Hash operations.

 *

 * This is the asynchronous version of hash.c with notification of

 * completion via a callback.

 *

 * Copyright (c) 2008 Loc Ho <lho@amcc.com>

	/*

	 * WARNING: Voodoo programming below!

	 *

	 * The code below is obscure and hard to understand, thus explanation

	 * is necessary. See include/crypto/hash.h and include/linux/crypto.h

	 * to understand the layout of structures used here!

	 *

	 * The code here will replace portions of the ORIGINAL request with

	 * pointers to new code and buffers so the hashing operation can store

	 * the result in aligned buffer. We will call the modified request

	 * an ADJUSTED request.

	 *

	 * The newly mangled request will look as such:

	 *

	 * req {

	 *   .result        = ADJUSTED[new aligned buffer]

	 *   .base.complete = ADJUSTED[pointer to completion function]

	 *   .base.data     = ADJUSTED[*req (pointer to self)]

	 *   .priv          = ADJUSTED[new priv] {

	 *           .result   = ORIGINAL(result)

	 *           .complete = ORIGINAL(base.complete)

	 *           .data     = ORIGINAL(base.data)

	 *   }

	/*

	 * WARNING: We do not backup req->priv here! The req->priv

	 *          is for internal use of the Crypto API and the

	 *          user must _NOT_ _EVER_ depend on it's content!

 Restore the original crypto request. */

 Free the req->priv.priv from the ADJUSTED request. */

	/*

	 * Restore the original request, see ahash_op_unaligned() for what

	 * goes where.

	 *

	 * The "struct ahash_request *req" here is in fact the "req.base"

	 * from the ADJUSTED request from ahash_op_unaligned(), thus as it

	 * is a pointer to self, it is also the ADJUSTED "req" .

 First copy req->result into req->priv.result */

 Complete the ORIGINAL request. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 size_t(ulong) <-> uint on 64 bit */

 size_t(ulong) <-> uint on 64 bit */

/*

 * Constant-time equality testing of memory regions.

 *

 * Authors:

 *

 *   James Yonan <james@openvpn.net>

 *   Daniel Borkmann <dborkman@redhat.com>

 *

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2013 OpenVPN Technologies, Inc. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2013 OpenVPN Technologies, Inc. All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of OpenVPN Technologies nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 Generic path for arbitrary size */

 CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS */

 Loop-free fast-path for frequently used 16-byte size */

 CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS */

/* Compare two areas of memory without leaking timing information,

 * and with special optimizations for common sizes.  Users should

 * not call this function directly, but should instead use

 * crypto_memneq defined in crypto/algapi.h.

 __HAVE_ARCH_CRYPTO_MEMNEQ */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * Blowfish Cipher Algorithm, by Bruce Schneier.

 * http://www.counterpane.com/blowfish.html

 *

 * Adapted from Kerneli implementation.

 *

 * Copyright (c) Herbert Valerio Riedel <hvr@hvrlab.org>

 * Copyright (c) Kyle McMartin <kyle@debian.org>

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

/*

 * Round loop unrolling macros, S is a pointer to a S-Box array

 * organized in 4 unsigned longs at a row.

 SPDX-License-Identifier: GPL-2.0-or-later

/*  Diffie-Hellman Key Agreement Method [RFC2631]

 *

 * Copyright (c) 2016, Intel Corporation

 * Authors: Salvatore Benedetto <salvatore.benedetto@intel.com>

 Value is guaranteed to be set. */

 Value is optional. */

 Value is guaranteed to be set. */

 Value is guaranteed to be set. */

/*

 * If base is g we compute the public key

 *	ya = g^xa mod p; [RFC2631 sec 2.1.1]

 * else if base if the counterpart public key we compute the shared secret

 *	ZZ = yb^xa mod p; [RFC2631 sec 2.1.1]

 val = base^xa mod p */

 Free the old MPI key if any */

/*

 * SP800-56A public key verification:

 *

 * * If Q is provided as part of the domain paramenters, a full validation

 *   according to SP800-56A section 5.6.2.3.1 is performed.

 *

 * * If Q is not provided, a partial validation according to SP800-56A section

 *   5.6.2.3.2 is performed.

	/*

	 * Step 1: Verify that 2 <= y <= p - 2.

	 *

	 * The upper limit check is actually y < p instead of y < p - 1

	 * as the mpi_sub_ui function is yet missing.

 Step 2: Verify that 1 = y^q mod p */

 SP800-56A rev3 5.7.1.1 check: Validation of shared secret */

 z <= 1 */

 z == p - 1 */

 SP800-56A rev 3 5.6.2.1.3 key check */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * Serpent Cipher Algorithm.

 *

 * Copyright (C) 2002 Dag Arne Osvik <osvik@ii.uib.no>

/* Key is padded to the maximum of 256 bits before round key generation.

 * Any key length <= 256 bits (32 bytes) is allowed by the algorithm.

/*

 * both gcc and clang have misoptimized this function in the past,

 * producing horrible object code from spilling temporary variables

 * on the stack. Forcing this part out of line avoids that.

 Copy key, add padding */

 Expand key using polynomial */

 Apply S-boxes */

 SPDX-License-Identifier: GPL-2.0-or-later

/* ECDH key-agreement protocol

 *

 * Copyright (c) 2016, Intel Corporation

 * Authors: Salvator Benedetto <salvatore.benedetto@intel.com>

 Public part is a point thus it has both coordinates */

 from here on it's invalid parameters */

 must have exactly two points to be on the curve */

 might want less than we've got */

 fall through */

 Public key is made of two coordinates, add one to the left shift */

 NIST p192 will fail to register in FIPS mode */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * geniv: Shared IV generator code

 *

 * This file provides common code to IV generators such as seqiv.

 *

 * Copyright (c) 2007-2019 Herbert Xu <herbert@gondor.apana.org.au>

 SPDX-License-Identifier: GPL-2.0-or-later */

/*

 * SM2 asymmetric public-key algorithm

 * as specified by OSCCA GM/T 0003.1-2012 -- 0003.5-2012 SM2 and

 * described at https://tools.ietf.org/html/draft-shen-sm2-ecdsa-02

 *

 * Copyright (c) 2020, Alibaba Group.

 * Authors: Tianjia Zhang <tianjia.zhang@linux.alibaba.com>

 Description of the curve.  */

 Number of bits.  */

 True if this is a FIPS140-2 approved curve */

	/* The model describing this curve.  This is mainly used to select

	 * the group equation.

	/* The actual ECC dialect used.  This is used for curve specific

	 * optimizations and to select encodings etc.

 The prime defining the field.  */

	const char *a, *b;          /* The coefficients.  For Twisted Edwards

				     * Curves b is used for d.  For Montgomery

				     * Curves (a,b) has ((A-2)/4,B^-1).

 The order of the base point.  */

 Base point.  */

 Cofactor.  */

 mpi_ec_setup_elliptic_curve */

/* RESULT must have been initialized and is set on success to the

 * point given by VALUE.

 No support for point compression */

 padding with zero */

 skip the starting zero */

 ZA = H256(ENTLA | IDA | a | b | xG | yG | xA | yA) */

 r, s in [1, n-1] */

 t = (r + s) % n, t == 0 */

 sG + tP = (x1, y1) */

 R = (e + x1) % n */

 check R == r */

 include the uncompressed flag '0x04' */

 Unlimited max size */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RSA padding templates.

 *

 * Copyright (c) 2015  Intel Corporation

/*

 * Hash algorithm OIDs plus ASN.1 DER wrappings [RFC4880 sec 5.2.2].

 OID */

 Find out new modulus size from rsa implementation */

 Find out new modulus size from rsa implementation */

	/*

	 * The maximum destination buffer size for the encrypt/sign operations

	 * will be the same as for RSA, even though it's smaller for

	 * decrypt/verify.

 Four billion to one */

 Reuse output buffer */

 Decrypted value had no leading 0 byte */

 Reuse input buffer, output to a new buffer */

 Reuse output buffer */

 Decrypted value had no leading 0 byte */

 Extract appended digest. */

 Do the actual verification step. */

/*

 * The verify operation is here for completeness similar to the verification

 * defined in RFC2313 section 10.2 except that block type 0 is not accepted,

 * as in RFC2437.  RFC2437 section 9.2 doesn't define any operation to

 * retrieve the DigestInfo from a signature, instead the user is expected

 * to call the sign operation to generate the expected signature and compare

 * signatures instead of the message-digests.

 Reuse input buffer, output to a new buffer */

/*

 * Cryptographic API.

 *

 * T10 Data Integrity Field CRC16 Crypto Transform

 *

 * Copyright (c) 2007 Oracle Corporation.  All rights reserved.

 * Written by Martin K. Petersen <martin.petersen@oracle.com>

 * Copyright (C) 2013 Intel Corporation

 * Author: Tim Chen <tim.c.chen@linux.intel.com>

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the Free

 * Software Foundation; either version 2 of the License, or (at your option)

 * any later version.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

/* Table generated using the following polynomium:

 * x^16 + x^15 + x^11 + x^9 + x^8 + x^7 + x^5 + x^4 + x^2 + x + 1

 * gt: 0x8bb7

 SPDX-License-Identifier: GPL-2.0-or-later

/* LRW: as defined by Cyril Guyot in

 *	http://grouper.ieee.org/groups/1619/email/pdf00017.pdf

 *

 * Copyright (c) 2006 Rik Snel <rsnel@cube.dyndns.org>

 *

 * Based on ecb.c

 * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>

/* This implementation is checked against the test vectors in the above

 * document and by a test vector provided by Ken Buchanan at

 * https://www.mail-archive.com/stds-p1619@listserv.ieee.org/msg00173.html

 *

	/*

	 * optimizes multiplying a random (non incrementing, as at the

	 * start of a new sector) value with key2, we could also have

	 * used 4k optimization tables or no optimization at all. In the

	 * latter case we would have to store key2 here

	/*

	 * stores:

	 *  key2*{ 0,0,...0,0,0,0,1 }, key2*{ 0,0,...0,0,0,1,1 },

	 *  key2*{ 0,0,...0,0,1,1,1 }, key2*{ 0,0,...0,1,1,1,1 }

	 *  key2*{ 0,0,...1,1,1,1,1 }, etc

	 * needed for optimized multiplication of incrementing values

	 * with key2

 initialize multiplication table for Key2 */

 initialize optimization table */

/*

 * Returns the number of trailing '1' bits in the words of the counter, which is

 * represented by 4 32-bit words, arranged from least to most significant.

 * At the same time, increments the counter by one.

 *

 * For example:

 *

 * u32 counter[4] = { 0xFFFFFFFF, 0x1, 0x0, 0x0 };

 * int i = lrw_next_index(&counter);

 * // i == 33, counter == { 0x0, 0x2, 0x0, 0x0 }

	/*

	 * If we get here, then x == 128 and we are incrementing the counter

	 * from all ones to all zeros. This means we must return index 127, i.e.

	 * the one corresponding to key2*{ 1,...,1 }.

/*

 * We compute the tweak masks twice (both before and after the ECB encryption or

 * decryption) to avoid having to allocate a temporary buffer and/or make

 * mutliple calls to the 'ecb(..)' instance, which usually would be slower than

 * just doing the lrw_next_index() calls again.

 set to our TFM to enforce correct alignment: */

			/* T <- I*Key2, using the optimization

 pass req->iv as IV (will be used by xor_tweak, ECB will ignore it) */

 calculate first value of T */

 T <- I*Key2 */

	/* Alas we screwed up the naming so we have to mangle the

	 * cipher name.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Software async crypto daemon.

 *

 * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>

 *

 * Added AEAD support to cryptd.

 *    Authors: Tadeusz Struk (tadeusz.struk@intel.com)

 *             Adrian Hoban <adrian.hoban@intel.com>

 *             Gabriele Paoloni <gabriele.paoloni@intel.com>

 *             Aidan O'Mahony (aidan.o.mahony@intel.com)

 *    Copyright (c) 2010, Intel Corporation.

/* Called in workqueue context, do one real cryption work (via

 * req->complete) and reschedule itself if there are more work to

	/*

	 * Only handle one request at a time to avoid hogging crypto workqueue.

	 * preempt_disable/enable is used to prevent being preempted by

	 * cryptd_enqueue_request(). local_bh_disable/enable is used to prevent

	 * cryptd_enqueue_request() being accessed from software interrupts.

	/*

	 * cryptd is allowed to wrap internal algorithms, but in that case the

	 * resulting cryptd instance will be marked as internal as well.

 No point in cryptd wrapping an algorithm that's already async. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* RSA asymmetric public-key algorithm [RFC3447]

 *

 * Copyright (c) 2015, Intel Corporation

 * Authors: Tadeusz Struk <tadeusz.struk@intel.com>

/*

 * RSAEP function [RFC3447 sec 5.1.1]

 * c = m^e mod n;

 (1) Validate 0 <= m < n */

 (2) c = m^e mod n */

/*

 * RSADP function [RFC3447 sec 5.1.2]

 * m = c^d mod n;

 (1) Validate 0 <= c < n */

 (2) m = c^d mod n */

 Free the old MPI key if any */

 Free the old MPI key if any */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RSA key extract helper

 *

 * Copyright (c) 2015, Intel Corporation

 * Authors: Tadeusz Struk <tadeusz.struk@intel.com>

 invalid key provided */

 In FIPS mode only allow key size 2K and higher */

 invalid key provided */

 invalid key provided */

 invalid key provided */

 invalid key provided */

 invalid key provided */

 invalid key provided */

 invalid key provided */

/**

 * rsa_parse_pub_key() - decodes the BER encoded buffer and stores in the

 *                       provided struct rsa_key, pointers to the raw key as is,

 *                       so that the caller can copy it or MPI parse it, etc.

 *

 * @rsa_key:	struct rsa_key key representation

 * @key:	key in BER format

 * @key_len:	length of key

 *

 * Return:	0 on success or error code in case of error

/**

 * rsa_parse_priv_key() - decodes the BER encoded buffer and stores in the

 *                        provided struct rsa_key, pointers to the raw key

 *                        as is, so that the caller can copy it or MPI parse it,

 *                        etc.

 *

 * @rsa_key:	struct rsa_key key representation

 * @key:	key in BER format

 * @key_len:	length of key

 *

 * Return:	0 on success or error code in case of error

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Crypto user configuration API.

 *

 * Copyright (C) 2011 secunet Security Networks AG

 * Copyright (C) 2011 Steffen Klassert <steffen.klassert@secunet.com>

	/* We can not unregister core algorithms such as aes-generic.

	 * We would loose the reference in the crypto_alg_list to this algorithm

	 * if we try to unregister. Unregistering such an algorithm without

	 * removing the module is not possible, so we restrict to crypto

 SPDX-License-Identifier: GPL-2.0

/*

 * Crypto user configuration API.

 *

 * Copyright (C) 2017-2018 Corentin Labbe <clabbe@baylibre.com>

 *

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2006

 * NTT (Nippon Telegraph and Telephone Corporation).

/*

 * Algorithm Specification

 *  https://info.isl.ntt.co.jp/crypt/eng/camellia/specifications.html

/*

 * NB: L and R below stand for 'left' and 'right' as in written numbers.

 * That is, in (xxxL,xxxR) pair xxxL holds most significant digits,

 * _not_ least significant ones!

 key constants */

/*

 *  macros

 absorb kw2 to other subkeys */

 round 2 */

 round 4 */

 round 6 */

 modified for FLinv(kl2) */

 round 8 */

 round 10 */

 round 12 */

 modified for FLinv(kl4) */

 round 14 */

 round 16 */

 round 18 */

 kw3 */

 absorb kw4 to other subkeys */

 modified for FLinv(kl6) */

 round 20 */

 round 22 */

 round 24 */

 kw3 */

 absorb kw4 to other subkeys */

 round 23 */

 round 21 */

 round 19 */

 modified for FL(kl5) */

 round 17 */

 round 15 */

 round 13 */

 modified for FL(kl3) */

 round 11 */

 round 9 */

 round 7 */

 modified for FL(kl1) */

 round 5 */

 round 3 */

 round 1 */

 kw1 */

 key XOR is end of F-function */

 kw1 */

 round 1 */

 round 2 */

 round 3 */

 round 4 */

 round 5 */

 FL(kl1) */

 round 6 */

 FL(kl1) */

 FLinv(kl2) */

 FLinv(kl2) */

 round 7 */

 round 8 */

 round 9 */

 round 10 */

 round 11 */

 FL(kl3) */

 round 12 */

 FL(kl3) */

 FLinv(kl4) */

 FLinv(kl4) */

 round 13 */

 round 14 */

 round 15 */

 round 16 */

 round 17 */

 round 18 */

 kw3 */

 FL(kl5) */

 round 18 */

 FL(kl5) */

 FLinv(kl6) */

 FLinv(kl6) */

 round 19 */

 round 20 */

 round 21 */

 round 22 */

 round 23 */

 round 24 */

 kw3 */

	/**

	 *  k == kll || klr || krl || krr (|| is concatenation)

 generate KL dependent subkeys */

 kw1 */

 kw2 */

 rotation left shift 15bit */

 k3 */

 k4 */

 rotation left shift 15+30bit */

 k7 */

 k8 */

 rotation left shift 15+30+15bit */

 k10 */

 rotation left shift 15+30+15+17 bit */

 kl3 */

 kl4 */

 rotation left shift 15+30+15+17+17 bit */

 k13 */

 k14 */

 rotation left shift 15+30+15+17+17+17 bit */

 k17 */

 k18 */

 generate KA */

 current status == (kll, klr, w0, w1) */

 generate KA dependent subkeys */

 k1, k2 */

 k5,k6 */

 kl1, kl2 */

 k9 */

 k11, k12 */

 k15, k16 */

 kw3, kw4 */

 left half of key */

 right half of key */

 temporary variables */

	/**

	 *  key = (kll || klr || krl || krr || krll || krlr || krrl || krrr)

	 *  (|| is concatenation)

 generate KL dependent subkeys */

 kw1 */

 kw2 */

 k9 */

 k10 */

 kl3 */

 kl4 */

 k17 */

 k18 */

 k23 */

 k24 */

 generate KR dependent subkeys */

 k3 */

 k4 */

 kl1 */

 kl2 */

 k13 */

 k14 */

 k19 */

 k20 */

 generate KA */

 generate KB */

 generate KA dependent subkeys */

 k5 */

 k6 */

 k11 */

 k12 */

 rotation left shift 32bit */

 kl5 */

 kl6 */

 rotation left shift 49 from k11,k12 -> k21,k22 */

 k21 */

 k22 */

 generate KB dependent subkeys */

 k1 */

 k2 */

 k7 */

 k8 */

 k15 */

 k16 */

 kw3 */

 kw4 */

/*

 * Encrypt/decrypt

 max = 24: 128bit encrypt, max = 32: 256bit encrypt */

 temporary variables */

 pre whitening but absorb kw2 */

 main iteration */

 post whitening but kw4 */

 NB: io[0],[1] should be swapped with [2],[3] by caller! */

 temporary variables */

 pre whitening but absorb kw2 */

 main iteration */

 post whitening but kw4 */

 NB: 0,1 should be swapped with 2,3 by caller! */

 for key lengths of 24 and 32 */

 do_encrypt returns 0,1 swapped with 2,3 */

 for key lengths of 24 and 32 */

 do_decrypt returns 0,1 swapped with 2,3 */

/*

 * DRBG: Deterministic Random Bits Generator

 *       Based on NIST Recommended DRBG from NIST SP800-90A with the following

 *       properties:

 *		* CTR DRBG with DF with AES-128, AES-192, AES-256 cores

 *		* Hash DRBG with DF with SHA-1, SHA-256, SHA-384, SHA-512 cores

 *		* HMAC DRBG with DF with SHA-1, SHA-256, SHA-384, SHA-512 cores

 *		* with and without prediction resistance

 *

 * Copyright Stephan Mueller <smueller@chronox.de>, 2014

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, and the entire permission notice in its entirety,

 *    including the disclaimer of warranties.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. The name of the author may not be used to endorse or promote

 *    products derived from this software without specific prior

 *    written permission.

 *

 * ALTERNATIVELY, this product may be distributed under the terms of

 * the GNU General Public License, in which case the provisions of the GPL are

 * required INSTEAD OF the above restrictions.  (This clause is

 * necessary due to a potential bad interaction between the GPL and

 * the restrictions contained in a BSD-style copyright.)

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES

 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, ALL OF

 * WHICH ARE HEREBY DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT

 * OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF

 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE

 * USE OF THIS SOFTWARE, EVEN IF NOT ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

 *

 * DRBG Usage

 * ==========

 * The SP 800-90A DRBG allows the user to specify a personalization string

 * for initialization as well as an additional information string for each

 * random number request. The following code fragments show how a caller

 * uses the kernel crypto API to use the full functionality of the DRBG.

 *

 * Usage without any additional data

 * ---------------------------------

 * struct crypto_rng *drng;

 * int err;

 * char data[DATALEN];

 *

 * drng = crypto_alloc_rng(drng_name, 0, 0);

 * err = crypto_rng_get_bytes(drng, &data, DATALEN);

 * crypto_free_rng(drng);

 *

 *

 * Usage with personalization string during initialization

 * -------------------------------------------------------

 * struct crypto_rng *drng;

 * int err;

 * char data[DATALEN];

 * struct drbg_string pers;

 * char personalization[11] = "some-string";

 *

 * drbg_string_fill(&pers, personalization, strlen(personalization));

 * drng = crypto_alloc_rng(drng_name, 0, 0);

 * // The reset completely re-initializes the DRBG with the provided

 * // personalization string

 * err = crypto_rng_reset(drng, &personalization, strlen(personalization));

 * err = crypto_rng_get_bytes(drng, &data, DATALEN);

 * crypto_free_rng(drng);

 *

 *

 * Usage with additional information string during random number request

 * ---------------------------------------------------------------------

 * struct crypto_rng *drng;

 * int err;

 * char data[DATALEN];

 * char addtl_string[11] = "some-string";

 * string drbg_string addtl;

 *

 * drbg_string_fill(&addtl, addtl_string, strlen(addtl_string));

 * drng = crypto_alloc_rng(drng_name, 0, 0);

 * // The following call is a wrapper to crypto_rng_get_bytes() and returns

 * // the same error codes.

 * err = crypto_drbg_get_bytes_addtl(drng, &data, DATALEN, &addtl);

 * crypto_free_rng(drng);

 *

 *

 * Usage with personalization and additional information strings

 * -------------------------------------------------------------

 * Just mix both scenarios above.

/***************************************************************

 * Backend cipher definitions available to DRBG

/*

 * The order of the DRBG definitions here matter: every DRBG is registered

 * as stdrng. Each DRBG receives an increasing cra_priority values the later

 * they are defined in this array (see drbg_fill_array).

 *

 * HMAC DRBGs are favored over Hash DRBGs over CTR DRBGs, and

 * the SHA256 / AES 256 over other ciphers. Thus, the favored

 * DRBGs are the latest entries in this array.

 256 bits as defined in 10.2.1 */

 320 bits as defined in 10.2.1 */

 384 bits as defined in 10.2.1 */

 CONFIG_CRYPTO_DRBG_CTR */

 440 bits */

 888 bits */

 888 bits */

 440 bits */

 CONFIG_CRYPTO_DRBG_HASH */

 block length of cipher */

 block length of cipher */

 block length of cipher */

 block length of cipher */

 CONFIG_CRYPTO_DRBG_HMAC */

/******************************************************************

 * Generic helper functions

/*

 * Return strength of DRBG according to SP800-90A section 8.4

 *

 * @flags DRBG flags reference

 *

 * Return: normalized strength in *bytes* value or 32 as default

 *	   to counter programming errors

/*

 * FIPS 140-2 continuous self test for the noise source

 * The test is performed on the noise source input data. Thus, the function

 * implicitly knows the size of the buffer to be equal to the security

 * strength.

 *

 * Note, this function disregards the nonce trailing the entropy data during

 * initial seeding.

 *

 * drbg->drbg_mutex must have been taken.

 *

 * @drbg DRBG handle

 * @entropy buffer of seed data to be checked

 *

 * return:

 *	0 on success

 *	-EAGAIN on when the CTRNG is not yet primed

 *	< 0 on error

 skip test if we test the overall system */

 only perform test in FIPS mode */

 Priming of FIPS test */

 priming: another round is needed */

 the test shall pass when the two values are not equal */

/*

 * Convert an integer into a byte representation of this integer.

 * The byte representation is big-endian

 *

 * @val value to be converted

 * @buf buffer holding the converted integer -- caller must ensure that

 *      buffer size is at least 32 bit

 defined(CONFIG_CRYPTO_DRBG_HASH) || defined(CONFIG_CRYPTO_DRBG_CTR) */

/******************************************************************

 * CTR DRBG callback functions

 BCC function for CTR DRBG as defined in 10.4.3 */

 10.4.3 step 2 / 4 */

 10.4.3 step 4.1 */

 10.4.3 step 4.2 */

 10.4.3 step 4.2 for last block */

/*

 * scratchpad usage: drbg_ctr_update is interlinked with drbg_ctr_df

 * (and drbg_ctr_bcc, but this function does not need any temporary buffers),

 * the scratchpad is used as follows:

 * drbg_ctr_update:

 *	temp

 *		start: drbg->scratchpad

 *		length: drbg_statelen(drbg) + drbg_blocklen(drbg)

 *			note: the cipher writing into this variable works

 *			blocklen-wise. Now, when the statelen is not a multiple

 *			of blocklen, the generateion loop below "spills over"

 *			by at most blocklen. Thus, we need to give sufficient

 *			memory.

 *	df_data

 *		start: drbg->scratchpad +

 *				drbg_statelen(drbg) + drbg_blocklen(drbg)

 *		length: drbg_statelen(drbg)

 *

 * drbg_ctr_df:

 *	pad

 *		start: df_data + drbg_statelen(drbg)

 *		length: drbg_blocklen(drbg)

 *	iv

 *		start: pad + drbg_blocklen(drbg)

 *		length: drbg_blocklen(drbg)

 *	temp

 *		start: iv + drbg_blocklen(drbg)

 *		length: drbg_satelen(drbg) + drbg_blocklen(drbg)

 *			note: temp is the buffer that the BCC function operates

 *			on. BCC operates blockwise. drbg_statelen(drbg)

 *			is sufficient when the DRBG state length is a multiple

 *			of the block size. For AES192 (and maybe other ciphers)

 *			this is not correct and the length for temp is

 *			insufficient (yes, that also means for such ciphers,

 *			the final output of all BCC rounds are truncated).

 *			Therefore, add drbg_blocklen(drbg) to cover all

 *			possibilities.

 Derivation Function for CTR DRBG as defined in 10.4.2 */

 S3 is input */

 10.4.2 step 7 */

 10.4.2 step 8 */

 10.4.2 step 1 is implicit as we work byte-wise */

 10.4.2 step 2 */

 10.4.2 step 2 -- calculate the entire length of all input data */

 10.4.2 step 3 */

 10.4.2 step 5: length is L_N, input_string, one byte, padding */

 wrap the padlen appropriately */

	/*

	 * pad / padlen contains the 0x80 byte and the following zero bytes.

	 * As the calculated padlen value only covers the number of zero

	 * bytes, this value has to be incremented by one for the 0x80 byte.

 10.4.2 step 4 -- first fill the linked list and then order it */

 10.4.2 step 9 */

		/*

		 * 10.4.2 step 9.1 - the padding is implicit as the buffer

		 * holds zeros after allocation -- even the increment of i

		 * is irrelevant as the increment remains within length of i

 10.4.2 step 9.2 -- BCC and concatenation with temp */

 10.4.2 step 9.3 */

 10.4.2 step 11 */

 10.4.2 step 12: overwriting of outval is implemented in next step */

 10.4.2 step 13 */

		/*

		 * 10.4.2 step 13.1: the truncation of the key length is

		 * implicit as the key is only drbg_blocklen in size based on

		 * the implementation of the cipher function callback

 10.4.2 step 13.2 and 14 */

/*

 * update function of CTR DRBG as defined in 10.2.1.2

 *

 * The reseed variable has an enhanced meaning compared to the update

 * functions of the other DRBGs as follows:

 * 0 => initial seed from initialization

 * 1 => reseed via drbg_seed

 * 2 => first invocation from drbg_ctr_update when addtl is present. In

 *      this case, the df_data scratchpad is not deleted so that it is

 *      available for another calls to prevent calling the DF function

 *      again.

 * 3 => second invocation from drbg_ctr_update. When the update function

 *      was called with addtl, the df_data memory already contains the

 *      DFed addtl information and we do not need to call DF again.

 10.2.1.2 step 1 */

		/*

		 * The DRBG uses the CTR mode of the underlying AES cipher. The

		 * CTR mode increments the counter value after the AES operation

		 * but SP800-90A requires that the counter is incremented before

		 * the AES operation. Hence, we increment it at the time we set

		 * it by one.

 10.2.1.3.2 step 2 and 10.2.1.4.2 step 2 */

 10.2.1.2 step 5 */

 10.2.1.2 step 6 */

 See above: increment counter by one to compensate timing of CTR op */

/*

 * scratchpad use: drbg_ctr_update is called independently from

 * drbg_ctr_extract_bytes. Therefore, the scratchpad is reused

 Generate function of CTR DRBG as defined in 10.2.1.5.2 */

 10.2.1.5.2 step 2 */

 10.2.1.5.2 step 4.1 */

 10.2.1.5.2 step 6 */

 CONFIG_CRYPTO_DRBG_CTR */

/******************************************************************

 * HMAC DRBG callback functions

 (CONFIG_CRYPTO_DRBG_HASH || CONFIG_CRYPTO_DRBG_HMAC) */

 update function of HMAC DRBG as defined in 10.1.2.2 */

 10.1.2.3 step 2 -- memset(0) of C is implicit with kzalloc */

 buffer of seed2 will be filled in for loop below with one byte */

 input data of seed is allowed to be NULL at this point */

 first round uses 0x0, second 0x1 */

 10.1.2.2 step 1 and 4 -- concatenation and HMAC for key */

 10.1.2.2 step 2 and 5 -- HMAC for V */

 10.1.2.2 step 3 */

 generate function of HMAC DRBG as defined in 10.1.2.5 */

 10.1.2.5 step 2 */

 10.1.2.5 step 4.1 */

 10.1.2.5 step 4.2 */

 10.1.2.5 step 6 */

 CONFIG_CRYPTO_DRBG_HMAC */

/******************************************************************

 * Hash DRBG callback functions

/*

 * Increment buffer

 *

 * @dst buffer to increment

 * @add value to add

 implied: dstlen > addlen */

/*

 * scratchpad usage: as drbg_hash_update and drbg_hash_df are used

 * interlinked, the scratchpad is used as follows:

 * drbg_hash_update

 *	start: drbg->scratchpad

 *	length: drbg_statelen(drbg)

 * drbg_hash_df:

 *	start: drbg->scratchpad + drbg_statelen(drbg)

 *	length: drbg_blocklen(drbg)

 *

 * drbg_hash_process_addtl uses the scratchpad, but fully completes

 * before either of the functions mentioned before are invoked. Therefore,

 * drbg_hash_process_addtl does not need to be specifically considered.

 Derivation Function for Hash DRBG as defined in 10.4.1 */

 10.4.1 step 3 */

 10.4.1 step 4.1 -- concatenation of data for input into hash */

 10.4.1 step 4 */

 10.4.1 step 4.1 */

 10.4.1 step 4.2 */

 update function for Hash DRBG as defined in 10.1.1.2 / 10.1.1.3 */

 10.1.1.3 step 1 */

 10.1.1.2 / 10.1.1.3 step 2 and 3 */

 10.1.1.2 / 10.1.1.3 step 4  */

 10.1.1.2 / 10.1.1.3 step 4 */

 processing of additional information string for Hash DRBG */

 10.1.1.4 step 2 */

 10.1.1.4 step 2a */

 10.1.1.4 step 2b */

 Hashgen defined in 10.1.1.4 */

 10.1.1.4 step hashgen 2 */

 10.1.1.4 step hashgen 4.1 */

 10.1.1.4 step hashgen 4.2 */

 10.1.1.4 hashgen step 4.3 */

 generate function for Hash DRBG as defined in  10.1.1.4 */

 10.1.1.4 step 2 */

 10.1.1.4 step 3 */

 this is the value H as documented in 10.1.1.4 */

 10.1.1.4 step 4 */

 10.1.1.4 step 5 */

/*

 * scratchpad usage: as update and generate are used isolated, both

 * can use the scratchpad

 CONFIG_CRYPTO_DRBG_HASH */

/******************************************************************

 * Functions common for DRBG implementations

 10.1.1.2 / 10.1.1.3 step 5 */

	/* Set seeded to false so that if __drbg_seed fails the

	 * next generate call will trigger a reseed.

/*

 * Seeding or reseeding of the DRBG

 *

 * @drbg: DRBG state struct

 * @pers: personalization / additional information buffer

 * @reseed: 0 for initial seed process, 1 for reseeding

 *

 * return:

 *	0 on success

 *	error value otherwise

 9.1 / 9.2 / 9.3.1 step 3 */

		/*

		 * Gather entropy equal to the security strength of the DRBG.

		 * With a derivation function, a nonce is required in addition

		 * to the entropy. A nonce must be at least 1/2 of the security

		 * strength of the DRBG in size. Thus, entropy + nonce is 3/2

		 * of the strength. The consideration of a nonce is only

		 * applicable during initial seeding.

 Get seed from in-kernel /dev/urandom */

 Get seed from Jitter RNG */

				/*

				 * Do not treat the transient failure of the

				 * Jitter RNG as an error that needs to be

				 * reported. The combined number of the

				 * maximum reseed threshold times the maximum

				 * number of Jitter RNG transient errors is

				 * less than the reseed threshold required by

				 * SP800-90A allowing us to treat the

				 * transient errors as such.

				 *

				 * However, we mandate that at least the first

				 * seeding operation must succeed with the

				 * Jitter RNG.

	/*

	 * concatenation of entropy with personalization str / addtl input)

	 * the variable pers is directly handed in by the caller, so check its

	 * contents whether it is appropriate

 Free all substructures in a DRBG state without the DRBG state structure */

/*

 * Allocate all sub-structures for a DRBG state.

 * The DRBG state structure must already be allocated.

 CONFIG_CRYPTO_DRBG_HMAC */

 CONFIG_CRYPTO_DRBG_HASH */

 CONFIG_CRYPTO_DRBG_CTR */

 scratchpad is only generated for CTR and Hash */

 temp */

 df_data */

 pad */

 iv */

 temp */

/*************************************************************************

 * DRBG interface functions

/*

 * DRBG generate function as required by SP800-90A - this function

 * generates random numbers

 *

 * @drbg DRBG state handle

 * @buf Buffer where to store the random numbers -- the buffer must already

 *      be pre-allocated by caller

 * @buflen Length of output buffer - this value defines the number of random

 *	   bytes pulled from DRBG

 * @addtl Additional input that is mixed into state, may be NULL -- note

 *	  the entropy is pulled by the DRBG internally unconditionally

 *	  as defined in SP800-90A. The additional input is mixed into

 *	  the state in addition to the pulled entropy.

 *

 * return: 0 when all bytes are generated; < 0 in case of an error

 9.3.1 step 2 */

 9.3.1 step 3 is implicit with the chosen DRBG */

 9.3.1 step 4 */

 9.3.1 step 5 is implicit with the chosen DRBG */

	/*

	 * 9.3.1 step 6 and 9 supplemented by 9.3.2 step c is implemented

	 * here. The spec is a bit convoluted here, we make it simpler.

 9.3.1 steps 7.1 through 7.3 */

 9.3.1 step 7.4 */

 9.3.1 step 8 and 10 */

 10.1.1.4 step 6, 10.1.2.5 step 7, 10.2.1.5.2 step 7 */

	/*

	 * Section 11.3.3 requires to re-perform self tests after some

	 * generated random numbers. The chosen value after which self

	 * test is performed is arbitrary, but it should be reasonable.

	 * However, we do not perform the self tests because of the following

	 * reasons: it is mathematically impossible that the initial self tests

	 * were successfully and the following are not. If the initial would

	 * pass and the following would not, the kernel integrity is violated.

	 * In this case, the entire kernel operation is questionable and it

	 * is unlikely that the integrity violation only affects the

	 * correct operation of the DRBG.

	 *

	 * Albeit the following code is commented out, it is provided in

	 * case somebody has a need to implement the test of 11.3.3.

			/*

			 * uninstantiate implies that from now on, only errors

			 * are returned when reusing this DRBG cipher handle

	/*

	 * All operations were successful, return 0 as mandated by

	 * the kernel crypto API interface.

/*

 * Wrapper around drbg_generate which can pull arbitrary long strings

 * from the DRBG without hitting the maximum request limitation.

 *

 * Parameters: see drbg_generate

 * Return codes: see drbg_generate -- if one drbg_generate request fails,

 *		 the entire drbg_generate_long request fails

 We do not need an HRNG in test mode. */

	/*

	 * Require frequent reseeds until the seed source is fully

	 * initialized.

/*

 * DRBG instantiation function as required by SP800-90A - this function

 * sets up the DRBG handle, performs the initial seeding and all sanity

 * checks required by SP800-90A

 *

 * @drbg memory of state -- if NULL, new memory is allocated

 * @pers Personalization string that is mixed into state, may be NULL -- note

 *	 the entropy is pulled by the DRBG internally unconditionally

 *	 as defined in SP800-90A. The additional input is mixed into

 *	 the state in addition to the pulled entropy.

 * @coreref reference to core

 * @pr prediction resistance enabled

 *

 * return

 *	0 on success

 *	error value otherwise

 9.1 step 1 is implicit with the selected DRBG type */

	/*

	 * 9.1 step 2 is implicit as caller can select prediction resistance

	 * and the flag is copied into drbg->flags --

	 * all DRBG types support prediction resistance

 9.1 step 4 is implicit in  drbg_sec_strength */

/*

 * DRBG uninstantiate function as required by SP800-90A - this function

 * frees all buffers and the DRBG handle

 *

 * @drbg DRBG state handle

 *

 * return

 *	0 on success

 no scrubbing of test_data -- this shall survive an uninstantiate */

/*

 * Helper function for setting the test data in the DRBG

 *

 * @drbg DRBG state handle

 * @data test data

 * @len test data length

/***************************************************************

 * Kernel crypto API cipher invocations requested by DRBG

 (CONFIG_CRYPTO_DRBG_HASH || CONFIG_CRYPTO_DRBG_HMAC) */

 there is only component in *in */

 Use caller-provided input buffer */

 Use scratchpad for in-place operation */

 Output buffer may not be valid for SGL, use scratchpad */

 CONFIG_CRYPTO_DRBG_CTR */

/***************************************************************

 * Kernel crypto API interface to register DRBG

/*

 * Look up the DRBG flags by given kernel crypto API cra_name

 * The code uses the drbg_cores definition to do this

 *

 * @cra_name kernel crypto API cra_name

 * @coreref reference to integer which is filled with the pointer to

 *  the applicable core

 * @pr reference for setting prediction resistance

 *

 * return: flags

 disassemble the names */

 remove the first part */

/*

 * Generate random numbers invoked by the kernel crypto API:

 * The API of the kernel crypto API is extended as follows:

 *

 * src is additional input supplied to the RNG.

 * slen is the length of src.

 * dst is the output buffer where random data is to be stored.

 * dlen is the length of dst.

 linked list variable is now local to allow modification */

/*

 * Seed the DRBG invoked by the kernel crypto API

/***************************************************************

 * Kernel module: code to load the module

/*

 * Tests as defined in 11.3.2 in addition to the cipher tests: testing

 * of the error handling.

 *

 * Note: testing of failing seed source as defined in 11.3.2 is not applicable

 * as seed source of get_random_bytes does not fail.

 *

 * Note 2: There is no sensible way of testing the reseed counter

 * enforcement, so skip it.

 only perform test in FIPS mode */

	/*

	 * if the following tests fail, it is likely that there is a buffer

	 * overflow as buf is much smaller than the requested or provided

	 * string lengths -- in case the error handling does not succeed

	 * we may get an OOPS. And we want to get an OOPS as this is a

	 * grave bug.

 overflow addtllen with additonal info string */

 overflow max_bits */

 overflow max addtllen with personalization string */

 all tests passed */

/*

 * Fill the array drbg_algs used to register the different DRBGs

 * with the kernel crypto API. To fill the array, the information

 * from drbg_cores[] is used.

	/*

	 * If FIPS mode enabled, the selected DRBG shall have the

	 * highest cra_priority over other stdrng instances to ensure

	 * it is selected.

 pointer to drbg_algs */

 pointer to drbg_cores */

	/*

	 * each DRBG definition can be used with PR and without PR, thus

	 * we instantiate each DRBG in drbg_cores[] twice.

	 *

	 * As the order of placing them into the drbg_algs array matters

	 * (the later DRBGs receive a higher cra_priority) we register the

	 * prediction resistance DRBGs first as the should not be too

	 * interesting.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API for the 842 software compression algorithm.

 *

 * Copyright (C) IBM Corporation, 2011-2015

 *

 * Original Authors: Robert Jennings <rcj@linux.vnet.ibm.com>

 *                   Seth Jennings <sjenning@linux.vnet.ibm.com>

 *

 * Rewrite: Dan Streetman <ddstreet@ieee.org>

 *

 * This is the software implementation of compression and decompression using

 * the 842 format.  This uses the software 842 library at lib/842/ which is

 * only a reference implementation, and is very, very slow as compared to other

 * software compressors.  You probably do not want to use this software

 * compression.  If you have access to the PowerPC 842 compression hardware, you

 * want to use the 842 hardware compression interface, which is at:

 * drivers/crypto/nx/nx-842-crypto.c

 working memory for compress */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Asynchronous Compression operations

 *

 * Copyright (c) 2016, Intel Corporation

 * Authors: Weigang Li <weigang.li@intel.com>

 *          Giovanni Cabiddu <giovanni.cabiddu@intel.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * algif_skcipher: User-space interface for skcipher algorithms

 *

 * This file provides the user-space API for symmetric key ciphers.

 *

 * Copyright (c) 2010 Herbert Xu <herbert@gondor.apana.org.au>

 *

 * The following concept of the memory management is used:

 *

 * The kernel maintains two SGLs, the TX SGL and the RX SGL. The TX SGL is

 * filled by user space with the data submitted via sendpage/sendmsg. Filling

 * up the TX SGL does not cause a crypto operation -- the data will only be

 * tracked by the kernel. Upon receipt of one recvmsg call, the caller must

 * provide a buffer which is tracked with the RX SGL.

 *

 * During the processing of the recvmsg operation, the cipher request is

 * allocated and prepared. As part of the recvmsg operation, the processed

 * TX buffers are extracted from the TX SGL into a separate SGL.

 *

 * After the completion of the crypto operation, the RX SGL and the cipher

 * request is released. The extracted TX SGL parts are released together with

 * the RX SGL release.

 Allocate cipher request for current operation. */

 convert iovecs of output buffers into RX SGL */

	/*

	 * If more buffers are to be expected to be processed, process only

	 * full block size buffers.

	/*

	 * Create a per request TX SGL for this request which tracks the

	 * SG entries from the global TX SGL.

 Initialize the crypto operation */

 AIO operation */

 Remember output size that will be generated. */

 AIO operation in progress */

 Synchronous operation */

		/*

		 * This error covers -EIOCBQUEUED which implies that we can

		 * only handle one AIO request. If the caller wants to have

		 * multiple AIO requests in parallel, he must make multiple

		 * separate AIO calls.

		 *

		 * Also return the error if no data has been processed so far.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * GHASH: hash function for GCM (Galois/Counter Mode).

 *

 * Copyright (c) 2007 Nokia Siemens Networks - Mikko Herranen <mh1@iki.fi>

 * Copyright (c) 2009 Intel Corp.

 *   Author: Huang Ying <ying.huang@intel.com>

/*

 * GHASH is a keyed hash function used in GCM authentication tag generation.

 *

 * The original GCM paper [1] presents GHASH as a function GHASH(H, A, C) which

 * takes a 16-byte hash key H, additional authenticated data A, and a ciphertext

 * C.  It formats A and C into a single byte string X, interprets X as a

 * polynomial over GF(2^128), and evaluates this polynomial at the point H.

 *

 * However, the NIST standard for GCM [2] presents GHASH as GHASH(H, X) where X

 * is the already-formatted byte string containing both A and C.

 *

 * "ghash" in the Linux crypto API uses the 'X' (pre-formatted) convention,

 * since the API supports only a single data stream per hash.  Thus, the

 * formatting of 'A' and 'C' is done in the "gcm" template, not in "ghash".

 *

 * The reason "ghash" is separate from "gcm" is to allow "gcm" to use an

 * accelerated "ghash" when a standalone accelerated "gcm(aes)" is unavailable.

 * It is generally inappropriate to use "ghash" for other purposes, since it is

 * an "-almost-XOR-universal hash function", not a cryptographic hash function.

 * It can only be used securely in crypto modes specially designed to use it.

 *

 * [1] The Galois/Counter Mode of Operation (GCM)

 *     (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.694.695&rep=rep1&type=pdf)

 * [2] Recommendation for Block Cipher Modes of Operation: Galois/Counter Mode (GCM) and GMAC

 *     (https://csrc.nist.gov/publications/detail/sp/800-38d/final)

 avoid violating alignment rules */

 SPDX-License-Identifier: GPL-2.0

/*

 * OFB: Output FeedBack mode

 *

 * Copyright (C) 2018 ARM Limited or its affiliates.

 * All rights reserved.

 OFB mode is a stream cipher. */

	/*

	 * To simplify the implementation, configure the skcipher walk to only

	 * give a partial block at the very end, never earlier.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 size_t(ulong) <-> uint on 64 bit */

 size_t(ulong) <-> uint on 64 bit */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * HMAC: Keyed-Hashing for Message Authentication (RFC2104).

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>

 *

 * The HMAC implementation is derived from USAGI.

 * Copyright (c) 2002 Kazunori Miyazawa <miyazawa@linux-ipv6.org> / USAGI

 The underlying hash algorithm must not require a key */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Quick & dirty crypto testing module.

 *

 * This will only exist until we have a better testing mechanism

 * (e.g. a char device).

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 * Copyright (c) 2002 Jean-Francois Dive <jef@linuxbe.org>

 * Copyright (c) 2007 Nokia Siemens Networks

 *

 * Updated RFC4106 AES-GCM testing.

 *    Authors: Aidan O'Mahony (aidan.o.mahony@intel.com)

 *             Adrian Hoban <adrian.hoban@intel.com>

 *             Gabriele Paoloni <gabriele.paoloni@intel.com>

 *             Tadeusz Struk (tadeusz.struk@intel.com)

 *             Copyright (c) 2010, Intel Corporation.

/*

 * Need slab memory for testing (size in number of pages).

/*

* Used by test_cipher_speed()

/*

 * return a string with the driver name

/*

 * Used by test_cipher_speed()

 Fire up a bunch of concurrent requests */

 Wait for all requests to finish */

 Warm-up run. */

 The real thing. */

 Set up tfm global state, i.e. the key */

 Now setup per request stuff, i.e. buffers */

 Warm-up run. */

 The real thing. */

				/*

				 * For decryption we need a proper auth so

				 * we do the encryption path once with buffers

				 * reversed (input <-> output) to calculate it

 Fire up a bunch of concurrent requests */

 Wait for all requests to finish */

 Warm-up run. */

 The real thing. */

 For some reason this only tests digests. */

 we assume there is enough space in 'out' for the result */

 Warm-up run. */

 The real thing. */

 Warm-up run. */

 The real thing. */

 Fire up a bunch of concurrent requests */

 Wait for all requests to finish */

 Warm-up run. */

 The real thing. */

 Set up tfm global state, i.e. the key */

 Now setup per request stuff, i.e. buffers */

 Warm-up run. */

 The real thing. */

 set key, plain text and IV */

 non-fips algs return -EINVAL in fips mode */

	/* We intentionaly return -EAGAIN to prevent keeping the module,

	 * unless we're running in fips mode. It does all its work from

	 * init() and doesn't offer any runtime functionality, but in

	 * the fips case, checking for a successful load is helpful.

	 * => we don't need it in the memory, do we?

	 *                                        -- mludvig

/*

 * If an init function is provided, an exit function must also be provided

 * to allow module unload.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API

 *

 * Michael MIC (IEEE 802.11i/TKIP) keyed digest

 *

 * Copyright (c) 2004 Jouni Malinen <j@w1.fi>

 Last block and padding (0x5a, 4..7 x 0) */

 l ^= 0; */

/*

 * Non-physical true random number generator based on timing jitter --

 * Linux Kernel Crypto API specific code

 *

 * Copyright Stephan Mueller <smueller@chronox.de>, 2015

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, and the entire permission notice in its entirety,

 *    including the disclaimer of warranties.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. The name of the author may not be used to endorse or promote

 *    products derived from this software without specific prior

 *    written permission.

 *

 * ALTERNATIVELY, this product may be distributed under the terms of

 * the GNU General Public License, in which case the provisions of the GPL2 are

 * required INSTEAD OF the above restrictions.  (This clause is

 * necessary due to a potential bad interaction between the GPL and

 * the restrictions contained in a BSD-style copyright.)

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES

 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, ALL OF

 * WHICH ARE HEREBY DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT

 * OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF

 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE

 * USE OF THIS SOFTWARE, EVEN IF NOT ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

/***************************************************************************

 * Helper function

/*

 * Obtain a high-resolution time stamp value. The time stamp is used to measure

 * the execution time of a given code path and its variations. Hence, the time

 * stamp must have a sufficiently high resolution.

 *

 * Note, if the function returns zero because a given architecture does not

 * implement a high-resolution time stamp, the RNG code's runtime test

 * will detect it and will not produce output.

	/*

	 * If random_get_entropy does not return a value, i.e. it is not

	 * implemented for a given architecture, use a clock source.

	 * hoping that there are timers we can work with.

/***************************************************************************

 * Kernel crypto API interface

 Return a permanent error in case we had too many resets in a row. */

 Reset RNG in case of health failures */

 Convert the Jitter RNG error into a usable error code */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SHA-512 code by Jean-Luc Cooke <jlcooke@certainkey.com>

 *

 * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>

 * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>

 * Copyright (c) 2003 Kyle McMartin <kyle@debian.org>

 load the state into our registers */

 now iterate */

 load the input */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Shared crypto simd helpers

 *

 * Copyright (c) 2012 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>

 * Copyright (c) 2016 Herbert Xu <herbert@gondor.apana.org.au>

 * Copyright (c) 2019 Google LLC

 *

 * Based on aesni-intel_glue.c by:

 *  Copyright (C) 2008, Intel Corp.

 *    Author: Huang Ying <ying.huang@intel.com>

/*

 * Shared crypto SIMD helpers.  These functions dynamically create and register

 * an skcipher or AEAD algorithm that wraps another, internal algorithm.  The

 * wrapper ensures that the internal algorithm is only executed in a context

 * where SIMD instructions are usable, i.e. where may_use_simd() returns true.

 * If SIMD is already usable, the wrapper directly calls the internal algorithm.

 * Otherwise it defers execution to a workqueue via cryptd.

 *

 * This is an alternative to the internal algorithm implementing a fallback for

 * the !may_use_simd() case itself.

 *

 * Note that the wrapper algorithm is asynchronous, i.e. it has the

 * CRYPTO_ALG_ASYNC flag set.  Therefore it won't be found by users who

 * explicitly allocate a synchronous algorithm.

 skcipher support */

 AEAD support */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * CMAC: Cipher Block Mode for Authentication

 *

 * Copyright  2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>

 *

 * Based on work by:

 *  Copyright  2013 Tom St Denis <tstdenis@elliptictech.com>

 * Based on crypto/xcbc.c:

 *  Copyright  2006 USAGI/WIDE Project,

 *   Author: Kazunori Miyazawa <miyazawa@linux-ipv6.org>

/*

 * +------------------------

 * | <parent tfm>

 * +------------------------

 * | cmac_tfm_ctx

 * +------------------------

 * | consts (block size * 2)

 * +------------------------

/*

 * +------------------------

 * | <shash desc>

 * +------------------------

 * | cmac_desc_ctx

 * +------------------------

 * | odds (block size)

 * +------------------------

 * | prev (block size)

 * +------------------------

 encrypt the zero block */

 gf(2^128) multiply zero-ciphertext with u and u^2 */

 gf(2^64) multiply zero-ciphertext with u and u^2 */

 checking the data can fill the block */

 filling odds with new data and encrypting it */

 clearing the length */

 encrypting the rest of data */

 keeping the surplus of blocksize */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ChaCha20-Poly1305 AEAD, RFC7539

 *

 * Copyright (C) 2015 Martin Willi

 key bytes we use for the ChaCha20 IV */

 zero byte padding for AD/ciphertext, as needed */

 tail data with AD/ciphertext lengths */

 must be last member */

 must be last member */

 the key we generate for Poly1305 using Chacha20 */

 calculated Poly1305 tag */

 length of data to en/decrypt, without ICV */

 Actual AD, excluding IV */

 request flags, with MAY_SLEEP cleared if needed */

 encrypting */

 encrypting */

	/* encrypt call chain:

	 * - chacha_encrypt/done()

	 * - poly_genkey/done()

	 * - poly_init/done()

	 * - poly_setkey/done()

	 * - poly_ad/done()

	 * - poly_adpad/done()

	 * - poly_cipher/done()

	 * - poly_cipherpad/done()

	 * - poly_tail/done/continue()

	 * - poly_copy_tag()

	/* decrypt call chain:

	 * - poly_genkey/done()

	 * - poly_init/done()

	 * - poly_setkey/done()

	 * - poly_ad/done()

	 * - poly_adpad/done()

	 * - poly_cipher/done()

	 * - poly_cipherpad/done()

	 * - poly_tail/done/continue()

	 * - chacha_decrypt/done()

	 * - poly_verify_tag()

 Need 16-byte IV size, including Initial Block Counter value */

 Not a stream cipher? */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * AEAD: Authenticated Encryption with Associated Data

 *

 * This file provides API support for AEAD algorithms.

 *

 * Copyright (c) 2007-2015 Herbert Xu <herbert@gondor.apana.org.au>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Handle async block request by crypto hardware engine.

 *

 * Copyright (C) 2016 Linaro, Inc.

 *

 * Author: Baolin Wang <baolin.wang@linaro.org>

/**

 * crypto_finalize_request - finalize one request if the request is done

 * @engine: the hardware engine

 * @req: the request need to be finalized

 * @err: error number

	/*

	 * If hardware cannot enqueue more requests

	 * and retry mechanism is not supported

	 * make sure we are completing the current request

/**

 * crypto_pump_requests - dequeue one request from engine queue to process

 * @engine: the hardware engine

 * @in_kthread: true if we are in the context of the request pump thread

 *

 * This function checks if there is any request in the engine queue that

 * needs processing and if so call out to the driver to initialize hardware

 * and handle each request.

 Make sure we are not already running a request */

 If another context is idling then defer */

 Check if the engine queue is idle */

 Only do teardown in the thread */

 Get the fist request from the engine queue to handle */

	/*

	 * If hardware doesn't support the retry mechanism,

	 * keep track of the request we are processing now.

	 * We'll need it on completion (crypto_finalize_request).

 Until here we get the request need to be encrypted successfully */

 Request unsuccessfully executed by hardware */

		/*

		 * If hardware queue is full (-ENOSPC), requeue request

		 * regardless of backlog flag.

		 * Otherwise, unprepare and complete the request.

		/*

		 * If retry mechanism is supported,

		 * unprepare current request and

		 * enqueue it back into crypto-engine queue.

		/*

		 * If hardware was unable to execute request, enqueue it

		 * back in front of crypto-engine queue, to keep the order

		 * of requests.

 If retry mechanism is supported, send new requests to engine */

	/*

	 * Batch requests is possible only if

	 * hardware can enqueue multiple requests

/**

 * crypto_transfer_request - transfer the new request into the engine queue

 * @engine: the hardware engine

 * @req: the request need to be listed into the engine queue

/**

 * crypto_transfer_request_to_engine - transfer one request to list

 * into the engine queue

 * @engine: the hardware engine

 * @req: the request need to be listed into the engine queue

/**

 * crypto_transfer_aead_request_to_engine - transfer one aead_request

 * to list into the engine queue

 * @engine: the hardware engine

 * @req: the request need to be listed into the engine queue

/**

 * crypto_transfer_akcipher_request_to_engine - transfer one akcipher_request

 * to list into the engine queue

 * @engine: the hardware engine

 * @req: the request need to be listed into the engine queue

/**

 * crypto_transfer_hash_request_to_engine - transfer one ahash_request

 * to list into the engine queue

 * @engine: the hardware engine

 * @req: the request need to be listed into the engine queue

/**

 * crypto_transfer_kpp_request_to_engine - transfer one kpp_request to list

 * into the engine queue

 * @engine: the hardware engine

 * @req: the request need to be listed into the engine queue

/**

 * crypto_transfer_skcipher_request_to_engine - transfer one skcipher_request

 * to list into the engine queue

 * @engine: the hardware engine

 * @req: the request need to be listed into the engine queue

/**

 * crypto_finalize_aead_request - finalize one aead_request if

 * the request is done

 * @engine: the hardware engine

 * @req: the request need to be finalized

 * @err: error number

/**

 * crypto_finalize_akcipher_request - finalize one akcipher_request if

 * the request is done

 * @engine: the hardware engine

 * @req: the request need to be finalized

 * @err: error number

/**

 * crypto_finalize_hash_request - finalize one ahash_request if

 * the request is done

 * @engine: the hardware engine

 * @req: the request need to be finalized

 * @err: error number

/**

 * crypto_finalize_kpp_request - finalize one kpp_request if the request is done

 * @engine: the hardware engine

 * @req: the request need to be finalized

 * @err: error number

/**

 * crypto_finalize_skcipher_request - finalize one skcipher_request if

 * the request is done

 * @engine: the hardware engine

 * @req: the request need to be finalized

 * @err: error number

/**

 * crypto_engine_start - start the hardware engine

 * @engine: the hardware engine need to be started

 *

 * Return 0 on success, else on fail.

/**

 * crypto_engine_stop - stop the hardware engine

 * @engine: the hardware engine need to be stopped

 *

 * Return 0 on success, else on fail.

	/*

	 * If the engine queue is not empty or the engine is on busy state,

	 * we need to wait for a while to pump the requests of engine queue.

/**

 * crypto_engine_alloc_init_and_set - allocate crypto hardware engine structure

 * and initialize it by setting the maximum number of entries in the software

 * crypto-engine queue.

 * @dev: the device attached with one hardware engine

 * @retry_support: whether hardware has support for retry mechanism

 * @cbk_do_batch: pointer to a callback function to be invoked when executing

 *                a batch of requests.

 *                This has the form:

 *                callback(struct crypto_engine *engine)

 *                where:

 *                @engine: the crypto engine structure.

 * @rt: whether this queue is set to run as a realtime task

 * @qlen: maximum size of the crypto-engine queue

 *

 * This must be called from context that can sleep.

 * Return: the crypto engine structure on success, else NULL.

	/*

	 * Batch requests is possible only if

	 * hardware has support for retry mechanism.

/**

 * crypto_engine_alloc_init - allocate crypto hardware engine structure and

 * initialize it.

 * @dev: the device attached with one hardware engine

 * @rt: whether this queue is set to run as a realtime task

 *

 * This must be called from context that can sleep.

 * Return: the crypto engine structure on success, else NULL.

/**

 * crypto_engine_exit - free the resources of hardware engine when exit

 * @engine: the hardware engine need to be freed

 *

 * Return 0 for success.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * echainiv: Encrypted Chain IV Generator

 *

 * This generator generates an IV based on a sequence number by multiplying

 * it with a salt and then encrypting it with the same key as used to encrypt

 * the plain text.  This algorithm requires that the block size be equal

 * to the IV size.  It is mainly useful for CBC.

 *

 * This generator can only be used by algorithms where authentication

 * is performed after encryption (i.e., authenc).

 *

 * Copyright (c) 2015 Herbert Xu <herbert@gondor.apana.org.au>

 SPDX-License-Identifier: GPL-2.0+ OR BSD-2-Clause

/*

 * Streebog hash function as specified by GOST R 34.11-2012 and

 * described at https://tools.ietf.org/html/rfc6986

 *

 * Copyright (c) 2013 Alexey Degtyarev <alexey@renatasystems.org>

 * Copyright (c) 2018 Vitaly Chikunov <vt@altlinux.org>

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the Free

 * Software Foundation; either version 2 of the License, or (at your option)

 * any later version.

 Ax */

 Starting E() */

 E() done */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * Cipher operations.

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 *               2002 Adam J. Richter <adam@yggdrasil.com>

 *               2004 Jean-Luc Cooke <jlcooke@certainkey.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * PCBC: Propagating Cipher Block Chaining mode

 *

 * Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 *

 * Derived from cbc.c

 * - Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>

/*

 * Key Wrapping: RFC3394 / NIST SP800-38F

 *

 * Copyright (C) 2015, Stephan Mueller <smueller@chronox.de>

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, and the entire permission notice in its entirety,

 *    including the disclaimer of warranties.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. The name of the author may not be used to endorse or promote

 *    products derived from this software without specific prior

 *    written permission.

 *

 * ALTERNATIVELY, this product may be distributed under the terms of

 * the GNU General Public License, in which case the provisions of the GPL2

 * are required INSTEAD OF the above restrictions.  (This clause is

 * necessary due to a potential bad interaction between the GPL and

 * the restrictions contained in a BSD-style copyright.)

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES

 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, ALL OF

 * WHICH ARE HEREBY DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT

 * OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF

 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE

 * USE OF THIS SOFTWARE, EVEN IF NOT ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

/*

 * Note for using key wrapping:

 *

 *	* The result of the encryption operation is the ciphertext starting

 *	  with the 2nd semiblock. The first semiblock is provided as the IV.

 *	  The IV used to start the encryption operation is the default IV.

 *

 *	* The input for the decryption is the first semiblock handed in as an

 *	  IV. The ciphertext is the data starting with the 2nd semiblock. The

 *	  return code of the decryption operation will be EBADMSG in case an

 *	  integrity error occurs.

 *

 * To obtain the full result of an encryption as expected by SP800-38F, the

 * caller must allocate a buffer of plaintext + 8 bytes:

 *

 *	unsigned int datalen = ptlen + crypto_skcipher_ivsize(tfm);

 *	u8 data[datalen];

 *	u8 *iv = data;

 *	u8 *pt = data + crypto_skcipher_ivsize(tfm);

 *		<ensure that pt contains the plaintext of size ptlen>

 *	sg_init_one(&sg, pt, ptlen);

 *	skcipher_request_set_crypt(req, &sg, &sg, ptlen, iv);

 *

 *	==> After encryption, data now contains full KW result as per SP800-38F.

 *

 * In case of decryption, ciphertext now already has the expected length

 * and must be segmented appropriately:

 *

 *	unsigned int datalen = CTLEN;

 *	u8 data[datalen];

 *		<ensure that data contains full ciphertext>

 *	u8 *iv = data;

 *	u8 *ct = data + crypto_skcipher_ivsize(tfm);

 *	unsigned int ctlen = datalen - crypto_skcipher_ivsize(tfm);

 *	sg_init_one(&sg, ct, ctlen);

 *	skcipher_request_set_crypt(req, &sg, &sg, ctlen, iv);

 *

 *	==> After decryption (which hopefully does not return EBADMSG), the ct

 *	pointer now points to the plaintext of size ctlen.

 *

 * Note 2: KWP is not implemented as this would defy in-place operation.

 *	   If somebody wants to wrap non-aligned data, he should simply pad

 *	   the input with zeros to fill it up to the 8 byte boundary.

/*

 * Fast forward the SGL to the "end" length minus SEMIBSIZE.

 * The start in the SGL defined by the fast-forward is returned with

 * the walk variable

 The caller should only operate on full SEMIBLOCKs. */

	/*

	 * Require at least 2 semiblocks (note, the 3rd semiblock that is

	 * required by SP800-38F is the IV.

 Place the IV into block A */

	/*

	 * src scatterlist is read-only. dst scatterlist is r/w. During the

	 * first loop, src points to req->src and dst to req->dst. For any

	 * subsequent round, the code operates on req->dst only.

 move pointer by nbytes in the SGL */

 get the source block */

 perform KW operation: modify IV with counter */

 perform KW operation: decrypt block */

 move pointer by nbytes in the SGL */

 Copy block->R into place */

 we now start to operate on the dst SGL only */

 Perform authentication check */

	/*

	 * Require at least 2 semiblocks (note, the 3rd semiblock that is

	 * required by SP800-38F is the IV that occupies the first semiblock.

	 * This means that the dst memory must be one semiblock larger than src.

	 * Also ensure that the given data is aligned to semiblock.

	/*

	 * Place the predefined IV into block A -- for encrypt, the caller

	 * does not need to provide an IV, but he needs to fetch the final IV.

	/*

	 * src scatterlist is read-only. dst scatterlist is r/w. During the

	 * first loop, src points to req->src and dst to req->dst. For any

	 * subsequent round, the code operates on req->dst only.

 get the source block */

 perform KW operation: encrypt block */

 perform KW operation: modify IV with counter */

 Copy block->R into place */

 we now start to operate on the dst SGL only */

 establish the IV for the caller to pick up */

 Section 5.1 requirement for KW */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * CRC32C chksum

 *

 *@Article{castagnoli-crc,

 * author =       { Guy Castagnoli and Stefan Braeuer and Martin Herrman},

 * title =        {{Optimization of Cyclic Redundancy-Check Codes with 24

 *                 and 32 Parity Bits}},

 * journal =      IEEE Transactions on Communication,

 * year =         {1993},

 * volume =       {41},

 * number =       {6},

 * pages =        {},

 * month =        {June},

 *}

 * Used by the iSCSI driver, possibly others, and derived from

 * the iscsi-crc.c module of the linux-iscsi driver at

 * http://linux-iscsi.sourceforge.net.

 *

 * Following the example of lib/crc32, this function is intended to be

 * flexible and useful for all users.  Modules that currently have their

 * own crc32c, but hopefully may be able to use this one are:

 *  net/sctp (please add all your doco to here if you change to

 *            use this one!)

 *  <endoflist>

 *

 * Copyright (c) 2004 Cisco Systems, Inc.

 * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>

/*

 * Steps through buffer one byte at a time, calculates reflected

 * crc using table.

/*

 * Setting the seed allows arbitrary accumulators and flexible XOR policy

 * If your algorithm starts with ~0, then XOR with ~0 before you set

 * the seed.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 *

 * Copyright (c) 2013 Chanho Min <chanho.min@lge.com>

 SPDX-License-Identifier: GPL-2.0 OR MIT

/*

 * shash interface to the generic implementation of BLAKE2s

 *

 * Copyright (C) 2015-2019 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.

 SPDX-License-Identifier: GPL-2.0-or-later

/* XTS: as defined in IEEE1619/D16

 *	http://grouper.ieee.org/groups/1619/email/pdf00086.pdf

 *

 * Copyright (c) 2007 Rik Snel <rsnel@cube.dyndns.org>

 *

 * Based on ecb.c

 * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>

	/* we need two cipher instances: one to compute the initial 'tweak'

	 * by encrypting the IV (usually the 'plain' iv) and the other

 tweak cipher, uses Key2 i.e. the second half of *key */

 data cipher, uses Key1 i.e. the first half of *key */

/*

 * We compute the tweak masks twice (both before and after the ECB encryption or

 * decryption) to avoid having to allocate a temporary buffer and/or make

 * mutliple calls to the 'ecb(..)' instance, which usually would be slower than

 * just doing the gf128mul_x_ble() calls again.

 set to our TFM to enforce correct alignment: */

 calculate first value of T */

	/* Alas we screwed up the naming so we have to mangle the

	 * cipher name.

/*

 * Non-physical true random number generator based on timing jitter --

 * Jitter RNG standalone code.

 *

 * Copyright Stephan Mueller <smueller@chronox.de>, 2015 - 2020

 *

 * Design

 * ======

 *

 * See https://www.chronox.de/jent.html

 *

 * License

 * =======

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, and the entire permission notice in its entirety,

 *    including the disclaimer of warranties.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. The name of the author may not be used to endorse or promote

 *    products derived from this software without specific prior

 *    written permission.

 *

 * ALTERNATIVELY, this product may be distributed under the terms of

 * the GNU General Public License, in which case the provisions of the GPL2 are

 * required INSTEAD OF the above restrictions.  (This clause is

 * necessary due to a potential bad interaction between the GPL and

 * the restrictions contained in a BSD-style copyright.)

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES

 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, ALL OF

 * WHICH ARE HEREBY DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT

 * OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF

 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE

 * USE OF THIS SOFTWARE, EVEN IF NOT ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

/*

 * This Jitterentropy RNG is based on the jitterentropy library

 * version 2.2.0 provided at https://www.chronox.de/jent.html

 The entropy pool */

	/* all data values that are vital to maintain the security

	 * of the RNG are marked as SENSITIVE. A user must not

	 * access that information while the RNG executes its loops to

 SENSITIVE Actual random number */

 SENSITIVE Previous random number */

 SENSITIVE Previous time stamp */

 SENSITIVE stuck test */

 SENSITIVE stuck test */

 Oversample rate */

	unsigned char *mem;	/* Memory access location with size of

 Pointer to byte in *mem */

 Number of memory blocks in *mem */

 Size of one memory block in bytes */

	unsigned int memaccessloops; /* Number of memory accesses per random

 Repetition Count Test */

 Number of stuck values */

 Adaptive Proportion Test for a significance level of 2^-30 */

 Taken from SP800-90B sec 4.4.2 */

 Data window size */

 LSB of time stamp to process */

 Number of collected observations */

 APT counter */

 APT base reference */

 APT base reference set? */

 Permanent health failure */

 Flags that can be used to initialize the RNG */

#define JENT_DISABLE_MEMORY_ACCESS (1<<2) /* Disable memory access for more

					   * entropy, saves MEMORY_SIZE RAM for

 -- error codes for init function -- */

 Timer service not available */

 Timer too coarse for RNG */

 Timer is not monotonic increasing */

#define JENT_EVARVAR		5 /* Timer does not produce variations of

				   * variations (2nd derivation of time is

 Too many stuck results during init. */

 Health test failed during initialization */

 RCT failed during initialization */

/***************************************************************************

 * Adaptive Proportion Test

 *

 * This test complies with SP800-90B section 4.4.2.

/*

 * Reset the APT counter

 *

 * @ec [in] Reference to entropy collector

 Reset APT counter */

/*

 * Insert a new entropy event into APT

 *

 * @ec [in] Reference to entropy collector

 * @delta_masked [in] Masked time delta to process

 Initialize the base reference */

/***************************************************************************

 * Stuck Test and its use as Repetition Count Test

 *

 * The Jitter RNG uses an enhanced version of the Repetition Count Test

 * (RCT) specified in SP800-90B section 4.4.1. Instead of counting identical

 * back-to-back values, the input to the RCT is the counting of the stuck

 * values during the generation of one Jitter RNG output block.

 *

 * The RCT is applied with an alpha of 2^{-30} compliant to FIPS 140-2 IG 9.8.

 *

 * During the counting operation, the Jitter RNG always calculates the RCT

 * cut-off value of C. If that value exceeds the allowed cut-off value,

 * the Jitter RNG output block will be calculated completely but discarded at

 * the end. The caller of the Jitter RNG is informed with an error code.

/*

 * Repetition Count Test as defined in SP800-90B section 4.4.1

 *

 * @ec [in] Reference to entropy collector

 * @stuck [in] Indicator whether the value is stuck

	/*

	 * If we have a count less than zero, a previous RCT round identified

	 * a failure. We will not overwrite it.

		/*

		 * The cutoff value is based on the following consideration:

		 * alpha = 2^-30 as recommended in FIPS 140-2 IG 9.8.

		 * In addition, we require an entropy value H of 1/OSR as this

		 * is the minimum entropy required to provide full entropy.

		 * Note, we collect 64 * OSR deltas for inserting them into

		 * the entropy pool which should then have (close to) 64 bits

		 * of entropy.

		 *

		 * Note, ec->rct_count (which equals to value B in the pseudo

		 * code of SP800-90B section 4.4.1) starts with zero. Hence

		 * we need to subtract one from the cutoff value as calculated

		 * following SP800-90B.

/*

 * Is there an RCT health test failure?

 *

 * @ec [in] Reference to entropy collector

 *

 * @return

 * 	0 No health test failure

 * 	1 Permanent health test failure

/*

 * Stuck test by checking the:

 * 	1st derivative of the jitter measurement (time delta)

 * 	2nd derivative of the jitter measurement (delta of time deltas)

 * 	3rd derivative of the jitter measurement (delta of delta of time deltas)

 *

 * All values must always be non-zero.

 *

 * @ec [in] Reference to entropy collector

 * @current_delta [in] Jitter time delta

 *

 * @return

 * 	0 jitter measurement not stuck (good bit)

 * 	1 jitter measurement stuck (reject bit)

	/*

	 * Insert the result of the comparison of two back-to-back time

	 * deltas.

 RCT with a stuck bit */

 RCT with a non-stuck bit */

/*

 * Report any health test failures

 *

 * @ec [in] Reference to entropy collector

 *

 * @return

 * 	0 No health test failure

 * 	1 Permanent health test failure

 Test is only enabled in FIPS mode */

/***************************************************************************

 * Noise sources

/*

 * Update of the loop count used for the next round of

 * an entropy collection.

 *

 * Input:

 * @ec entropy collector struct -- may be NULL

 * @bits is the number of low bits of the timer to consider

 * @min is the number of bits we shift the timer value to the right at

 *	the end to make sure we have a guaranteed minimum value

 *

 * @return Newly calculated loop counter

	/*

	 * Mix the current state of the random number into the shuffle

	 * calculation to balance that shuffle a bit more.

	/*

	 * We fold the time value as much as possible to ensure that as many

	 * bits of the time stamp are included as possible.

	/*

	 * We add a lower boundary value to ensure we have a minimum

	 * RNG loop count.

/*

 * CPU Jitter noise source -- this is the noise source based on the CPU

 *			      execution time jitter

 *

 * This function injects the individual bits of the time value into the

 * entropy pool using an LFSR.

 *

 * The code is deliberately inefficient with respect to the bit shifting

 * and shall stay that way. This function is the root cause why the code

 * shall be compiled without optimization. This function not only acts as

 * folding operation, but this function's execution is used to measure

 * the CPU execution time jitter. Any change to the loop in this function

 * implies that careful retesting must be done.

 *

 * @ec [in] entropy collector struct

 * @time [in] time stamp to be injected

 * @loop_cnt [in] if a value not equal to 0 is set, use the given value as

 *		  number of loops to perform the folding

 * @stuck [in] Is the time stamp identified as stuck?

 *

 * Output:

 * updated ec->data

 *

 * @return Number of loops the folding operation is performed

	/*

	 * testing purposes -- allow test app to set the counter, not

	 * needed during runtime

			/*

			* Fibonacci LSFR with polynomial of

			*  x^64 + x^61 + x^56 + x^31 + x^28 + x^23 + 1 which is

			*  primitive according to

			*   http://poincare.matf.bg.ac.rs/~ezivkovm/publications/primpol1.pdf

			* (the shift values are the polynomial values minus one

			* due to counting bits from 0 to 63). As the current

			* position is always the LSB, the polynomial only needs

			* to shift data in from the left without wrap.

	/*

	 * If the time stamp is stuck, do not finally insert the value into

	 * the entropy pool. Although this operation should not do any harm

	 * even when the time stamp has no entropy, SP800-90B requires that

	 * any conditioning operation (SP800-90B considers the LFSR to be a

	 * conditioning operation) to have an identical amount of input

	 * data according to section 3.1.5.

/*

 * Memory Access noise source -- this is a noise source based on variations in

 *				 memory access times

 *

 * This function performs memory accesses which will add to the timing

 * variations due to an unknown amount of CPU wait states that need to be

 * added when accessing memory. The memory size should be larger than the L1

 * caches as outlined in the documentation and the associated testing.

 *

 * The L1 cache has a very high bandwidth, albeit its access rate is  usually

 * slower than accessing CPU registers. Therefore, L1 accesses only add minimal

 * variations as the CPU has hardly to wait. Starting with L2, significant

 * variations are added because L2 typically does not belong to the CPU any more

 * and therefore a wider range of CPU wait states is necessary for accesses.

 * L3 and real memory accesses have even a wider range of wait states. However,

 * to reliably access either L3 or memory, the ec->mem memory must be quite

 * large which is usually not desirable.

 *

 * @ec [in] Reference to the entropy collector with the memory access data -- if

 *	    the reference to the memory block to be accessed is NULL, this noise

 *	    source is disabled

 * @loop_cnt [in] if a value not equal to 0 is set, use the given value

 *		  number of loops to perform the LFSR

	/*

	 * testing purposes -- allow test app to set the counter, not

	 * needed during runtime

		/*

		 * memory access: just add 1 to one byte,

		 * wrap at 255 -- memory access implies read

		 * from and write to memory location

		/*

		 * Addition of memblocksize - 1 to pointer

		 * with wrap around logic to ensure that every

		 * memory location is hit evenly

/***************************************************************************

 * Start of entropy processing logic

/*

 * This is the heart of the entropy generation: calculate time deltas and

 * use the CPU jitter in the time deltas. The jitter is injected into the

 * entropy pool.

 *

 * WARNING: ensure that ->prev_time is primed before using the output

 *	    of this function! This can be done by calling this function

 *	    and not using its result.

 *

 * @ec [in] Reference to entropy collector

 *

 * @return result of stuck test

 Invoke one noise source before time measurement to add variations */

	/*

	 * Get time stamp and calculate time delta to previous

	 * invocation to measure the timing variations

 Check whether we have a stuck measurement. */

 Now call the next noise sources which also injects the data */

/*

 * Generator of one 64 bit random number

 * Function fills rand_data->data

 *

 * @ec [in] Reference to entropy collector

 priming of the ->prev_time value */

 If a stuck measurement is received, repeat measurement */

		/*

		 * We multiply the loop value with ->osr to obtain the

		 * oversampling rate requested by the caller

/*

 * Entry function: Obtain entropy for the caller.

 *

 * This function invokes the entropy gathering logic as often to generate

 * as many bytes as requested by the caller. The entropy gathering logic

 * creates 64 bit per invocation.

 *

 * This function truncates the last 64 bit entropy value output to the exact

 * size specified by the caller.

 *

 * @ec [in] Reference to entropy collector

 * @data [in] pointer to buffer for storing random data -- buffer must already

 *	      exist

 * @len [in] size of the buffer, specifying also the requested number of random

 *	     in bytes

 *

 * @return 0 when request is fulfilled or an error

 *

 * The following error codes can occur:

 *	-1	entropy_collector is NULL

 *	-2	RCT failed

 *	-3	APT test failed

			/*

			 * Re-initialize the noise source

			 *

			 * If the health test fails, the Jitter RNG remains

			 * in failure state and will return a health failure

			 * during next invocation.

 Set APT to initial state */

 Set RCT to initial state */

 Re-enable Jitter RNG */

			/*

			 * Return the health test failure status to the

			 * caller as the generated value is not appropriate.

/***************************************************************************

 * Initialization logic

		/* Allocate memory for adding variations based on memory

		 * access

 verify and set the oversampling rate */

 minimum sampling rate is 1 */

 fill the data pad with non-zero values */

 Required for RCT */

	/* We could perform statistical tests here, but the problem is

	 * that we only have a few loop counts to do testing. These

	 * loop counts may show some slight skew and we produce

	 * false positives.

	 *

	 * Moreover, only old systems show potentially problematic

	 * jitter entropy that could potentially be caught here. But

	 * the RNG is intended for hardware that is available or widely

	 * used, but not old systems that are long out of favor. Thus,

	 * no statistical tests.

	/*

	 * We could add a check for system capabilities such as clock_getres or

	 * check for CONFIG_X86_TSC, but it does not make much sense as the

	 * following sanity checks verify that we have a high-resolution

	 * timer.

	/*

	 * TESTLOOPCOUNT needs some loops to identify edge systems. 100 is

	 * definitely too little.

	 *

	 * SP800-90B requires at least 1024 initial test cycles.

 Invoke core entropy collection logic */

 test whether timer works */

		/*

		 * test whether timer is fine grained enough to provide

		 * delta even when called shortly after each other -- this

		 * implies that we also have a high resolution timer

		/*

		 * up to here we did not modify any variable that will be

		 * evaluated later, but we already performed some work. Thus we

		 * already have had an impact on the caches, branch prediction,

		 * etc. with the goal to clear it to get the worst case

		 * measurements.

			/*

			 * Ensure that the APT succeeded.

			 *

			 * With the check below that count_stuck must be less

			 * than 10% of the overall generated raw entropy values

			 * it is guaranteed that the APT is invoked at

			 * floor((TESTLOOPCOUNT * 0.9) / 64) == 14 times.

 Validate RCT */

 test whether we have an increasing timer */

 use 32 bit value to ensure compilation on 32 bit arches */

		/*

		 * ensure that we have a varying delta timer which is necessary

		 * for the calculation of entropy -- perform this check

		 * only after the first loop is executed as we need to prime

		 * the old_data value

	/*

	 * we allow up to three times the time running backwards.

	 * CLOCK_REALTIME is affected by adjtime and NTP operations. Thus,

	 * if such an operation just happens to interfere with our test, it

	 * should not fail. The value of 3 should cover the NTP case being

	 * performed during our test run.

	/*

	 * Variations of deltas of time must on average be larger

	 * than 1 to ensure the entropy estimation

	 * implied with 1 is preserved

	/*

	 * Ensure that we have variations in the time stamp below 10 for at

	 * least 10% of all checks -- on some platforms, the counter increments

	 * in multiples of 100, but not always

	/*

	 * If we have more than 90% stuck results, then this Jitter RNG is

	 * likely to not work well.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Public Key Encryption

 *

 * Copyright (c) 2015, Intel Corporation

 * Authors: Tadeusz Struk <tadeusz.struk@intel.com>

 SPDX-License-Identifier: GPL-2.0-or-later

 might want less than we've got */

/*

 * VMAC: Message Authentication Code using Universal Hashing

 *

 * Reference: https://tools.ietf.org/html/draft-krovetz-vmac-01

 *

 * Copyright (c) 2009, Intel Corporation.

 * Copyright (c) 2018, Google Inc.

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms and conditions of the GNU General Public License,

 * version 2, as published by the Free Software Foundation.

 *

 * This program is distributed in the hope it will be useful, but WITHOUT

 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or

 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for

 * more details.

 *

 * You should have received a copy of the GNU General Public License along with

 * this program; if not, write to the Free Software Foundation, Inc., 59 Temple

 * Place - Suite 330, Boston, MA 02111-1307 USA.

/*

 * Derived from:

 *	VMAC and VHASH Implementation by Ted Krovetz (tdk@acm.org) and Wei Dai.

 *	This implementation is herby placed in the public domain.

 *	The authors offers no warranty. Use at your own risk.

 *	Last modified: 17 APR 08, 1700 PDT

/*

 * User definable settings.

 Must be 128, 192 or 256			*/

 Must 2^i for any 3 < i < 13 Standard = 128*/

 per-transform (per-key) context */

 per-request context */

 partial block */

 size of the partial block */

 running total of L2-hash */

 nonce bytes filled so far */

/*

 * Constants and masks

 2^64 - 257 prime  */

 62-bit mask       */

 63-bit mask       */

 64-bit mask       */

 Poly key mask     */

 Prefer little endian */

/*

 * The following routines are used in this implementation. They are

 * written via macros to simulate zero-overhead call-by-reference.

 *

 * MUL64: 64x64->128-bit multiplication

 * PMUL64: assumes top bits cleared on inputs

 * ADD128: 128x128->128-bit addition

 Assumes m doesn't overflow */	\

/*

 * For highest performance the L1 NH and L2 polynomial hashes should be

 * carefully implemented to take advantage of one's target architecture.

 * Here these two hash functions are defined multiple time; once for

 * 64-bit architectures, once for 32-bit SSE2 architectures, and once

 * for the rest (32-bit) architectures.

 * For each, nh_16 *must* be defined (works on multiples of 16 bytes).

 * Optionally, nh_vmac_nhbytes can be defined (for multiples of

 * VMAC_NHBYTES), and nh_16_2 and nh_vmac_nhbytes_2 (versions that do two

 * NH computations at once).

 These versions do 64-bytes of message at a time */

 compute ab*cd, put bd into result registers */	\

 add 2 * ac to result */				\

 add together ad + bc */				\

 now (ah,al), (t2l,2*t2h) need summing */		\

 first add the high registers, carrying into t2h */	\

 double t2h and add top bit of ah */			\

 now add the low registers */				\

 ! CONFIG_64BIT */

 end of specialized NH and poly definitions */

 At least nh_16 is defined. Defined others as needed here */

 fully reduce (p1,p2)+(len,0) mod p127 */

 At this point, (p1,p2) is at most 2^127+(len<<64) */

 compute (p1,p2)/(2^64-2^32) and (p1,p2)%(2^64-2^32) */

 compute (p1+k1)%p64 and (p2+k2)%p64 */

 compute (p1+k1)*(p2+k2)%p64 */

 L1 and L2-hash one or more VMAC_NHBYTES-byte blocks */

 Fill nh key */

 Fill poly key */

 Fill ip key */

 Nonce is passed as first VMAC_NONCEBYTES bytes of data */

 TODO: 'p' may be misaligned here */

 L1 and L2-hash the final block if needed */

 Zero-pad to next 128-bit boundary */

 L3-hash the 128-bit output of L2-hash */

	/*

	 * The VMAC specification requires a nonce at least 1 bit shorter than

	 * the block cipher's block length, so we actually only accept a 127-bit

	 * nonce.  We define the unused bit to be the first one and require that

	 * it be 0, so the needed prepending of a 0 bit is implicit.

 Finish calculating the VHASH of the message */

 Generate pseudorandom pad by encrypting the nonce */

 The VMAC is the sum of VHASH and the pseudorandom pad */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ECB: Electronic CodeBook mode

 *

 * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>

 ECB mode doesn't take an IV */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * GCM: Galois/Counter Mode.

 *

 * Copyright (c) 2007 Nokia Siemens Networks - Mikko Herranen <mh1@iki.fi>

 The skcipher algorithm must be CTR mode, using 16-byte blocks. */

 Underlying IV size must be 12. */

 Not a stream cipher? */

 Underlying IV size must be 12. */

 Not a stream cipher? */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Scatterlist Cryptographic API.

 *

 * Procfs information.

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

 * Copyright (c) 2005 Herbert Xu <herbert@gondor.apana.org.au>

 for module_name() */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * DES & Triple DES EDE Cipher Algorithms.

 *

 * Copyright (c) 2005 Dag Arne Osvik <da@osvik.no>

/*

 * Cryptographic API.

 *

 * Anubis Algorithm

 *

 * The Anubis algorithm was developed by Paulo S. L. M. Barreto and

 * Vincent Rijmen.

 *

 * See

 *

 *	P.S.L.M. Barreto, V. Rijmen,

 *	``The Anubis block cipher,''

 *	NESSIE submission, 2000.

 *

 * This software implements the "tweaked" version of Anubis.

 * Only the S-box and (consequently) the rounds constants have been

 * changed.

 *

 * The original authors have disclaimed all copyright interest in this

 * code and thus put it in the public domain. The subsequent authors

 * have put this under the GNU General Public License.

 *

 * By Aaron Grothe ajgrothe@yahoo.com, October 28, 2004

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; either version 2 of the License, or

 * (at your option) any later version.

 *

 in bits

 * map cipher key to initial key state (mu): */

	/*

	 * generate R + 1 round keys:

		/*

		 * generate r-th round key K^r:

		/*

		 * compute kappa^{r+1} from kappa^r:

	/*

	 * generate inverse key schedule: K'^0 = K^R, K'^R =

	 * 				  K^0, K'^r = theta(K^{R-r}):

	/*

	 * map plaintext block to cipher state (mu)

	 * and add initial round key (sigma[K^0]):

	/*

	 * R - 1 full rounds:

	/*

	 * last round:

	/*

	 * map cipher state to ciphertext block (mu^{-1}):

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SM3 secure hash, as specified by OSCCA GM/T 0004-2012 SM3 and

 * described at https://tools.ietf.org/html/draft-shen-sm3-hash-01

 *

 * Copyright (C) 2017 ARM Limited or its affiliates.

 * Written by Gilad Ben-Yossef <gilad@benyossef.com>

 load the input */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Elliptic Curve (Russian) Digital Signature Algorithm for Cryptographic API

 *

 * Copyright (c) 2019 Vitaly Chikunov <vt@altlinux.org>

 *

 * References:

 * GOST 34.10-2018, GOST R 34.10-2012, RFC 7091, ISO/IEC 14888-3:2018.

 *

 * Historical references:

 * GOST R 34.10-2001, RFC 4357, ISO/IEC 14888-3:2006/Amd 1:2010.

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the Free

 * Software Foundation; either version 2 of the License, or (at your option)

 * any later version.

 overall public key oid */

 parameter */

 parameter */

 curve from oid */

 parameter (bytes) */

 digest name from oid */

 @key length (bytes) */

 raw public key */

 point storage for @pub_key */

 The following two aren't implemented: */

 witness (r) */

 -r */

 second part of sig (s) */

 h \mod q */

 e^{-1} \mod q */

 reuse s, e */

	/*

	 * Digest value, digest algorithm, and curve (modulus) should have the

	 * same length (256 or 512 bits), public key and signature should be

	 * twice bigger.

 Step 1: verify that 0 < r < q, 0 < s < q */

 Step 2: calculate hash (h) of the message (passed as input) */

 Step 3: calculate e = h \mod q */

 Step 4: calculate v = e^{-1} \mod q */

 Step 5: calculate z_1 = sv \mod q, z_2 = -rv \mod q */

 Step 6: calculate point C = z_1P + z_2Q, and R = x_c \mod q */

 Step 7: if R == r signature is valid */

 Optional. If present should match expected digest algo OID. */

 Parse BER encoded subjectPublicKey. */

 Key parameters is in the key after keylen. */

 Parse SubjectPublicKeyInfo.AlgorithmIdentifier.parameters. */

	/*

	 * Sizes of algo (set in digest_len) and curve should match

	 * each other.

	/*

	 * Key is two 256- or 512-bit coordinates which should match

	 * curve size.

	/*

	 * Verify doesn't need any output, so it's just informational

	 * for keyctl to determine the key bit size.

/*

 * Cryptographic API.

 *

 * Whirlpool hashing Algorithm

 *

 * The Whirlpool algorithm was developed by Paulo S. L. M. Barreto and

 * Vincent Rijmen.  It has been selected as one of cryptographic

 * primitives by the NESSIE project http://www.cryptonessie.org/

 *

 * The original authors have disclaimed all copyright interest in this

 * code and thus put it in the public domain. The subsequent authors

 * have put this under the GNU General Public License.

 *

 * By Aaron Grothe ajgrothe@yahoo.com, August 23, 2004

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; either version 2 of the License, or

 * (at your option) any later version.

 *

/*

 * Though Whirlpool is endianness-neutral, the encryption tables are listed

 * in BIG-ENDIAN format, which is adopted throughout this implementation

 * (but little-endian notation would be equally suitable if consistently

 * employed).

/*

 * The core Whirlpool transform.

 the round key */

 mu(buffer) */

 the cipher state */

	/*

	* apply the Miyaguchi-Preneel compression function:

 convert to number of bits

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * SHA1 Secure Hash Algorithm.

 *

 * Derived from cryptoapi implementation, adapted for in-place

 * scatterlist interface.

 *

 * Copyright (c) Alan Smithee.

 * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>

 * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>

 SPDX-License-Identifier: GPL-2.0

/*

 * Adiantum length-preserving encryption mode

 *

 * Copyright 2018 Google LLC

/*

 * Adiantum is a tweakable, length-preserving encryption mode designed for fast

 * and secure disk encryption, especially on CPUs without dedicated crypto

 * instructions.  Adiantum encrypts each sector using the XChaCha12 stream

 * cipher, two passes of an -almost--universal (-U) hash function based on

 * NH and Poly1305, and an invocation of the AES-256 block cipher on a single

 * 16-byte block.  See the paper for details:

 *

 *	Adiantum: length-preserving encryption for entry-level processors

 *      (https://eprint.iacr.org/2018/720.pdf)

 *

 * For flexibility, this implementation also allows other ciphers:

 *

 *	- Stream cipher: XChaCha12 or XChaCha20

 *	- Block cipher: any with a 128-bit block size and 256-bit key

 *

 * This implementation doesn't currently allow other -U hash functions, i.e.

 * HPolyC is not supported.  This is because Adiantum is ~20% faster than HPolyC

 * but still provably as secure, and also the -U hash function of HBSH is

 * formally defined to take two inputs (tweak, message) which makes it difficult

 * to wrap with the crypto_shash API.  Rather, some details need to be handled

 * here.  Nevertheless, if needed in the future, support for other -U hash

 * functions could be added here.

/*

 * Size of right-hand part of input data, in bytes; also the size of the block

 * cipher's block size and the hash function's output.

 Size of the block cipher key (K_E) in bytes */

 Size of the hash key (K_H) in bytes */

/*

 * The specification allows variable-length tweaks, but Linux's crypto API

 * currently only allows algorithms to support a single length.  The "natural"

 * tweak length for Adiantum is 16, since that fits into one Poly1305 block for

 * the best performance.  But longer tweaks are useful for fscrypt, to avoid

 * needing to derive per-file keys.  So instead we use two blocks, or 32 bytes.

	/*

	 * Buffer for right-hand part of data, i.e.

	 *

	 *    P_L => P_M => C_M => C_R when encrypting, or

	 *    C_R => C_M => P_M => P_L when decrypting.

	 *

	 * Also used to build the IV for the stream cipher.

 interpret as element of Z/(2^{128}Z) */

 true if encrypting, false if decrypting */

	/*

	 * The result of the Poly1305 -U hash function applied to

	 * (bulk length, tweak)

 Sub-requests, must be last */

/*

 * Given the XChaCha stream key K_S, derive the block cipher key K_E and the

 * hash key K_H as follows:

 *

 *     K_E || K_H || ... = XChaCha(key=K_S, nonce=1||0^191)

 *

 * Note that this denotes using bits from the XChaCha keystream, which here we

 * get indirectly by encrypting a buffer containing all 0's.

 must be last */

 Set the stream cipher key (K_S) */

 Derive the subkeys */

 Set the block cipher key (K_E) */

 Set the hash key (K_H) */

 Addition in Z/(2^{128}Z) */

 Subtraction in Z/(2^{128}Z) */

/*

 * Apply the Poly1305 -U hash function to (bulk length, tweak) and save the

 * result to rctx->header_hash.  This is the calculation

 *

 *	H_T  Poly1305_{K_T}(bin_{128}(|L|) || T)

 *

 * from the procedure in section 6.4 of the Adiantum paper.  The resulting value

 * is reused in both the first and second hash steps.  Specifically, it's added

 * to the result of an independently keyed -U hash function (for equal length

 * inputs only) taken over the left-hand part (the "bulk") of the message, to

 * give the overall Adiantum hash of the (tweak, left-hand part) pair.

 Hash the left-hand part (the "bulk") of the message using NHPoly1305 */

 Continue Adiantum encryption/decryption after the stream cipher step */

 If decrypting, decrypt C_M with the block cipher to get P_M */

	/*

	 * Second hash step

	 *	enc: C_R = C_M - H_{K_H}(T, C_L)

	 *	dec: P_R = P_M - H_{K_H}(T, P_L)

	/*

	 * First hash step

	 *	enc: P_M = P_R + H_{K_H}(T, P_L)

	 *	dec: C_M = C_R + H_{K_H}(T, C_L)

 If encrypting, encrypt P_M with the block cipher to get C_M */

 Initialize the rest of the XChaCha IV (first part is C_M) */

 nonce || stream position */

	/*

	 * XChaCha needs to be done on all the data except the last 16 bytes;

	 * for disk encryption that usually means 4080 or 496 bytes.  But ChaCha

	 * implementations tend to be most efficient when passed a whole number

	 * of 64-byte ChaCha blocks, or sometimes even a multiple of 256 bytes.

	 * And here it doesn't matter whether the last 16 bytes are written to,

	 * as the second hash step will overwrite them.  Thus, round the XChaCha

	 * length up to the next 64-byte boundary if possible.

/*

 * Check for a supported set of inner algorithms.

 * See the comment at the beginning of this file.

 Stream cipher, e.g. "xchacha12" */

 Block cipher, e.g. "aes" */

 NHPoly1305 -U hash function */

 Check the set of algorithms */

 Instance fields */

	/*

	 * The block cipher is only invoked once per message, so for long

	 * messages (e.g. sectors for disk encryption) its performance doesn't

	 * matter as much as that of the stream cipher and hash function.  Thus,

	 * weigh the block cipher's ->cra_priority less.

 adiantum(streamcipher_name, blockcipher_name [, nhpoly1305_name]) */

 SPDX-License-Identifier: GPL-2.0

/*

 * SM4 Cipher Algorithm.

 *

 * Copyright (C) 2018 ARM Limited or its affiliates.

 * All rights reserved.

/**

 * sm4_setkey - Set the SM4 key.

 * @tfm:	The %crypto_tfm that is used in the context.

 * @in_key:	The input key.

 * @key_len:	The size of the key.

 *

 * This function uses sm4_expandkey() to expand the key.

 * &sm4_ctx _must_ be the private data embedded in @tfm which is

 * retrieved with crypto_tfm_ctx().

 *

 * Return: 0 on success; -EINVAL on failure (only happens for bad key lengths)

 encrypt a block of text */

 decrypt a block of text */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Scalar fixed time AES core transform

 *

 * Copyright (C) 2017 Linaro Ltd <ard.biesheuvel@linaro.org>

	/*

	 * Temporarily disable interrupts to avoid races where cachelines are

	 * evicted when the CPU is interrupted to do something else.

	/*

	 * Temporarily disable interrupts to avoid races where cachelines are

	 * evicted when the CPU is interrupted to do something else.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (c) 2021 IBM Corporation

 pub key x and y coordinates */

/*

 * Get the r and s components of a signature from the X509 certificate.

	/* diff = 0: 'value' has exacly the right size

	 * diff > 0: 'value' has too many bytes; one leading zero is allowed that

	 *           makes the value a positive integer; error on more

	 * diff < 0: 'value' is missing leading zeros, which we add

 skip over leading zeros that make 'value' a positive int */

 leading zeros not given in 'value' */

 0 < r < n  and 0 < s < n */

 hash is given */

 s1 = (s^-1) mod n */

 u1 = (hash * s1) mod n */

 u2 = (r * s1) mod n */

 res = u1*G + u2 * pub_key */

 res.x = res.x mod n (if res.x > order) */

 faster alternative for NIST p384, p256 & p192 */

/*

 * Verify an ECDSA signature.

 if the hash is shorter then we will add leading zeros to fit to ndigits */

 given hash is longer, we take the left-most bytes */

/*

 * Set the public key given the raw uncompressed key data from an X509

 * certificate. The key data contain the concatenated X and Y coordinates of

 * the public key.

 we only accept uncompressed format indicated by '4' */

 NIST p192 may not be available in FIPS mode */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * FIPS 200 support.

 *

 * Copyright (c) 2008 Neil Horman <nhorman@tuxdriver.com>

 Process kernel command-line parameter at boot time. fips=0 or fips=1 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Create default crypto algorithm instances.

 *

 * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>

 Do not test internal algorithms. */

/*

 * This is arch_initcall() so that the crypto self-tests are run on algorithms

 * registered early by subsys_initcall().  subsys_initcall() is needed for

 * generic implementations so that they're available for comparison tests when

 * other implementations are registered later by module_init().

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * The AEGIS-128 Authenticated-Encryption Algorithm

 *

 * Copyright (c) 2017-2018 Ondrej Mosnacek <omosnacek@gmail.com>

 * Copyright (C) 2017-2018 Red Hat, Inc. All rights reserved.

		/*

		 * From Chapter 4. 'Security Analysis' of the AEGIS spec [0]

		 *

		 * "3. If verification fails, the decrypted plaintext and the

		 *     wrong authentication tag should not be given as output."

		 *

		 * [0] https://competitions.cr.yp.to/round3/aegisv11.pdf

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C)2006 USAGI/WIDE Project

 *

 * Author:

 * 	Kazunori Miyazawa <miyazawa@linux-ipv6.org>

/*

 * +------------------------

 * | <parent tfm>

 * +------------------------

 * | xcbc_tfm_ctx

 * +------------------------

 * | consts (block size * 2)

 * +------------------------

/*

 * +------------------------

 * | <shash desc>

 * +------------------------

 * | xcbc_desc_ctx

 * +------------------------

 * | odds (block size)

 * +------------------------

 * | prev (block size)

 * +------------------------

 checking the data can fill the block */

 filling odds with new data and encrypting it */

 clearing the length */

 encrypting the rest of data */

 keeping the surplus of blocksize */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2019 Linaro, Ltd. <ard.biesheuvel@linaro.org>

 shift rows

 sub bytes

 mix columns

	/*

	 * We use inline asm here instead of the vaeseq_u8/vaesmcq_u8 intrinsics

	 * to force the compiler to issue the aese/aesmc instructions in pairs.

	 * This is much faster on many cores, where the instruction pair can

	 * execute in a single cycle.

/*

 * AArch32 does not provide these intrinsics natively because it does not

 * implement the underlying instructions. AArch32 only provides 64-bit

 * wide vtbl.8/vtbx.8 instruction, so use those instead.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Symmetric key cipher operations.

 *

 * Generic encrypt/decrypt wrapper for ciphers, handles operations across

 * multiple page boundaries by using temporary blocks.  In user context,

 * the kernel is given a chance to schedule us once per page.

 *

 * Copyright (c) 2015 Herbert Xu <herbert@gondor.apana.org.au>

/* Get a spot of the specified length that does not straddle a page.

 * The caller needs to ensure that there is enough space for this operation.

			/*

			 * Didn't process all bytes.  Either the algorithm is

			 * broken, or this was the last step and it turned out

			 * the message wasn't evenly divisible into blocks but

			 * the algorithm requires it.

 Short-circuit for the common/fast path. */

 Start with the minimum alignment of kmalloc. */

 Calculate the minimum alignment of p->buffer. */

 Minimum size to align p->buffer by alignmask. */

 Minimum size to ensure p->buffer does not straddle a page. */

 Minimum size to align buffer by alignmask. */

 Minimum size to ensure buffer does not straddle a page. */

 Only sync algorithms allowed. */

	/*

	 * Make sure we do not allocate something that might get used with

	 * an on-stack request: check the request size.

/**

 * skcipher_alloc_instance_simple - allocate instance of simple block cipher mode

 *

 * Allocate an skcipher_instance for a simple block cipher mode of operation,

 * e.g. cbc or ecb.  The instance context will have just a single crypto_spawn,

 * that for the underlying cipher.  The {min,max}_keysize, ivsize, blocksize,

 * alignmask, and priority are set from the underlying cipher but can be

 * overridden if needed.  The tfm context defaults to skcipher_ctx_simple, and

 * default ->setkey(), ->init(), and ->exit() methods are installed.

 *

 * @tmpl: the template being instantiated

 * @tb: the template parameters

 *

 * Return: a pointer to the new instance, or an ERR_PTR().  The caller still

 *	   needs to register the instance.

 Default algorithm properties, can be overridden */

 Use skcipher_ctx_simple by default, can be overridden */

 SPDX-License-Identifier: GPL-2.0

/*

 * NHPoly1305 - -almost--universal hash function for Adiantum

 *

 * Copyright 2018 Google LLC

/*

 * "NHPoly1305" is the main component of Adiantum hashing.

 * Specifically, it is the calculation

 *

 *	H_L  Poly1305_{K_L}(NH_{K_N}(pad_{128}(L)))

 *

 * from the procedure in section 6.4 of the Adiantum paper [1].  It is an

 * -almost--universal (-U) hash function for equal-length inputs over

 * Z/(2^{128}Z), where the "" operation is addition.  It hashes 1024-byte

 * chunks of the input with the NH hash function [2], reducing the input length

 * by 32x.  The resulting NH digests are evaluated as a polynomial in

 * GF(2^{130}-5), like in the Poly1305 MAC [3].  Note that the polynomial

 * evaluation by itself would suffice to achieve the -U property; NH is used

 * for performance since it's over twice as fast as Poly1305.

 *

 * This is *not* a cryptographic hash function; do not use it as such!

 *

 * [1] Adiantum: length-preserving encryption for entry-level processors

 *     (https://eprint.iacr.org/2018/720.pdf)

 * [2] UMAC: Fast and Secure Message Authentication

 *     (https://fastcrypto.org/umac/umac_proc.pdf)

 * [3] The Poly1305-AES message-authentication code

 *     (https://cr.yp.to/mac/poly1305-20050329.pdf)

 Pass the next NH hash value through Poly1305 */

/*

 * Feed the next portion of the source data, as a whole number of 16-byte

 * "NH message units", through NH and Poly1305.  Each NH hash is taken over

 * 1024 bytes, except possibly the final one which is taken over a multiple of

 * 16 bytes up to 1024.  Also, in the case where data is passed in misaligned

 * chunks, we combine partial hashes; the end result is the same either way.

 Starting a new NH message */

 Continuing a previous NH message */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 *

 * Copyright (c) 2013 Chanho Min <chanho.min@lge.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * Deflate algorithm (RFC 1951), implemented here primarily for use

 * by IPCOMP (RFC 3173 & RFC 2394).

 *

 * Copyright (c) 2003 James Morris <jmorris@intercode.com.au>

 *

 * FIXME: deflate transforms will require up to a total of about 436k of kernel

 * memory on i386 (390k for compression, the rest for decompression), as the

 * current zlib kernel code uses a worst case pre-allocation system by default.

 * This needs to be fixed so that the amount of memory required is properly

 * related to the  winbits and memlevel parameters.

 *

 * The default winbits of 11 should suit most packets, and it may be something

 * to configure on a per-tfm basis in the future.

 *

 * Currently, compression history is not maintained between tfm calls, as

 * it is not needed for IPCOMP and keeps the code simpler.  It can be

 * implemented if someone wants it.

	/*

	 * Work around a bug in zlib, which sometimes wants to taste an extra

	 * byte when being used in the (undocumented) raw deflate mode.

	 * (From USAGI).

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * CTR: Counter mode

 *

 * (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>

 create keystream */

 increment counter in counterblock */

 create keystream */

 increment counter in counterblock */

 Block size must be >= 4 bytes. */

 If this is false we'd fail the alignment of crypto_inc. */

 CTR mode is a stream cipher. */

	/*

	 * To simplify the implementation, configure the skcipher walk to only

	 * give a partial block at the very end, never earlier.

 the nonce is stored in bytes at end of key */

 set up counter block */

 initialize counter portion of counter block */

 We only support 16-byte blocks. */

 Not a stream cipher? */

/*

 * Cryptographic API.

 *

 * AES Cipher Algorithm.

 *

 * Based on Brian Gladman's code.

 *

 * Linux developers:

 *  Alexander Kjeldaas <astor@fast.no>

 *  Herbert Valerio Riedel <hvr@hvrlab.org>

 *  Kyle McMartin <kyle@debian.org>

 *  Adam J. Richter <adam@yggdrasil.com> (conversion to 2.5 API).

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; either version 2 of the License, or

 * (at your option) any later version.

 *

 * ---------------------------------------------------------------------------

 * Copyright (c) 2002, Dr Brian Gladman <brg@gladman.me.uk>, Worcester, UK.

 * All rights reserved.

 *

 * LICENSE TERMS

 *

 * The free distribution and use of this software in both source and binary

 * form is allowed (with or without changes) provided that:

 *

 *   1. distributions of this source code include the above copyright

 *      notice, this list of conditions and the following disclaimer;

 *

 *   2. distributions in binary form include the above copyright

 *      notice, this list of conditions and the following disclaimer

 *      in the documentation and/or other associated materials;

 *

 *   3. the copyright holder's name is not used to endorse products

 *      built using this software without specific written permission.

 *

 * ALTERNATIVELY, provided that this notice is retained in full, this product

 * may be distributed under the terms of the GNU General Public License (GPL),

 * in which case the provisions of the GPL apply INSTEAD OF those given above.

 *

 * DISCLAIMER

 *

 * This software is provided 'as is' with no explicit or implied warranties

 * in respect of its properties, including, but not limited to, correctness

 * and/or fitness for purpose.

 * ---------------------------------------------------------------------------

 cacheline-aligned to facilitate prefetching into cache */

/**

 * crypto_aes_set_key - Set the AES key.

 * @tfm:	The %crypto_tfm that is used in the context.

 * @in_key:	The input key.

 * @key_len:	The size of the key.

 *

 * This function uses aes_expand_key() to expand the key.  &crypto_aes_ctx

 * _must_ be the private data embedded in @tfm which is retrieved with

 * crypto_tfm_ctx().

 *

 * Return: 0 on success; -EINVAL on failure (only happens for bad key lengths)

 encrypt a block of text */

 decrypt a block of text */

/* FCrypt encryption algorithm

 *

 * Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License

 * as published by the Free Software Foundation; either version

 * 2 of the License, or (at your option) any later version.

 *

 * Based on code:

 *

 * Copyright (c) 1995 - 2000 Kungliga Tekniska Hgskolan

 * (Royal Institute of Technology, Stockholm, Sweden).

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 *

 * 3. Neither the name of the Institute nor the names of its contributors

 *    may be used to endorse or promote products derived from this software

 *    without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE INSTITUTE AND CONTRIBUTORS ``AS IS'' AND

 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED.  IN NO EVENT SHALL THE INSTITUTE OR CONTRIBUTORS BE LIABLE

 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT

 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY

 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF

 * SUCH DAMAGE.

 Rotate right two 32 bit numbers as a 56 bit number */

 Rotate right one 64 bit number as a 56 bit number */

/*

 * Sboxes for Feistel network derived from

 * /afs/transarc.com/public/afsps/afs.rel31b.export-src/rxkad/sboxes.h

/*

 * This is a 16 round Feistel network with permutation F_ENCRYPT

/*

 * encryptor

/*

 * decryptor

/*

 * Generate a key schedule from key, the least significant bit in each key byte

 * is parity and shall be ignored. This leaves 56 significant bits in the key

 * to scatter over the 16 key schedules. For each schedule extract the low

 * order 32 bits and use as schedule, then rotate right by 11 bits.

#if BITS_PER_LONG == 64  /* the 64-bit version can also be used for 32-bit

			  * kernels - it seems to be faster but the code is

 k holds all 56 non-parity bits */

 discard the parity bits */

 Use lower 32 bits for schedule, rotate by 11 each round (16 times) */

 hi is upper 24 bits and lo lower 32, total 56 */

 discard the parity bits */

 Use lower 32 bits for schedule, rotate by 11 each round (16 times) */

 SPDX-License-Identifier: GPL-2.0

/*

 * Load a TPM key from the blob provided by userspace

 session for loading the key */

 generate odd nonce */

 calculate authorization HMAC value */

 build the request buffer */

/*

 * Execute the FlushSpecific TPM command

/*

 * Decrypt a blob provided by userspace using a specific key handle.

 * The handle is a well known handle or previously loaded by e.g. LoadKey2

 session for loading the key */

 generate odd nonce */

 calculate authorization HMAC value */

 build the request buffer */

/*

 * Sign a blob provided by userspace (that has had the hash function applied)

 * using a specific key handle.  The handle is assumed to have been previously

 * loaded by e.g. LoadKey2.

 *

 * Note that the key signature scheme of the used key should be set to

 * TPM_SS_RSASSAPKCS1v15_DER.  This allows the hashed input to be of any size

 * up to key_length_in_bytes - 11 and not be limited to size 20 like the

 * TPM_SS_RSASSAPKCS1v15_SHA1 signature scheme.

 session for loading the key */

 generate odd nonce */

 calculate authorization HMAC value */

 build the request buffer */

 Room to fit two u32 zeros for algo id and parameters length. */

/*

 * Maximum buffer size for the BER/DER encoded public key.  The public key

 * is of the form SEQUENCE { INTEGER n, INTEGER e } where n is a maximum 2048

 * bit key and e is usually 65537

 * The encoding overhead is:

 * - max 4 bytes for SEQUENCE

 *   - max 4 bytes for INTEGER n type/length

 *     - 257 bytes of n

 *   - max 2 bytes for INTEGER e type/length

 *     - 3 bytes of e

 * - 4+4 of zeros for set_pub_key parameters (SETKEY_PARAMS_SIZE)

/*

 * Provide a part of a description of the key for /proc/keys.

 How many bytes will it take to encode the length */

 SEQUENCE */

 INTEGER n */

 Zero parameters to satisfy set_pub_key ABI. */

/*

 * Determine the crypto algorithm name.

/*

 * Query information about a key.

 TPM only works on private keys, public keys still done in software */

/*

 * Encryption operation is performed with the public key.  Hence it is done

 * in software

/*

 * Decryption operation is performed with the private key in the TPM.

 TODO: Handle a non-all zero SRK authorization */

 TODO: Handle a non-all zero key authorization */

/*

 * Hash algorithm OIDs plus ASN.1 DER wrappings [RFC4880 sec 5.2.2].

 OID */

/*

 * Sign operation is performed with the private key in the TPM.

 request enough space for the ASN.1 template + input hash */

 Copy ASN.1 template, then the input */

 TODO: Handle a non-all zero SRK authorization */

 TODO: Handle a non-all zero key authorization */

/*

 * Do encryption, decryption and signing ops.

 Perform the encryption calculation. */

/*

 * Verify a signature using a public key.

/*

 * Parse enough information out of TPM_KEY structure:

 * TPM_STRUCT_VER -> 4 bytes

 * TPM_KEY_USAGE -> 2 bytes

 * TPM_KEY_FLAGS -> 4 bytes

 * TPM_AUTH_DATA_USAGE -> 1 byte

 * TPM_KEY_PARMS -> variable

 * UINT32 PCRInfoSize -> 4 bytes

 * BYTE* -> PCRInfoSize bytes

 * TPM_STORE_PUBKEY

 * UINT32 encDataSize;

 * BYTE* -> encDataSize;

 *

 * TPM_KEY_PARMS:

 * TPM_ALGORITHM_ID -> 4 bytes

 * TPM_ENC_SCHEME -> 2 bytes

 * TPM_SIG_SCHEME -> 2 bytes

 * UINT32 parmSize -> 4 bytes

 * BYTE* -> variable

 Ensure this is a legacy key */

 Skip to TPM_KEY_PARMS */

 Make sure this is an RSA key */

 Make sure this is TPM_ES_RSAESPKCSv15 encoding scheme */

 Make sure this is TPM_SS_RSASSAPKCS1v15_DER signature scheme */

 Move to TPM_RSA_KEY_PARMS */

 Grab the RSA key length */

 Move just past TPM_KEY_PARMS */

 Move to TPM_STORE_PUBKEY */

 Grab the size of the public key, it should jive with the key size */

 Given the blob, parse it and load it into the TPM */

 We don't support TPM2 yet */

/*

 * TPM-based asymmetric key subtype

 SPDX-License-Identifier: GPL-2.0-or-later

/* Asymmetric public-key cryptography key type

 *

 * See Documentation/crypto/asymmetric-keys.rst

 *

 * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/**

 * find_asymmetric_key - Find a key by ID.

 * @keyring: The keys to search.

 * @id_0: The first ID to look for or NULL.

 * @id_1: The second ID to look for or NULL.

 * @partial: Use partial match if true, exact if false.

 *

 * Find a key in the given keyring by identifier.  The preferred identifier is

 * the id_0 and the fallback identifier is the id_1.  If both are given, the

 * lookup is by the former, but the latter must also match.

 Construct an identifier "id:<keyid>". */

 Hide some search errors */

/**

 * asymmetric_key_generate_id: Construct an asymmetric key ID

 * @val_1: First binary blob

 * @len_1: Length of first binary blob

 * @val_2: Second binary blob

 * @len_2: Length of second binary blob

 *

 * Construct an asymmetric key ID from a pair of binary blobs.

/**

 * asymmetric_key_id_same - Return true if two asymmetric keys IDs are the same.

 * @kid1: The key ID to compare

 * @kid2: The key ID to compare

/**

 * asymmetric_key_id_partial - Return true if two asymmetric keys IDs

 * partially match

 * @kid1: The key ID to compare

 * @kid2: The key ID to compare

/**

 * asymmetric_match_key_ids - Search asymmetric key IDs

 * @kids: The list of key IDs to check

 * @match_id: The key ID we're looking for

 * @match: The match function to use

 helper function can be called directly with pre-allocated memory */

/**

 * asymmetric_key_hex_to_key_id - Convert a hex string into a key ID.

 * @id: The ID as a hex string.

/*

 * Match asymmetric keys by an exact match on an ID.

/*

 * Match asymmetric keys by a partial match on an IDs.

/*

 * Preparse the match criterion.  If we don't set lookup_type and cmp,

 * the default will be an exact match on the key description.

 *

 * There are some specifiers for matching key IDs rather than by the key

 * description:

 *

 *	"id:<id>" - find a key by partial match on any available ID

 *	"ex:<id>" - find a key by exact match on any available ID

 *

 * These have to be searched by iteration rather than by direct lookup because

 * the key is hashed according to its description.

/*

 * Free the preparsed the match criterion.

/*

 * Describe the asymmetric key

 put something here to indicate the key's capabilities */

/*

 * Preparse a asymmetric payload to get format the contents appropriately for the

 * internal payload to cut down on the number of scans of the data performed.

 *

 * We also generate a proposed description from the contents of the key that

 * can be used to name the key if the user doesn't want to provide one.

/*

 * Clean up the key ID list

/*

 * Clean up the preparse data

/*

 * dispose of the data dangling from the corpse of a asymmetric key

/*

 * look up keyring restrict functions for asymmetric keys

/**

 * register_asymmetric_key_parser - Register a asymmetric key blob parser

 * @parser: The parser to register

/**

 * unregister_asymmetric_key_parser - Unregister a asymmetric key blob parser

 * @parser: The parser to unregister

/*

 * Module stuff

 SPDX-License-Identifier: GPL-2.0-or-later

/* Parse a signed PE binary

 *

 * Copyright (C) 2014 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Parse a PE binary.

/*

 * Check and strip the PE wrapper from around the signature and check that the

 * remnant looks something like PKCS#7.

	/* Both pesign and sbsign round up the length of certificate table

	 * (in optional header data directories) to 8 byte alignment.

	/* It looks like the pkcs signature length in wrapper->length and the

	 * size obtained from the data dir entries, which lists the total size

	 * of certificate table, are both aligned to an octaword boundary, so

	 * we may have to deal with some padding.

 What's left should be a PKCS#7 cert */

 There may be padding */

/*

 * Compare two sections for canonicalisation.

/*

 * Load the contents of the PE binary into the digest, leaving out the image

 * checksum and the certificate data block.

	/* Digest the header and data directory, but leave out the image

	 * checksum and the data dirent for the signature.

	/* We have to canonicalise the section table, so we perform an

	 * insertion sort.

/*

 * Digest the contents of the PE binary, leaving out the image checksum and the

 * certificate data block.

	/* Allocate the hashing algorithm we're going to need and find out how

	 * big the hash operational data will be.

	/* Check that the PE file digest matches that in the MSCODE part of the

	 * PKCS#7 certificate.

/**

 * verify_pefile_signature - Verify the signature on a PE binary image

 * @pebuf: Buffer containing the PE binary image

 * @pelen: Length of the binary image

 * @trust_keys: Signing certificate(s) to use as starting points

 * @usage: The use to which the key is being put.

 *

 * Validate that the certificate chain inside the PKCS#7 message inside the PE

 * binary image intersects keys we already know and trust.

 *

 * Returns, in order of descending priority:

 *

 *  (*) -ELIBBAD if the image cannot be parsed, or:

 *

 *  (*) -EKEYREJECTED if a signature failed to match for which we have a valid

 *	key, or:

 *

 *  (*) 0 if at least one signature chain intersects with the keys in the trust

 *	keyring, or:

 *

 *  (*) -ENODATA if there is no signature present.

 *

 *  (*) -ENOPKG if a suitable crypto module couldn't be found for a check on a

 *	chain.

 *

 *  (*) -ENOKEY if we couldn't find a match for any of the signature chains in

 *	the message.

 *

 * May also return -ENOMEM.

	/* Generate the digest and check against the PKCS7 certificate

	 * contents.

 SPDX-License-Identifier: GPL-2.0-or-later

/* Parse a Microsoft Individual Code Signing blob

 *

 * Copyright (C) 2014 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Parse a Microsoft Individual Code Signing blob

/*

 * Check the content type OID

	/*

	 * pesign utility had a bug where it was putting

	 * OID_msIndividualSPKeyPurpose instead of OID_msPeImageDataObjId

	 * So allow both OIDs.

/*

 * Note the digest algorithm OID

/*

 * Note the digest we're guaranteeing with this certificate

 SPDX-License-Identifier: GPL-2.0-or-later

/* Instantiate a public key crypto key from an X.509 Certificate

 *

 * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Set up the signature parameters in an X.509 certificate.  This involves

 * digesting the signed data and extracting the signature.

 We check the hash if we can - even if we can't then verify it */

	/* Allocate the hashing algorithm we're going to need and find out how

	 * big the hash operational data will be.

/*

 * Check for self-signedness in an X.509 cert and if found, check the signature

 * immediately if we can.

		/* If the AKID is present it may have one or two parts.  If

		 * both are supplied, both must match.

/*

 * Attempt to parse a data blob for a key as an X509 certificate.

 Don't permit addition of blacklisted keys */

 Propose a description */

 We're pinning the module by being linked against it */

 We've finished with the certificate */

/*

 * Module stuff

 SPDX-License-Identifier: GPL-2.0-or-later

/* Verify the signature on a PKCS#7 message.

 *

 * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Digest the relevant parts of the PKCS#7 data

 The digest was calculated already. */

	/* Allocate the hashing algorithm we're going to need and find out how

	 * big the hash operational data will be.

 Digest the message [RFC2315 9.3] */

	/* However, if there are authenticated attributes, there must be a

	 * message digest attribute amongst them which corresponds to the

	 * digest we just calculated.

		/* We then calculate anew, using the authenticated attributes

		 * as the contents of the digest instead.  Note that we need to

		 * convert the attributes from a CONT.0 into a SET before we

		 * hash it.

	/*

	 * This function doesn't support messages with more than one signature.

/*

 * Find the key (X.509 certificate) to use to verify a PKCS#7 message.  PKCS#7

 * uses the issuer's name and the issuing certificate serial number for

 * matching purposes.  These must match the certificate issuer's name (not

 * subject's name) and the certificate serial number [RFC 2315 6.7].

		/* I'm _assuming_ that the generator of the PKCS#7 message will

		 * encode the fields from the X.509 cert in the same way in the

		 * PKCS#7 message - but I can't be 100% sure of that.  It's

		 * possible this will need element-by-element comparison.

	/* The relevant X.509 cert isn't found here, but it might be found in

	 * the trust keyring.

/*

 * Verify the internal certificate chain as best we can.

			/* If this cert is blacklisted, then mark everything

			 * that depends on this as blacklisted too.

			/* If there's no authority certificate specified, then

			 * the certificate must be self-signed and is the root

			 * of the chain.  Likewise if the cert is its own

			 * authority.

		/* Look through the X.509 certificates in the PKCS#7 message's

		 * list to see if the next one is there.

 We didn't find the root of this chain */

		/* We matched issuer + serialNumber, but if there's an

		 * authKeyId.keyId, that must match the CA subjKeyId also.

	/* Just prune the certificate chain at this point if we lack some

	 * crypto module to go further.  Note, however, we don't want to set

	 * sinfo->unsupported_crypto as the signed info block may still be

	 * validatable against an X.509 cert lower in the chain that we have a

	 * trusted copy of.

/*

 * Verify one signed information block from a PKCS#7 message.

	/* First of all, digest the data in the PKCS#7 message and the

	 * signed information block

 Find the key for the signature if there is one */

	/* Check that the PKCS#7 signing time is valid according to the X.509

	 * certificate.  We can't, however, check against the system clock

	 * since that may not have been set yet and may be wrong.

 Verify the PKCS#7 binary against the key */

 Verify the internal certificate chain */

/**

 * pkcs7_verify - Verify a PKCS#7 message

 * @pkcs7: The PKCS#7 message to be verified

 * @usage: The use to which the key is being put

 *

 * Verify a PKCS#7 message is internally consistent - that is, the data digest

 * matches the digest in the AuthAttrs and any signature in the message or one

 * of the X.509 certificates it carries that matches another X.509 cert in the

 * message can be verified.

 *

 * This does not look to match the contents of the PKCS#7 message against any

 * external public keys.

 *

 * Returns, in order of descending priority:

 *

 *  (*) -EKEYREJECTED if a key was selected that had a usage restriction at

 *      odds with the specified usage, or:

 *

 *  (*) -EKEYREJECTED if a signature failed to match for which we found an

 *	appropriate X.509 certificate, or:

 *

 *  (*) -EBADMSG if some part of the message was invalid, or:

 *

 *  (*) 0 if a signature chain passed verification, or:

 *

 *  (*) -EKEYREJECTED if a blacklisted key was encountered, or:

 *

 *  (*) -ENOPKG if none of the signature chains are verifiable because suitable

 *	crypto modules couldn't be found.

 Authattr presence checked in parser */

/**

 * pkcs7_supply_detached_data - Supply the data needed to verify a PKCS#7 message

 * @pkcs7: The PKCS#7 message

 * @data: The data to be verified

 * @datalen: The amount of data

 *

 * Supply the detached data needed to verify a PKCS#7 message.  Note that no

 * attempt to retain/pin the data is made.  That is left to the caller.  The

 * data will not be modified by pkcs7_verify() and will not be freed when the

 * PKCS#7 message is freed.

 *

 * Returns -EINVAL if data is already supplied in the message, 0 otherwise.

 SPDX-License-Identifier: GPL-2.0-or-later

/* PKCS#7 parser

 *

 * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 Message being constructed */

 SignedInfo being constructed */

 Certificate cache */

 Start of data */

 Last OID encountered */

/*

 * Free a signed information block.

/**

 * pkcs7_free_message - Free a PKCS#7 message

 * @pkcs7: The PKCS#7 message to free

/*

 * Check authenticatedAttributes are provided or not provided consistently.

/**

 * pkcs7_parse_message - Parse a PKCS#7 message

 * @data: The raw binary ASN.1 encoded message to be parsed

 * @datalen: The size of the encoded message

 Attempt to decode the signature */

/**

 * pkcs7_get_content_data - Get access to the PKCS#7 content

 * @pkcs7: The preparsed PKCS#7 message to access

 * @_data: Place to return a pointer to the data

 * @_data_len: Place to return the data length

 * @_headerlen: Size of ASN.1 header not included in _data

 *

 * Get access to the data content of the PKCS#7 message.  The size of the

 * header of the ASN.1 object that contains it is also provided and can be used

 * to adjust *_data and *_data_len to get the entire object.

 *

 * Returns -ENODATA if the data object was missing from the message.

/*

 * Note an OID when we find one for later processing when we know how

 * to interpret it.

/*

 * Note the digest algorithm for the signature.

/*

 * Note the public key algorithm for the signature.

/*

 * We only support signed data [RFC2315 sec 9].

/*

 * Note the SignedData version

		/* PKCS#7 SignedData [RFC2315 sec 9.1]

		 * CMS ver 1 SignedData [RFC5652 sec 5.1]

 CMS ver 3 SignedData [RFC2315 sec 5.1] */

/*

 * Note the SignerInfo version

		/* PKCS#7 SignerInfo [RFC2315 sec 9.2]

		 * CMS ver 1 SignerInfo [RFC5652 sec 5.3]

 CMS ver 3 SignerInfo [RFC2315 sec 5.3] */

/*

 * Extract a certificate and store it in the context.

	/* We have to correct for the header so that the X.509 parser can start

	 * from the beginning.  Note that since X.509 stipulates DER, there

	 * probably shouldn't be an EOC trailer - but it is in PKCS#7 (which

	 * stipulates BER).

 Indefinite length - there should be an EOC */

/*

 * Save the certificate list

/*

 * Note the content type.

/*

 * Extract the data from the message and store that and its content type OID in

 * the context.

/*

 * Parse authenticated attributes.

		/* Should we check that the signing time is consistent

		 * with the signer's X.509 cert?

		/* Microsoft SpOpusInfo seems to be contain cont[0] 16-bit BE

		 * char URLs and cont[1] 8-bit char URLs.

		 *

		 * Microsoft StatementType seems to contain a list of OIDs that

		 * are also used as extendedKeyUsage types in X.509 certs.

 I'm not sure how to validate these */

 We permit max one item per AuthenticatedAttribute and no repeats */

/*

 * Note the set of auth attributes for digestion purposes [RFC2315 sec 9.3]

 We need to switch the 'CONT 0' to a 'SET OF' when we digest */

/*

 * Note the issuing certificate serial number

/*

 * Note the issuer's name

/*

 * Note the issuing cert's subjectKeyIdentifier

/*

 * Note the signature data

/*

 * Note a signature information block

 Generate cert issuer + serial number key ID */

 SPDX-License-Identifier: GPL-2.0-or-later

/* X.509 certificate parser

 *

 * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 Certificate being constructed */

 Start of data */

 Start of cert content */

 Key data */

 Size of key data */

 Key parameters */

 Size of key parameters */

 Public key algorithm */

 Last OID encountered */

 Algorithm OID */

 Number of MPIs stored */

 Size of organizationName (O) */

 Size of commonName (CN) */

 Size of emailAddress */

 Offset of organizationName (O) */

 Offset of commonName (CN) */

 Offset of emailAddress */

 Raw authorityKeyId in ASN.1 */

 Raw directoryName in authorityKeyId */

/*

 * Free an X.509 certificate

/*

 * Parse an X.509 certificate

 Attempt to decode the certificate */

 Decode the AuthorityKeyIdentifier */

 Grab the signature bits */

 Generate cert issuer + serial number key ID */

 Detect self-signed certificates */

/*

 * Note an OID when we find one for later processing when we know how

 * to interpret it.

/*

 * Save the position of the TBS data so that we can check the signature over it

 * later.

/*

 * Record the public key algorithm

 Unsupported combination */

/*

 * Note the whereabouts and type of the signature.

 Discard the BIT STRING metadata */

/*

 * Note the certificate serial number

/*

 * Note some of the name segments from which we'll fabricate a name.

/*

 * Fabricate and save the issuer and subject names

 Empty name string if no material */

		/* Consider combining O and CN, but use only the CN if it is

		 * prefixed by the O, or a significant portion thereof.

/*

 * Extract the parameters for the public key

	/*

	 * AlgorithmIdentifier is used three times in the x509, we should skip

	 * first and ignore third, using second one which is after subject and

	 * before subjectPublicKey.

/*

 * Extract the data for the public key algorithm

 Discard the BIT STRING metadata */

 The keyIdentifier in AuthorityKeyIdentifier SEQUENCE is tag(CONT,PRIM,0) */

/*

 * Process certificate extensions that are used to qualify the certificate.

 Get hold of the key fingerprint */

 Get hold of the CA key fingerprint */

/**

 * x509_decode_time - Decode an X.509 time ASN.1 object

 * @_t: The time to fill in

 * @hdrlen: The length of the object header

 * @tag: The object tag

 * @value: The object value

 * @vlen: The size of the object value

 *

 * Decode an ASN.1 universal time or generalised time field into a struct the

 * kernel can handle and check it for validity.  The time is decoded thus:

 *

 *	[RFC5280 4.1.2.5]

 *	CAs conforming to this profile MUST always encode certificate validity

 *	dates through the year 2049 as UTCTime; certificate validity dates in

 *	2050 or later MUST be encoded as GeneralizedTime.  Conforming

 *	applications MUST be able to process validity dates that are encoded in

 *	either UTCTime or GeneralizedTime.

 UTCTime: YYMMDDHHMMSSZ */

 GenTime: YYYYMMDDHHMMSSZ */

 ISO 8601 permits 24:00:00 as midnight tomorrow */

 ISO 8601 permits leap seconds [X.680 46.3] */

/*

 * Note a key identifier-based AuthorityKeyIdentifier

/*

 * Note a directoryName in an AuthorityKeyIdentifier

/*

 * Note a serial number in an AuthorityKeyIdentifier

 SPDX-License-Identifier: GPL-2.0-or-later

/* Instantiate a public key crypto key from an X.509 Certificate

 *

 * Copyright (C) 2012, 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 default system keyring */

 owner key 'id:xxxxxx' */

/**

 * restrict_link_by_signature - Restrict additions to a ring of public keys

 * @dest_keyring: Keyring being linked to.

 * @type: The type of key being added.

 * @payload: The payload of the new key.

 * @trust_keyring: A ring of keys that can be used to vouch for the new cert.

 *

 * Check the new certificate against the ones in the trust keyring.  If one of

 * those is the signing key and validates the new certificate, then mark the

 * new certificate as being trusted.

 *

 * Returns 0 if the new certificate was accepted, -ENOKEY if we couldn't find a

 * matching parent certificate in the trusted list, -EKEYREJECTED if the

 * signature check fails or the key is blacklisted, -ENOPKG if the signature

 * uses unsupported crypto, or some other error if there is a matching

 * certificate but the signature check cannot be performed.

 See if we have a key that signed this one. */

 See if we have a key that signed this one. */

			/*

			 * The auth_ids come from the candidate key (the

			 * one that is being considered for addition to

			 * dest_keyring) and identify the key that was

			 * used to sign.

			 *

			 * The signer_ids are identifiers for the

			 * signing key specified for dest_keyring.

			 *

			 * The first auth_id is the preferred id, and

			 * the second is the fallback. If only one

			 * auth_id is present, it may match against

			 * either signer_id. If two auth_ids are

			 * present, the first auth_id must match one

			 * signer_id and the second auth_id must match

			 * the second signer_id.

 See if the destination has a key that signed this one. */

/**

 * restrict_link_by_key_or_keyring - Restrict additions to a ring of public

 * keys using the restrict_key information stored in the ring.

 * @dest_keyring: Keyring being linked to.

 * @type: The type of key being added.

 * @payload: The payload of the new key.

 * @trusted: A key or ring of keys that can be used to vouch for the new cert.

 *

 * Check the new certificate only against the key or keys passed in the data

 * parameter. If one of those is the signing key and validates the new

 * certificate, then mark the new certificate as being ok to link.

 *

 * Returns 0 if the new certificate was accepted, -ENOKEY if we

 * couldn't find a matching parent certificate in the trusted list,

 * -EKEYREJECTED if the signature check fails, -ENOPKG if the signature uses

 * unsupported crypto, or some other error if there is a matching certificate

 * but the signature check cannot be performed.

/**

 * restrict_link_by_key_or_keyring_chain - Restrict additions to a ring of

 * public keys using the restrict_key information stored in the ring.

 * @dest_keyring: Keyring being linked to.

 * @type: The type of key being added.

 * @payload: The payload of the new key.

 * @trusted: A key or ring of keys that can be used to vouch for the new cert.

 *

 * Check the new certificate against the key or keys passed in the data

 * parameter and against the keys already linked to the destination keyring. If

 * one of those is the signing key and validates the new certificate, then mark

 * the new certificate as being ok to link.

 *

 * Returns 0 if the new certificate was accepted, -ENOKEY if we

 * couldn't find a matching parent certificate in the trusted list,

 * -EKEYREJECTED if the signature check fails, -ENOPKG if the signature uses

 * unsupported crypto, or some other error if there is a matching certificate

 * but the signature check cannot be performed.

 SPDX-License-Identifier: GPL-2.0

/*

 * Note the key data of the ASN.1 blob.

/*

 * Parse a TPM-encrypted private key blob.

 Attempt to decode the private key */

/*

 * Attempt to parse a data blob for a key as a TPM private key blob.

	/*

	 * TPM 1.2 keys are max 2048 bits long, so assume the blob is no

	 * more than 4x that

 We're pinning the module by being linked against it */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Testing module to load key from trusted PKCS#7 message

 *

 * Copyright (C) 2014 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Retrieve the PKCS#7 message content.

/*

 * Preparse a PKCS#7 wrapped and validated data blob.

/*

 * user defined keys take an arbitrary string as the description and an

 * arbitrary blob of data as the payload

/*

 * Module stuff

 SPDX-License-Identifier: GPL-2.0-or-later

/* In-software asymmetric public-key crypto subtype

 *

 * See Documentation/crypto/asymmetric-keys.rst

 *

 * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Provide a part of a description of the key for /proc/keys.

/*

 * Destroy a public key algorithm key.

/*

 * Destroy a public key algorithm key.

/*

 * Determine the crypto algorithm name.

		/* The data wangled by the RSA algorithm is typically padded

		 * and encoded in some manner, such as EMSA-PKCS1-1_5 [RFC3447

		 * sec 8.2].

/*

 * Query information about a key.

/*

 * Do encryption, decryption and signing ops.

 Perform the encryption calculation. */

 ! IS_REACHABLE(CONFIG_CRYPTO_SM2) */

/*

 * Verify a signature using a public key.

/*

 * Public key algorithm asymmetric key subtype

 SPDX-License-Identifier: GPL-2.0-or-later

/* Validate the trust chain of a PKCS#7 message.

 *

 * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Check the trust on one PKCS#7 SignedInfo block.

		/* Look to see if this certificate is present in the trusted

		 * keys.

			/* One of the X.509 certificates in the PKCS#7 message

			 * is apparently the same as one we already trust.

			 * Verify that the trusted variant can also validate

			 * the signature on the descendant.

		 /* Self-signed certificates form roots of their own, and if we

		  * don't know them, then we can't accept them.

	/* No match - see if the root certificate has a signer amongst the

	 * trusted keys.

	/* As a last resort, see if we have a trusted public key that matches

	 * the signed info directly.

/**

 * pkcs7_validate_trust - Validate PKCS#7 trust chain

 * @pkcs7: The PKCS#7 certificate to validate

 * @trust_keyring: Signing certificates to use as starting points

 *

 * Validate that the certificate chain inside the PKCS#7 message intersects

 * keys we already know and trust.

 *

 * Returns, in order of descending priority:

 *

 *  (*) -EKEYREJECTED if a signature failed to match for which we have a valid

 *	key, or:

 *

 *  (*) 0 if at least one signature chain intersects with the keys in the trust

 *	keyring, or:

 *

 *  (*) -ENOPKG if a suitable crypto module couldn't be found for a check on a

 *	chain.

 *

 *  (*) -ENOKEY if we couldn't find a match for any of the signature chains in

 *	the message.

 *

 * May also return -ENOMEM.

 SPDX-License-Identifier: GPL-2.0-or-later

/* PKCS#8 Private Key parser [RFC 5208].

 *

 * Copyright (C) 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 Start of data */

 Last OID encountered */

 Algorithm OID */

/*

 * Note an OID when we find one for later processing when we know how to

 * interpret it.

/*

 * Note the version number of the ASN.1 blob.

/*

 * Note the public algorithm.

/*

 * Note the key data of the ASN.1 blob.

/*

 * Parse a PKCS#8 private key blob.

 Attempt to decode the private key */

/*

 * Attempt to parse a data blob for a key as a PKCS#8 private key.

 We're pinning the module by being linked against it */

/*

 * Module stuff

 SPDX-License-Identifier: GPL-2.0-or-later

/* Signature verification with an asymmetric key

 *

 * See Documentation/crypto/asymmetric-keys.rst

 *

 * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Destroy a public key signature.

/**

 * query_asymmetric_key - Get information about an aymmetric key.

 * @params: Various parameters.

 * @info: Where to put the information.

/**

 * encrypt_blob - Encrypt data using an asymmetric key

 * @params: Various parameters

 * @data: Data blob to be encrypted, length params->data_len

 * @enc: Encrypted data buffer, length params->enc_len

 *

 * Encrypt the specified data blob using the private key specified by

 * params->key.  The encrypted data is wrapped in an encoding if

 * params->encoding is specified (eg. "pkcs1").

 *

 * Returns the length of the data placed in the encrypted data buffer or an

 * error.

/**

 * decrypt_blob - Decrypt data using an asymmetric key

 * @params: Various parameters

 * @enc: Encrypted data to be decrypted, length params->enc_len

 * @data: Decrypted data buffer, length params->data_len

 *

 * Decrypt the specified data blob using the private key specified by

 * params->key.  The decrypted data is wrapped in an encoding if

 * params->encoding is specified (eg. "pkcs1").

 *

 * Returns the length of the data placed in the decrypted data buffer or an

 * error.

/**

 * create_signature - Sign some data using an asymmetric key

 * @params: Various parameters

 * @data: Data blob to be signed, length params->data_len

 * @enc: Signature buffer, length params->enc_len

 *

 * Sign the specified data blob using the private key specified by params->key.

 * The signature is wrapped in an encoding if params->encoding is specified

 * (eg. "pkcs1").  If the encoding needs to know the digest type, this can be

 * passed through params->hash_algo (eg. "sha1").

 *

 * Returns the length of the data placed in the signature buffer or an error.

/**

 * verify_signature - Initiate the use of an asymmetric key to verify a signature

 * @key: The asymmetric key to verify against

 * @sig: The signature to check

 *

 * Returns 0 if successful or else an error.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * xor offload engine api

 *

 * Copyright  2006, Intel Corporation.

 *

 *      Dan Williams <dan.j.williams@intel.com>

 *

 *      with architecture considerations by:

 *      Neil Brown <neilb@suse.de>

 *      Jeff Garzik <jeff@garzik.org>

 do_async_xor - dma map the pages and perform the xor with an engine */

		/* if we are submitting additional xors, leave the chain open

		 * and clear the callback parameters

		/* Drivers force forward progress in case they can not provide a

		 * descriptor

 spin wait for the preceding transactions to complete */

 drop completed sources */

 use the intermediate result a source */

 convert to buffer pointers */

 set destination address */

 process up to 'MAX_XOR_BLOCKS' sources */

 drop completed sources */

/**

 * async_xor_offs - attempt to xor a set of blocks with a dma engine.

 * @dest: destination page

 * @offset: dst offset to start transaction

 * @src_list: array of source pages

 * @src_offs: array of source pages offset, NULL means common src/dst offset

 * @src_cnt: number of source pages

 * @len: length in bytes

 * @submit: submission / completion modifiers

 *

 * honored flags: ASYNC_TX_ACK, ASYNC_TX_XOR_ZERO_DST, ASYNC_TX_XOR_DROP_DST

 *

 * xor_blocks always uses the dest as a source so the

 * ASYNC_TX_XOR_ZERO_DST flag must be set to not include dest data in

 * the calculation.  The assumption with dma eninges is that they only

 * use the destination buffer as a source when it is explicity specified

 * in the source list.

 *

 * src_list note: if the dest is also a source it must be at index zero.

 * The contents of this array will be overwritten if a scribble region

 * is not specified.

 run the xor asynchronously */

 map it bidirectional as it may be re-used as a source */

 run the xor synchronously */

		/* in the sync case the dest is an implied source

		 * (assumes the dest is the first source)

 wait for any prerequisite operations */

/**

 * async_xor - attempt to xor a set of blocks with a dma engine.

 * @dest: destination page

 * @src_list: array of source pages

 * @offset: common src/dst offset to start transaction

 * @src_cnt: number of source pages

 * @len: length in bytes

 * @submit: submission / completion modifiers

 *

 * honored flags: ASYNC_TX_ACK, ASYNC_TX_XOR_ZERO_DST, ASYNC_TX_XOR_DROP_DST

 *

 * xor_blocks always uses the dest as a source so the

 * ASYNC_TX_XOR_ZERO_DST flag must be set to not include dest data in

 * the calculation.  The assumption with dma eninges is that they only

 * use the destination buffer as a source when it is explicity specified

 * in the source list.

 *

 * src_list note: if the dest is also a source it must be at index zero.

 * The contents of this array will be overwritten if a scribble region

 * is not specified.

/**

 * async_xor_val_offs - attempt a xor parity check with a dma engine.

 * @dest: destination page used if the xor is performed synchronously

 * @offset: des offset in pages to start transaction

 * @src_list: array of source pages

 * @src_offs: array of source pages offset, NULL means common src/det offset

 * @src_cnt: number of source pages

 * @len: length in bytes

 * @result: 0 if sum == 0 else non-zero

 * @submit: submission / completion modifiers

 *

 * honored flags: ASYNC_TX_ACK

 *

 * src_list note: if the dest is also a source it must be at index zero.

 * The contents of this array will be overwritten if a scribble region

 * is not specified.

/**

 * async_xor_val - attempt a xor parity check with a dma engine.

 * @dest: destination page used if the xor is performed synchronously

 * @src_list: array of source pages

 * @offset: offset in pages to start transaction

 * @src_cnt: number of source pages

 * @len: length in bytes

 * @result: 0 if sum == 0 else non-zero

 * @submit: submission / completion modifiers

 *

 * honored flags: ASYNC_TX_ACK

 *

 * src_list note: if the dest is also a source it must be at index zero.

 * The contents of this array will be overwritten if a scribble region

 * is not specified.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * core routines for the asynchronous memory transfer/transform api

 *

 * Copyright  2006, Intel Corporation.

 *

 *	Dan Williams <dan.j.williams@intel.com>

 *

 *	with architecture considerations by:

 *	Neil Brown <neilb@suse.de>

 *	Jeff Garzik <jeff@garzik.org>

/**

 * __async_tx_find_channel - find a channel to carry out the operation or let

 *	the transaction execute synchronously

 * @submit: transaction dependency and submission modifiers

 * @tx_type: transaction type

 see if we can keep the chain on one channel */

/**

 * async_tx_channel_switch - queue an interrupt descriptor with a dependency

 * 	pre-attached.

 * @depend_tx: the operation that must finish before the new operation runs

 * @tx: the new operation

 first check to see if we can still append to depend_tx */

 attached dependency, flush the parent channel */

	/* see if we can schedule an interrupt

	 * otherwise poll for completion

		/* safe to chain outside the lock since we know we are

		 * not submitted yet

 check if we need to append */

/**

 * submit_disposition - flags for routing an incoming operation

 * @ASYNC_TX_SUBMITTED: we were able to append the new operation under the lock

 * @ASYNC_TX_CHANNEL_SWITCH: when the lock is dropped schedule a channel switch

 * @ASYNC_TX_DIRECT_SUBMIT: when the lock is dropped submit directly

 *

 * while holding depend_tx->lock we must avoid submitting new operations

 * to prevent a circular locking dependency with drivers that already

 * hold a channel lock when calling async_tx_run_dependencies.

		/* sanity check the dependency chain:

		 * 1/ if ack is already set then we cannot be sure

		 * we are referring to the correct operation

		 * 2/ dependencies are 1:1 i.e. two transactions can

		 * not depend on the same parent

		/* the lock prevents async_tx_run_dependencies from missing

		 * the setting of ->next when ->parent != NULL

			/* we have a parent so we can not submit directly

			 * if we are staying on the same channel: append

			 * else: channel switch

			/* we do not have a parent so we may be able to submit

			 * directly if we are staying on the same channel

/**

 * async_trigger_callback - schedules the callback function to be run

 * @submit: submission and completion parameters

 *

 * honored flags: ASYNC_TX_ACK

 *

 * The callback is run after any dependent operations have completed.

		/* see if we can schedule an interrupt

		 * otherwise poll for completion

 wait for any prerequisite operations */

/**

 * async_tx_quiesce - ensure tx is complete and freeable upon return

 * @tx - transaction to quiesce

		/* if ack is already set then we cannot be sure

		 * we are referring to the correct operation

 SPDX-License-Identifier: GPL-2.0-only

/*

 * copy offload engine support

 *

 * Copyright  2006, Intel Corporation.

 *

 *      Dan Williams <dan.j.williams@intel.com>

 *

 *      with architecture considerations by:

 *      Neil Brown <neilb@suse.de>

 *      Jeff Garzik <jeff@garzik.org>

/**

 * async_memcpy - attempt to copy memory with a dma engine.

 * @dest: destination page

 * @src: src page

 * @dest_offset: offset into 'dest' to start transaction

 * @src_offset: offset into 'src' to start transaction

 * @len: length in bytes

 * @submit: submission / completion modifiers

 *

 * honored flags: ASYNC_TX_ACK

 wait for any prerequisite operations */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright(c) 2007 Yuri Tikhonov <yur@emcraft.com>

 * Copyright(c) 2009 Intel Corporation

/**

 * pq_scribble_page - space to hold throwaway P or Q buffer for

 * synchronous gen_syndrome

/* the struct page *blocks[] parameter passed to async_gen_syndrome()

 * and async_syndrome_val() contains the 'P' destination address at

 * blocks[disks-2] and the 'Q' destination address at blocks[disks-1]

 *

 * note: these are macros as they are used as lvalues

/**

 * do_async_gen_syndrome - asynchronously calculate P and/or Q

		/* if we are submitting additional pqs, leave the chain open,

		 * clear the callback parameters, and leave the destination

		 * buffers mapped

		/* Drivers force forward progress in case they can not provide

		 * a descriptor

 drop completed sources */

/**

 * do_sync_gen_syndrome - synchronously calculate a raid6 syndrome

 P or Q can't be zero */

/**

 * async_gen_syndrome - asynchronously calculate a raid6 syndrome

 * @blocks: source blocks from idx 0..disks-3, P @ disks-2 and Q @ disks-1

 * @offsets: offset array into each block (src and dest) to start transaction

 * @disks: number of blocks (including missing P or Q, see below)

 * @len: length of operation in bytes

 * @submit: submission/completion modifiers

 *

 * General note: This routine assumes a field of GF(2^8) with a

 * primitive polynomial of 0x11d and a generator of {02}.

 *

 * 'disks' note: callers can optionally omit either P or Q (but not

 * both) from the calculation by setting blocks[disks-2] or

 * blocks[disks-1] to NULL.  When P or Q is omitted 'len' must be <=

 * PAGE_SIZE as a temporary buffer of this size is used in the

 * synchronous path.  'disks' always accounts for both destination

 * buffers.  If any source buffers (blocks[i] where i < disks - 2) are

 * set to NULL those buffers will be replaced with the raid6_zero_page

 * in the synchronous path and omitted in the hardware-asynchronous

 * path.

 XORing P/Q is only implemented in software */

 run the p+q asynchronously */

		/* convert source addresses being careful to collapse 'empty'

		 * sources and update the coefficients accordingly

		/*

		 * DMAs use destinations as sources,

		 * so use BIDIRECTIONAL mapping

 run the pq synchronously */

 wait for any prerequisite operations */

/**

 * async_syndrome_val - asynchronously validate a raid6 syndrome

 * @blocks: source blocks from idx 0..disks-3, P @ disks-2 and Q @ disks-1

 * @offset: common offset into each block (src and dest) to start transaction

 * @disks: number of blocks (including missing P or Q, see below)

 * @len: length of operation in bytes

 * @pqres: on val failure SUM_CHECK_P_RESULT and/or SUM_CHECK_Q_RESULT are set

 * @spare: temporary result buffer for the synchronous case

 * @s_off: spare buffer page offset

 * @submit: submission / completion modifiers

 *

 * The same notes from async_gen_syndrome apply to the 'blocks',

 * and 'disks' parameters of this routine.  The synchronous path

 * requires a temporary result buffer and submit->scribble to be

 * specified.

		/* caller must provide a temporary result buffer and

		 * allow the input parameters to be preserved

 wait for any prerequisite operations */

		/* recompute p and/or q into the temporary buffer and then

		 * check to see the result matches the current value

 restore P, Q and submit */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Asynchronous RAID-6 recovery calculations ASYNC_TX API.

 * Copyright(c) 2009 Intel Corporation

 *

 * based on raid6recov.c:

 *   Copyright 2002 H. Peter Anvin

 engine only looks at Q, but expects it to follow P */

		/* could not get a descriptor, unmap and fall through to

		 * the synchronous path

 run the operation synchronously */

 Q multiplier table */

		/* this looks funny, but the engine looks for Q at

		 * dma_dest[1] and ignores dma_dest[0] as a dest

		 * due to DMA_PREP_PQ_DISABLE_P

		/* could not get a descriptor, unmap and fall through to

		 * the synchronous path

	/* no channel available, or failed to allocate a descriptor, so

	 * perform the operation synchronously

 in the 4 disk case P + Pxy == P and Q + Qxy == Q */

 Dx = A*(P+Pxy) + B*(Q+Qxy) */

 Dy = P+Pxy+Dx */

	/* Compute syndrome with zero for the missing data pages

	 * Use the dead data pages as temporary storage for delta p and

	 * delta q

 compute P + Pxy */

 compute Q + Qxy */

 Dx = A*(P+Pxy) + B*(Q+Qxy) */

 Dy = P+Pxy+Dx */

	/* Compute syndrome with zero for the missing data pages

	 * Use the dead data pages as temporary storage for

	 * delta p and delta q

 Restore pointer table */

 compute P + Pxy */

 compute Q + Qxy */

 Dx = A*(P+Pxy) + B*(Q+Qxy) */

 Dy = P+Pxy+Dx */

/**

 * async_raid6_2data_recov - asynchronously calculate two missing data blocks

 * @disks: number of disks in the RAID-6 array

 * @bytes: block size

 * @faila: first failed drive index

 * @failb: second failed drive index

 * @blocks: array of source pointers where the last two entries are p and q

 * @offs: array of offset for pages in blocks

 * @submit: submission/completion modifiers

	/* if a dma resource is not available or a scribble buffer is not

	 * available punt to the synchronous path.  In the 'dma not

	 * available' case be sure to use the scribble buffer to

	 * preserve the content of 'blocks' as the caller intended.

 There must be at least 2 sources - the failed devices. */

		/* dma devices do not uniformly understand a zero source pq

		 * operation (in contrast to the synchronous case), so

		 * explicitly handle the special case of a 4 disk array with

		 * both data disks missing.

		/* dma devices do not uniformly understand a single

		 * source pq operation (in contrast to the synchronous

		 * case), so explicitly handle the special case of a 5 disk

		 * array with 2 of 3 data disks missing.

/**

 * async_raid6_datap_recov - asynchronously calculate a data and the 'p' block

 * @disks: number of disks in the RAID-6 array

 * @bytes: block size

 * @faila: failed drive index

 * @blocks: array of source pointers where the last two entries are p and q

 * @offs: array of offset for pages in blocks

 * @submit: submission/completion modifiers

	/* if a dma resource is not available or a scribble buffer is not

	 * available punt to the synchronous path.  In the 'dma not

	 * available' case be sure to use the scribble buffer to

	 * preserve the content of 'blocks' as the caller intended.

	/* Compute syndrome with zero for the missing data page

	 * Use the dead data page as temporary storage for delta q

	/* in the 4-disk case we only need to perform a single source

	 * multiplication with the one good data block.

 Restore pointer table */

 calculate g^{-faila} */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * asynchronous raid6 recovery self test

 * Copyright (c) 2009, Intel Corporation.

 *

 * based on drivers/md/raid6test/test.c:

 * 	Copyright 2002-2007 H. Peter Anvin

 Including P and Q */

 Recover two failed blocks. */

 P+Q failure.  Just rebuild the syndrome. */

			/* data+Q failure.  Reconstruct data from P,

			 * then rebuild syndrome

 data+P failure. */

 data+data failure. */

 Nuke syndromes */

 Generate assumed good syndrome */

 the 4-disk and 5-disk cases are special for the recovery code */

	/* the 11 and 12 disk cases are special for ioatdma (p-disabled

	 * q-continuation without extended descriptor)

	/* the 24 disk case is special for ioatdma as it is the boudary point

	 * at which it needs to switch from 8-source ops to 16-source

	 * ops for continuation (assumes DMA_HAS_PQ_CONTINUE is not set)

/* when compiled-in wait for drivers to load first (assumes dma drivers

 * are also compliled-in)

